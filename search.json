[
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "utils",
    "section": "",
    "text": "source\n\ntest_grad_off\n\n test_grad_off (model)\n\nTest that all non-batch norm grads are off, but batch norm grads are on.\n\nsource\n\n\ntest_grad_on\n\n test_grad_on (model)\n\nTest that all grads are on for modules with parameters.\n\nsource\n\n\nseed_everything\n\n seed_everything (seed=42)\n\n” Seed everything.\n\nsource\n\n\nload_config\n\n load_config (file_path)\n\n\nsource\n\n\nadjust_config_with_derived_values\n\n adjust_config_with_derived_values (config)\n\n\nsource\n\n\npretty_print_ns\n\n pretty_print_ns (ns)\n\nPretty print a SimpleNamespace object\nBasic network mostly used for testing.\n\nsource\n\n\nresnet_arch_to_encoder\n\n resnet_arch_to_encoder (arch:Literal['smallres','resnet18','resnet34','re\n                         snet50','cifar_resnet18'], weight_type:Literal['r\n                         andom','imgnet_bt_pretrained','imgnet_sup_pretrai\n                         ned','dermnet_bt_pretrained','imgnet_bt_dermnet_b\n                         t_pretrained','cifar10_pretrained,']='random',\n                         remove_pool=False, flatten=True, n_in=3)\n\n*Given a ResNet architecture, return the encoder configured for 3 input channels. The ‘weight_type’ argument specifies the weight initialization strategy.\nArgs: arch: The architecture of the ResNet. weight_type: Specifies the weight initialization strategy. Defaults to ‘random’.\nReturns: Encoder: An encoder configured for 3 input channels and specified architecture.*\n\nsource\n\n\nget_cifar_resnet18\n\n get_cifar_resnet18 (model, n_in=3)\n\nModifies a ResNet18 model for CIFAR-10.\n\nsource\n\n\nget_resnet_encoder\n\n get_resnet_encoder (model, n_in=3, flatten=True, remove_pool=False)\n\nAdd a\n\nsource\n\n\nBinocularEncoder\n\n BinocularEncoder (res)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\nsource\n\n\nSimpleCNN\n\n SimpleCNN (in_channels=3, out_channels=3)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\nNote: this arch seems to be worse for vicreg:\n\nsource\n\n\ntest_resnet_parameter_sharing_with_training\n\n test_resnet_parameter_sharing_with_training (encoder_left, encoder_right)\n\n\nsource\n\n\nshare_resnet_parameters\n\n share_resnet_parameters (encoder_left, encoder_right)\n\nJust tested for resnet18 or cifar_resnet18. Share params up to and inc stage 1.\n\nsource\n\n\ngenerate_config_hash\n\n generate_config_hash (config)\n\n*Generates a unique hash for a given experiment configuration.\nArgs: config (dict or Namespace): Experiment configuration. Can be a dictionary or a namespace object.\nReturns: str: A unique hash representing the experiment configuration.*\nTest generate_config_hash\n\nconfig1 = SimpleNamespace(arch='resnet18', dataset='cifar10', n_in=3, encoder_dimension=512)\nconfig2 = SimpleNamespace(arch='resnet34', dataset='cifar10', n_in=3, encoder_dimension=512)\nconfig3 = SimpleNamespace(arch='resnet50', dataset='cifar10', n_in=3, encoder_dimension=2048)\n\ntest_eq(generate_config_hash(config1), generate_config_hash(config1))\ntest_ne(generate_config_hash(config1), generate_config_hash(config2))\ntest_ne(generate_config_hash(config1), generate_config_hash(config3))\ntest_ne(generate_config_hash(config2), generate_config_hash(config3))\n\nconfig4 = SimpleNamespace(dataset='cifar10', arch='resnet18', n_in=3, encoder_dimension=512)  # Different order\ntest_eq(generate_config_hash(config1), generate_config_hash(config4))\n\n\nsource\n\n\nsetup_experiment\n\n setup_experiment (config, base_dir)\n\n\nsource\n\n\nget_latest_commit_hash\n\n get_latest_commit_hash (repo_path)\n\n\nsource\n\n\nupdate_experiment_index\n\n update_experiment_index (project_root, details)\n\n\nsource\n\n\nsave_metadata_file\n\n save_metadata_file (experiment_dir, git_commit_hash)\n\nSaves a metadata file with the Git commit hash\n\nsource\n\n\nsave_configuration\n\n save_configuration (config, experiment_dir)\n\n*Saves the experiment configuration as a YAML file in the experiment directory.\nArgs: config (dict, Namespace, or any serializable object): Experiment configuration. experiment_dir (str): Path to the directory where the config file will be saved.*\n\nsource\n\n\ncreate_experiment_directory\n\n create_experiment_directory (base_dir, config)\n\n\nsource\n\n\nSaveLearnerCheckpoint\n\n SaveLearnerCheckpoint (experiment_dir, start_epoch=0, save_interval=250,\n                        with_opt=True)\n\nBasic class handling tweaks of the training loop by changing a Learner in various events\n\nsource\n\n\nInterruptCallback\n\n InterruptCallback (interrupt_epoch)\n\nBasic class handling tweaks of the training loop by changing a Learner in various events\n\nsource\n\n\nget_highest_num_path\n\n get_highest_num_path (base_dir, config)\n\nCheck in the specific experiment directory derived from the config and return the path to the file with the highest number along with its experiment directory.\n\nsource\n\n\nreturn_max_filename\n\n return_max_filename (filename1, filename2)\n\n\nsource\n\n\nfind_largest_file\n\n find_largest_file (directory_path)\n\nFind the file with the largest number (e.g. epoch) in a directory.\n\nsource\n\n\nextract_number\n\n extract_number (filename)\n\nExtract the number from end of filename. e.g. epoch\n\nsource\n\n\nload_dict_from_gdrive\n\n load_dict_from_gdrive (directory, filename)\n\n\nsource\n\n\nsave_dict_to_gdrive\n\n save_dict_to_gdrive (d, directory, filename)\n\n\nsource\n\n\ndownload_weights\n\n download_weights ()\n\n\nimport nbdev; nbdev.nbdev_export()",
    "crumbs": [
      "utils"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "base_rbt",
    "section": "",
    "text": "Package implementing paper\nComparison of supervised and self-supervised (via Barlow Twins) ImageNet pre-training, on the downstream task of fine-tuning a cancer image dataset with limited labelled data.\nImplements further SSL pre-training, where an already pre-trained model is further pre-trained.",
    "crumbs": [
      "base_rbt"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "base_rbt",
    "section": "How to use",
    "text": "How to use\nPlease see Experiments which gives details on running code e.g. in google Colab.",
    "crumbs": [
      "base_rbt"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "base_rbt",
    "section": "References",
    "text": "References\n\npaper\nself-supervised library",
    "crumbs": [
      "base_rbt"
    ]
  },
  {
    "objectID": "isicufes_dataloading.html",
    "href": "isicufes_dataloading.html",
    "title": "isicufes_dataloading",
    "section": "",
    "text": "Example on google colab.\nNeed to unzip isic and ufes.\nufes\nMain dataloader functions:\n\nsource\n\nget_bt_isicufes_train_dls\n\n get_bt_isicufes_train_dls (bs, size, device, pct_dataset=1.0,\n                            num_workers=12)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbs\n\n\n\n\n\nsize\n\n\nnot needed\n\n\ndevice\n\n\n\n\n\npct_dataset\nfloat\n1.0\n\n\n\nnum_workers\nint\n12",
    "crumbs": [
      "isicufes_dataloading"
    ]
  },
  {
    "objectID": "histooralcancer_dataloading.html",
    "href": "histooralcancer_dataloading.html",
    "title": "histooralcancer_dataloading",
    "section": "",
    "text": "Unzip example\nMain dataloader functions:\n\nsource\n\nget_bt_histooralcancer_train_dls\n\n get_bt_histooralcancer_train_dls (bs, size, device, pct_dataset=1.0,\n                                   num_workers=12)\n\n\nsource\n\n\nget_supervised_histooralcancer_test_dls\n\n get_supervised_histooralcancer_test_dls (bs, dataset_dir, size=256,\n                                          device='cpu', pct_dataset=1.0,\n                                          num_workers=12)\n\n\nsource\n\n\nget_supervised_histooralcancer_train_dls\n\n get_supervised_histooralcancer_train_dls (bs, dataset_dir, size=256,\n                                           device='cpu', pct_dataset=1.0,\n                                           num_workers=12)\n\n\nsource\n\n\nlabel_func\n\n label_func (x)",
    "crumbs": [
      "histooralcancer_dataloading"
    ]
  },
  {
    "objectID": "cifar10_dataloading.html",
    "href": "cifar10_dataloading.html",
    "title": "cifar10_dataloading",
    "section": "",
    "text": "CIFAR10\n\nsource\n\nlabel_func\n\n label_func (fname)\n\n\nsource\n\n\nload_cifar10_test_data\n\n load_cifar10_test_data (pct_dataset=1.0)\n\n\nsource\n\n\nload_cifar10_train_data\n\n load_cifar10_train_data (pct_dataset=1.0)\n\n\nsource\n\n\nget_bt_cifar10_train_dls\n\n get_bt_cifar10_train_dls (bs, size, device, dataset_dir=None,\n                           pct_dataset=1.0, num_workers=12)\n\n\nsource\n\n\nget_supervised_cifar10_test_dls\n\n get_supervised_cifar10_test_dls (bs, size, device, dataset_dir=None,\n                                  pct_dataset=1.0, num_workers=12)\n\n\nsource\n\n\nget_supervised_cifar10_train_dls\n\n get_supervised_cifar10_train_dls (bs, size, device, dataset_dir=None,\n                                   pct_dataset=1.0, num_workers=12)\n\n\nsource\n\n\nget_bt_cifar10_train_dls\n\n get_bt_cifar10_train_dls (bs, size, device, dataset_dir=None,\n                           pct_dataset=1.0, num_workers=12)",
    "crumbs": [
      "cifar10_dataloading"
    ]
  },
  {
    "objectID": "metrics.html",
    "href": "metrics.html",
    "title": "metrics",
    "section": "",
    "text": "source\n\n\n\n Stdev (x)\n\n\nsource\n\n\n\n\n predict_model (xval, yval, model, aug_pipelines_test, numavg=3,\n                criterion=FlattenedLoss of CrossEntropyLoss(),\n                deterministic_test=False)\n\nNote that this assumes xval is entire validation set. If it doesn’t fit in memory, can’t use this guy\n\nsource\n\n\n\n\n predict_ensemble (yval, scores1, scores2)\n\nscores can be normalized (softmax) or not\n\nsource\n\n\n\n\n classification_report_wrapper (ypred, y, int_to_classes,\n                                print_report=True)\n\n\nsource\n\n\n\n\n format_classification_report (data_dict)\n\n\nsource\n\n\n\n\n Mean_Report (reports, classes)\n\n\nsource\n\n\n\n\n print_confusion_matrix (ypred, y, vocab)\n\nWe monkey patch some plotting functions from scikitplot and edit them - we need greater control of legend etc\n\nsource\n\n\n\n\n plot_pr (ytest, probs, int_to_classes)\n\n\nsource\n\n\n\n\n plot_roc (ytest, probs, int_to_classes)\n\nFunctions to plot ROC curve and precision-recall curves:\n\nsource\n\n\n\n\n plot_pr (ytest, probs, int_to_classes)\n\n\nsource\n\n\n\n\n plot_roc (ytest, probs, int_to_classes)\n\n\nsource\n\n\n\n\n Pr_Dict (ytest, probs, int_to_classes=None)\n\nMostly used to verify results of plot (debug)\n\nsource\n\n\n\n\n Auc_Dict (ytest, probs, int_to_classes=None)\n\nMostly used to verify results of plot (debug)\n\nsource\n\n\n\n\n Mean_Results (results, vocab)\n\nGet mean classification report and display it\n\nsource\n\n\n\n\n get_xval_metrics (xval, yval, model, aug_pipelines_test, int_to_classes,\n                   numavg=3)\n\nget metrics from gives batch (xval,yval)\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nxval\n\n\n\n\n\nyval\n\n\n\n\n\nmodel\n\n\n\n\n\naug_pipelines_test\n\n\n\n\n\nint_to_classes\n\n\n\n\n\nnumavg\nint\n3\nnote that we can’t call dls.vocab as it might be smaller on the test set\n\n\n\n\nsource\n\n\n\n\n get_dls_metrics (dls, model, aug_pipelines_test, int_to_classes,\n                  numavg=3, deterministic_test=False)\n\nget metrics from model and dataloader\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndls\n\n\n\n\n\nmodel\n\n\n\n\n\naug_pipelines_test\n\n\n\n\n\nint_to_classes\n\n\n\n\n\nnumavg\nint\n3\n\n\n\ndeterministic_test\nbool\nFalse\nnote that we can’t call dls.vocab as it might be smaller on the test set\n\n\n\n\nsource\n\n\n\n\n predict_whole_model (dls_test, model, aug_pipelines_test, numavg=3,\n                      deterministic_test=False, criterion=FlattenedLoss of\n                      CrossEntropyLoss(), deterministic=False)\n\n*Predicts the labels and probabilities for the entire test set using the specified model and data augmentation pipelines. Returns a dictionary containing the labels, probabilities, predicted labels, and accuracy.\nArgs: dls_test: The test dataloader. model: The trained model. aug_pipelines_test: The test data augmentation pipelines. numavg: The number of times to perform test-time augmentation. criterion: The loss function to use for computing the accuracy. deterministic: Whether to use deterministic computation.\nReturns: A dictionary containing the labels, probabilities, predicted labels, and accuracy.*\nVerify Mean_Results looks correct:",
    "crumbs": [
      "metrics"
    ]
  },
  {
    "objectID": "metrics.html#predictions-given-xval-and-yval",
    "href": "metrics.html#predictions-given-xval-and-yval",
    "title": "metrics",
    "section": "",
    "text": "source\n\n\n\n Stdev (x)\n\n\nsource\n\n\n\n\n predict_model (xval, yval, model, aug_pipelines_test, numavg=3,\n                criterion=FlattenedLoss of CrossEntropyLoss(),\n                deterministic_test=False)\n\nNote that this assumes xval is entire validation set. If it doesn’t fit in memory, can’t use this guy\n\nsource\n\n\n\n\n predict_ensemble (yval, scores1, scores2)\n\nscores can be normalized (softmax) or not\n\nsource\n\n\n\n\n classification_report_wrapper (ypred, y, int_to_classes,\n                                print_report=True)\n\n\nsource\n\n\n\n\n format_classification_report (data_dict)\n\n\nsource\n\n\n\n\n Mean_Report (reports, classes)\n\n\nsource\n\n\n\n\n print_confusion_matrix (ypred, y, vocab)\n\nWe monkey patch some plotting functions from scikitplot and edit them - we need greater control of legend etc\n\nsource\n\n\n\n\n plot_pr (ytest, probs, int_to_classes)\n\n\nsource\n\n\n\n\n plot_roc (ytest, probs, int_to_classes)\n\nFunctions to plot ROC curve and precision-recall curves:\n\nsource\n\n\n\n\n plot_pr (ytest, probs, int_to_classes)\n\n\nsource\n\n\n\n\n plot_roc (ytest, probs, int_to_classes)\n\n\nsource\n\n\n\n\n Pr_Dict (ytest, probs, int_to_classes=None)\n\nMostly used to verify results of plot (debug)\n\nsource\n\n\n\n\n Auc_Dict (ytest, probs, int_to_classes=None)\n\nMostly used to verify results of plot (debug)\n\nsource\n\n\n\n\n Mean_Results (results, vocab)\n\nGet mean classification report and display it\n\nsource\n\n\n\n\n get_xval_metrics (xval, yval, model, aug_pipelines_test, int_to_classes,\n                   numavg=3)\n\nget metrics from gives batch (xval,yval)\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nxval\n\n\n\n\n\nyval\n\n\n\n\n\nmodel\n\n\n\n\n\naug_pipelines_test\n\n\n\n\n\nint_to_classes\n\n\n\n\n\nnumavg\nint\n3\nnote that we can’t call dls.vocab as it might be smaller on the test set\n\n\n\n\nsource\n\n\n\n\n get_dls_metrics (dls, model, aug_pipelines_test, int_to_classes,\n                  numavg=3, deterministic_test=False)\n\nget metrics from model and dataloader\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndls\n\n\n\n\n\nmodel\n\n\n\n\n\naug_pipelines_test\n\n\n\n\n\nint_to_classes\n\n\n\n\n\nnumavg\nint\n3\n\n\n\ndeterministic_test\nbool\nFalse\nnote that we can’t call dls.vocab as it might be smaller on the test set\n\n\n\n\nsource\n\n\n\n\n predict_whole_model (dls_test, model, aug_pipelines_test, numavg=3,\n                      deterministic_test=False, criterion=FlattenedLoss of\n                      CrossEntropyLoss(), deterministic=False)\n\n*Predicts the labels and probabilities for the entire test set using the specified model and data augmentation pipelines. Returns a dictionary containing the labels, probabilities, predicted labels, and accuracy.\nArgs: dls_test: The test dataloader. model: The trained model. aug_pipelines_test: The test data augmentation pipelines. numavg: The number of times to perform test-time augmentation. criterion: The loss function to use for computing the accuracy. deterministic: Whether to use deterministic computation.\nReturns: A dictionary containing the labels, probabilities, predicted labels, and accuracy.*\nVerify Mean_Results looks correct:",
    "crumbs": [
      "metrics"
    ]
  },
  {
    "objectID": "isicufesdermnet_dataloading.html",
    "href": "isicufesdermnet_dataloading.html",
    "title": "isicufesdermnet_dataloading",
    "section": "",
    "text": "Example on google colab.\nNeed to unzip isic and ufes.\nufes\ndermnet\nMain dataloader functions:\n\nsource\n\nget_bt_isicufesdermnet_train_dls\n\n get_bt_isicufesdermnet_train_dls (bs, size, device, pct_dataset=1.0,\n                                   num_workers=12)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbs\n\n\n\n\n\nsize\n\n\nnot needed\n\n\ndevice\n\n\n\n\n\npct_dataset\nfloat\n1.0\n\n\n\nnum_workers\nint\n12",
    "crumbs": [
      "isicufesdermnet_dataloading"
    ]
  },
  {
    "objectID": "base_supervised.html",
    "href": "base_supervised.html",
    "title": "base_supervised",
    "section": "",
    "text": "API:\n\nTrain and then test linear head. Requires inputs: encoder, dls_val, augpipe_val, indim,outdim, num_epochs,\n\n\nsource\n\nget_linear_batch_augs\n\n get_linear_batch_augs (size, resize=True, flip=True, flip_prob=0.5,\n                        resize_scale=(0.08, 1.0), resize_ratio=(0.75,\n                        1.3333333333333333), stats=None, cuda=False,\n                        xtra_tfms=[])\n\nInput batch augmentations implemented in tv+kornia+fastai\nThe model for linear evaluation and semi-supervised learning requires an encoder and a (randomly) initialised head.\n\nsource\n\n\nLM\n\n LM (encoder, numout, encoder_dimension=2048)\n\nBasic linear model\nThe ‘callback’ for linear evaluation is the following:\n\nsource\n\n\nLinearBt\n\n LinearBt (aug_pipelines, n_in, show_batch=False, print_augs=False,\n           data=None, tune_model_path=None, tune_save_after=None)\n\nBasic class handling tweaks of the training loop by changing a Learner in various events\nTest:\nExample usage: First inputs needed. In the next cell we get dls_val and dls_test.\nAugmentations and learner:\n\nsource\n\n\nshow_linear_batch\n\n show_linear_batch (dls, n_in, aug, n=2, print_augs=True)\n\nGiven a linear learner, show a batch\n\n# def get_bt_cifar10_aug_pipelines(size):\n#     aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n#                                                     bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n#                                                     resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n#                                                     bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n#                                                     stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n#                                                     )\n\n#     aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n#                                                     bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n#                                                     resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n#                                                     bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n#                                                     stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n#                                                     )\n\n#     bt_cifar10_aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n\n#     return bt_cifar10_aug_pipelines\n\n# #Add other augmentations here e.g. BYOL augs\n\n# bt_aug_func_dict = {'bt_cifar10_aug_pipelines':get_bt_cifar10_aug_pipelines}\n\n\n# def get_bt_aug_pipelines(bt_augs,size):\n\n#     return bt_aug_func_dict[bt_augs](size)\n\n\nsource\n\n\nget_supervised_dls\n\n get_supervised_dls (dataset, pct_dataset_train, pct_dataset_test, bs,\n                     dataset_dir, bs_test, size, device)\n\nGet train and test dataloaders for supervised learning\n\nsource\n\n\nget_supervised_aug_pipelines\n\n get_supervised_aug_pipelines (augs, size)\n\n\nsource\n\n\nget_supervised_isic_augmentations\n\n get_supervised_isic_augmentations (size)\n\n\nsource\n\n\nget_supervised_cifar10_augmentations\n\n get_supervised_cifar10_augmentations (size)\n\nTest:\nThis enables us to freeze the encoder as needed:\n\nsource\n\n\nencoder_head_splitter\n\n encoder_head_splitter (m)\n\nSupervisedLearning allows us to perform either linear evaluation, semi-supervised learning, or standard supervised learning.\n\nsource\n\n\nSaveSupLearnerModel\n\n SaveSupLearnerModel (experiment_dir, num_run)\n\nBasic class handling tweaks of the training loop by changing a Learner in various events\n\nsource\n\n\nSupervisedLearning\n\n SupervisedLearning (model, dls_train, aug_pipelines_supervised, n_in, wd,\n                     device, num_it=100, num_run=None,\n                     experiment_dir=None)\n\nTrain model using supervised learning. Either linear evaluation or semi-supervised.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodel\n\n\n\n\n\ndls_train\n\n\n\n\n\naug_pipelines_supervised\n\n\n\n\n\nn_in\n\n\n\n\n\nwd\n\n\n\n\n\ndevice\n\n\n\n\n\nnum_it\nint\n100\n\n\n\nnum_run\nNoneType\nNone\nn of num_runs. e.g. num_runs=5 and num_run=3 means this is the 3rd run.\n\n\nexperiment_dir\nNoneType\nNone\nBasically just tells what name to save checkpoint as - if applicable.\n\n\n\n\nsource\n\n\nget_encoder\n\n get_encoder (arch, weight_type, load_pretrained_path=None)\n\nGet an encoder for supervised learner. If load_pretrained_path is not None, load the weights from that path.\n\nsource\n\n\nload_sup_model\n\n load_sup_model (config, numout, path)\n\n\nsource\n\n\nsave_metrics\n\n save_metrics (model, aug_pipelines_supervised, experiment_dir, num_run,\n               dls_train, dls_test, numavg=3, deterministic_test=False)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodel\n\n\ntrained model\n\n\naug_pipelines_supervised\n\n\n\n\n\nexperiment_dir\n\n\nwhere to save\n\n\nnum_run\n\n\nhow to name metrics files\n\n\ndls_train\n\n\njust used to compute vocab\n\n\ndls_test\n\n\ntest set\n\n\nnumavg\nint\n3\n\n\n\ndeterministic_test\nbool\nFalse\n\n\n\n\n\n# #| export \n\n# def get_largest_metric_file(experiment_dir):\n#     metric_files = [f for f in os.listdir(experiment_dir) if 'metrics' in f]\n    \n#     if not metric_files:\n#         return None,None\n    \n#     max_num = -1\n#     max_file = ''\n    \n#     for file in metric_files:\n#         match = re.search(r'_(\\d+)\\.pkl$', file)\n#         if match:\n#             num = int(match.group(1))\n#             if num &gt; max_num:\n#                 max_num = num\n#                 max_file = file\n    \n#     num = max_file.split('.pkl')[0].split('_')[-1]\n#     return max_file,num\n\n\n# #| hide\n# with tempfile.TemporaryDirectory() as dir:\n\n#     save_dict_to_gdrive({'a':1}, dir, 'metrics_num_run_1')\n#     save_dict_to_gdrive({'a':2}, dir, 'metrics_num_run_2')\n#     save_dict_to_gdrive({'a':4}, dir, 'metrics_num_run_4')\n\n#     print(os.listdir(dir))\n\n#     max_file,num = get_largest_metric_file(dir)\n\n#     test_eq(max_file,'metrics_num_run_4.pkl')\n#     test_eq(num,'4')\n\n\nsource\n\n\nmain_sup_train\n\n main_sup_train (config, dataset_dir=None, num_run=None, train=True,\n                 test=True, experiment_dir=None)\n\nBasically map from config to training a supervised model. Optionally save checkpoints of learner. Also compute metrics on test set and save. If train is False load model according to num_run (means it already exists) and just compute metrics.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nconfig\n\n\n\n\n\ndataset_dir\nNoneType\nNone\n\n\n\nnum_run\nNoneType\nNone\nrun we are up to - tell us what name to give the saved checkpoint, if applicable.\n\n\ntrain\nbool\nTrue\nif False, load model and compute and save metrics only\n\n\ntest\nbool\nTrue\n\n\n\nexperiment_dir\nNoneType\nNone\nwhere to save checkpoints\n\n\n\n\nsource\n\n\ncheck_run_exists\n\n check_run_exists (experiment_dir, num_run)\n\n\nsource\n\n\nmain_sup_experiment\n\n main_sup_experiment (config, base_dir, dataset_dir)\n\nRun a supervised learning experiment with the given configuration and save the results to the experiment directory. Return the experiment directory and experiment hash.\nFull example\n\n# #| hide\nwith tempfile.TemporaryDirectory() as base_dir:\n    \n    config_path = '../configs/cifar10/supervised/sup_test_config.yaml'\n    \n    config = load_config(config_path)\n\n    pretty_print_ns(config)\n\n    experiment_dir,experiment_hash,num_run = main_sup_experiment(config,base_dir,dataset_dir=None)\n    \n    print(os.listdir(experiment_dir))\n    print(os.listdir(base_dir))\n    print('experiment_dir and base_dir')\n\ndataset: cifar10\narch: smallres\ntrain_type: supervised\nweight_type: random\nlearn_type: standard\nsize: 32\nn_in: 3\nbs: 64\nbs_test: 64\nsup_augs: supervised_cifar10_augmentations\nwd: 0.0\nfreeze_epochs: 1\nnum_it: 10\npct_dataset_train: 0.01\npct_dataset_test: 0.1\nepochs: 1\nnum_runs: 2\nload_pretrained_path: None\nencoder_dimension: 512\nThe experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpeedfi0b2/supervised/cifar10/smallres/58adecf5 and the experiment hash is: 58adecf5\nConfiguration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpeedfi0b2/supervised/cifar10/smallres/58adecf5/config.yaml\nThe git hash is: 1b1dded7163406a323457a46a0ecea8bacf4b04b\nnum_run=1 doesn't exist. Training now.\nRandomResizedCrop:\nencodes: (object,object) -&gt; RandomResizedCropdecodes: \nPipeline: \n\n\n\n\n\n\n\n\n\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n  warn(\"Your generator is empty.\")\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n2.347234\nNone\nNone\n00:03\n\n\n\n\n\nModel state dict saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpeedfi0b2/supervised/cifar10/smallres/58adecf5/trained_model_num_run_1.pth\ncomputing metrics on test set.\nrunning `predict_whole_model`\n\n\n\n\n\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\n              precision    recall  f1-score   support\n\n    airplane       1.00      0.30      0.46       133\n  automobile       0.00      0.00      0.00       112\n        bird       0.50      0.01      0.02        93\n         cat       0.00      0.00      0.00        96\n        deer       0.00      0.00      0.00       111\n         dog       0.00      0.00      0.00       102\n        frog       0.00      0.00      0.00        85\n       horse       0.00      0.00      0.00       101\n        ship       0.09      1.00      0.16        85\n       truck       0.00      0.00      0.00        82\n\n    accuracy                           0.13      1000\n   macro avg       0.16      0.13      0.06      1000\nweighted avg       0.19      0.13      0.08      1000\n\nauc_dict is: {'airplane': 0.4723140030005811, 'automobile': 0.33448459620334625, 'bird': 0.5503787744069424, 'cat': 0.45438099188790565, 'deer': 0.6396649743106436, 'dog': 0.6080396523865671, 'frog': 0.3816457730633237, 'horse': 0.5547638189847905, 'ship': 0.6911218257794922, 'truck': 0.4535177214517243}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nauc_dict is: {'airplane': 0.16474747874243187, 'automobile': 0.07964735340934488, 'bird': 0.12836125684868444, 'cat': 0.08108436324162081, 'deer': 0.15367216812204582, 'dog': 0.1319117268093623, 'frog': 0.06374041778060538, 'horse': 0.12355952886202198, 'ship': 0.14531493375436247, 'truck': 0.07210147530044403}\nMetrics computation time: 11.30 seconds\nnum_run=2 doesn't exist. Training now.\nRandomResizedCrop:\nencodes: (object,object) -&gt; RandomResizedCropdecodes: \nPipeline: \n\n\n\n\n\n\n\n\n\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n  warn(\"Your generator is empty.\")\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n2.330904\nNone\nNone\n00:04\n\n\n\n\n\nModel state dict saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpeedfi0b2/supervised/cifar10/smallres/58adecf5/trained_model_num_run_2.pth\ncomputing metrics on test set.\nrunning `predict_whole_model`\n\n\n\n\n\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\n              precision    recall  f1-score   support\n\n    airplane       0.42      0.39      0.40       133\n  automobile       0.08      0.31      0.13        90\n        bird       0.00      0.00      0.00       107\n         cat       0.00      0.00      0.00        93\n        deer       0.00      0.00      0.00        87\n         dog       0.00      0.00      0.00       122\n        frog       0.00      0.00      0.00        86\n       horse       0.00      0.00      0.00        93\n        ship       0.00      0.00      0.00        91\n       truck       0.12      0.62      0.20        98\n\n    accuracy                           0.14      1000\n   macro avg       0.06      0.13      0.07      1000\nweighted avg       0.07      0.14      0.08      1000\n\nauc_dict is: {'airplane': 0.44563831724640324, 'automobile': 0.463058608058608, 'bird': 0.5671840169124343, 'cat': 0.504872497065832, 'deer': 0.461167554229457, 'dog': 0.516752866051757, 'frog': 0.5026334537682561, 'horse': 0.4755486004908063, 'ship': 0.5331665034635331, 'truck': 0.4552072491967962}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nauc_dict is: {'airplane': 0.16511664979584073, 'automobile': 0.08059534476650243, 'bird': 0.16002385525068155, 'cat': 0.09289151758176256, 'deer': 0.07870456324248618, 'dog': 0.12325328375621142, 'frog': 0.08896711593028082, 'horse': 0.09030965750445723, 'ship': 0.09273068752108606, 'truck': 0.09628101087936629}\nMetrics computation time: 7.03 seconds\n              precision    recall  f1-score   support\n\n    airplane       0.71      0.35      0.43     133.0\n  automobile       0.04      0.16      0.06     101.0\n        bird       0.25      0.01      0.01     100.0\n         cat       0.00      0.00      0.00      94.5\n        deer       0.00      0.00      0.00      99.0\n         dog       0.00      0.00      0.00     112.0\n        frog       0.00      0.00      0.00      85.5\n       horse       0.00      0.00      0.00      97.0\n        ship       0.04      0.50      0.08      88.0\n       truck       0.06      0.31      0.10      90.0\n\n    accuracy                           0.13    1000.0\n   macro avg       0.11      0.13      0.07    1000.0\nweighted avg       0.13      0.13      0.08    1000.0\n\nmean acc is 0.13350000232458115 with std 0.010606602139266699\nMetadata saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpeedfi0b2/supervised/cifar10/smallres/58adecf5/metadata.yaml\nUpdated experiment index for hash: 58adecf5\n['metrics_num_run_1.pkl', 'metrics_num_run_2.pkl', 'trained_model_num_run_2.pth', 'trained_model_num_run_1.pth', 'metadata.yaml', 'config.yaml', 'mean_results.pkl']\n['supervised', 'experiment_index.json']\nexperiment_dir and base_dir\n\n\n\nsource\n\n\nmain_fine_tune_isic\n\n main_fine_tune_isic (config, base_dir, dataset_dir)\n\nJust call main_sup_experiment for each different pct_dataset_train value and for given config",
    "crumbs": [
      "base_supervised"
    ]
  },
  {
    "objectID": "dermnet_dataloading.html",
    "href": "dermnet_dataloading.html",
    "title": "derment_dataloading",
    "section": "",
    "text": "source\n\nget_bt_dermnet_train_dls\n\n get_bt_dermnet_train_dls (bs, size, device, pct_dataset=1.0,\n                           num_workers=12)\n\n\nsource\n\n\nlabel_func\n\n label_func (x)",
    "crumbs": [
      "derment_dataloading"
    ]
  },
  {
    "objectID": "base_model.html",
    "href": "base_model.html",
    "title": "base_model",
    "section": "",
    "text": "Here we have the base functions and classes to train a basic BT-style model. Note that this (mostly) all comes directly from here: https://github.com/KeremTurgutlu/self_supervised/blob/main/nbs/14%20-%20barlow_twins.ipynb but we needed to extend some of the functionality for our purposes.\nSome of the base classes and functions needed for image augmentation pipeline:\n\nsource\n\nget_barlow_twins_aug_pipelines\n\n get_barlow_twins_aug_pipelines (size, flip=True, crop=True, noise=True,\n                                 rotate=True, jitter=True, bw=True,\n                                 blur=True, solar=True, cutout=False,\n                                 quarter_mask=False, resize_scale=(0.08,\n                                 1.0), resize_ratio=(0.75,\n                                 1.3333333333333333), noise_std=0.025,\n                                 rotate_deg=30, jitter_s=0.6, blur_s=(4,\n                                 32), blur_r=(0.1, 2), blur_sig=None,\n                                 sol_t=0.05, sol_a=0.05,\n                                 min_dropout_size=(25, 100),\n                                 max_dropout_size=(50, 150), flip_p=0.5,\n                                 rotate_p=0.3, noise_p=0.2, jitter_p=0.3,\n                                 bw_p=0.3, blur_p=0.3, sol_p=0.1,\n                                 cut_p=0.0, quarter_mask_p=0.5,\n                                 same_on_batch=False, stats=([0.485,\n                                 0.456, 0.406], [0.229, 0.224, 0.225]),\n                                 cuda=False, xtra_tfms=[])\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsize\n\n\n\n\n\nflip\nbool\nTrue\n\n\n\ncrop\nbool\nTrue\n\n\n\nnoise\nbool\nTrue\n\n\n\nrotate\nbool\nTrue\n\n\n\njitter\nbool\nTrue\n\n\n\nbw\nbool\nTrue\n\n\n\nblur\nbool\nTrue\n\n\n\nsolar\nbool\nTrue\n\n\n\ncutout\nbool\nFalse\n\n\n\nquarter_mask\nbool\nFalse\nWhether to use given aug or not\n\n\nresize_scale\ntuple\n(0.08, 1.0)\n\n\n\nresize_ratio\ntuple\n(0.75, 1.3333333333333333)\n\n\n\nnoise_std\nfloat\n0.025\n\n\n\nrotate_deg\nint\n30\n\n\n\njitter_s\nfloat\n0.6\n\n\n\nblur_s\ntuple\n(4, 32)\nhps of diff augs\n\n\nblur_r\ntuple\n(0.1, 2)\n\n\n\nblur_sig\nNoneType\nNone\n\n\n\nsol_t\nfloat\n0.05\n\n\n\nsol_a\nfloat\n0.05\n\n\n\nmin_dropout_size\ntuple\n(25, 100)\n\n\n\nmax_dropout_size\ntuple\n(50, 150)\nhps of diff augs\n\n\nflip_p\nfloat\n0.5\n\n\n\nrotate_p\nfloat\n0.3\n\n\n\nnoise_p\nfloat\n0.2\n\n\n\njitter_p\nfloat\n0.3\n\n\n\nbw_p\nfloat\n0.3\n\n\n\nblur_p\nfloat\n0.3\n\n\n\nsol_p\nfloat\n0.1\n\n\n\ncut_p\nfloat\n0.0\n\n\n\nquarter_mask_p\nfloat\n0.5\nprob of performing aug\n\n\nsame_on_batch\nbool\nFalse\n\n\n\nstats\ntuple\n([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\n\n\ncuda\nbool\nFalse\n\n\n\nxtra_tfms\nlist\n[]\n\n\n\n\n\nsource\n\n\nget_multi_aug_pipelines\n\n get_multi_aug_pipelines (size, flip=True, crop=True, noise=True,\n                          rotate=True, jitter=True, bw=True, blur=True,\n                          solar=True, cutout=False, quarter_mask=False,\n                          resize_scale=(0.08, 1.0), resize_ratio=(0.75,\n                          1.3333333333333333), noise_std=0.025,\n                          rotate_deg=30, jitter_s=0.6, blur_s=(4, 32),\n                          blur_r=(0.1, 2), blur_sig=None, sol_t=0.05,\n                          sol_a=0.05, min_dropout_size=(25, 100),\n                          max_dropout_size=(50, 150), flip_p=0.5,\n                          rotate_p=0.3, noise_p=0.2, jitter_p=0.3,\n                          bw_p=0.3, blur_p=0.3, sol_p=0.1, cut_p=0.0,\n                          quarter_mask_p=0.5, same_on_batch=False,\n                          stats=([0.485, 0.456, 0.406], [0.229, 0.224,\n                          0.225]), cuda=False, xtra_tfms=[])\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsize\n\n\n\n\n\nflip\nbool\nTrue\n\n\n\ncrop\nbool\nTrue\n\n\n\nnoise\nbool\nTrue\n\n\n\nrotate\nbool\nTrue\n\n\n\njitter\nbool\nTrue\n\n\n\nbw\nbool\nTrue\n\n\n\nblur\nbool\nTrue\n\n\n\nsolar\nbool\nTrue\n\n\n\ncutout\nbool\nFalse\n\n\n\nquarter_mask\nbool\nFalse\nWhether to use given aug or not\n\n\nresize_scale\ntuple\n(0.08, 1.0)\n\n\n\nresize_ratio\ntuple\n(0.75, 1.3333333333333333)\n\n\n\nnoise_std\nfloat\n0.025\n\n\n\nrotate_deg\nint\n30\n\n\n\njitter_s\nfloat\n0.6\n\n\n\nblur_s\ntuple\n(4, 32)\nhps of diff augs\n\n\nblur_r\ntuple\n(0.1, 2)\n\n\n\nblur_sig\nNoneType\nNone\n\n\n\nsol_t\nfloat\n0.05\n\n\n\nsol_a\nfloat\n0.05\n\n\n\nmin_dropout_size\ntuple\n(25, 100)\n\n\n\nmax_dropout_size\ntuple\n(50, 150)\nhps of diff augs\n\n\nflip_p\nfloat\n0.5\n\n\n\nrotate_p\nfloat\n0.3\n\n\n\nnoise_p\nfloat\n0.2\n\n\n\njitter_p\nfloat\n0.3\n\n\n\nbw_p\nfloat\n0.3\n\n\n\nblur_p\nfloat\n0.3\n\n\n\nsol_p\nfloat\n0.1\n\n\n\ncut_p\nfloat\n0.0\n\n\n\nquarter_mask_p\nfloat\n0.5\nprob of performing aug\n\n\nsame_on_batch\nbool\nFalse\n\n\n\nstats\ntuple\n([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\n\n\ncuda\nbool\nFalse\n\n\n\nxtra_tfms\nlist\n[]\n\n\n\n\n\nsource\n\n\nRandomQuarterMask\n\n RandomQuarterMask (p=0.5)\n\nRandomly mask a quarter of the image with probability p\n\nsource\n\n\nget_BT_batch_augs\n\n get_BT_batch_augs (size, flip=True, crop=True, noise=True, rotate=True,\n                    jitter=True, bw=True, blur=True, solar=True,\n                    cutout=False, quarter_mask=False, resize_scale=(0.08,\n                    1.0), resize_ratio=(0.75, 1.3333333333333333),\n                    noise_std=0.025, rotate_deg=30, jitter_s=0.6,\n                    blur_s=(4, 32), blur_r=(0.1, 2), blur_sig=None,\n                    sol_t=0.05, sol_a=0.05, min_dropout_size=(25, 100),\n                    max_dropout_size=(50, 150), flip_p=0.5, rotate_p=0.3,\n                    noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3,\n                    sol_p=0.1, cut_p=0.0, quarter_mask_p=0.5,\n                    same_on_batch=False, stats=([0.485, 0.456, 0.406],\n                    [0.229, 0.224, 0.225]), cuda=False, xtra_tfms=[])\n\nInput batch augmentations implemented in tv+kornia+fastai\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsize\n\n\n\n\n\nflip\nbool\nTrue\n\n\n\ncrop\nbool\nTrue\n\n\n\nnoise\nbool\nTrue\n\n\n\nrotate\nbool\nTrue\n\n\n\njitter\nbool\nTrue\n\n\n\nbw\nbool\nTrue\n\n\n\nblur\nbool\nTrue\n\n\n\nsolar\nbool\nTrue\n\n\n\ncutout\nbool\nFalse\n\n\n\nquarter_mask\nbool\nFalse\nWhether to use given aug or not\n\n\nresize_scale\ntuple\n(0.08, 1.0)\n\n\n\nresize_ratio\ntuple\n(0.75, 1.3333333333333333)\n\n\n\nnoise_std\nfloat\n0.025\n\n\n\nrotate_deg\nint\n30\n\n\n\njitter_s\nfloat\n0.6\n\n\n\nblur_s\ntuple\n(4, 32)\nhps of diff augs\n\n\nblur_r\ntuple\n(0.1, 2)\n\n\n\nblur_sig\nNoneType\nNone\n\n\n\nsol_t\nfloat\n0.05\n\n\n\nsol_a\nfloat\n0.05\n\n\n\nmin_dropout_size\ntuple\n(25, 100)\n\n\n\nmax_dropout_size\ntuple\n(50, 150)\nhps of diff augs\n\n\nflip_p\nfloat\n0.5\n\n\n\nrotate_p\nfloat\n0.3\n\n\n\nnoise_p\nfloat\n0.2\n\n\n\njitter_p\nfloat\n0.3\n\n\n\nbw_p\nfloat\n0.3\n\n\n\nblur_p\nfloat\n0.3\n\n\n\nsol_p\nfloat\n0.1\n\n\n\ncut_p\nfloat\n0.0\n\n\n\nquarter_mask_p\nfloat\n0.5\nprob of performing aug\n\n\nsame_on_batch\nbool\nFalse\n\n\n\nstats\ntuple\n([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\n\n\ncuda\nbool\nFalse\n\n\n\nxtra_tfms\nlist\n[]\n\n\n\n\n\nsource\n\n\nRandomCenterDropout\n\n RandomCenterDropout (p=0.5, min_dropout_size=(20, 20),\n                      max_dropout_size=(60, 60), fill_value=0,\n                      same_on_batch=False)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\nsource\n\n\nRandomGaussianBlur\n\n RandomGaussianBlur (p=1.0, prob=0.5, s=(8, 32), sig=None, blur_r=(0.1,\n                     2), same_on_batch=False, **kwargs)\n\nRandomly apply gaussian blur with probability p with a value of s\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\np\nfloat\n1.0\ndebugging (bug in libraries implementation)\n\n\nprob\nfloat\n0.5\nthe real probability\n\n\ns\ntuple\n(8, 32)\nkernel\n\n\nsig\nNoneType\nNone\nsig_val is either manually input OR\n\n\nblur_r\ntuple\n(0.1, 2)\nis randomly chosen from uniform with these bounds\n\n\nsame_on_batch\nbool\nFalse\n\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nget_bt_aug_pipelines\n\n get_bt_aug_pipelines (bt_augs, size)\n\n\nsource\n\n\nget_bt_dermnet_aug_pipelines\n\n get_bt_dermnet_aug_pipelines (size)\n\n\nsource\n\n\nget_bt_imagenet_aug_pipelines\n\n get_bt_imagenet_aug_pipelines (size)\n\n\nsource\n\n\nhelper_get_bt_augs\n\n helper_get_bt_augs (size, Augs={'flip_p1': 0.5, 'flip_p2': 0.5,\n                     'jitter_p1': 0.8, 'jitter_p2': 0.8, 'bw_p1': 0.2,\n                     'bw_p2': 0.2, 'blur_p1': 1.0, 'blur_p2': 0.1,\n                     'sol_p1': 0.0, 'sol_p2': 0.2, 'noise_p1': 0.0,\n                     'noise_p2': 0.0, 'cut_p': 0, 'resize_scale': (0.7,\n                     1.0), 'resize_ratio': (0.75, 1.3333333333333333),\n                     'rotate_deg': 45.0, 'rotate_p': 0.5, 'blur_r': (0.1,\n                     2), 'blur_s': 13, 'sol_t': 0.1, 'sol_a': 0.1,\n                     'noise_std': 0.1, 'min_dropout_size': None,\n                     'max_dropout_size': None})\n\n\nsource\n\n\nget_bt_cifar10_aug_pipelines\n\n get_bt_cifar10_aug_pipelines (size)\n\nNew\n\nsource\n\n\nget_bt_predhalf_aug_pipelines\n\n get_bt_predhalf_aug_pipelines (size)\n\n\n# dls = get_ssl_dls('cifar10', bs=32, size=32, device=default_device())\n# aug = get_bt_aug_pipelines('bt_predhalf_aug_pipelines', 32)\n# show_bt_batch(dls, n_in=3, aug=aug, n=2, print_augs=True)\n\n\n# import torch\n# import torch.nn.functional as F\n# import matplotlib.pyplot as plt\n\n# def downsample_image(image, scale_factor=0.125):\n#     \"\"\"Downsample an image and then upsample to original size.\"\"\"\n#     _, _, H, W = image.shape\n#     downsampled = F.interpolate(image, scale_factor=scale_factor, mode='bilinear', align_corners=False)\n#     return F.interpolate(downsampled, size=(H, W), mode='bilinear', align_corners=False)\n\n# def display_original_and_downsampled(original_batch, downsampled_batch, num_images=5):\n#     fig, axes = plt.subplots(2, num_images, figsize=(num_images*3, 6))\n    \n#     for i in range(num_images):\n#         # Display original image\n#         axes[0, i].imshow(original_batch[i].permute(1, 2, 0).cpu())\n#         axes[0, i].axis('off')\n#         axes[0, i].set_title('Original')\n        \n#         # Display downsampled image\n#         axes[1, i].imshow(downsampled_batch[i].permute(1, 2, 0).cpu())\n#         axes[1, i].axis('off')\n#         axes[1, i].set_title('Downsampled')\n    \n#     plt.tight_layout()\n#     plt.show()\n\n# x,y = dls.one_batch()\n# # Downsample the batch\n# downsampled_x = downsample_image(x, scale_factor=0.2)  # Downsampling to 1/4 of original size\n\n# # Display the original and downsampled images\n# display_original_and_downsampled(x, downsampled_x, num_images=5)\n\n# print(f\"Original shape: {x.shape}\")\n# print(f\"Downsampled shape: {downsampled_x.shape}\")\n\n\nsource\n\n\nget_ssl_dls\n\n get_ssl_dls (dataset, bs, size, device, pct_dataset=1.0)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset\n\n\ncifar10, dermnet, etc\n\n\nbs\n\n\n\n\n\nsize\n\n\n\n\n\ndevice\n\n\n\n\n\npct_dataset\nfloat\n1.0\n\n\n\n\nBase functions / classes we need to train a BT / RBT model.\n\nsource\n\n\nBarlowTwins\n\n BarlowTwins (aug_pipelines, n_in, lmb, sparsity_level,\n              model_type='barlow_twins', print_augs=False)\n\nBasic class handling tweaks of the training loop by changing a Learner in various events\n\nsource\n\n\ncreate_barlow_twins_model\n\n create_barlow_twins_model (encoder, hidden_size=256, projection_size=128,\n                            bn=True, nlayers=3)\n\nCreate Barlow Twins model\n\nsource\n\n\nBarlowTwinsModel\n\n BarlowTwinsModel (encoder, projector)\n\nAn encoder followed by a projector\nWe can modify the above for vicreg:\n\nsource\n\n\nVICReg\n\n VICReg (aug_pipelines, n_in=3, sim_coeff=25, std_coeff=25, cov_coeff=1,\n         model_type='vicreg', print_augs=False)\n\nBasic class handling tweaks of the training loop by changing a Learner in various events\n\nsource\n\n\noff_diagonal\n\n off_diagonal (x)\n\n\nsource\n\n\ncreate_vicreg_model\n\n create_vicreg_model (left_encoder, right_encoder, hidden_size=256,\n                      projection_size=128, bn=True, nlayers=3,\n                      shared_projector=True)\n\n*Create VICReg model with flexible projector configuration\nArgs: - left_encoder: first encoder model - right_encoder: second encoder model (can be the same as left_encoder for shared encoder) - hidden_size: hidden size for projector - projection_size: output size for projector - bn: whether to use batch normalization in projector - nlayers: number of layers in projector - shared_projector: if True, use the same projector for both branches*\n\nsource\n\n\nin_channels\n\n in_channels (m)\n\n\nsource\n\n\nVICRegModel\n\n VICRegModel (left_encoder, right_encoder, left_projector,\n              right_projector)\n\nVICReg model with options for shared or separate projectors\nNew idea / method: PredHalf\nDefinition of barlow twins loss and sparse barlow twins loss functions, and proposes modifications\n\nsource\n\n\nlf_bt\n\n lf_bt (pred, I, lmb)\n\n\n\n\n\nDetails\n\n\n\n\npred\n\n\n\nI\n\n\n\nlmb\nstandard bt loss\n\n\n\n\nsource\n\n\nlf_bt_sparse_head\n\n lf_bt_sparse_head (pred, I, lmb, projector, sparsity_level)\n\n\nsource\n\n\nlf_bt_indiv_sparse\n\n lf_bt_indiv_sparse (pred, I, lmb, sparsity_level)\n\n\nsource\n\n\nlf_bt_group_sparse\n\n lf_bt_group_sparse (pred, I, lmb, sparsity_level)\n\n\nsource\n\n\nlf_bt_group_norm_sparse\n\n lf_bt_group_norm_sparse (pred, I, lmb, sparsity_level)\n\n\nsource\n\n\nlf_bt_fun\n\n lf_bt_fun (pred, I, lmb, sparsity_level)\n\n\nsource\n\n\nlf_bt_proj_group_sparse\n\n lf_bt_proj_group_sparse (pred, I, lmb, sparsity_level)\n\n\nsource\n\n\noff_diagonal\n\n off_diagonal (x)\n\n\nsource\n\n\nlf_predhalf\n\n lf_predhalf (pred_enc, pred, I, lmb)\n\nPatch in loss function:\n\nsource\n\n\nBarlowTwins.lf\n\n BarlowTwins.lf (pred, *yb)\n\nAssumes model created according to type p3\n\nsource\n\n\nmy_splitter_bt\n\n my_splitter_bt (m)\n\n\nsource\n\n\nmy_splitter_bt_last_block_resnet50\n\n my_splitter_bt_last_block_resnet50 (m)\n\nFreeze all but the last bottleneck layer\nHere we show how to use the above functions in an end to end fashion. First we get some data and plonk it into a dls, Then create an encoder, an augmentation pipeline, a learner, then fit the learner. This is the complete process of training BT.\n\nsource\n\n\nshow_vicreg_batch\n\n show_vicreg_batch (dls, n_in, aug, n=2, print_augs=True,\n                    model_type='vicreg')\n\nGiven a linear learner, show a batch\n\nsource\n\n\nshow_bt_batch\n\n show_bt_batch (dls, n_in, aug, n=2, print_augs=True)\n\nGiven a linear learner, show a batch\n\nsource\n\n\nSaveVicRegLearnerModel\n\n SaveVicRegLearnerModel (experiment_dir)\n\nBasic class handling tweaks of the training loop by changing a Learner in various events\n\nsource\n\n\nSaveBarlowLearnerModel\n\n SaveBarlowLearnerModel (experiment_dir)\n\nBasic class handling tweaks of the training loop by changing a Learner in various events\n\nsource\n\n\nSaveBarlowLearnerCheckpoint\n\n SaveBarlowLearnerCheckpoint (experiment_dir, start_epoch=0,\n                              save_interval=250, with_opt=True)\n\nSave such that can resume training\n\nsource\n\n\nload_vicreg_model\n\n load_vicreg_model (arch, ps, hs, path)\n\n\nsource\n\n\nload_barlow_model\n\n load_barlow_model (arch, ps, hs, path)\n\n\nsource\n\n\nBarlowTrainer\n\n BarlowTrainer (model, dls, bt_aug_pipelines, lmb, sparsity_level, n_in,\n                model_type, wd, device, fit=False, sgdr=False,\n                splitter_str='none', num_it=100, load_learner_path=None,\n                experiment_dir=None, start_epoch=0, save_interval=None,\n                export=False)\n\nSetup a learner for training a BT model. Can do transfer learning, normal training, or resume training.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodel\n\n\nAn encoder followed by a projector\n\n\ndls\n\n\n\n\n\nbt_aug_pipelines\n\n\n\n\n\nlmb\n\n\n\n\n\nsparsity_level\n\n\n\n\n\nn_in\n\n\n\n\n\nmodel_type\n\n\n\n\n\nwd\n\n\n\n\n\ndevice\n\n\n\n\n\nfit\nbool\nFalse\nThis means use learn.fit(.) in FastAI\n\n\nsgdr\nbool\nFalse\n\n\n\nsplitter_str\nstr\nnone\n\n\n\nnum_it\nint\n100\nNumber of iterations to run lr_find for.\n\n\nload_learner_path\nNoneType\nNone\nPath to load learner from (optional)\n\n\nexperiment_dir\nNoneType\nNone\nWhere to save model checkpoints (optional)\n\n\nstart_epoch\nint\n0\nWhich epoch to start from\n\n\nsave_interval\nNoneType\nNone\nHow often to save model checkpoints (optional).\n\n\nexport\nbool\nFalse\n\n\n\n\n\n\nWe can inherit from the above for vicreg version. Just setting up the learner is different\n\nsource\n\nVICRegTrainer\n\n VICRegTrainer (model, dls, bt_aug_pipelines, sparsity_level, sim_coeff,\n                std_coeff, cov_coeff, n_in, model_type, wd, device,\n                fit=False, sgdr=False, splitter_str='none', num_it=100,\n                load_learner_path=None, experiment_dir=None,\n                start_epoch=0, save_interval=None, export=False)\n\nSetup a learner for training a BT model. Can do transfer learning, normal training, or resume training.\nVerify that splitting/freezings works in bt_transfer_learning.\nIt’s a bit hacky but looks to work.\nCopy pasted from bt_transfer_learning\nBit hacky, but ok.\n\nsource\n\n\nmain_bt_train\n\n main_bt_train (config, start_epoch=0, interrupt_epoch=100,\n                load_learner_path=None, learn_type='standard',\n                experiment_dir=None)\n\nBasically map from config to training a BT model. Optionally save checkpoints of learner, to reload and continue;\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nconfig\n\n\n\n\n\nstart_epoch\nint\n0\n\n\n\ninterrupt_epoch\nint\n100\n\n\n\nload_learner_path\nNoneType\nNone\n\n\n\nlearn_type\nstr\nstandard\ncan be ‘standard’, ‘transfer_learning’, or ‘continue_learning’\n\n\nexperiment_dir\nNoneType\nNone\n\n\n\n\nAs above but for vicreg\n\nsource\n\n\nmain_vicreg_train\n\n main_vicreg_train (config, start_epoch=0, interrupt_epoch=100,\n                    load_learner_path=None, learn_type='standard',\n                    experiment_dir=None)\n\nBasically map from config to training a vicreg model (standard or br) Optionally save checkpoints of learner, to reload and continue;\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nconfig\n\n\n\n\n\nstart_epoch\nint\n0\n\n\n\ninterrupt_epoch\nint\n100\n\n\n\nload_learner_path\nNoneType\nNone\n\n\n\nlearn_type\nstr\nstandard\ncan be ‘standard’, ‘transfer_learning’, or ‘continue_learning’\n\n\nexperiment_dir\nNoneType\nNone\n\n\n\n\n\nsource\n\n\nget_bt_experiment_state\n\n get_bt_experiment_state (config, base_dir)\n\nGet the load_learner_path, learn_type, start_epoch, interrupt_epoch for BT experiment. Basically this tells us how to continue learning (e.g. we have run two sessions for 100 epochs, and want to continue for another 100 epochs). Return values are None if we are starting from scratch.\n\nsource\n\n\nmain_bt_experiment\n\n main_bt_experiment (config, base_dir)\n\nRun several epochs of the experiment as defined in the config and where we are up to. e.g. epoch 0, or resuming at epoch 99 etc. Basically a stateful version of main_bt_train that can be resumed. And saving.\nFull end to end example with BT\n\n# #| hide\n# with tempfile.TemporaryDirectory() as base_dir:\n    \n#     config_path = '../configs/cifar10/bt_test_config.yaml'\n#     config = load_config(config_path)\n\n#     # config.model_type = 'sparse_head_barlow_twins'\n#     # config.sparsity_level=10\n#     # config.epochs=100\n#     # config.save_interval=100\n\n#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n    \n#     print(os.listdir(experiment_dir))\n#     print(os.listdir(base_dir))\n#     print('experiment_dir and base_dir')\n\n\n#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n#     print(os.listdir(experiment_dir))\n#     print(os.listdir(base_dir))\n#     print('experiment_dir and base_dir')\n\n#     #get path to fully fitted model\n#     path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n#     model = load_barlow_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n#     print(model)\n\n#     #New config but the first part of experiment_dir is same - just hash is different\n#     #It shouldnt find a max file path\n#     config.epochs=config.epochs+1\n#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n\nFull end to end example for vicreg\n\n# #| hide\n# with tempfile.TemporaryDirectory() as base_dir:\n    \n#     config_path = '../configs/cifar10/vicreg_test_config.yaml'\n#     config = load_config(config_path)\n\n#     # config.model_type = 'sparse_head_barlow_twins'\n#     # config.sparsity_level=10\n#     # config.epochs=100\n#     # config.save_interval=100\n\n#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n    \n#     print(os.listdir(experiment_dir))\n#     print(os.listdir(base_dir))\n#     print('experiment_dir and base_dir')\n\n#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n#     print(os.listdir(experiment_dir))\n#     print(os.listdir(base_dir))\n#     print('experiment_dir and base_dir')\n\n#     #get path to fully fitted model\n#     path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n#     model = load_vicreg_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n#     print(model)\n\n#     #New config but the first part of experiment_dir is same - just hash is different\n#     #It shouldnt find a max file path\n#     config.epochs=config.epochs+1\n#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n\nVerify runs with br_vicreg\n\n# #| hide\n# with tempfile.TemporaryDirectory() as base_dir:\n    \n#     #config_path = '../configs/cifar10/vicreg_test_config.yaml'\n#     config_path = '../configs/cifar10/bt_predhalfconfig.yaml'\n#     config = load_config(config_path)\n#     config.pct_dataset = 0.01\n#     #config.model_type = 'br_vicreg'\n#     #config.arch = 'cnn_lr_cifar_resnet18'\n\n#     pretty_print_ns(config)\n#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n\n\n# dls = get_ssl_dls('cifar10', bs=32, size=32, device=default_device())\n# aug = get_bt_aug_pipelines('bt_predhalf_aug_pipelines', 32)\n# show_bt_batch(dls, n_in=3, aug=aug, n=10, print_augs=True)",
    "crumbs": [
      "base_model"
    ]
  },
  {
    "objectID": "isic_dataloading.html",
    "href": "isic_dataloading.html",
    "title": "isic_dataloading",
    "section": "",
    "text": "source\n\ncleanup_and_move_files\n\n cleanup_and_move_files (target_dir, unwanted_prefix)\n\n*Moves files from nested directories to the target directory and removes empty directories.\nParameters: - target_dir: Target directory where files should ultimately reside. - unwanted_prefix: Prefix to identify unwanted nested directories for removal.*\n\nsource\n\n\nunzip_and_cleanup\n\n unzip_and_cleanup (zip_file_path, target_dir)\n\n*Unzips the dataset files and cleans up the directory structure by removing a hardcoded unwanted prefix.\nParameters: - zip_file_path: Full path to the zip file. - target_dir: Directory where the files will be extracted to and cleaned up.*\nExample on google colab.\nMain dataloader functions:\n\nsource\n\n\nget_bt_isic_train_dls\n\n get_bt_isic_train_dls (bs, size, device, pct_dataset=1.0, num_workers=12)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbs\n\n\n\n\n\nsize\n\n\nnot needed\n\n\ndevice\n\n\n\n\n\npct_dataset\nfloat\n1.0\n\n\n\nnum_workers\nint\n12\n\n\n\n\n\nsource\n\n\nget_supervised_isic_train_dls\n\n get_supervised_isic_train_dls (bs, dataset_dir, size=None, device='cpu',\n                                pct_dataset=1.0, num_workers=12)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbs\n\n\n\n\n\ndataset_dir\n\n\nAdded parameter for dataset directory\n\n\nsize\nNoneType\nNone\npreset by default to 256.\n\n\ndevice\nstr\ncpu\n\n\n\npct_dataset\nfloat\n1.0\n\n\n\nnum_workers\nint\n12\n\n\n\n\n\nsource\n\n\nget_supervised_isic_test_dls\n\n get_supervised_isic_test_dls (bs, dataset_dir, size=None, device='cpu',\n                               pct_dataset=1.0, num_workers=12)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbs\n\n\n\n\n\ndataset_dir\n\n\nAdded parameter for dataset directory\n\n\nsize\nNoneType\nNone\npreset by default to 256.\n\n\ndevice\nstr\ncpu\n\n\n\npct_dataset\nfloat\n1.0\n\n\n\nnum_workers\nint\n12",
    "crumbs": [
      "isic_dataloading"
    ]
  },
  {
    "objectID": "ufes_dataloading.html",
    "href": "ufes_dataloading.html",
    "title": "ufes_dataloading",
    "section": "",
    "text": "source\n\nget_bt_ufes_train_dls\n\n get_bt_ufes_train_dls (bs, size, device, pct_dataset=1.0, num_workers=12)\n\n\nsource\n\n\nlabel_func\n\n label_func (x)",
    "crumbs": [
      "ufes_dataloading"
    ]
  },
  {
    "objectID": "oralcancer_dataloading.html",
    "href": "oralcancer_dataloading.html",
    "title": "oralcancer_dataloading",
    "section": "",
    "text": "Unzip example\nMain dataloader functions:\n\nsource\n\nget_bt_oralcancer_train_dls\n\n get_bt_oralcancer_train_dls (bs, size, device, pct_dataset=1.0,\n                              num_workers=12)\n\n\nsource\n\n\nget_supervised_oralcancer_test_dls\n\n get_supervised_oralcancer_test_dls (bs, dataset_dir, size=256,\n                                     device='cpu', pct_dataset=1.0,\n                                     num_workers=12)\n\n\nsource\n\n\nget_supervised_oralcancer_train_dls\n\n get_supervised_oralcancer_train_dls (bs, dataset_dir, size=256,\n                                      device='cpu', pct_dataset=1.0,\n                                      num_workers=12)\n\n\nsource\n\n\nlabel_func\n\n label_func (x)",
    "crumbs": [
      "oralcancer_dataloading"
    ]
  },
  {
    "objectID": "dermnetufes_dataloading.html",
    "href": "dermnetufes_dataloading.html",
    "title": "dermnetufes_dataloading",
    "section": "",
    "text": "source\n\nget_bt_dermnetufes_train_dls\n\n get_bt_dermnetufes_train_dls (bs, size, device, pct_dataset=1.0,\n                               num_workers=12)\n\n\nsource\n\n\nlabel_func\n\n label_func (x)",
    "crumbs": [
      "dermnetufes_dataloading"
    ]
  }
]