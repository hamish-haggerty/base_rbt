{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_supervised\n",
    "> API needed for linear evaluation protocol, and semi-supervised learning (k-nn?) Also includes test set evaluation.\n",
    "\n",
    "All we require here is the following: \n",
    "\n",
    "- an `encoder` (already pretrained)\n",
    "- a training set (for fine tuning), `dls`\n",
    "- possibly: a test set (for evaluation) `dls_test`\n",
    "- augmentations, generally pretty standard but e.g. cifar vs mnist will be different.\n",
    "\n",
    "The general API will involve:\n",
    "\n",
    "- i) running learning rate finder\n",
    "- ii) training using 1cycle policy and the lr found in a)\n",
    "\n",
    "Designed to be extensible and work with any encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import self_supervised\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import kornia.augmentation as korniatfm\n",
    "import torchvision.transforms as tvtfm\n",
    "from base_rbt.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API:\n",
    "\n",
    "\n",
    "- Train and then test linear head. Requires inputs: encoder, dls_val, augpipe_val, indim,outdim, num_epochs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Batch level augmentations for linear classifier. At present time, just RandomResizedCrop and Normalization.\n",
    "def get_linear_batch_augs(size,resize=True,\n",
    "                    resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),\n",
    "                    stats=None,cuda=default_device().type == 'cuda',xtra_tfms=[]):\n",
    "    \n",
    "    \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    tfms = []\n",
    "    if resize:tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "    if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "    tfms += xtra_tfms\n",
    "    pipe = Pipeline(tfms, split_idx = 0)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model for linear evaluation and semi-supervised learning requires an encoder and a (randomly)\n",
    "initialised head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#Linear model \n",
    "# class LinearModel(Module):\n",
    "#     \"\"\"Linear model\n",
    "#     \"\"\"\n",
    "#     def __init__(self,encoder,\n",
    "#                  indim=1024,#dimension of encoder output\n",
    "#                  outdim=10, #number of classes\n",
    "#                 ):\n",
    "#         self.encoder=encoder\n",
    "#         self.L = nn.Linear(indim,outdim)\n",
    "        \n",
    "#         if torch.cuda.is_available():\n",
    "#             self.L.to('cuda')\n",
    "        \n",
    "#     def forward(self,x):return self.L(self.encoder(x))\n",
    "\n",
    "\n",
    "class LM(nn.Module):\n",
    "    \"Basic linear model\"\n",
    "    def __init__(self,encoder,numout,enc_dim=2048):\n",
    "        super().__init__()\n",
    "        self.encoder=encoder\n",
    "        self.head=nn.Linear(enc_dim,numout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.head(self.encoder(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'callback' for linear evaluation is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# class LinearBt(Callback):\n",
    "#     order,run_valid = 9,True\n",
    "#     def __init__(self,aug_pipelines,n_in, show_batch=False, print_augs=False,data=None):\n",
    "#         assert_aug_pipelines(aug_pipelines)\n",
    "#         self.aug1= aug_pipelines[0]\n",
    "#         self.aug2=Pipeline( split_idx = 0) #empty pipeline\n",
    "#         if print_augs: print(self.aug1), print(self.aug2)\n",
    "#         self.n_in=n_in\n",
    "#         self._show_batch=show_batch\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "#         self.data=data #if data is just e.g. 20 samples then don't bother re-loading each time\n",
    "        \n",
    "#     def before_fit(self): \n",
    "#         self.learn.loss_func = self.lf\n",
    "            \n",
    "#     def before_batch(self):\n",
    "\n",
    "#         if self.n_in == 1:\n",
    "#             xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))                            \n",
    "#         elif self.n_in == 3:\n",
    "#             xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "#         self.learn.xb = (xi,)\n",
    "\n",
    "#         if self._show_batch:\n",
    "#             self.learn.aug_x = torch.cat([xi, xj])\n",
    "\n",
    "#     def lf(self, pred, *yb):        \n",
    "#         loss=self.criterion(pred,self.y)\n",
    "#         return loss\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def show(self, n=1):\n",
    "#         if self._show_batch==False:\n",
    "#             print('Need to set show_batch=True')\n",
    "#             return\n",
    "#         bs = self.learn.aug_x.size(0)//2\n",
    "#         x1,x2  = self.learn.aug_x[:bs], self.learn.aug_x[bs:]\n",
    "#         idxs = np.random.choice(range(bs),n,False)\n",
    "#         x1 = self.aug1.decode(x1[idxs].to('cpu').clone(),full=False).clamp(0,1) #full=True / False\n",
    "#         x2 = self.aug2.decode(x2[idxs].to('cpu').clone(),full=False).clamp(0,1) #full=True / False\n",
    "#         images = []\n",
    "#         for i in range(n): images += [x1[i],x2[i]]\n",
    "#         return show_batch(x1[0], None, images, max_n=len(images), nrows=n)\n",
    "\n",
    "\n",
    "#A more comprehensive callback, copy pasted from cancer-proj\n",
    "class LinearBt(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self,aug_pipelines,n_in, show_batch=False, print_augs=False,data=None,\n",
    "                 tune_model_path=None,tune_save_after=None):\n",
    "        self.aug1= aug_pipelines[0]\n",
    "        self.aug2=Pipeline( split_idx = 0) #empty pipeline\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        self.n_in=n_in\n",
    "        self._show_batch=show_batch\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.data=data #if data is just e.g. 20 samples then don't bother re-loading each time\n",
    "        self.tune_model_path=tune_model_path\n",
    "        self.tune_save_after = tune_save_after\n",
    "\n",
    "\n",
    "    def after_create(self):\n",
    "        self.learn.tune_model_path_dict = {}\n",
    "        self.learn.tune_model_path=self.tune_model_path\n",
    "\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.learn.loss_func = self.lf\n",
    "            \n",
    "    def before_batch(self):\n",
    "\n",
    "        if self.n_in == 1:\n",
    "            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))                            \n",
    "        elif self.n_in == 3:\n",
    "            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "        self.learn.xb = (xi,)\n",
    "\n",
    "        if self._show_batch:\n",
    "            self.learn.aug_x = torch.cat([xi, xj])\n",
    "\n",
    "            \n",
    "    def after_epoch(self):\n",
    "        \"Usually patched in based on how we want to save\"\n",
    "        \n",
    "        true_epoch = self.epoch+1\n",
    "\n",
    "        \n",
    "        # if true_epoch%self.tune_save_after == 0 and self.learn.tune_model_path!=None:\n",
    "        #     #self.learn.tune_path = self.learn.tune_path +f'_epochs={self.n_epoch//50}'\n",
    "        #     #path = self.learn.tune_model_path + f'_epochs={true_epoch}'\n",
    "            \n",
    "        #     path = self.learn.tune_model_path\n",
    "        #     print(f'We are saving after true epoch {true_epoch} at path {path}')\n",
    "        #     torch.save(self.learn.model.state_dict(), path)\n",
    "        #     #self.learn.tune_model_path_dict[true_epoch]=path\n",
    "\n",
    "\n",
    "    def lf(self, pred, *yb):        \n",
    "        loss=self.criterion(pred,self.y)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1):\n",
    "        if self._show_batch==False:\n",
    "            print('Need to set show_batch=True')\n",
    "            return\n",
    "        bs = self.learn.aug_x.size(0)//2\n",
    "        x1,x2  = self.learn.aug_x[:bs], self.learn.aug_x[bs:]\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone(),full=False).clamp(0,1) #full=True / False\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone(),full=False).clamp(0,1) #full=True / False\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]]\n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage: First inputs needed. In the next cell we get dls_val and dls_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "#Inputs needed: First set hps and get dls_val and dls_test\n",
    "device=default_device().type\n",
    "cuda=(device=='cuda')\n",
    "#hps\n",
    "n_in=3\n",
    "bs=4\n",
    "bs_test=4 #Make sure it divides length of test set\n",
    "trs_len=2*bs #number of training examples\n",
    "tst_len=2*bs_test #num\n",
    "size=32\n",
    "\n",
    "#get the data\n",
    "path = untar_data(URLs.CIFAR)\n",
    "fnames = get_image_files(path / \"train\")\n",
    "fnames=fnames.shuffle()\n",
    "def label_func(fname):\n",
    "    return fname.name.split('_')[1].strip('png').strip('.')\n",
    "\n",
    "labels = [label_func(fname) for fname in fnames]\n",
    "\n",
    "dls_train = ImageDataLoaders.from_lists(path, fnames[0:trs_len], labels[0:trs_len],bs=bs, item_tfms=[Resize(size=size)], #batch_tfms=[ToTensor(), IntToFloatTensor()],\n",
    "                                  valid_pct=0.0,num_workers=0,device=device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dls_test = ImageDataLoaders.from_lists(path, fnames[0:tst_len], labels[0:tst_len],bs=bs_test, item_tfms=[Resize(size=size)], #batch_tfms=[ToTensor(), IntToFloatTensor()],\n",
    "                                  valid_pct=0.0,num_workers=0,device=device)\n",
    "\n",
    "\n",
    "\n",
    "set(labels) #Check that the labels make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentations and learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_linear_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "    bt = LinearBt(aug,show_batch=True,n_in=n_in,print_augs=print_augs)\n",
    "    learn = Learner(dls,model=None, cbs=[bt])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.linear_bt.show(n=n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "# mpl.rc('image', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: RandomResizedCrop -> Normalize -- {'mean': tensor([[[[0.4910]],\n",
      "\n",
      "         [[0.4820]],\n",
      "\n",
      "         [[0.4470]]]]), 'std': tensor([[[[0.2470]],\n",
      "\n",
      "         [[0.2430]],\n",
      "\n",
      "         [[0.2610]]]]), 'axes': (0, 2, 3)}\n",
      "Pipeline: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "aug_pipelines_supervised = [get_linear_batch_augs(size=size,resize=True,stats=cifar_stats,resize_scale=(0.3, 1.0))]\n",
    "show_linear_batch(dls=dls_train,n_in=n_in,n=2,aug=aug_pipelines_supervised,print_augs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to compute e.g. test set accuracy of a given model. We use test time augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_model(xval,yval,model,aug_pipelines_test,numavg=3,criterion = CrossEntropyLossFlat(),deterministic=False):\n",
    "    \"Note that this assumes xval is entire validation set. If it doesn't fit in memory, can't use this guy\"\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    N=xval.shape[0]\n",
    "    \n",
    "    if not deterministic:\n",
    "\n",
    "        probs=0\n",
    "        for _ in range(numavg):\n",
    "\n",
    "            probs += torch.softmax(model(aug_pipelines_test[0](xval)),dim=1) #test time augmentation. This also gets around issue of randomness in the dataloader in each session...\n",
    "\n",
    "        probs *= 1/numavg\n",
    "        \n",
    "    else:\n",
    "        probs = torch.softmax(model(xval),dim=1)\n",
    "\n",
    "    \n",
    "    ypred = cast(torch.argmax(probs, dim=1),TensorCategory)\n",
    "\n",
    "    correct = (ypred == yval)#.type(torch.FloatTensor)\n",
    "\n",
    "    #correct = (torch.argmax(ypred,dim=1) == yval).type(torch.FloatTensor)\n",
    "    num_correct = correct.sum()\n",
    "    accuracy = num_correct/N\n",
    "\n",
    "    #val_loss = criterion(scores,yval)\n",
    "    \n",
    "    return probs,ypred,accuracy.item()#,val_loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_whole_model(dls_test, model, aug_pipelines_test, numavg=3, criterion=CrossEntropyLossFlat(), deterministic=False):\n",
    "    \"\"\"\n",
    "    Predicts the labels and probabilities for the entire test set using the specified model and data augmentation\n",
    "    pipelines. Returns a dictionary containing the labels, probabilities, predicted labels, and accuracy.\n",
    "\n",
    "    Args:\n",
    "        dls_test: The test dataloader.\n",
    "        model: The trained model.\n",
    "        aug_pipelines_test: The test data augmentation pipelines.\n",
    "        numavg: The number of times to perform test-time augmentation.\n",
    "        criterion: The loss function to use for computing the accuracy.\n",
    "        deterministic: Whether to use deterministic computation.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the labels, probabilities, predicted labels, and accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_len = len(dls_test.dataset)\n",
    "    y = torch.zeros(total_len, dtype=torch.long)\n",
    "    probs = torch.zeros(total_len, model.head.out_features)\n",
    "    ypred = torch.zeros(total_len, dtype=torch.long)\n",
    "\n",
    "    start_idx = 0\n",
    "    for xval, yval in dls_test.train:\n",
    "        end_idx = start_idx + len(xval)\n",
    "        _probs, _ypred, acc = predict_model(xval, yval, model, aug_pipelines_test, numavg, criterion, deterministic)\n",
    "        y[start_idx:end_idx] = yval\n",
    "        probs[start_idx:end_idx] = _probs\n",
    "        ypred[start_idx:end_idx] = _ypred\n",
    "        start_idx = end_idx\n",
    "\n",
    "    # Calculate the overall accuracy\n",
    "    acc = (ypred == y).float().mean().item()\n",
    "\n",
    "    # Return the predictions and labels in a dictionary\n",
    "    #return {'y': y, 'probs': probs, 'ypred': ypred, 'acc': acc}\n",
    "    return y,probs,ypred,acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This enables us to freeze the encoder as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encoder_head_splitter(m):\n",
    "    return L(sequential(*m.encoder),m.head).map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SupervisedLearning` allows us to perform either linear evaluation or semi-supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SupervisedLearning:\n",
    "    \"Train model using supervised learning. Either linear evaluation or semi-supervised.\"\n",
    "\n",
    "    def __init__(self,encoder,device,config):\n",
    "\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.device = device\n",
    "        \n",
    "        for key, value in vars(config).items():\n",
    "            setattr(self, key, value)\n",
    "        \n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    \n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics.\n",
    "\n",
    "        Returns:\n",
    "        - learn: The Learner object.\n",
    "        \"\"\"\n",
    "        # Setup the model: encoder + head\n",
    "        model = LM(encoder=self.encoder, enc_dim=self.enc_dim, numout=len(self.dls_train.vocab))\n",
    "        model.to(self.device)\n",
    "\n",
    "        # Setup the learner with callbacks and metrics\n",
    "        bt = LinearBt(aug_pipelines=self.aug_pipelines_supervised, show_batch=True, n_in=self.n_in, print_augs=True)\n",
    "        learn = Learner(self.dls_train, model, splitter=encoder_head_splitter,cbs=[bt],wd=self.wd, metrics=accuracy)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def supervised_learning(self,epochs:int=1):\n",
    "\n",
    "        test_grad_on(self.learn.model.encoder)\n",
    "        test_grad_on(self.learn.model.head)\n",
    "        lrs = self.learn.lr_find()\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley)\n",
    "        return self.learn.model\n",
    "    \n",
    "    def linear_evaluation(self,epochs:int=1):\n",
    "\n",
    "        self.learn.freeze() #freeze encoder\n",
    "        test_grad_off(self.learn.model.encoder)\n",
    "        lrs = self.learn.lr_find() #find learning rate\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley) #fit head\n",
    "        return self.learn.model\n",
    "\n",
    "    def semi_supervised(self,freeze_epochs:int=1,epochs:int=1):\n",
    "\n",
    "        self.learn.freeze() #freeze encoder\n",
    "        test_grad_off(self.learn.model.encoder)\n",
    "        self.learn.fit(freeze_epochs) #fit head for (typically one) epoch\n",
    "        self.learn.unfreeze() #unfreeze encoder\n",
    "        test_grad_on(self.learn.model)\n",
    "        lrs = self.learn.lr_find() #find learning rate\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley) #fit all\n",
    "        return self.learn.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full example of how to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# encoder = create_fastai_encoder(xresnet18(),pretrained=False,n_in=n_in) #Need an encoder (this will be trained by BT)\n",
    "# enc_dim=1024\n",
    "\n",
    "# hp_dict = {'dls_train':dls_train,'dls_test':dls_test, 'aug_pipelines_supervised':aug_pipelines_supervised,'n_in':n_in,'wd':0, 'enc_dim':enc_dim}\n",
    "\n",
    "\n",
    "# supervised = SupervisedLearning(encoder=encoder,hp_dict=hp_dict)\n",
    "# model = supervised.linear_evaluation(epochs=1)\n",
    "# y,probs,ypred,acc = predict_whole_model(dls_test, model, aug_pipelines_supervised, numavg=3, criterion=CrossEntropyLossFlat(), deterministic=False)\n",
    "\n",
    "# supervised = SupervisedLearning(encoder=encoder,hp_dict=hp_dict)\n",
    "# model = supervised.semi_supervised(freeze_epochs=2,epochs=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One we have a trained model, making predictions and measuring performance on test set is straightforward:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#y,probs,ypred,acc = predict_whole_model(dls_test, model, aug_pipelines_supervised, numavg=3, criterion=CrossEntropyLossFlat(), deterministic=False)\n",
    "#print(f\"Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
