{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_supervised\n",
    "> API needed for linear evaluation protocol, and semi-supervised learning (k-nn?) Also includes test set evaluation.\n",
    "\n",
    "All we require here is the following: \n",
    "\n",
    "- an `encoder` (already pretrained)\n",
    "- a training set (for fine tuning), `dls`\n",
    "- possibly: a test set (for evaluation) `dls_test`\n",
    "- augmentations, generally pretty standard but e.g. cifar vs mnist will be different.\n",
    "\n",
    "The general API will involve:\n",
    "\n",
    "- i) running learning rate finder\n",
    "- ii) training using 1cycle policy and the lr found in a)\n",
    "\n",
    "Designed to be extensible and work with any encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import self_supervised\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import kornia.augmentation as korniatfm\n",
    "import torchvision.transforms as tvtfm\n",
    "\n",
    "from base_rbt.helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API:\n",
    "\n",
    "\n",
    "- Train and then test linear head. Requires inputs: encoder, dls_val, augpipe_val, indim,outdim, num_epochs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Batch level augmentations for linear classifier. At present time, just RandomResizedCrop and Normalization.\n",
    "def get_linear_batch_augs(size,resize=True,\n",
    "                    resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),\n",
    "                    stats=None,cuda=default_device().type == 'cuda',xtra_tfms=[]):\n",
    "    \n",
    "    \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    tfms = []\n",
    "    if resize:tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "    if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "    tfms += xtra_tfms\n",
    "    pipe = Pipeline(tfms, split_idx = 0)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model for linear evaluation and semi-supervised learning requires an encoder and a (randomly)\n",
    "initialised head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#Linear model \n",
    "# class LinearModel(Module):\n",
    "#     \"\"\"Linear model\n",
    "#     \"\"\"\n",
    "#     def __init__(self,encoder,\n",
    "#                  indim=1024,#dimension of encoder output\n",
    "#                  outdim=10, #number of classes\n",
    "#                 ):\n",
    "#         self.encoder=encoder\n",
    "#         self.L = nn.Linear(indim,outdim)\n",
    "        \n",
    "#         if torch.cuda.is_available():\n",
    "#             self.L.to('cuda')\n",
    "        \n",
    "#     def forward(self,x):return self.L(self.encoder(x))\n",
    "\n",
    "\n",
    "class LM(nn.Module):\n",
    "    \"Basic linear model\"\n",
    "    def __init__(self,encoder,numout,enc_dim=2048):\n",
    "        super().__init__()\n",
    "        self.encoder=encoder\n",
    "        self.head=nn.Linear(enc_dim,numout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.head(self.encoder(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'callback' for linear evaluation is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# class LinearBt(Callback):\n",
    "#     order,run_valid = 9,True\n",
    "#     def __init__(self,aug_pipelines,n_in, show_batch=False, print_augs=False,data=None):\n",
    "#         assert_aug_pipelines(aug_pipelines)\n",
    "#         self.aug1= aug_pipelines[0]\n",
    "#         self.aug2=Pipeline( split_idx = 0) #empty pipeline\n",
    "#         if print_augs: print(self.aug1), print(self.aug2)\n",
    "#         self.n_in=n_in\n",
    "#         self._show_batch=show_batch\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "#         self.data=data #if data is just e.g. 20 samples then don't bother re-loading each time\n",
    "        \n",
    "#     def before_fit(self): \n",
    "#         self.learn.loss_func = self.lf\n",
    "            \n",
    "#     def before_batch(self):\n",
    "\n",
    "#         if self.n_in == 1:\n",
    "#             xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))                            \n",
    "#         elif self.n_in == 3:\n",
    "#             xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "#         self.learn.xb = (xi,)\n",
    "\n",
    "#         if self._show_batch:\n",
    "#             self.learn.aug_x = torch.cat([xi, xj])\n",
    "\n",
    "#     def lf(self, pred, *yb):        \n",
    "#         loss=self.criterion(pred,self.y)\n",
    "#         return loss\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def show(self, n=1):\n",
    "#         if self._show_batch==False:\n",
    "#             print('Need to set show_batch=True')\n",
    "#             return\n",
    "#         bs = self.learn.aug_x.size(0)//2\n",
    "#         x1,x2  = self.learn.aug_x[:bs], self.learn.aug_x[bs:]\n",
    "#         idxs = np.random.choice(range(bs),n,False)\n",
    "#         x1 = self.aug1.decode(x1[idxs].to('cpu').clone(),full=False).clamp(0,1) #full=True / False\n",
    "#         x2 = self.aug2.decode(x2[idxs].to('cpu').clone(),full=False).clamp(0,1) #full=True / False\n",
    "#         images = []\n",
    "#         for i in range(n): images += [x1[i],x2[i]]\n",
    "#         return show_batch(x1[0], None, images, max_n=len(images), nrows=n)\n",
    "\n",
    "\n",
    "#A more comprehensive callback, copy pasted from cancer-proj\n",
    "class LinearBt(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self,aug_pipelines,n_in, show_batch=False, print_augs=False,data=None,\n",
    "                 tune_model_path=None,tune_save_after=None):\n",
    "        self.aug1= aug_pipelines[0]\n",
    "        self.aug2=Pipeline( split_idx = 0) #empty pipeline\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        self.n_in=n_in\n",
    "        self._show_batch=show_batch\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.data=data #if data is just e.g. 20 samples then don't bother re-loading each time\n",
    "        self.tune_model_path=tune_model_path\n",
    "        self.tune_save_after = tune_save_after\n",
    "\n",
    "\n",
    "    def after_create(self):\n",
    "        self.learn.tune_model_path_dict = {}\n",
    "        self.learn.tune_model_path=self.tune_model_path\n",
    "\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.learn.loss_func = self.lf\n",
    "            \n",
    "    def before_batch(self):\n",
    "\n",
    "        if self.n_in == 1:\n",
    "            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))                            \n",
    "        elif self.n_in == 3:\n",
    "            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "        self.learn.xb = (xi,)\n",
    "\n",
    "        if self._show_batch:\n",
    "            self.learn.aug_x = torch.cat([xi, xj])\n",
    "\n",
    "            \n",
    "    def after_epoch(self):\n",
    "        \"Usually patched in based on how we want to save\"\n",
    "        \n",
    "        true_epoch = self.epoch+1\n",
    "\n",
    "        \n",
    "        # if true_epoch%self.tune_save_after == 0 and self.learn.tune_model_path!=None:\n",
    "        #     #self.learn.tune_path = self.learn.tune_path +f'_epochs={self.n_epoch//50}'\n",
    "        #     #path = self.learn.tune_model_path + f'_epochs={true_epoch}'\n",
    "            \n",
    "        #     path = self.learn.tune_model_path\n",
    "        #     print(f'We are saving after true epoch {true_epoch} at path {path}')\n",
    "        #     torch.save(self.learn.model.state_dict(), path)\n",
    "        #     #self.learn.tune_model_path_dict[true_epoch]=path\n",
    "\n",
    "\n",
    "    def lf(self, pred, *yb):        \n",
    "        loss=self.criterion(pred,self.y)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1):\n",
    "        if self._show_batch==False:\n",
    "            print('Need to set show_batch=True')\n",
    "            return\n",
    "        bs = self.learn.aug_x.size(0)//2\n",
    "        x1,x2  = self.learn.aug_x[:bs], self.learn.aug_x[bs:]\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone(),full=False).clamp(0,1) #full=True / False\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone(),full=False).clamp(0,1) #full=True / False\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]]\n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage: First inputs needed. In the next cell we get dls_val and dls_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "#Inputs needed: First set hps and get dls_val and dls_test\n",
    "device=default_device().type\n",
    "cuda=(device=='cuda')\n",
    "#hps\n",
    "n_in=3\n",
    "bs=4\n",
    "bs_test=4 #Make sure it divides length of test set\n",
    "trs_len=2*bs #number of training examples\n",
    "tst_len=2*bs_test #num\n",
    "size=32\n",
    "\n",
    "#get the data\n",
    "path = untar_data(URLs.CIFAR)\n",
    "fnames = get_image_files(path / \"train\")\n",
    "fnames=fnames.shuffle()\n",
    "def label_func(fname):\n",
    "    return fname.name.split('_')[1].strip('png').strip('.')\n",
    "\n",
    "labels = [label_func(fname) for fname in fnames]\n",
    "\n",
    "dls_train = ImageDataLoaders.from_lists(path, fnames[0:trs_len], labels[0:trs_len],bs=bs, item_tfms=[Resize(size=size)], #batch_tfms=[ToTensor(), IntToFloatTensor()],\n",
    "                                  valid_pct=0.0,num_workers=0,device=device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dls_test = ImageDataLoaders.from_lists(path, fnames[0:tst_len], labels[0:tst_len],bs=bs_test, item_tfms=[Resize(size=size)], #batch_tfms=[ToTensor(), IntToFloatTensor()],\n",
    "                                  valid_pct=0.0,num_workers=0,device=device)\n",
    "\n",
    "\n",
    "\n",
    "set(labels) #Check that the labels make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentations and learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_linear_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "    bt = LinearBt(aug,show_batch=True,n_in=n_in,print_augs=print_augs)\n",
    "    learn = Learner(dls,model=None, cbs=[bt])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.linear_bt.show(n=n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "# mpl.rc('image', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: RandomResizedCrop -> Normalize -- {'mean': tensor([[[[0.4910]],\n",
      "\n",
      "         [[0.4820]],\n",
      "\n",
      "         [[0.4470]]]]), 'std': tensor([[[[0.2470]],\n",
      "\n",
      "         [[0.2430]],\n",
      "\n",
      "         [[0.2610]]]]), 'axes': (0, 2, 3)}\n",
      "Pipeline: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAHiCAYAAADbK6SdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9/UlEQVR4nO3deZBd53nf+eecu/Xtvr13A43GQuwgBBKkuGihRMayZUqUZVu2a2KNnYxT46QyVRlXZRnF0jjJVGbGU65UTcYVe2KPncSliuJKxlO2tdiSrMW0KFpcJS4AsZBYiK0BNBq99+2+yznzB+1yqvz8Xt2+aOIFiO/nz/fFc+/pc889D27V85wnyfM8NwAAEE0a+wAAALjTkYwBAIiMZAwAQGQkYwAAIiMZAwAQGckYAIDISMYAAERGMgYAIDKSMQAAkRU7/YdJkrydx4FbULXXX//J/1bHPPFxf/0D79cxOzd3fky3v9vrgXf/1//yv8u9LPf/L99u6b9xebnurs/Mz8iYxcUF//2zTMYUCgV3vVQuyZhSSd/jSkX/VpmW9S200NN213sHZIhVB/zzU601ZUxPVf+mKiQ97nreHpQxeeZ/8Uupf2xmZiP98+76poHZQIz/esWi/nsW1ypy7/pC2V2vr/jrZmZlcX7Gavp9ajX/uivV/M/bzGzX4d+Qe3+JX8YAAERGMgYAIDKSMQAAkZGMAQCIjGQMAEBkJGMAACLruLUJd576ir8+dUzHXN3vr89t1zHL/f56n2itws1TTPX/19stf73V0i0ejfqqu766vCRj6iuL/kagS6xY8luYUtPtUEnodihaO4tNfRCtlv9erTV9DKur/vlpZw0ZUwm0AlVr/noh8DuslYqWrIJ/bGZmI2X/M+ozfdztNf+crqzpVqSFhv6M1jK/na0t/h4zszxd82MCrbxN9XKZfp9O8MsYAIDISMYAAERGMgYAIDKSMQAAkZGMAQCIjGpqrNuxP9d7u8f99R0jOkbMG7Dde3XMoKjAxsZqrulq4bU1v7p2cVFUP5vZ9evX3PWZmWkZsyLK+kuiYtrMrFqt+jFFv+LWzKyQ6eEAuajUzTP9eybP/arpZmCQRjMXt+SiX/VrZtZb1RXLgwN+VXBfb2C4RMXf6y/o9xkyv7S+nOrzvWr+kIZFca7NzFYK+jNfLflV2K1Mn+9MVEAna6JVwMxW2v7nOnCD2ZRfxgAAREYyBgAgMpIxAACRkYwBAIiMZAwAQGQkYwAAIqO1Ces2Fdj7/Of99UXdmWG7zvnrd9+vYx46pPcOHdB7WJ8LF/WnXV/zhzssrczLmBnR2jS/cF3G5KI1pafity+ZmSW537JSDgy+KKW6bcZSv0UoN92Go8ZBtDM9hKDd9I8hb+lb9XJZD55oihbAYqC1aaDkn+9aIFuUMn8zLeqgUuq3kpVb+nOoNwODS8RwBzGPwszMVsTrrS7roLL4ZNeauvWrE/wyBgAgMpIxAACRkYwBAIiMZAwAQGQkYwAAIqOaGhtKPe7/v3xFx3ygz18vbBmQMUPDehjBoXHxYPjAsAr4jp56Ve61m/6giCTTD9lPzP9symVdvdps+dWr7bauXm2u1t31RqBiupDo3yZZu+mupyV9C00K/uvp2mc9XKIRqMBevKb/psU+f3hCf1kfd7HgVzknFf0+pYp/fD0V/7yZmVVE1XZRnAMzs0IjVBotznfTPwdmZitN//UWF/T7JG2/NWSlrq/7TvDLGACAyEjGAABERjIGACAykjEAAJGRjAEAiIxkDABAZLQ2vaMM65173u+u9w5NypiLx2b8jZmvBo5hJbDne+7Uw+76PR/cK2OuLp2Xe8dOfdddP1gMHJvuorqjvfHmKblXK/stI+N9NRkzVO31N8pi3cyW1vwWqtVV3dpUF61NmRg6YWZWFy0rZmbFit/uUyzqdp9i2Y9JA8Mq8kS1fulb9dysbt1JxPCERkufh74lvx1pbFgPxaiM9fiv1avfp9Ljf67lVMfkBd1y1Mj889Bc1eenLa6H1UbgOqn7e/U1HdMJfhkDABAZyRgAgMhIxgAAREYyBgAgMpIxAACRUU19yxpyV3/y5z6tI7bvkXv/4Tf/P3d99si/W9dRvR2aL/lVzlMf/REZs7xzXO79/pP+39rzpedkzGjPWXd9sNevyjUzGx73q3kHxmSIPfC43rsVra7oimVR+GsDVf2g/5aoXi209THkbb+Ctt3SQfWWf9xLDb+C18wsaejfJsWSX5FbKvoV02ZmRbE3MqovkH2H73bXN01ukzHLi3oYw+nTZ931mXO68ve+sbvc9XpzQcYsLM666wMVnWJ6K34FfVrWn0M18PNxIPWvh2YhUHUvXi8PjPNotfzznWc39tuWX8YAAERGMgYAIDKSMQAAkZGMAQCIjGQMAEBkJGMAACKjtSkq/X+h8T2fcNdPvKnbGI5+9rOB9/pSh8cUw1F39Qu/8ikZ8QV7KPB6z4r1q50f0l/wH3//lnfv8tfvPaxj/p/brLUpM90CsySGMVya1y1HSw2/ja1HtA6ZmeWiHaohWkzMzFq535oS+nuyNd3OkjX8v7XWPyJjHjzsX6OP/cAPyphW7g+e+KM//rqMuXThitybn59315st3eK1e98D7vpAnx7c8tqZN9z1Y2/4729mllrLXe8JtBMe2K3vmZNjfgtT3rMoY5bFfJJqnwwxy/3rO2nroSGd4JcxAACRkYwBAIiMZAwAQGQkYwAAIiMZAwAQWZLnuS4v/K//YeI/rB3dO3hID304eWHJXW/P/0bgFQNP28dN88iE3nt6qqOv2y1j08io3MtVVWmqq5KLRf///8XA/aVULPgxqb9uZlYu+ZWtlaKueM1Mv95a0//cHnjPB2XMI4992F0/euK0jHnm2e+462dOvy5j7r9fl+9Pbt3krn/ta1+VMdWaP4RlYpMeVtErTmtfya+eNzPbsskP2r+3KmMO7euXe9s2+xX5eaKPYantV+SvNvQ13Fz1j3utro/7R3/2t+XeX+KXMQAAkZGMAQCIjGQMAEBkJGMAACIjGQMAEBnJGACAyBgUcVPsc1ePHX0xEPO1t+dQotkS2Ju6aUdxM6zorojbTprqlqNM/J1Jov+Pr2LqYmiAmVkj81uoeksVGVMp+MddCrQvhQwN+y1Ce+86IGNOHPPbkb71radlTH3Nb8MZHhmWMefPX5B78/Oz7vov/dI/kzGvvHrMXT/y8ksy5sBB/x63tqKHs/SKLqVWrgeATF33/x4zs3rL/8xHBvX1ONDr740OyhCzIX956Qa/+PwyBgAgMpIxAACRkYwBAIiMZAwAQGQkYwAAIiMZAwAQGa1NN8Gv/c+fd9eXaroU/jP/8lf8jbXPbcQh3XS//aUX5N7f+/l/7m9c+Q9v09G8vV7S3Ry3nf7+Xrm3tORPFgsNgsszf08svxWT+JtruW6HSrKGvx6Y9JSabql56F0Puus//cmfkzFDk/652//FvTLmt3/zd9z1a9OLMiYLnLwtE/4Isfc89H4Zc/z4JXf90Ud+UMZMjvS468eO+NeImdnirH/cM3P+Z2dmdup8Xe6NDq+669sndHvets197vrWTbptrlYTk8dKtDYBAHBbIxkDABAZyRgAgMhIxgAAREYyBgAgMqqpN8j/+IO/q/d++eC6X+/Tn/mP7vq7f+KwjHnpD//put/nZvm7PzIp9/7Pu/3KzuNXTgZecUjuvGvCf8r7yctflzEtuxJ4rzvX6Oio3Gu1/GrmlRV/2IGZWSYmRSS64NXytl9128xC1dRqQ79Puacq9yZ23O2u55meKJC2/Arjn/rYT8uYvFFy13/t139Vxly9fFnuTV+ddtf/yT/5RRkzOrzVXf/Rxx+XMVfOHnXX+0s1GdMWVff1lj8YxMxsZa4s987N+OlsZkpXyV8S82u2b9MV3ZvG/Yr8ao+uwNZ37b/CL2MAACIjGQMAEBnJGACAyEjGAABERjIGACAykjEAAJHR2rRB9h3+kZvyPt/7g0/Jve336JaAC0c/83YcTseSUO+K9IDceeLRfyT3rrz0ZXe9HRgEAN/goG7dmZ+fd9dXV/0H9pvpIRJJqOeoi58M7dR/vZWmvgZGNm2Xe/Xmmrv+pS/715qZ2Yc/8jfc9V0HRmTM4Qfuc9f3771HxhQz3VKzedRvU9q222/VMjP75N/8CXd9+0S/jPm9N19x1xdX9WCHnoJ/3IVMD/MoJ7q1aa3tf7bL83qQxoW6GFZxTccMjfj32U2j+hr+qNz5K/wyBgAgMpIxAACRkYwBAIiMZAwAQGQkYwAAIqOaet38/7+8cXFJhywM+OtiuVt/8KVPy72Hd/2W2DmzsQfRFb+y89Ch/0lG/NIv/qTc+19/4Xl3PV/UlZ3w9fT4ww7MzAYG/OraPFdTGsxWVvzPoC0GSJjpSvw8EGOiantiYkKG7N69T+5dmT7vrld6dXXv1h3++Tl+/LiM+eIXv+KuhyrUC4m+jQ8P+X/vgf33y5ixiXF/fasepFGq+QMuri/PyJhapc9dTwO/EdWgETOzREwHSXL9eqJI3tau6Zilef99lmf1gJRO8MsYAIDISMYAAERGMgYAIDKSMQAAkZGMAQCIjGQMAEBktDatm99m8dnf+z0ZcXbqb7nrX3hqdEOO6C89tFPvTRz6BXf98tF/vKHHoD0od37hF19w1//Nr3T3Tjt+Szzw/wytTetVquohBKObht314RHdDrWy5A+XmF1c1DHLDXe9taYfzL9z6353/WNP/LiM6R/fLPfu2rvTXT9wQLdDff2bX3PXL1+ZlTH7du1x159/6jsypljQt/HtO7e46418TsbktuyuNwPnuyhSSWtNtyKtZX67VqEQ+o2oj0F0swVj1PyaNAm0V7X9N1pc1O1nneCXMQAAkZGMAQCIjGQMAEBkJGMAACIjGQMAEBnV1OvWdlcX7OsyYjHzByGYfWQDjuev/ONfPSf3Lh/9nQ19L22TWP9FGfH4j23sEWy5RxzDFzb2fe4E5YqujO7t9YcD9PXqB+anactdX1rWg1auXvFjpq/oIQ17D/rfuULFH4JgZrbqF22bmdnyctNd//wf/qmM6a36gxC2bxPV/mb2uc991l0/d+6UjBnoG5J7H/7hR9z16cUFGbOwcN1dH6npdDE3N+eu6wpnPfQhDwUFKqNlhCqZNrNCoeCvJ/oYUvF6aXZjv235ZQwAQGQkYwAAIiMZAwAQGckYAIDISMYAAERGMgYAIDJam9btUXf1kUc/LCP+9t//wIa9+zeP6L0//erTgcjTG3YMYe9zV0d2H5QRO/1n+ndtYNRvKcH65bl+0H9VtLps2azbofp7e931QjYgY2Ym/dc7fkYf21Jj2l3fvW+XjNm9Tw99OH7idXe9VOiXMVsm/BamF178cxnz7W/9mbteqfjtXWZm5arfnmNmVhsYdNcHN+vjfuY7/vFtm3hCxmzbvtNdP/naazJmrbnmrpcCgy/SVP+tqoUp1Nqk2qjagQ6qXLxenoVasr4/fhkDABAZyRgAgMhIxgAAREYyBgAgMpIxAACRkYwBAIjsjm1tet+uX5B7dz/2N+Tef/P3fspd/1gX3UtHLuq9z33umLv+6tELMuaRB98j9176yg6x479P93a7q4vmt4aYma3l92zoERSb65/sAp+arGNmlqT+BLNKVbfhjI36t5y+sm616R/2fzO0Sv7UKDOzUtFvUxobG5Uxiwvzci8t+G0rs7N+C9VbMWLC28KMjNmzx/+enj6jW4R6empy7+oVfxTV7gObZcziQt1fX9LTuBIx/ajV1tdPa81vbUr0MC4rFvV3u1j0r63QFCi1F7jszVJ/M72xziZ+GQMAEBvJGACAyEjGAABERjIGACAykjEAAJHdAdXU97mrhb4DMmJ2ST+MfPqaXyn6J9/Vp3Luur/+xvElGdNXnXTXd2yTIfZvf/nv680NrZr+oNz5R//sU+76VdPlicVA9WQ3Tr1+ZmNf8E4WqBAttP1q4XLalDE1Ufhbq+nvXLHmV03n5XEZs7jgD6Q4duKEjOnrHZJ7zZYaaqB/z+zY6n9Z52auyZgnPvpxd/1rX5chtn//u+TeieMv+Bv5IRnTXxly1y9f9M+BmVml5p/vhfqsjCmu+ZXRaRKofk71+c78yzFYTS2HSASGS6hbWRqK6QC/jAEAiIxkDABAZCRjAAAiIxkDABAZyRgAgMhIxgAARPaOb20aq77XXX/4scdlzM7DO+VeueSfsmef1mX/T//ZcXf93nt0e0Ffv///pONHTskYs28E9jZOtefdcu8f/EO/JeuEaO8yM7umOj0G13FQ/5VCqdJdIP6aap8e+tBb8Vs5SoHbSppX3fWeVH9mpV7RVlTRLVSvvfodd30g0L70+A/rlr1Tp0666/19/lAFM7N2yx/S0FjTAxd27fYHXDzx0U/ImNz0eVhb8794Lzz/lIw5+C7/vnT86PdkTKHst1Ad2KeP7egLfmtnZnpoSFG0L5mZFcSwCtm+ZHq4RFHc583MCql4n5TWJgAAbmskYwAAIiMZAwAQGckYAIDISMYAAETWcTX1o35RspmZlUTB3OKMjnn+zU7f+cbc/8G97vqn/4VftWhmtnmzfr0jZ/310yd1NejogP9e731In/5vfNOvuHzyi/9axtwsvWN+RayZ2Z7R9a2bmf2r33vdXZ++uEnGfPIxXWr94Hsf8Td+U7+e2dXA3p1rfEJXC5dFBXSjrSd/rK76ldGNmq5ELZX8vVp1UcaMb/bfZ2Ve/z3Xr1+Re9PT/vCRdqa7KObn/NLfalWXBK+uzLnrpcCAhNNnzsu9rZN+d8NC3X8fM7NS2R/MMTyoBy5MTT3vru/dq8/3i8/6566+5r+/mVna1JXo5YJ/3ZWLgUr9ov9e5aa+hksl8T7lG5t4wy9jAAAiIxkDABAZyRgAgMhIxgAAREYyBgAgMpIxAACRddza9L736L1hVTnuPyfdzMz2iHkH//mPOj2iznzkiUfd9VD7UkgmqvsXFnWLw9Ej/gPWxyc+IGOee049yD00KOLmmLnsPyjdzGxBrA8EXm/2mt/qsTp7QQcFWpta8v+YN9Z6cCeamNQP+p9f9tevr+rz3J72W0nquW6bGR7yW5t6A0MaJif8K+6qnnth169dlHtZ22+pabf1Te7atH98w0P621AqZe56peKvm5mNj+nvwtzctHgf/R0+dfqou75tXA9w2L9vp7t+fupFGdMUbWGra/paKOrDtnbq30fywHCJrOWf1zzwPrm6hgLv0wl+GQMAEBnJGACAyEjGAABERjIGACAykjEAAJF1XE19zz16b8uwv14NFK9OHPTXl2o65gW/yM8SXWhoY5uH3PVrgSEWlT69d/Wyv744p19w+opfFbwwq4cTNFaXxI442WZmdi6wt4Fa6tjMvvWkv/7xH9AvtzTtV8suZ4Fy/IA1Uw+a18MI4Bsc1F/i+qpfPjqzIsqszWx5wb/lLK/oz2Z5xa+uHRvRvyVWlvxjKxb0zaJU0JXjebbqrhdSXfmbqes3UKqbJGIIQY+OGR3T1dm9df/1lpb1Z7Rt2xZ3fXVxVsakiT8J5sq0Pj+5ic+iHTinesuaqf/55YH80Cr6pdGtlr4Wmi3/Gm5lDIoAAOC2RjIGACAykjEAAJGRjAEAiIxkDABAZCRjAAAi67i1aedOvTc56a8PDOmY2nV/vRGYKLBtr79+9g1xAGb27LPPuOuXL9wlYya3VOXe9Tl/fenaoowZHfB7pT70gU0yZrj3h9z106+9JmNW6jvkntkXA3vrdVru/Ltf/6673pM+IGPqU36/Ql/vmIx5/U25Za1UPdD+Bp/kfgcq5HoIQUm0+9iqbptZWvJjWk3df5KIlpGkpVrYzBbm/WtqeHBIxswt6PbERsP/flfK+hZa7fH3SsXAdZj4LTWVim5tyjLdFlau9LrreeC70G77e0PDEzLm7Otv+Otn9DCPVss/7nZT9y+1E33cWcGPawfa2ZqZf77TRJ/TUsH/XFdzfT12gl/GAABERjIGACAykjEAAJGRjAEAiIxkDABAZB1XU1cDaXtIPB97TBdiWp8YxpD26Ji5eX/9P/32JRlzeuiz7vqPf+xDMubnf1ZXWn/rW/76m7WtMmbHhF9dWg0U32WNFXe9N1C9+f73/025941vqgrXb+qDMPU36UrDP3/qD9316UtnZcz2nX6VZrWkH7z+739NP7T+yuIvix19ncA3M6O/+EvL/rXYaOvrIy/4wxPywpqMaYuBAo1WRcasiZebuqg7AUqpbuWo9fs3pkpN37AKRb+6t1TS56clKtRLxUA1dVlXHzfW/PPd26OPYXrKr4xu1cZlzJnTp/yNXL/P6Lh/3FdndAV2va7/1rTtX4/Fgr7RqqLpQDG1HC7RbPvrneKXMQAAkZGMAQCIjGQMAEBkJGMAACIjGQMAEBnJGACAyDpubWr5nTZmZpaqiu5A606feJb/oWEd89pJf33xqo5ZvPqku770vmkZM75VtzaVRGV90tQPMO/v9evklxdkiC0vXnTXy0Vd9n9g3x65Vyz8jLv+7HPbZczc/BmxIwYEmNn01efE+pMy5hMTn3HXe8p6UMQL3/59ubfS/lV3XTfCmOnGmjvbhTf1AJSG3zVjpbJuw+kb9G8KfX36d8GAaB/qKem2onrqH8PcnB4GUejRbTOlIf/qyc0fNGBmttrw94ppYFBELgYXBIYQFANDH+YX/c+vXNZtg4O9/rl77Yj/3TYzm5ry7xV336uH4Wye8D+LCxfEhWVmV/Vt2+Zm/US0WteDIjLRelUS14+ZWS4uk3ZbXz+d4JcxAACRkYwBAIiMZAwAQGQkYwAAIiMZAwAQGckYAIDIOm5tCpWUj4thHiO66t9MdCXognKzA3f76wffq2MuHvPXr14TU0bM7NLJh+Te88/55fjHjz8pY9q538N06nV9glaWjrvrQ8O61WRhRv9N7ZU5d72xoF/PTIyosn2BGNWO9LqMSFK/lWFiQreuHNqvm5GeespfHxftdGZml8VpuLE5LLe/1rJuC0kz/9va31uVMQN9fktNT78+0wO1Xne9tzAkY8rDfsxIWcdcuXpd7l26dN5d799UkzHVmt+OlCf6truy7J+HZfH9NTOrVv2/1cwsT/3WnSvX9d/ayv1jePHIERkzOuT/rrvvvt0yZnXVb8naNqFbJ+dndIPi1Wn/bz0/pe8Vl6b9L359WbdXtTL/c03zjtOpH39D0QAA4IaRjAEAiIxkDABAZCRjAAAiIxkDABBZx+Vff/Ki3lPFavqR7GY7xUyDUf1ccauKIs0PPaZjvieeoV7IpmTMyy/o17t88ai7vjT/poxpZkvu+muvLOs3EhXG+/boEzQ4EKrO9j+k8TH9/7E3pwfEjq7ENJsX6/45MDN7+VW/anugpmO29+sKyQ8+4q9fuiJD7Mlv++szd/gEibFhPaAgW/Mro/tKegjBkBgiUejRk2jKBf/10pa+ffVW+tz16ug2GXP07Fm5d/KU/71/5IM7Zcz4Zv/4GnVdEVxfGXXXjx+7JGPagersrdt2uetbth2SMSdf96umF5f1/erA3f59aetO0WpjZisrfiXzphEZYo1FfT0uzvr3svOT+j7yxpSfB85e0FN8ZqbFQIqVwACQDvDLGACAyEjGAABERjIGACAykjEAAJGRjAEAiIxkDABAZB23Nn1JtH6YmZ0WPUxTgc6dd4tq8717dUxDPLt7304dM7vVXy+3dOPVhdO6zWJ5/qy73mroSRqNpv/HnjtzWcZs2eq3OGzfOSFjBgf0Q/1XRNn95NbQg9f9toi6XZAxZrOBPfE+V/0hEhcu6gfgbzug9+65x18v6vkFNvcNvXcnGx/V10e+5n8G1ZIe8NFX8lub0lyPiMmb/uAANQTBzKyZ+re2C+fE5BgzGxjQfWyHDvitUrt35zLGSuf8YwsM0JnY7g+eeOYF/Z1bXR3SLyjaEMfGt8iIB+5/j7t+5uQJGVMb8O8vgUvBem3QXS8W9Bc1Keu2uZFe/zPv66/LmJ5BNbjkqow53ePf4y6d13mjE/wyBgAgMpIxAACRkYwBAIiMZAwAQGQkYwAAIuu4mvrcq4G9M/76+Ys65pIoJH7o3TqmJgo7L4r3NzPLRAV2rVdXTtZ6/AeYm5mlmV+dmOZqQIJZpegfRKulH0aetfzqxCTT1YRpqgY7mPX2+1WfE9t1zH2pX009dUlXMl+87FchtkxXjj/8Xv+h9QcP7pMx09Mn5V5FPEv+hA6xG3vE+zvX5vFhuddY8iugi22/ItjMrNDyr998WVdTl8aG3PWZFT1R4Phrc+76zp36e3/wXfq4K73b3fU80S0js7P9fkzFXzczy9f8K7G+qO8vSUmfh2rF/66eOe53MJiZDR9+wF3/O5/8BzKmXPMHLiS5rkq2VJ1vfY/rKevq/v6Kv1ft1V0mparfnVKp6a6Q4UG/anr3tkBlfQf4ZQwAQGQkYwAAIiMZAwAQGckYAIDISMYAAERGMgYAILKOW5uCxNCHo0/rkFy0HOWBZ20P+89qt9de0TF94lnySVGXz5+7cFzuXb9+1l1v1P3SfjOzaq/fttFX0yX3gzX/afLVim6lSIv6/1a94r1GxvWT3Ftt/4Ht1b5xGdM36P+tJ07olpKhIf+DHRoZkzHFHv35nTqyw13/+lP+g/uhTWx9r9xrrPmtHFlbtynV6/51vRaYnlCu+q07/W1/gISZ2UExSGRwWPS9mVnB9M0nb/jv1W7r4+4VgyxKJf09zRM/5ic+/oSMWWrov2lt1f+MBvt1O1S/aN3pH9RtRZn5e/Mzug0yTfxjWGvp91lp63tmKjqL2nqeiKU1f1jF9t5JGTO5SbSdJvq67wS/jAEAiIxkDABAZCRjAAAiIxkDABAZyRgAgMg2ppq6CyeO+OujupDORsXz1c8EBgAc2i+qBlP9RucunpJ7s3MX3PXG6rSM6e/1q4UHarrScKDmlwb2VEQZupmlBV1dWin4/+/qz3Ql5tKSH1Pt0w/UL4nTOjunH7xeKPrljpWKfp/Jcb9i2szsqS9vdtcbRjX1ep0Tgz/MzNrZ+sdr5LlfDRv6VbA2f81dF5e0mZlV+/zvz/KSfpj/irjezUKVsjomFdXUea6PIcta7nrfoGglMTO9Y7bW8O8XaWDAxWqz7q/P6mEvJv6kRFSHv3UMqhI9MECn7Z+ft97LX8/VwZk87CD1PoXQBdkBfhkDABAZyRgAgMhIxgAAREYyBgAgMpIxAACRkYwBAIgsyUN19gAA4G3HL2MAACIjGQMAEBnJGACAyEjGAABERjIGACAykjEAAJGRjAEAiIxkDABAZCRjAAAiIxkDABAZyRgAgMhIxgAAREYyBgAgMpIxAACRkYwBAIiMZAwAQGQkYwAAIiMZAwAQGckYAIDISMYAAERGMgYAIDKSMQAAkZGMAQCIjGQMAEBkJGMAACIjGQMAEBnJGACAyEjGAABERjIGACAykjEAAJGRjAEAiIxkDABAZCRjAAAiIxkDABAZyRgAgMhIxgAAREYyBgAgMpIxAACRkYwBAIiMZAwAQGQkYwAAIit2+g9/4I9X5F5B5PQ0kOsLYj3p9IA2QCberR047mYhk3t5krvr6m81Myu3/d00bweiWuJ99Dupv9XMLDf/uM1CxyDeJ/ABZoETkbfFNZTrz0LtNAPv076ZF5jw5OPl2IfQsV/5T38o9xJxTaWBc5wk/qZa71Yqjq3bdwld14oKEbeJsHxjz0+W6oPo5vgyeQ+5teW5OO7A+W6LE5Rn+hx8+md//PseC7+MAQCIjGQMAEBkJGMAACIjGQMAEBnJGACAyEjGAABE1nFrU5YGWkxUGfiGV7uHXnD9bTiqnSJNdG9MMdhiIF7PdDtUMWus45X+ctP/LER3UAevqNpAdEwiP4vAZ5T5LVlvRflx+n3e2vUUAn0o4RYa0bIQaANRLR26XczM7PZpbQpdA6k6l4FTLFuOAqerm9vIBndKyT/ppjX0dNUPtcGHENrr4oTLtqKbauMulNB3pRP8MgYAIDKSMQAAkZGMAQCIjGQMAEBkJGMAACLruJo6FxW8ZoGKwg0vltNVyWp4Qoiqfism+n0KWSn4iv6yrrIriONOAgMSssQ/htAQhFC1Y0FWgQdeT22EBly0Q5+fEorxq94Lua6GL3RRtaseDG9mZon/97aDx337CFfUqyr8jf3i3wq/GLr6i26FYuENtNF/jronhaus198N0ZXA/VJW1t9gxfutcJ0DAHBHIxkDABAZyRgAgMhIxgAAREYyBgAgMpIxAACRddzaVAh0atwCzzDvSipK6IuZ/mOz3B/sYGbWki1HgcEARb9QPsv0SW2rrcBnVAz8tytd//P+7yyhLiV1kt4h/81V10YwJnDl6Dkr8a+2PHTccpCJptvC9AWlYsK32PXfgMNnW7WsbeQRBN69i2Eu4a1Qz6cI6uIPutEr+B1yywAA4PZFMgYAIDKSMQAAkZGMAQCIjGQMAEBkHVdTp4GH/HdVRSbLNG9eVWUuqvaywFCMLHB45dUFf33ZXzczyyv+ezWqgzJmrezvtdp6SIOqBn1rT1n/w9LDn1/o/34bV48ZrsYMVMyK6vq0iwLO9J0xJyI8+CP1bx+h74h6AP/Gd2Ss/wMIDlNRg1sCB57mYnhNogeZqGEv3QzsCAp9rvKq1u+T6jJ5/S7i3IXuVUmgy0TdX0K3AzWTIgt+rm9P+xC/jAEAiIxkDABAZCRjAAAiIxkDABAZyRgAgMhIxgAARLaOQREb2ypwKz8YviVaNr6fct1vYRqZOipj1kpNd70+vkfG5Jve5a63C+t/0L2ZWSZK9QumWzCU4KcaaBmzvIteIPFmaWC6QR5owVDdDMG/ScXcpsNT/jr9XVBXR/BPv4XPS6hlJTe/FSgLnJ9MXIfq+2YWuAbj3y433vo7qII5Rd1Buui6CrYztsUxhO6xHb3nDUUDAIAbRjIGACAykjEAAJGRjAEAiIxkDABAZJ1XU4cqa1W1WjDVxy8P1IcdqOzN9B+Vl0ruel0MgzAzW/rml9z1lbH9Mqb5noq73rNLV2Crh/qbmWUt8UD7bgQ+1kJX10PoOhHXZPDJ8KFj8IUOO/64k7dXu13We8W6u17J9bWmhnEE3aRS4tCAGKW6NK1fr+xfn62eERnTEl0rweEJXV1toZj1f0aqyjn0ecsjCLx9aAiJequNPjtq70YbBfhlDABAZCRjAAAiIxkDABAZyRgAgMhIxgAAREYyBgAgso5bm9qpztsFUdRdCNR6qweiq+ENZmZ5oPWgm4eBq2L0RDwU3swsCxxfs1Jz1+d7J2TMC2f94RKXnv6GjLHvXXeX7/m5vyNDNu/eIfcqVb9Vytrrf3B+HmgLC/7PT36AoafGb2ybTCKv8dB58GNu4XkI6/Lo2Dm59/rCoLt+LQsMl1Dn/xboBUtCn5q4Pttlv53RzKx59jU/ZstBGVMa8tuesra+J3Uj3C12cxr2unm10PdKHnUXX8YseIJU3rix88MvYwAAIiMZAwAQGckYAIDISMYAAERGMgYAILKOq6lbgaf8J22/graY68paNXYiVE3dDpRM54E5FpIosws9lD1P9V6r0u+uL9d2yphLzUl/Y/pPZYxN+5XWRyZ3yZDiJ35Y7m3bJyqtxedqZtZOmv5Goqs+87auPNVF2IFSSFGuH6qKVQ+0NzNLRbV+O/B66q8NjBq5rUy8elbuFbaNuevfLd0lY+qZX7lf6GKgQLjzQm4FBL734rpplf2KcjOzN+r+kI3LT39bxjzwyGPuet+wf28xs3DXg/g+Jnngd5h6uWBZsn9+Qt839WrddiLoGnD9ipnY6+YYbnSeCb+MAQCIjGQMAEBkJGMAACIjGQMAEBnJGACAyEjGAABE1nFrUxroSmkV/PL5Vq7bXFLxUP5iFojJAkMIRC26fvi/yVr0UIV6Gmyb8Y+9p+a3OJiZjX3sw+76taPfCxzF0/7yF39DRrw0KIZBmNm2uz7prqd5n4zJRHNalouWJzPLgkMk1t8MlIn/S4Zeq5vug9CRqcEh6vzcblaPteRe/tJJd33XD+m//djAHne9FWiDVO0xaShGtud013+i2mNCLze5x/9bz547L2Neecn/3r//sQ8Ejk3fX3LR4xUa6KL+1lArWXDIhqBbm7r9jPy/KXRkuo315k8u4ZcxAACRkYwBAIiMZAwAQGQkYwAAIiMZAwAQGckYAIDIOm5t2vb0C3Jvbvtmd31xy7iMScS8m1zOwbHg1JAk8dspQlNDumlzCEWo8v5iSbd67Dl82F2/duA+/UYnRGuTHdExf/DHcuu7e/0WjAcffkTGpEX/0mkFpsEkSaBJSI9ckdrirZJgy8v6WzCCw2rkeKCb3xrxdlh7VEwVM7Oxc2IC09NnZcywf6nZ3J7dMka2rASvp5vTWpYHrqe+/iF3fdPmCRlz4cIFd/21V47KmMP363tFW0x0Ct361ISq0CSsjf1e3Z7fneB9ogP8MgYAIDKSMQAAkZGMAQCIjGQMAEBkJGMAACLruJr6gd/5L3Lv5Mc/4q6f/fAmGZOkfiVklgaqqUMFkgX9sPSbRVVWJoH/84xv2e5v3Pdu/UYnVIXrJR2z/AW5demzfnXnPQcPyJjy4Ii/EagoDFZwioEeWSAmE6c1FxWkf7Eb2POFinYLosQ09JnfTs4MDci93sqquz42oafK7L940V0/ujQkYxYHx9z1Ult/MG1x3XQz0KBbiagK3hGoHF+avuaunz99VsZsGhmWexO7drnreUsPAGmqyuhgxXQ3FdD+66VdFlN3UdC9oULV5p14Z9wxAAC4jZGMAQCIjGQMAEBkJGMAACIjGQMAEBnJGACAyDpubfq709+Qe390cdBdX76yVcZMbd/rrpdMt0UUMt3K0Cz4/69IA60MN7PNQUnF/4e23XtQxlx4/uP+xpnfCryTbmWwM593l//09++XIe/92OPu+sTuu2RMvrYm9+ris20Fhj6Yam0JDKvorgVDH0Mq+rXE5XjbOXpJn6/XXnjTXd+0qV/GPPHAkLu+p3ldxrxS73PX2z26nTFV3TnBp/mHrg0VF4rx2zRLgR6YUsm/cHbVdMtne/qU3Jsp+P2g/SOiNdHM0rJ/XoNzdUT/X/Bsi82uBy7Ijyj+fb4T75BbBgAAty+SMQAAkZGMAQCIjGQMAEBkJGMAACLruJq67+G63Du8+YK7frnxuoz5Wn2Lu56Ve/VBBEpUxdwJXVZpZt1VSG5sZV4iKnXHR/XD3y/s3+NvnOn2KPyH9zf/LDBcYos/QKBa0tM8+voCn23RvxQLgc9cVcMXQpMduvho00A1tRoGEKriv530DI/KvZb4zJZWFmTM+LR/3RQu+PcQM7Nt+/xr6lzPDhnTTvyYNDBNINxd4V+H6vM3M8vE6+VFfU33Ff2uh0V/JsdfHIOutD56/ri7vnOnP3zDzGyHGFLTDjRkJKpboxD4wolK7yTR56ebYQxZU5+fYuIfd5rpa0FX5HecTv33vKFoAABww0jGAABERjIGACAykjEAAJGRjAEAiIxkDABAZB3XYl/7hwfk3q7lhrv+xPIxGfPcNX9QxMyY3/JkZtaq6daYkqhezxJd1p6JMvnEdHtOaGiA7psJ1eP7564cGpAQPL4NdPlLcuv0V2ru+tqSPu59D94v93rG/QfXl3urMiZVpyHVPRihQQFt9eD6wMeXZmJAib7sbis9iR7uUROtTRdndB/O7377nLv+tw9vljH3inkzhcV5GTNr/r0ikxeNWSv0vRItMBZolVJ6x3Tb4tWhcXf90vnLMmahsSz3FjP/+/PmjG4/uzebdde3DurfbqW06a4ngbai9pIfY6uB72grcF8UH1+91iNDrjT9IST1QkW/TyLSZi7+ng7xyxgAgMhIxgAAREYyBgAgMpIxAACRkYwBAIis42rqsWcClWKv+g8j3zfrV06amX30h/0qtif7H5UxZ/r3yb3VQsldLwSqktPM30sDD14PVTKrKuzQg89bYqhBSzxE3cys0Ofv3dQC3uPfcpcvHp+WIReffVDu7f3vfsZdn7znsIxpiarLNFABbAV9lvKyOOdl/9oyM0tT/yuUdvFA+1vR7tPX5F5zadFdX6zoP/7lll/521dfkTE/Lz6XR7fqz7nR9iu6m4FhB61AZXRb7IU/Zn83D9yTDr1nwl1/pqTPz5Nv+p+DmdlgSZwj8dmZmV0/8Yq7/uiDuuK9JL4Ha4G7UqPtXwutVb/DxMys0Nb30oZIUVNXdO7avK3fjzFRwm9mqwU/Js1vrMuFX8YAAERGMgYAIDKSMQAAkZGMAQCIjGQMAEBkJGMAACLruLXpmX/jty+Zmb1vVTwYfseQjPmZTWf9jb49MiaxUbk3mwyImACxmQUfGK/bEhLR/pAGjiITgyeGh/SAhK13+S0G52xQxpjph+p355JYn9Mhr+qH089cfL+7/vADO2XMSK9/XivpkowpJOt/mHu2FriKVv3/zybN0P9zJ9d9DLGcLejrffek/zcenNTna77pX6PLbd0C88q5K+76eM1vjzQzq5T9B/1XdJdasKWxreZEBL7bhYJ/fgoFHVMr+m09V1b059DOdEtWWQxwSFN9Ik5M++fhM5+/KmMOjfj3zE885LcBmZnNJ2V3PevV351ePfPBZkRH1Ow1fX52+Idg+Zp/zZmZTa36f2uj4g/P6RS/jAEAiIxkDABAZCRjAAAiIxkDABAZyRgAgMhIxgAARNZxa9P762/KvX8vyvv/+8N7ZUz6uF8e/reWdPl8//QZufeyaBdZK+oWodXEr5NfDrU2FQITgXLR/yCmQ4VMTOqWgMGH73XXz/XrqUi2+M11H0N39HQZs1Nypz3tt879UK8/xcbM7CN7/Mt3oKQn0lQa+viSubq7vnpGt0plU6qfIvSZ/w+BvVvLy7MX5d4bPf5km21pr4wZKvrncqg4K2OSRb8l7tqyP/XHzKyR+d/hUo/oZTGzUqDvqafjO+VfKaR+S00WuB9kmX8vnRLXppnZUKBda0VMOVpq6/aq1pJ/vudX/XYxM7OzYmLRaqbvY0Nl/29Ke/T9txmY2jRR9VuyNm3VMcsN//tbauhrK1/07yH5qM53neCXMQAAkZGMAQCIjGQMAEBkJGMAACIjGQMAEFkXNYJ/3c+bXzU4tqArJH+sX7z1PjF0wsx+PJ/Se83r/sZaoDK6Jf4vkgcGA+T6YfKWiypJMUDiLeIYksAxTPjVwl/8F3fLkP/j13Ql8zPndKX8xhKfkZktfP4/uuvJ3bqCftuuA/5GMfB/zCzw+YlK8PLaZR0yLwZwXNXX8e1UTX3w3Q/JvVLF71RoikpmM7OZpn9e3py9JmPy6XPu+pUrOmZmyX+fpmh4MDPLE307LJb8vWLga5qJ73CpoM9PX8kvjR4IVEzPNHSVczvx/+Biou9JS00xgKUkOgfMbE4MU/m/v6nv2VVxukODNIqB+2Ka+nvlwP2gUvYPohW4UNpimMe24dC95fvjlzEAAJGRjAEAiIxkDABAZCRjAAAiIxkDABAZyRgAgMg2pLVJ+ePmjNz7sSkxEGIkcEhl/wHmb+2JOP1ceDNTrUiB/odmYABAptoFAv/nUW0OgdYDqzbd5R/9mH4o+7Xvjcm9Z373ZrU2BSy95i7/v/9ZfxYPFP3Wlnu36EEFhW26DcTGRdtES1/HlovWJtMPmr+dJKluw2k1/KEpSaD9pCLaVnonNsuY5qQ/LGRgWQ/9GJ7y29Eunr8kY6ZndCvm7LLfKpUFWuXa4nsf6GyynoJ/w6pVdVB9VX9Hyol/DKITyczMssyPabb1+2TiXjo9o4e2tFRrqXh/MzPRvWRmZmr2RTHTx10U1+Pk6IiMuff+g+56oapjOsEvYwAAIiMZAwAQGckYAIDISMYAAERGMgYAILKOq6n/7f16b1YUFPZU9GCAo3/yvLt+6OwO/UZb/apKMzMbHPbXBwLld2VRZZf7VaJmFi6SbYn3SkLlk+IJ8D2BmFRUWvfMyZDr9SX9erewrx7VQxq++hn1YfTImH/1sU1y71P/dLu/kenXswH//7NZ0R+iYPbO+R+wrPcPfOUSMTQlX/M7BMzMSqKiu1CpyZi7du9217ffpe8vS8v6y72y4HdyrKzpe0Uu/tb6sv4uXrzod5mkrbqM6Q90jLTFvbmR6a4QdX329eg3Khf9+1i1T393envVdyRwAakOGDNLxTGUAl+4/prfgbIpcJ0kBf9zbTcDeaMD75T7AgAAty2SMQAAkZGMAQCIjGQMAEBkJGMAACIjGQMAEFnHrU2rY/oh2GPtOXd9U0W3K+RnTrvr1xb0w9r7j52Re+2C3+bQO6qHBtigGBpQE+1GZuH/vqgH5AcenG9qboFqXzIzUw+nX9Hn+9njU/r1bmmB4SByT39+3zipL/lPNSf9jV79sHvr8Vst0jzUnnEbCVy76qugWnreejnRChaYnpBYw10vtfSgiJZoLUsDgy+GRsbl3sCwv1fN9DFkS3Pu+qnz/t9jZjYvDi9rBIY0BD6jpmgFGh4clDH79u9310dGh2RMoey3PRUCfUUF0Yqke+bMLNCSlaT+ey0vzOmXE+dVteCZmWVNfy8JtmR9f/wyBgAgMpIxAACRkYwBAIiMZAwAQGQkYwAAIuu4mvrkzp+SeyMrb7jrK8uvy5iZ037V9OLLl2TMtcWLcu+iKHgt1fSDynsGRQW2WDczG6vpasxqya+mKwQqo0slVZkXqEgVBYXFQBXxV46FqpLfaXRV+Vff0FXlf/Blv2NgsqTPXU08O79U0p/F/h+VW7eeQFWpEvoffm5+J0AeuN5TcZsayaZlzJkpf+DCfF10IpjZ8pwebDNR9IdIXFvVwwHmlvzhDqeWddXtjm3b3PXpa7qaOinooST1Of/abS3r416sr7rrE726MyUXp7UtKo/f2lPf00DFdOh6TPzrZHlZn7uiqICuBK7iTDXN6CPrCL+MAQCIjGQMAEBkJGMAACIjGQMAEBnJGACAyEjGAABE1nFr04sf+pdyb/r0MXd95qU/lzH58S+760vnXwwchS7H1/wy/fDetS7e51bQF/sAbgO6Tekn//V3bsoR5P/8przN2041meShJg8xQCPUFqJaSa6km3RQ1f+cq4m+h2Rt3VKT17a460mghe3Ciy+763XVB2RmC7n/eg8/9gMy5vgR//5rZja/7N/jlpb1gIuVBfEdCbQVqZ3QjBz9qev20W76h4ZHh9cdkwX+1oLYC7XndYJfxgAAREYyBgAgMpIxAACRkYwBAIiMZAwAQGQdV1P3DQ7KvcL+d7nrg5vGZEz9/sPu+rnX9HCJ1e8el3t24hWxEYgJVNbenvyH2QM3UxIuod0weapvX70jfqV1LdW/PzYlgd8mmT/UoJXpCuz+gbPu+vXzl2XM9ctX3PWeB+6XMXft3iX39r3roLu+qCqmzay/T3RlhGY0iM8872LQyEbLAp+RErqGZeX4DY6K4JcxAACRkYwBAIiMZAwAQGQkYwAAIiMZAwAQGckYAIDIOm5tqhV1ifrIuP8g7nSbfpD7SslvbZp8eEnGXH30Tbl3/PnvuevZk8/KGDvzkno1HWMzgb34ZfzA7SjUAqPaTJIk8H1rqoEQuv2kGTiGTPxsyRM91OC+hx9y13ceWJQx6vhagWMbGhmRe3nSctf7+zfLmLZoBcpawd4mvRfZzWq1u1H8MgYAIDKSMQAAkZGMAQCIjGQMAEBkJGMAACIjGQMAEFnHrU3WbsutbMkvn0+XGjKmr1Rx18ulmowZOHBI7t29d7e7vvTED8mYqSl/esobZ3QLVf3kablnl8Q0lrk5HdMW7QIz13TMyhmx8bKOwV8ItTmMivXxQExVrOuWF/x1SRr4XNY/dMfygmoR0i8WmrqTiq9pkgXafYr+NTAyrluRVHdkO9P338CfZJk4eQ3/lv3W64mWsbSLFqHg9KNbYKLTrYRfxgAAREYyBgAgMpIxAACRkYwBAIiMZAwAQGQdV1Onqc7buXy4uX69gq246z0tPSgiLerDzft6/der6krYwbExd337gbtlzNxDs3KvMe9XQCeLV2RM85pfgf3qy3pYRftJ/9xZM1TBq6sxbw17xLquoLfdW/31gUEdM9qv98b9vXRMV7+Wi35XgOW3x8Ppb4QulA0MfRD3ilBdbTfP+U8zMVwiVOUeeJ9W6lclJ4GK4FyUOadN/V2UhxA4CaHTk4rfW3kS+B2mBnAEq5+7qIzu5isSGigir62NrtpWr3dj33l+GQMAEBnJGACAyEjGAABERjIGACAykjEAAJGRjAEAiKzj1qZEPSndzLLUf5lwSXnTXR1pXJUR6cqq3Ls4N+S/S1aSMVnu7yWpjhkXnSxmZgPDftvEQFGfh4XZeXf9Ul0Pirja9GPMemSM2XJg7xYw9Ii7XP7pj8uQDzz2gB9T08NGSn36HJX7/Ou4UvXb5szMUtUi0sVwg9uNHqwQGMYgQoItQvK11t9K0m2TS6r+1sAhyJguhF6pm78pCX1GXZ2k9Qep7r9gm1toV1xDXXVQBYPengEX/DIGACAykjEAAJGRjAEAiIxkDABAZCRjAAAi67iaum1rci8TQwiSwMunVnXXt7d1FbFdPSG3nnvVH57w+pWGjFk6Lyq3T70uY4Z7p+Te2Kr/estX9d90aUOrnHcG9vTnZ9bawGPo0tyMu9xY86vuzcwGJyfc9TwwMKMd+FPr836F6dpiXQfJARyhc6oHT9xONvJx+W9PferGkbMTAn/s2zNO4J1DndNQkXxwVMVtfmL5ZQwAQGQkYwAAIiMZAwAQGckYAIDISMYAAERGMgYAILKOW5uyrJu8rQvR26n/epfTTTKmWfDbl8zM1ooX/Y3CgoyRh9fSx12v6uNbHBpz12eqS/oY3nxK763boN4a9ocqmJlZSbQCXT0SeK9jHR1R5877y9O6LaxQ9C/fluo2MjPL9GebiN6IvN3N1Ic74f+5t3pD0saRXTOhuQW3eavN202dnsDMkHe0O+GOAQDALY1kDABAZCRjAAAiIxkDABAZyRgAgMjWUU0dGvrgCz3wWxW8Xkj9h/+bma306GPIRvwSvL5mRcYsLYuH+S/roQqF3fr4bNOwu9xe1cMO7E1VlRwYmCH5wzfMzOxDH5ZbE4d2u+uX/7dfD7zXObHe7eCLy/7yzKwOyfwq52A1ZuCaTOVe6P+s/H/2TtDN0Ac5XOJGD+Yd4p03UOTGjo47CQAAkZGMAQCIjGQMAEBkJGMAACIjGQMAEBnJGACAyJI8v1Mfyw0AwK2BX8YAAERGMgYAIDKSMQAAkZGMAQCIjGQMAEBkJGMAACIjGQMAEBnJGACAyEjGAABE9v8D1e4PTow/5UsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "aug_pipelines_supervised = [get_linear_batch_augs(size=size,resize=True,stats=cifar_stats,resize_scale=(0.3, 1.0))]\n",
    "show_linear_batch(dls=dls_train,n_in=n_in,n=2,aug=aug_pipelines_supervised,print_augs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to compute e.g. test set accuracy of a given model. We use test time augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_model(xval,yval,model,aug_pipelines_test,numavg=3,criterion = CrossEntropyLossFlat(),deterministic=False):\n",
    "    \"Note that this assumes xval is entire validation set. If it doesn't fit in memory, can't use this guy\"\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    N=xval.shape[0]\n",
    "    \n",
    "    if not deterministic:\n",
    "\n",
    "        probs=0\n",
    "        for _ in range(numavg):\n",
    "\n",
    "            probs += torch.softmax(model(aug_pipelines_test[0](xval)),dim=1) #test time augmentation. This also gets around issue of randomness in the dataloader in each session...\n",
    "\n",
    "        probs *= 1/numavg\n",
    "        \n",
    "    else:\n",
    "        probs = torch.softmax(model(xval),dim=1)\n",
    "\n",
    "    \n",
    "    ypred = cast(torch.argmax(probs, dim=1),TensorCategory)\n",
    "\n",
    "    correct = (ypred == yval)#.type(torch.FloatTensor)\n",
    "\n",
    "    #correct = (torch.argmax(ypred,dim=1) == yval).type(torch.FloatTensor)\n",
    "    num_correct = correct.sum()\n",
    "    accuracy = num_correct/N\n",
    "\n",
    "    #val_loss = criterion(scores,yval)\n",
    "    \n",
    "    return probs,ypred,accuracy.item()#,val_loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_whole_model(dls_test, model, aug_pipelines_test, numavg=3, criterion=CrossEntropyLossFlat(), deterministic=False):\n",
    "    \"\"\"\n",
    "    Predicts the labels and probabilities for the entire test set using the specified model and data augmentation\n",
    "    pipelines. Returns a dictionary containing the labels, probabilities, predicted labels, and accuracy.\n",
    "\n",
    "    Args:\n",
    "        dls_test: The test dataloader.\n",
    "        model: The trained model.\n",
    "        aug_pipelines_test: The test data augmentation pipelines.\n",
    "        numavg: The number of times to perform test-time augmentation.\n",
    "        criterion: The loss function to use for computing the accuracy.\n",
    "        deterministic: Whether to use deterministic computation.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the labels, probabilities, predicted labels, and accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_len = len(dls_test.dataset)\n",
    "    y = torch.zeros(total_len, dtype=torch.long)\n",
    "    probs = torch.zeros(total_len, model.head.out_features)\n",
    "    ypred = torch.zeros(total_len, dtype=torch.long)\n",
    "\n",
    "    start_idx = 0\n",
    "    for xval, yval in dls_test.train:\n",
    "        end_idx = start_idx + len(xval)\n",
    "        _probs, _ypred, acc = predict_model(xval, yval, model, aug_pipelines_test, numavg, criterion, deterministic)\n",
    "        y[start_idx:end_idx] = yval\n",
    "        probs[start_idx:end_idx] = _probs\n",
    "        ypred[start_idx:end_idx] = _ypred\n",
    "        start_idx = end_idx\n",
    "\n",
    "    # Calculate the overall accuracy\n",
    "    acc = (ypred == y).float().mean().item()\n",
    "\n",
    "    # Return the predictions and labels in a dictionary\n",
    "    #return {'y': y, 'probs': probs, 'ypred': ypred, 'acc': acc}\n",
    "    return y,probs,ypred,acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This enables us to freeze the encoder as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encoder_head_splitter(m):\n",
    "    return L(sequential(*m.encoder),m.head).map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SupervisedLearning` allows us to perform either linear evaluation or semi-supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SupervisedLearning:\n",
    "    \"Train model using supervised learning. Either linear evaluation or semi-supervised.\"\n",
    "\n",
    "    def __init__(self,encoder,hp_dict):\n",
    "\n",
    "\n",
    "        self.encoder = encoder\n",
    "        \n",
    "        for key, value in hp_dict.items():\n",
    "            setattr(self, key, value)\n",
    "        \n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    \n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics.\n",
    "\n",
    "        Returns:\n",
    "        - learn: The Learner object.\n",
    "        \"\"\"\n",
    "        # Setup the model: encoder + head\n",
    "        model = LM(encoder=self.encoder, enc_dim=self.enc_dim, numout=len(self.dls_train.vocab))\n",
    "        if torch.cuda.is_available():\n",
    "            model.to('cuda')\n",
    "\n",
    "        # Setup the learner with callbacks and metrics\n",
    "        bt = LinearBt(aug_pipelines=self.aug_pipelines_supervised, show_batch=True, n_in=self.n_in, print_augs=True)\n",
    "        learn = Learner(self.dls_train, model, splitter=encoder_head_splitter,cbs=[bt],wd=0, metrics=accuracy)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def supervised_learning(self,epochs:int=1):\n",
    "\n",
    "        test_grad_on(self.learn.model.encoder)\n",
    "        test_grad_on(self.learn.model.head)\n",
    "        lrs = self.learn.lr_find()\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley)\n",
    "        return self.learn.model\n",
    "    \n",
    "    def linear_evaluation(self,epochs:int=1):\n",
    "\n",
    "        self.learn.freeze() #freeze encoder\n",
    "        test_grad_off(self.learn.model.encoder)\n",
    "        lrs = self.learn.lr_find() #find learning rate\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley) #fit head\n",
    "        return self.learn.model\n",
    "\n",
    "    def semi_supervised(self,freeze_epochs:int=1,epochs:int=1):\n",
    "\n",
    "        self.learn.freeze() #freeze encoder\n",
    "        test_grad_off(self.learn.model.encoder)\n",
    "        self.learn.fit(freeze_epochs) #fit head for (typically one) epoch\n",
    "        self.learn.unfreeze() #unfreeze encoder\n",
    "        test_grad_on(self.learn.model)\n",
    "        lrs = self.learn.lr_find() #find learning rate\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley) #fit all\n",
    "        return self.learn.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debugging\n",
    "\n",
    "encoder = create_fastai_encoder(xresnet18(),pretrained=False,n_in=n_in) #Need an encoder (this will be trained by BT)\n",
    "enc_dim = 1024\n",
    "\n",
    "model = LM(encoder=encoder, enc_dim=enc_dim, numout=len(dls_train.vocab))\n",
    "\n",
    "test_grad_on(model)\n",
    "\n",
    "# bt = LinearBt(aug_pipelines=aug_pipelines_supervised, show_batch=True, n_in=n_in, print_augs=True)\n",
    "# learn = Learner(dls_train, model, splitter=encoder_head_splitter,cbs=[bt],wd=0, metrics=accuracy)\n",
    "\n",
    "# learn.freeze()\n",
    "# learn.summary()\n",
    "# test_grad_off(learn.model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_resnet_encoder(model,n_in=3):\n",
    "    model = create_body(model, n_in=n_in, pretrained=False, cut=len(list(model.children()))-1)\n",
    "    model.add_module('flatten', torch.nn.Flatten())\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def create_model(which_model,device,ps=8192,n_in=3):\n",
    "\n",
    "    #pretrained=True if 'which_model' in ['bt_pretrain', 'supervised_pretrain'] else False\n",
    "\n",
    "    if which_model == 'bt_pretrain': model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
    "    \n",
    "    elif which_model == 'no_pretrain': model = resnet50()\n",
    "\n",
    "    elif which_model == 'supervised_pretrain': model = resnet50(weights='IMAGENET1K_V2')\n",
    "\n",
    "    #ignore the 'pretrained=False' argument here. Just means we use the weights above \n",
    "    #(which themselves are either pretrained or not)\n",
    "    encoder = get_resnet_encoder(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full example of how to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# encoder = create_fastai_encoder(xresnet18(),pretrained=False,n_in=n_in) #Need an encoder (this will be trained by BT)\n",
    "# enc_dim=1024\n",
    "\n",
    "# hp_dict = {'dls_train':dls_train,'dls_test':dls_test, 'aug_pipelines_supervised':aug_pipelines_supervised,'n_in':n_in, 'enc_dim':enc_dim}\n",
    "\n",
    "\n",
    "# supervised = SupervisedLearning(encoder=encoder,hp_dict=hp_dict)\n",
    "# model = supervised.linear_evaluation(epochs=1)\n",
    "# y,probs,ypred,acc = predict_whole_model(dls_test, model, aug_pipelines_supervised, numavg=3, criterion=CrossEntropyLossFlat(), deterministic=False)\n",
    "\n",
    "# supervised = SupervisedLearning(encoder=encoder,hp_dict=hp_dict)\n",
    "# model = supervised.semi_supervised(freeze_epochs=2,epochs=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One we have a trained model, making predictions and measuring performance on test set is straightforward:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#y,probs,ypred,acc = predict_whole_model(dls_test, model, aug_pipelines_supervised, numavg=3, criterion=CrossEntropyLossFlat(), deterministic=False)\n",
    "#print(f\"Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
