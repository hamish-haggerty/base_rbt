{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# isic_dataloading\n",
    "\n",
    "> How to load isic datasets for supervised learning, and possibly later SSL\n",
    "\n",
    "Important: Note that we unzip isic files in colab first like: \n",
    "- !unzip -q \"/content/drive/MyDrive/isic-2019.zip\"\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp isic_dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#directory = \"/content/drive/MyDrive/ISIC_2019_Training_Input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "# from self_supervised.augmentations import *\n",
    "# from self_supervised.layers import *\n",
    "from base_rbt.utils import *\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a bunch of helper functions to construct the `fnames` and \n",
    "other things used to construct the `dls` builder functions.\n",
    "\n",
    "Admiteddly this following cell is a bit opaque, but the functions here\n",
    "are only ever used once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "\n",
    "# def process_path(name):\n",
    "#     return name.as_posix().split('/')[-1] #basically get end part of Path('...') as a string\n",
    "\n",
    "# def extract_id(string):\n",
    "#     regex = r'ISIC_\\d+'\n",
    "#     match = re.search(regex, string)\n",
    "#     if match:\n",
    "#         return match.group(0)\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# def get_class_from_id(string):\n",
    "#     \"Given the identifier e.g. ISIC_0000000.jpg return the class label\"\n",
    "\n",
    "#     row=data.loc[data['image'] == string]\n",
    "#     lst = [colname for colname in row.columns if row[colname].values==1]\n",
    "#     test_eq(len(lst),1)\n",
    "\n",
    "#     return lst[0]\n",
    "\n",
    "# def get_label_func_dict(_fnames):\n",
    "#     label_func_dict={}\n",
    "#     for name in _fnames:\n",
    "#         label_func_dict[name] = get_class_from_id(extract_id(process_path(name)))\n",
    "\n",
    "#     return label_func_dict\n",
    "\n",
    "\n",
    "# #label_func_dict = get_label_func_dict(_fnames) #can just load this in future to save time\n",
    "# #label_func_dict = data_dict['label_func_dict']\n",
    "\n",
    "# def get_difference(x1, x2):\n",
    "#     return list(set(x1) - set(x2))\n",
    "\n",
    "# #_labels = [label_func(x) for x in _fnames] \n",
    "# #test_eq(len(_labels),len(_fnames))\n",
    "\n",
    "# # %% ../nbs/cancer_dataloading.ipynb 6\n",
    "# def get_fnames(_fnames,_labels,label_func):\n",
    "\n",
    "#     fnames_train=[]\n",
    "#     labels_train=[]\n",
    "#     count_dict={i:0 for i in set(_labels)}\n",
    "\n",
    "#     fnames = _fnames[0:5000]\n",
    "#     labels = _labels[0:5000]\n",
    "\n",
    "#     for i,lab in enumerate(labels):\n",
    "\n",
    "#         if count_dict[lab]<500:\n",
    "#             fnames_train.append(_fnames[i])\n",
    "#             labels_train.append(_labels[i])\n",
    "\n",
    "#         count_dict[lab]+=1\n",
    "\n",
    "#     fnames_valid = _fnames[5000:5000+256*5]\n",
    "#     labels_valid = _labels[5000:5000+256*5]\n",
    "\n",
    "#     fnames_test = get_difference(_fnames,fnames_train+fnames_valid)\n",
    "#     fnames_test.sort()\n",
    "#     labels_test = [label_func(path) for path in fnames_test]\n",
    "\n",
    "   \n",
    "#     return {'fnames_train':fnames_train,'fnames_valid':fnames_valid,'fnames_test':fnames_test,\n",
    "#             'labels_train':labels_train,'labels_valid':labels_valid,'labels_test':labels_test\n",
    "#            }\n",
    "\n",
    "# def get_data(load=False):\n",
    "\n",
    "#     data = pd.read_csv(\"/content/drive/MyDrive/ISIC_2019_Training_GroundTruth.csv\").drop(\"UNK\", axis=1)\n",
    "#     data = data[~data[\"image\"].str.contains(\"downsampled\")]\n",
    "#     labels = pd.read_csv(\"/content/drive/MyDrive/ISIC_2019_Training_GroundTruth.csv\")\n",
    "\n",
    "#     if not load:\n",
    "#     #Method 1: load from saved dict in drive\n",
    "#         data_dict = load_dict_from_gdrive(directory='/content/drive/My Drive/cancer_colab',filename='data_dict')\n",
    "#         _fnames = data_dict['_fnames']\n",
    "#         label_func_dict = data_dict['label_func_dict']\n",
    "\n",
    "#     else:\n",
    "#     #Method 2: compute freshly (and I guess we could save for future use)\n",
    "#         _fnames = get_image_files(directory)\n",
    "#         _fnames = [name for name in _fnames if 'downsampled' not in name.as_posix()]\n",
    "#         label_func_dict = get_label_func_dict(_fnames) #can just load this in future to save time\n",
    "\n",
    "#     return _fnames,label_func_dict\n",
    "\n",
    "# def get_pct_dataset(fnames,\n",
    "#             labels,\n",
    "#             pct_dataset=1.0\n",
    "#             ):\n",
    "    \n",
    "#     N = len(fnames)\n",
    "#     n=int(pct_dataset*N)\n",
    "\n",
    "#     new_labels = labels[0:n]\n",
    "#     new_fnames = fnames[0:n]\n",
    "\n",
    "#     return new_fnames,new_labels\n",
    "\n",
    "\n",
    "# def load_data(load=False):\n",
    "\n",
    "#     global fnames,labels, fnames_train,labels_train, fnames_test,labels_test, label_func\n",
    "    \n",
    "#     _fnames,label_func_dict = get_data(load=load) #get _fnames, label_func_dict\n",
    "\n",
    "#     # def label_func(name):\n",
    "#     #     return label_func_dict[name]\n",
    "\n",
    "#     def get_label_func(label_func_dict):\n",
    "\n",
    "#         def label_func(name):\n",
    "\n",
    "#             return label_func_dict[name]\n",
    "\n",
    "#         return label_func\n",
    "\n",
    "#     label_func = get_label_func(label_func_dict) #get label_func\n",
    "\n",
    "#     _labels = [label_func(i) for i in _fnames] #get _labels \n",
    "\n",
    "#     test_eq(process_path(_fnames[0]),'ISIC_0071718.jpg')\n",
    "#     test_eq(process_path(_fnames[10]),'ISIC_0071719.jpg')\n",
    "\n",
    "#     _fnames_dict = get_fnames(_fnames,_labels,label_func)\n",
    "#     fnames_train,fnames_valid,fnames_test = _fnames_dict['fnames_train'],_fnames_dict['fnames_valid'],_fnames_dict['fnames_test']\n",
    "#     labels_train,labels_valid,labels_test = _fnames_dict['labels_train'],_fnames_dict['labels_valid'],_fnames_dict['labels_test']\n",
    "\n",
    "\n",
    "# def is_colab():\n",
    "#     return 'COLAB_GPU' in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main dataloader functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_supervised_isic_test_dls(bs, \n",
    "                                 size=None, \n",
    "                                 device='cpu', \n",
    "                                 pct_dataset=1.0, \n",
    "                                 num_workers=12):\n",
    "    max_retries = 3\n",
    "    retry_delay = 1\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            resized_dir = \"/content/drive/MyDrive/ISIC_2019_Test_Resized/\"\n",
    "            labels_file = \"/content/drive/MyDrive/ISIC_2019_Test_Resized/labels.csv\"\n",
    "\n",
    "            with open(labels_file, 'r') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                next(reader)  # Skip the header row\n",
    "                labels = {row[0]: row[1] for row in reader}\n",
    "\n",
    "            resized_fnames = list(labels.keys())\n",
    "\n",
    "            subset_size = int(len(resized_fnames) * pct_dataset)\n",
    "            _resized_fnames = [os.path.join(resized_dir, fname) for fname in resized_fnames[:subset_size]]\n",
    "            _labels = [labels[os.path.basename(fname)] for fname in _resized_fnames]\n",
    "\n",
    "            # Test the first and ninth elements (fill in the test_eq based on your inspection)\n",
    "\n",
    "            test_eq((_resized_fnames[0], _labels[0]), ('/content/drive/MyDrive/ISIC_2019_Test_Resized/ISIC_0069373.jpg', 'MEL'))\n",
    "            test_eq((_resized_fnames[8], _labels[8]), ('/content/drive/MyDrive/ISIC_2019_Test_Resized/ISIC_0069383.jpg', 'NV'))\n",
    "\n",
    "            counter = Counter(_labels)\n",
    "            if pct_dataset == 1.0:\n",
    "                test_eq(Counter({'NV': 10601, 'MEL': 3339, 'BCC': 2549, 'BKL': 1663, 'AK': 498, 'SCC': 414, 'VASC': 186, 'DF': 173}), counter)\n",
    "\n",
    "            dls = ImageDataLoaders.from_path_func(\n",
    "                resized_dir,\n",
    "                _resized_fnames,\n",
    "                lambda x: labels[os.path.basename(x)],\n",
    "                bs=bs,\n",
    "                valid_pct=0,\n",
    "                device=device,\n",
    "                num_workers=num_workers * (device == 'cuda'),\n",
    "                drop_last=False,\n",
    "            )\n",
    "            if pct_dataset == 1.0:\n",
    "                test_eq(len(dls.train_ds), 19423)\n",
    "\n",
    "            return dls\n",
    "        except IOError as e:\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries} failed with IOError: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "def get_supervised_isic_train_dls(bs, size, device, pct_dataset=1.0, num_workers=12):\n",
    "    max_retries = 3\n",
    "    retry_delay = 1\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            resized_dir = \"/content/drive/MyDrive/ISIC_2019_Training_Resized/\"\n",
    "            labels_file = \"/content/drive/MyDrive/ISIC_2019_Training_Resized/labels.csv\"\n",
    "            \n",
    "            with open(labels_file, 'r') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                next(reader)  # Skip the header row\n",
    "                labels = {row[0]: row[1] for row in reader}\n",
    "            \n",
    "            resized_fnames = list(labels.keys())\n",
    "            \n",
    "            subset_size = int(len(resized_fnames) * pct_dataset)\n",
    "            _resized_fnames = [os.path.join(resized_dir, fname) for fname in resized_fnames[:subset_size]]\n",
    "            _labels = [labels[os.path.basename(fname)] for fname in _resized_fnames]\n",
    "            \n",
    "            # Test the first and ninth elements\n",
    "            test_eq((_resized_fnames[0],_labels[0]),('/content/drive/MyDrive/ISIC_2019_Training_Resized/ISIC_0069487.jpg','BKL'))\n",
    "\n",
    "            test_eq((_resized_fnames[8],_labels[8]),('/content/drive/MyDrive/ISIC_2019_Training_Resized/ISIC_0069630.jpg','AK'))\n",
    "            \n",
    "            counter = Counter(_labels)\n",
    "            if pct_dataset == 1.0:\n",
    "                test_eq(Counter({'NV': 500, 'MEL': 500, 'BCC': 500, 'BKL': 467, 'AK': 306, 'SCC': 171, 'VASC': 55, 'DF': 55}), counter)\n",
    "            elif pct_dataset == 0.5:\n",
    "                test_eq(Counter({'BKL': 350, 'AK': 243, 'MEL': 212, 'BCC': 182, 'SCC': 129, 'NV': 85, 'DF': 40, 'VASC': 36}), counter)\n",
    "            elif pct_dataset == 0.25:\n",
    "                test_eq(Counter({'BKL': 244, 'AK': 166, 'SCC': 89, 'MEL': 48, 'BCC': 37, 'DF': 28, 'VASC': 26}), counter)\n",
    "                \n",
    "            \n",
    "            dls = ImageDataLoaders.from_path_func(\n",
    "                resized_dir,\n",
    "                _resized_fnames,\n",
    "                lambda x: labels[os.path.basename(x)],\n",
    "                bs=bs,\n",
    "                valid_pct=0,\n",
    "                device=device,\n",
    "                num_workers=num_workers * (device == 'cuda'),\n",
    "                drop_last=False\n",
    "            )\n",
    "\n",
    "            return dls\n",
    "        except IOError as e:\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries} failed with IOError: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
