{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32189ee",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> utility stuff.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e903be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39912107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastcore.test import *\n",
    "from fastai.vision.all import *\n",
    "import torch\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "import random \n",
    "import os \n",
    "import yaml\n",
    "import numpy as np\n",
    "import yaml\n",
    "import configparser\n",
    "from types import SimpleNamespace\n",
    "import importlib\n",
    "from nbdev import config\n",
    "import json\n",
    "import hashlib\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "cfg = config.get_config()\n",
    "PACKAGE_NAME = cfg.lib_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e917f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def test_grad_on(model):\n",
    "    \"\"\"\n",
    "    Test that all grads are on for modules with parameters.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        # Check each parameter in the module\n",
    "        for param_name, param in module.named_parameters(recurse=False):\n",
    "            assert param.requires_grad, f\"Gradients are off for {name}.{param_name}\"\n",
    "\n",
    "def test_grad_off(model):\n",
    "    \"\"\"\n",
    "    Test that all non-batch norm grads are off, but batch norm grads are on.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        # Distinguish between BatchNorm and other layers\n",
    "        if isinstance(module, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, torch.nn.BatchNorm3d)):\n",
    "            for param_name, param in module.named_parameters(recurse=False):\n",
    "                assert param.requires_grad, f\"BatchNorm parameter does not require grad in {name}.{param_name}\"\n",
    "        else:\n",
    "            for param_name, param in module.named_parameters(recurse=False):\n",
    "                assert not param.requires_grad, f\"Gradients are on for non-BatchNorm layer {name}.{param_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c693f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"\"\n",
    "    Seed everything.\n",
    "    \"\"\"   \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cdd84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def adjust_config_with_derived_values(config):\n",
    "    # Adjust n_in based on dataset\n",
    "    if config.dataset == 'cifar10':\n",
    "        config.n_in = 3\n",
    "\n",
    "    # Adjust encoder_dimension based on architecture\n",
    "    if config.arch == 'resnet18':\n",
    "        config.encoder_dimension = 512\n",
    "    elif config.arch == 'resnet34':\n",
    "        config.encoder_dimension = 512\n",
    "    elif config.arch == 'resnet50':\n",
    "        config.encoder_dimension = 2048\n",
    "\n",
    "    else :\n",
    "        raise ValueError(f\"Architecture {config.arch} not supported\")\n",
    "\n",
    "    return config\n",
    "\n",
    "def load_config(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "        config = SimpleNamespace(**config)\n",
    "        config = adjust_config_with_derived_values(config)\n",
    "        \n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae73551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_ssl_dls(dataset,bs,device):\n",
    "    # Define the base package name in a variable for easy modification\n",
    "\n",
    "    try:\n",
    "        # Construct the module path\n",
    "        module_path = f\"{PACKAGE_NAME}.{dataset}_dataloading\"\n",
    "        \n",
    "        # Dynamically import the module\n",
    "        dataloading_module = importlib.import_module(module_path)\n",
    "    except ModuleNotFoundError:\n",
    "        # Handle the case where the module cannot be found\n",
    "        raise ImportError(f\"Could not find a data loading module for '{dataset}'. \"\n",
    "                          f\"Make sure '{module_path}' exists and is correctly named.\") from None\n",
    "    \n",
    "    # Assuming the function name follows a consistent naming convention\n",
    "    func_name = f\"get_bt_{dataset}_train_dls\"\n",
    "    try:\n",
    "        # Retrieve the data loading function from the module\n",
    "        data_loader_func = getattr(dataloading_module, func_name)\n",
    "    except AttributeError:\n",
    "        # Handle the case where the function does not exist in the module\n",
    "        raise AttributeError(f\"The function '{func_name}' was not found in '{module_path}'. \"\n",
    "                             \"Ensure it is defined and named correctly.\") from None\n",
    "    \n",
    "    # Proceed to call the function with arguments from the config\n",
    "    try:\n",
    "        dls_train = data_loader_func(bs=bs,device=device)\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the function call\n",
    "        raise RuntimeError(f\"An error occurred while calling '{func_name}' from '{module_path}': {e}\") from None\n",
    "    \n",
    "    return dls_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac66af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@torch.no_grad()\n",
    "def get_resnet_encoder(model,n_in=3):\n",
    "    model = create_body(model, n_in=n_in, pretrained=False, cut=len(list(model.children()))-1)\n",
    "    model.add_module('flatten', torch.nn.Flatten())\n",
    "    return model\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def create_resnet50_encoder(weight_type):\n",
    "\n",
    "#     #pretrained=True if 'weight_type' in ['bt_pretrain', 'supervised_pretrain'] else False\n",
    "\n",
    "#     if weight_type == 'bt_pretrain': model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
    "    \n",
    "#     elif weight_type == 'no_pretrain': model = resnet50()\n",
    "\n",
    "#     elif weight_type == 'supervised_pretrain': model = resnet50(weights='IMAGENET1K_V2')\n",
    "\n",
    "#     #ignore the 'pretrained=False' argument here. Just means we use the weights above \n",
    "#     #(which themselves are either pretrained or not)\n",
    "#     encoder = get_resnet_encoder(model)\n",
    "\n",
    "#     return encoder\n",
    "\n",
    "@torch.no_grad()\n",
    "def resnet_arch_to_encoder(arch:str,weight_type='random'):\n",
    "    \"\"\"Given resnet architecture, return the encoder. Works for 3 channels.\n",
    "       The 'weight_type' argument is used to specify whether the model is pretrained or not\n",
    "    \"\"\"\n",
    "\n",
    "    n_in=3\n",
    "\n",
    "    test_eq(arch in ['resnet18','resnet34','resnet50'],True)\n",
    "    test_eq(weight_type in ['bt_pretrained','supervised_pretrained','random'],True)\n",
    "\n",
    "    if weight_type == 'bt_pretrained': test_eq(arch,'resnet50')\n",
    "\n",
    "    \n",
    "    if arch == 'resnet50':\n",
    "\n",
    "        if weight_type == 'bt_pretrained':\n",
    "            _model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
    "\n",
    "        elif weight_type == 'supervised_pretrained':\n",
    "            _model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "        elif weight_type == 'random':\n",
    "            _model = resnet50()\n",
    "        \n",
    "\n",
    "    elif arch == 'resnet34':\n",
    "\n",
    "        if weight_type == 'supervised_pretrained':\n",
    "            _model = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        elif weight_type == 'random':\n",
    "            _model = resnet34() \n",
    "\n",
    "    elif arch == 'resnet18':\n",
    "        if weight_type == 'supervised_pretrained':\n",
    "            _model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1) \n",
    "\n",
    "        elif weight_type == 'random':\n",
    "            _model = resnet18()\n",
    "        \n",
    "    else: raise ValueError('Architecture not recognized')\n",
    "\n",
    "    return get_resnet_encoder(_model,n_in) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d288f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def generate_config_hash(config):\n",
    "    \"\"\"\n",
    "    Generates a unique hash for a given experiment configuration.\n",
    "    \n",
    "    Args:\n",
    "    config (dict or Namespace): Experiment configuration. Can be a dictionary or a namespace object.\n",
    "    \n",
    "    Returns:\n",
    "    str: A unique hash representing the experiment configuration.\n",
    "    \"\"\"\n",
    "    # Convert config to dict if it's a Namespace\n",
    "    config_dict = vars(config) if not isinstance(config, dict) else config\n",
    "    \n",
    "    # Serialize configuration to a sorted JSON string to ensure consistency\n",
    "    config_str = json.dumps(config_dict, sort_keys=True)\n",
    "    \n",
    "    # Generate SHA-256 hash from the serialized string\n",
    "    hash_obj = hashlib.sha256(config_str.encode())  # Encode to convert string to bytes\n",
    "    config_hash = hash_obj.hexdigest()\n",
    "    \n",
    "    # Optionally, return a truncated version of the hash for readability\n",
    "    short_hash = config_hash[:8]  # Use the first 8 characters as an example\n",
    "    return short_hash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7879decf",
   "metadata": {},
   "source": [
    "Test `generate_config_hash`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = SimpleNamespace(arch='resnet18', dataset='cifar10', n_in=3, encoder_dimension=512)\n",
    "config2 = SimpleNamespace(arch='resnet34', dataset='cifar10', n_in=3, encoder_dimension=512)\n",
    "config3 = SimpleNamespace(arch='resnet50', dataset='cifar10', n_in=3, encoder_dimension=2048)\n",
    "\n",
    "test_eq(generate_config_hash(config1), generate_config_hash(config1))\n",
    "test_ne(generate_config_hash(config1), generate_config_hash(config2))\n",
    "test_ne(generate_config_hash(config1), generate_config_hash(config3))\n",
    "test_ne(generate_config_hash(config2), generate_config_hash(config3))\n",
    "\n",
    "config4 = SimpleNamespace(dataset='cifar10', arch='resnet18', n_in=3, encoder_dimension=512)  # Different order\n",
    "test_eq(generate_config_hash(config1), generate_config_hash(config4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_experiment_directory(base_dir, config):\n",
    "    # Generate a unique hash for the configuration\n",
    "    unique_hash = generate_config_hash(config)\n",
    "    \n",
    "    # Construct the directory path for this experiment\n",
    "    experiment_dir = os.path.join(base_dir, config.train_type, config.dataset, config.arch, unique_hash)\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(experiment_dir, exist_ok=True)\n",
    "    \n",
    "    return experiment_dir,unique_hash\n",
    "\n",
    "\n",
    "def save_configuration(config, experiment_dir):\n",
    "    \"\"\"\n",
    "    Saves the experiment configuration as a YAML file in the experiment directory.\n",
    "\n",
    "    Args:\n",
    "    config (dict, Namespace, or any serializable object): Experiment configuration.\n",
    "    experiment_dir (str): Path to the directory where the config file will be saved.\n",
    "    \"\"\"\n",
    "    config_file_path = os.path.join(experiment_dir, 'config.yaml')\n",
    "    \n",
    "    # Check if config is not a dictionary (e.g., a Namespace object) and convert if necessary\n",
    "    config_dict = vars(config) if not isinstance(config, dict) else config\n",
    "    \n",
    "    with open(config_file_path, 'w') as file:\n",
    "        yaml.dump(config_dict, file)\n",
    "    \n",
    "    print(f\"Configuration saved to {config_file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_metadata_file(experiment_dir, git_commit_hash, Description):\n",
    "    \"\"\"\n",
    "    Saves a metadata file with the Git commit hash, start/end times, and a description for the experiment.\n",
    "    \"\"\"\n",
    "    metadata_file_path = os.path.join(experiment_dir, 'metadata.yaml')\n",
    "    metadata_content = {\n",
    "        \"Git Commit Hash\": git_commit_hash,\n",
    "        \"Description\": Description\n",
    "    }\n",
    "\n",
    "    with open(metadata_file_path, 'w') as file:\n",
    "        yaml.dump(metadata_content, file)\n",
    "\n",
    "    print(f\"Metadata saved to {metadata_file_path}\")\n",
    "\n",
    "\n",
    "def update_experiment_index(project_root, details):\n",
    "    central_json_path = os.path.join(project_root, 'experiment_index.json')\n",
    "    \n",
    "    if os.path.exists(central_json_path):\n",
    "        with open(central_json_path, 'r') as file:\n",
    "            experiments_index = json.load(file)\n",
    "    else:\n",
    "        experiments_index = {}\n",
    "    \n",
    "    experiment_hash = details[\"experiment_hash\"]\n",
    "    experiments_index[experiment_hash] = details\n",
    "    \n",
    "    with open(central_json_path, 'w') as file:\n",
    "        json.dump(experiments_index, file, indent=4)\n",
    "    \n",
    "    print(f\"Updated experiment index for hash: {experiment_hash}\")\n",
    "\n",
    "\n",
    "def get_latest_commit_hash(repo_path):\n",
    "    try:\n",
    "        commit_hash = subprocess.check_output(['git', 'rev-parse', 'HEAD'], cwd=repo_path).decode('ascii').strip()\n",
    "        return commit_hash\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error obtaining latest commit hash: {e}\")\n",
    "        return None\n",
    "\n",
    "def setup_experiment(config,base_dir,Description:str):\n",
    "\n",
    "    # Create a unique directory for this experiment based on its configuration\n",
    "    # This directory will contain all artifacts related to the experiment, such as model checkpoints and logs.\n",
    "    experiment_dir, experiment_hash = create_experiment_directory(base_dir, config)\n",
    "\n",
    "    print(f\"The experiment_dir is: {experiment_dir} and the experiment hash is: {experiment_hash}\")\n",
    "\n",
    "    # Save the loaded configuration to the experiment directory as a YAML file\n",
    "    # This ensures that we can reproduce or analyze the experiment later.\n",
    "    save_configuration(config, experiment_dir)\n",
    "\n",
    "    git_commit_hash = get_latest_commit_hash('.')\n",
    "    print(f\"The git hash is: {git_commit_hash}\")\n",
    "\n",
    "    return experiment_dir, experiment_hash,git_commit_hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
