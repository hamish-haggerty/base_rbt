{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# histooralcancer_dataloading\n",
    "\n",
    "> How to load datasets for supervised learning, and SSL\n",
    "\n",
    "Important: Note that have to download the data first from \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp histooralcancer_dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "# from self_supervised.augmentations import *\n",
    "# from self_supervised.layers import *\n",
    "from base_rbt.utils import *\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#!unzip -q -o \"/content/drive/My Drive/histo_oral_cancer.zip\" -d \"/content/drive/My Drive/histo_oral_cancer\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main dataloader functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def label_func(x):\n",
    "    # Function to extract the label from the parent directory name\n",
    "    return x.parent.name\n",
    "\n",
    "def get_supervised_histooralcancer_train_dls(bs, dataset_dir, size=256, device='cpu', pct_dataset=1.0, num_workers=12):\n",
    "    \n",
    "    train_dir = os.path.join(dataset_dir, \"train\")  # Corrected path to the train directory\n",
    "    \n",
    "    train_dir = os.path.join(dataset_dir, \"train\")  # Corrected path to the train directory\n",
    "\n",
    "    # Paths to Normal and OSCC directories\n",
    "    normal_dir = os.path.join(train_dir, \"Normal\")\n",
    "    oscc_dir = os.path.join(train_dir, \"OSCC\")\n",
    "\n",
    "    # Get image files from the Normal and OSCC directories\n",
    "    fnames_normal = get_image_files(normal_dir)\n",
    "    fnames_oscc = get_image_files(oscc_dir)\n",
    "\n",
    "    # Sort filenames to ensure consistency\n",
    "    fnames_normal = sorted(fnames_normal)\n",
    "    fnames_oscc = sorted(fnames_oscc)\n",
    "\n",
    "    # Apply subset size\n",
    "    n_normal = int(len(fnames_normal) * (pct_dataset / 2))\n",
    "    n_oscc = int(len(fnames_oscc) * (pct_dataset / 2))\n",
    "\n",
    "    fnames_normal = fnames_normal[:n_normal]\n",
    "    fnames_oscc = fnames_oscc[:n_oscc]\n",
    "\n",
    "    # Combine the file lists\n",
    "    fnames = fnames_normal + fnames_oscc\n",
    "\n",
    "    # Data transformations\n",
    "\n",
    "    # Create the DataLoader\n",
    "    dls = ImageDataLoaders.from_path_func(\n",
    "        path=train_dir,\n",
    "        fnames=fnames,\n",
    "        label_func=label_func,\n",
    "        bs=bs,\n",
    "        valid_pct=0.0,  # No validation split, using all for training\n",
    "        device=device,\n",
    "        num_workers=num_workers * (device == 'cuda')\n",
    "    )\n",
    "\n",
    "    return dls\n",
    "\n",
    "def get_supervised_histooralcancer_test_dls(bs, dataset_dir, size=256, device='cpu', pct_dataset=1.0, num_workers=12):\n",
    "    test_dir = os.path.join(dataset_dir, \"test\")  # Corrected path to the test directory\n",
    "    val_dir = os.path.join(dataset_dir, \"val\")    # Path to the validation directory\n",
    "    \n",
    "    # Get image files from the testing and validation directories\n",
    "    fnames = get_image_files(test_dir) + get_image_files(val_dir)\n",
    "\n",
    "    # Apply subset size\n",
    "    n = int(len(fnames) * pct_dataset)\n",
    "    fnames = fnames[:n]\n",
    "\n",
    "    # Data transformations\n",
    "    # Create the DataLoader\n",
    "    dls = ImageDataLoaders.from_path_func(\n",
    "        path=test_dir,  # Path used for DataLoader\n",
    "        fnames=fnames,\n",
    "        label_func=label_func,\n",
    "        bs=bs,\n",
    "        valid_pct=0,  # No validation split for the test set\n",
    "        device=device,\n",
    "        drop_last=False,\n",
    "        num_workers=num_workers * (device == 'cuda')\n",
    "    )\n",
    "\n",
    "    return dls\n",
    "\n",
    "\n",
    "\n",
    "def get_bt_histooralcancer_train_dls(bs,size,device,pct_dataset=1.0,num_workers=12):\n",
    "\n",
    "    pct_oscc = 0.025\n",
    "    pct_normal = 1.0\n",
    "\n",
    "    dataset_dir = \"/content/drive/My Drive/histo_oral_cancer_resized\"\n",
    "    train_dir = os.path.join(dataset_dir, \"train\")  # Corrected path to the train directory\n",
    "\n",
    "    # Paths to Normal and OSCC directories\n",
    "    normal_dir = os.path.join(train_dir, \"Normal\")\n",
    "    oscc_dir = os.path.join(train_dir, \"OSCC\")\n",
    "\n",
    "    # Get image files from the Normal and OSCC directories\n",
    "    fnames_normal = get_image_files(normal_dir)\n",
    "    fnames_oscc = get_image_files(oscc_dir)\n",
    "\n",
    "    # Sort filenames to ensure consistency\n",
    "    fnames_normal = sorted(fnames_normal)\n",
    "    fnames_oscc = sorted(fnames_oscc)\n",
    "\n",
    "    # Apply subset size\n",
    "    n_normal = int(len(fnames_normal) * pct_normal)\n",
    "    n_oscc = int(len(fnames_oscc) * pct_oscc)\n",
    "\n",
    "    fnames_normal = fnames_normal[:n_normal]\n",
    "    fnames_oscc = fnames_oscc[:n_oscc]\n",
    "\n",
    "    # Combine the file lists\n",
    "    fnames = fnames_normal + fnames_oscc*10\n",
    "\n",
    "    # Create the DataLoader\n",
    "    dls = ImageDataLoaders.from_path_func(\n",
    "        path=train_dir,\n",
    "        fnames=fnames,\n",
    "        label_func=label_func,\n",
    "        bs=bs,\n",
    "        valid_pct=0.0,  # No validation split, using all for training\n",
    "        device=device,\n",
    "        num_workers=num_workers * (device == 'cuda')\n",
    "    )\n",
    "\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
