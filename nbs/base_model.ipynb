{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_model\n",
    "\n",
    "> In this module we have the base model, learner and other things we need to train encoder with Barlow Twins and other methods.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import importlib\n",
    "import sys\n",
    "import self_supervised\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import kornia.augmentation as korniatfm\n",
    "import torchvision.transforms as tvtfm\n",
    "from base_rbt.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the base functions and classes to train a basic BT-style model. Note that this (mostly) all comes directly from here: `https://github.com/KeremTurgutlu/self_supervised/blob/main/nbs/14%20-%20barlow_twins.ipynb`\n",
    "but we needed to extend some of the functionality for our purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the base classes and functions needed for image augmentation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#My edited version of RandTransform\n",
    "class RandomGaussianBlur(RandTransform):\n",
    "    \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "    order = 11\n",
    "    def __init__(self, \n",
    "                 p=1.0, #debugging (bug in libraries implementation)\n",
    "                 prob=0.5,#the real probability\n",
    "                 s=(8,32), #kernel\n",
    "                 sig=None, #sig_val is either manually input OR\n",
    "                 blur_r=(0.1,2),#is randomly chosen from uniform with these bounds\n",
    "                 same_on_batch=False, \n",
    "                 **kwargs): \n",
    "        \n",
    "        store_attr()\n",
    "        super().__init__(p=p, **kwargs)\n",
    "\n",
    "    def encodes(self, x:TensorImage):\n",
    "        \n",
    "        if isinstance(self.s, int):   s = (self.s,self.s)\n",
    "        elif isinstance(self.s, tuple) or isinstance(self.s, list): s=self.s\n",
    "     \n",
    "        #Default for ImageNet from BYOL / BT papers\n",
    "        if self.sig is None:\n",
    "            sig_val = np.random.uniform(self.blur_r[0],self.blur_r[1])\n",
    "        \n",
    "        else:\n",
    "            sig_val = self.sig\n",
    "            \n",
    "\n",
    "        tfm = korniatfm.RandomGaussianBlur(kernel_size=s,sigma=(sig_val,sig_val),same_on_batch=self.same_on_batch,p=self.prob)\n",
    "        return tfm(x)\n",
    "\n",
    "#Delete later: leaving for backward compatibility for now\n",
    "# class RandomGaussianBlur(RandTransform):\n",
    "#     \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "#     order = 11\n",
    "#     def __init__(self, p=0.5, s=(8,32), same_on_batch=False, **kwargs): \n",
    "#         store_attr()\n",
    "#         super().__init__(p=p, **kwargs)\n",
    "        \n",
    "#     def encodes(self, x:TensorImage):\n",
    "#         if isinstance(self.s, tuple): s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, list):  s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, int):   s = self.s\n",
    "#         s2 = int(s/4)*2+1\n",
    "#         tfm = korniatfm.RandomGaussianBlur((s2,s2),(s,s),same_on_batch=self.same_on_batch,p=1.) #p=1. is a bug\n",
    "#                                             #kernel #sigma\n",
    "        \n",
    "#         return tfm(x)\n",
    "\n",
    "\n",
    "class RandomCenterDropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.5, min_dropout_size=(20, 20), max_dropout_size=(60, 60), fill_value=0, same_on_batch=False):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.min_dropout_size = min_dropout_size\n",
    "        self.max_dropout_size = max_dropout_size\n",
    "        self.fill_value = fill_value\n",
    "        self.same_on_batch = same_on_batch\n",
    "        #self.id_transform = tvtfm.RandomResizedCrop((256, 256), scale=(1.,1.), ratio=(1.,1.))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Check if the augmentation should be applied to the whole batch or individually\n",
    "\n",
    "        #x=self.id_transform(x)\n",
    "\n",
    "        if self.same_on_batch:\n",
    "            if random.random() < self.p:\n",
    "                return self._apply_dropout(x)\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            # Apply dropout individually with given probability\n",
    "            for i in range(x.size(0)):\n",
    "                tem=random.random()\n",
    "                #print(f\"tem is: {tem}\")\n",
    "                if tem < self.p:\n",
    "                    x[i] = self._apply_dropout(x[i].unsqueeze(0)).squeeze(0)\n",
    "            return x\n",
    "\n",
    "    def _apply_dropout(self, img):\n",
    "        for i,count in enumerate(range(img.size(0))):  # Iterate through batch if necessary\n",
    "            _, h, w = img[i].shape\n",
    "            # Generate random dropout size within specified limits\n",
    "            dh = random.randint(self.min_dropout_size[0], self.max_dropout_size[0])\n",
    "            dw = random.randint(self.min_dropout_size[1], self.max_dropout_size[1])\n",
    "            \n",
    "            x1 = int(max((w - dw) / 2, 0))\n",
    "            y1 = int(max((h - dh) / 2, 0))\n",
    "            \n",
    "            mask = torch.ones_like(img[i])\n",
    "            mask[:, y1:y1+dh, x1:x1+dw] = self.fill_value\n",
    "            img[i] = img[i] * mask\n",
    "        \n",
    "        return img\n",
    "\n",
    "    \n",
    "def get_BT_batch_augs(size,\n",
    "                    flip=True,crop=True,noise=True,rotate=True,jitter=True,bw=True,blur=True,solar=True,cutout=False, #Whether to use  given aug or not\n",
    "                    resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.025, rotate_deg=30,jitter_s=.6,blur_s=(4,32),#hps of diff augs\n",
    "                    blur_r=(0.1,2),blur_sig=None,sol_t=0.05,sol_a=0.05,min_dropout_size=(25, 100),max_dropout_size=(50,150), #hps of diff augs\n",
    "                    flip_p=0.5, rotate_p=0.3,noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3,sol_p=0.1,cut_p=0.0, #prob of performing aug\n",
    "                    same_on_batch=False,stats=imagenet_stats,cuda=default_device().type == 'cuda',xtra_tfms=[]\n",
    "                    ):\n",
    "    \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    \n",
    "    tfms = []\n",
    "\n",
    "    korniatfm.RandomHorizontalFlip.order = RandomResizedCrop.order-1\n",
    "\n",
    "\n",
    "    if crop: tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "    #Unfortunately for some reason this doesn't work, so we can't apply \"same_on_batch=False\"\n",
    "    #tfms += [korniatfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio, same_on_batch=same_on_batch)]\n",
    "\n",
    "    if cutout: tfms+=[RandomCenterDropout(min_dropout_size=min_dropout_size,max_dropout_size=max_dropout_size, fill_value=0, p=cut_p,same_on_batch=same_on_batch)]\n",
    "    \n",
    "  \n",
    "    if flip: tfms += [korniatfm.RandomHorizontalFlip(p=flip_p,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if rotate: tfms += [Rotate(max_deg=rotate_deg, p=rotate_p, batch=same_on_batch)]\n",
    "\n",
    "                                             #brightness,contrast,saturation,hue\n",
    "    if jitter: tfms += [korniatfm.ColorJitter(0.4*jitter_s, 0.4*jitter_s, 0.2*jitter_s, 0.1*jitter_s, p=jitter_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if bw:     tfms += [korniatfm.RandomGrayscale(p=bw_p, same_on_batch=same_on_batch)]\n",
    "        \n",
    "    #sig will usually be None\n",
    "    if blur:   tfms += [RandomGaussianBlur(prob=blur_p, s=blur_s,sig=blur_sig,blur_r=blur_r, same_on_batch=same_on_batch)]\n",
    "\n",
    "    korniatfm.RandomSolarize.order = RandomGaussianBlur.order + 1 #we want to apply solarization after RandomGaussianBlur\n",
    "    \n",
    "    if solar: tfms += [korniatfm.RandomSolarize(p=sol_p,thresholds=sol_t, additions=sol_a,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if noise: tfms+=[korniatfm.RandomGaussianNoise(mean=0.0, std=noise_std, same_on_batch=same_on_batch, p=noise_p)]\n",
    "    \n",
    "    if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "\n",
    "    tfms += xtra_tfms\n",
    "\n",
    "    pipe = Pipeline(tfms, split_idx = 0)\n",
    "    return pipe\n",
    "\n",
    "@delegates(get_BT_batch_augs)\n",
    "def get_multi_aug_pipelines(size, **kwargs): return get_BT_batch_augs(size, **kwargs)\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(size=size,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_cifar10_aug_pipelines(size):\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    bt_cifar10_aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return bt_cifar10_aug_pipelines\n",
    "\n",
    "#Add other augmentations here e.g. BYOL augs\n",
    "IMAGENET_Augs = dict(flip_p1=0.5,flip_p2=0.5,jitter_p1=0.8,jitter_p2=0.8,bw_p1=0.2,\n",
    "                bw_p2=0.2,blur_p1=1.0,blur_p2=0.1,sol_p1=0.0,sol_p2=0.2,noise_p1=0.0,\n",
    "                noise_p2=0.0,cut_p=0,resize_scale=(0.7, 1.0),resize_ratio=(3/4, 4/3),rotate_deg=45.0,\n",
    "                rotate_p=0.5,blur_r=(0.1,2),blur_s=13,sol_t=0.1,sol_a=0.1,noise_std=0.1,min_dropout_size=None,max_dropout_size=None,\n",
    "                )\n",
    "\n",
    "DERMNET_Augs = IMAGENET_Augs.copy()\n",
    "DERMNET_Augs['min_dropout_size']=(50, 185)\n",
    "DERMNET_Augs['max_dropout_size']=(100,190)\n",
    "DERMNET_Augs['cut_p']=0.33\n",
    "\n",
    "def helper_get_bt_augs(size,Augs=IMAGENET_Augs):\n",
    "\n",
    "\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p1'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p1'],\n",
    "                        jitter_p=Augs['jitter_p1'], bw_p=Augs['bw_p1'], blur_p=Augs['blur_p1'],\n",
    "                        sol_p=Augs['sol_p1'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p2'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p2'],\n",
    "                        jitter_p=Augs['jitter_p2'], bw_p=Augs['bw_p2'], blur_p=Augs['blur_p2'],\n",
    "                        sol_p=Augs['sol_p2'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return aug_pipelines\n",
    "\n",
    "def get_bt_imagenet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=IMAGENET_Augs)\n",
    "\n",
    "def get_bt_dermnet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=DERMNET_Augs)\n",
    "\n",
    "\n",
    "\n",
    "bt_aug_func_dict = {'bt_cifar10_aug_pipelines':get_bt_cifar10_aug_pipelines,'bt_imagenet_aug_pipelines':get_bt_imagenet_aug_pipelines,\n",
    "                   'bt_dermnet_aug_pipelines':get_bt_dermnet_aug_pipelines\n",
    "                   }\n",
    "\n",
    "def get_bt_aug_pipelines(bt_augs,size):\n",
    "\n",
    "    return bt_aug_func_dict[bt_augs](size)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_ssl_dls(dataset,#cifar10, dermnet, etc\n",
    "            bs,\n",
    "            size,\n",
    "            device,\n",
    "            pct_dataset=1.0):\n",
    "    # Define the base package name in a variable for easy modification\n",
    "\n",
    "    try:\n",
    "        # Construct the module path\n",
    "        module_path = f\"{PACKAGE_NAME}.{dataset}_dataloading\"\n",
    "        \n",
    "        # Dynamically import the module\n",
    "        dataloading_module = importlib.import_module(module_path)\n",
    "    except ModuleNotFoundError:\n",
    "        # Handle the case where the module cannot be found\n",
    "        raise ImportError(f\"Could not find a data loading module for '{dataset}'. \"\n",
    "                          f\"Make sure '{module_path}' exists and is correctly named.\") from None\n",
    "    \n",
    "    # Assuming the function name follows a consistent naming convention\n",
    "    func_name = f\"get_bt_{dataset}_train_dls\"\n",
    "\n",
    "    try:\n",
    "        # Retrieve the data loading function from the module\n",
    "        data_loader_func = getattr(dataloading_module, func_name)\n",
    "    except AttributeError:\n",
    "        # Handle the case where the function does not exist in the module\n",
    "        raise AttributeError(f\"The function '{func_name}' was not found in '{module_path}'. \"\n",
    "                             \"Ensure it is defined and named correctly.\") from None\n",
    "    \n",
    "    # Proceed to call the function with arguments from the config\n",
    "    try:\n",
    "        dls_train = data_loader_func(bs=bs,size=size,device=device,pct_dataset=pct_dataset)\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the function call\n",
    "        raise RuntimeError(f\"An error occurred while calling '{func_name}' from '{module_path}': {e}\") from None\n",
    "    \n",
    "    return dls_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base functions / classes we need to train a BT / RBT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Base functions / classes we need to train a BT / RBT model.\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "\n",
    "# class BarlowTwinsModel(Module):\n",
    "#     \"\"\"An encoder followed by a projector\n",
    "#     \"\"\"\n",
    "#     def __init__(self,encoder,projector):\n",
    "#         self.encoder = encoder\n",
    "#         self.projector = projector\n",
    "        \n",
    "#     def forward(self,x): \n",
    "        \n",
    "#         return self.projector(self.encoder(x))\n",
    "\n",
    "# def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "#     \"Create Barlow Twins model\"\n",
    "#     n_in  = in_channels(encoder)\n",
    "#     with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "#     projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "#     apply_init(projector)\n",
    "#     return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "\n",
    "#We want access to both representation and projection\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        \n",
    "    def forward(self,x): \n",
    "        tem = self.encoder(x)\n",
    "        return tem,self.projector(tem) #get access to both representation and projection if needed for loss\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'forward returns tuple of (encoder(x),projector(encoder(x)))'\n",
    "\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    " \n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "\n",
    "#Note: this requires an lf (loss function), which is patched in later.\n",
    "#The reason for this is we can specify via a string argument (e.g. via\n",
    "#a config file) what loss function we want to use. lf_bt is the default\n",
    "#(standard barlow twins loss function).\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines,n_in,lmb,sparsity_level, \n",
    "                model_type='barlow_twins',print_augs=False\n",
    "                 ):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        store_attr('sparsity_level')\n",
    "        self.n_in=n_in\n",
    "        self.model_type = model_type\n",
    "        self.index=-1 #Gets updated after each batch\n",
    "        self.acc_dict = {}\n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self.index=-1  \n",
    "  \n",
    "    def before_batch(self):\n",
    "        \n",
    "        #TODO: Make this nicer (possibly can load in data as TensorImage(BW) or something?)\n",
    "        #This is a bit of a hack. Can make this more elegant later. But in new version of FastAI\n",
    "        #seems we need to compute TensorImage(BW) here, and depends on whether color or not, i.e. n_in.\n",
    "        if self.n_in == 1:\n",
    "\n",
    "            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            \n",
    "            #print(xi.shape)\n",
    "                                    \n",
    "        elif self.n_in == 3:\n",
    "            \n",
    "            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    " \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1): \n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]]\n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the above for vicreg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Base functions / classes we need to train a \n",
    "#  model\n",
    "class VICRegModel(Module):\n",
    "    \"\"\"VICReg model with options for shared or separate projectors\"\"\"\n",
    "    def __init__(self, encoder1, encoder2, projector1, projector2):\n",
    "        #may have encoder2 = encoder1 and projector2 = projector1.\n",
    "        #or e.g. encoders may have shared weights.\n",
    "        self.encoder1 = encoder1\n",
    "        self.encoder2 = encoder2\n",
    "        self.projector1 = projector1\n",
    "        self.projector2 = projector2\n",
    "        \n",
    "    def forward(self,x): #x is stacked xi,xj the two augmented views of batch\n",
    "      \n",
    "        x1, x2 = x[:x.size(0)//2], x[x.size(0)//2:]\n",
    "        \n",
    "        z1,z2 = self.projector1(self.encoder1(x1)), self.projector2(self.encoder2(x2))\n",
    "    \n",
    "        return z1, z2\n",
    "\n",
    "def create_vicreg_model(encoder1, encoder2, hidden_size=256, projection_size=128, bn=True, nlayers=3, shared_projector=True):\n",
    "    \"\"\"\n",
    "    Create VICReg model with flexible projector configuration\n",
    "    \n",
    "    Args:\n",
    "    - encoder1: first encoder model\n",
    "    - encoder2: second encoder model (can be the same as encoder1 for shared encoder)\n",
    "    - hidden_size: hidden size for projector\n",
    "    - projection_size: output size for projector\n",
    "    - bn: whether to use batch normalization in projector\n",
    "    - nlayers: number of layers in projector\n",
    "    - shared_projector: if True, use the same projector for both branches\n",
    "    \"\"\"\n",
    "    n_in = in_channels(encoder1)\n",
    "    with torch.no_grad(): representation = encoder1(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    projector1 = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "    apply_init(projector1)\n",
    "    \n",
    "    if not shared_projector:\n",
    "        projector2 = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "        apply_init(projector2)\n",
    "    else:\n",
    "        projector2 = projector1\n",
    "    \n",
    "    return VICRegModel(encoder1, encoder2, projector1, projector2)\n",
    "\n",
    "#helper function to compute vicreg loss.\n",
    "def off_diagonal(x):\n",
    "        n, m = x.shape\n",
    "        assert n == m\n",
    "        return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "class VICReg(BarlowTwins):\n",
    "    def __init__(self, aug_pipelines, n_in=3, sim_coeff=25, std_coeff=25, cov_coeff=1, \n",
    "                 model_type='vicreg', print_augs=False):\n",
    "        super().__init__(aug_pipelines, n_in, None, None, model_type, print_augs)\n",
    "        self.sim_coeff = sim_coeff\n",
    "        self.std_coeff = std_coeff\n",
    "        self.cov_coeff = cov_coeff\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.learn.loss_func = self.lf\n",
    "\n",
    "    def lf(self, pred, *yb):\n",
    "        x, y = pred  # Assuming the model returns two views (see VICRegModel)\n",
    "\n",
    "        # Invariance loss\n",
    "        repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "        # Variance loss\n",
    "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "        # Covariance loss\n",
    "        x = x - x.mean(dim=0)\n",
    "        y = y - y.mean(dim=0)\n",
    "        cov_x = (x.T @ x) / (x.size(0) - 1)\n",
    "        cov_y = (y.T @ y) / (y.size(0) - 1)\n",
    "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(x.size(1)) + \\\n",
    "                   off_diagonal(cov_y).pow_(2).sum().div(y.size(1))\n",
    "\n",
    "        # Total loss\n",
    "        loss = (\n",
    "            self.sim_coeff * repr_loss +\n",
    "            self.std_coeff * std_loss +\n",
    "            self.cov_coeff * cov_loss\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def before_batch(self):\n",
    "        #if self.model_type == 'br_vicreg':\n",
    "\n",
    "    #         # Create two copies of the input\n",
    "    #         x_left, x_right = self.x.clone(), self.x.clone()\n",
    "            \n",
    "    #         # Zero out the right half of x_left and the left half of x_right\n",
    "    #         mid = x_left.shape[-1] // 2\n",
    "    #         x_left[..., mid:] = 0\n",
    "    #         x_right[..., :mid] = 0\n",
    "            \n",
    "    #         print(f\"x shape: {self.x.shape}\")\n",
    "    #         print(f\"x_left shape: {x_left.shape}\")\n",
    "    #         print(f\"x_right shape: {x_right.shape}\")\n",
    "\n",
    "    #         # Apply augmentations\n",
    "    #         if self.n_in == 1:\n",
    "    #             xi = self.aug1(TensorImageBW(x_left))\n",
    "    #             xj = self.aug2(TensorImageBW(x_right))\n",
    "    #         elif self.n_in == 3:\n",
    "    #             xi = self.aug1(TensorImage(x_left))\n",
    "    #             xj = self.aug2(TensorImage(x_right))\n",
    "\n",
    "    #         print(f\"xi shape after aug: {xi.shape}\")\n",
    "    #         print(f\"xj shape after aug: {xj.shape}\")\n",
    "\n",
    "    #         # Concatenate the augmented halves\n",
    "    #         self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "    #         print(f\"Final self.learn.xb shape: {self.learn.xb[0].shape}\")\n",
    "\n",
    "        # The above splits x into x_left and x_right, with padding, then applies\n",
    "        # aug1 and aug2. Alternatively, we could compute aug1(x) and aug2(x). \n",
    "        # then zero pad the right half of aug1(x) and the left half of aug2(x).\n",
    "\n",
    "        #zero padding approach:\n",
    "        # if self.model_type == 'br_vicreg':\n",
    "        #     # Apply augmentations first\n",
    "        #     if self.n_in == 1:\n",
    "        #         xi = self.aug1(TensorImageBW(self.x))\n",
    "        #         xj = self.aug2(TensorImageBW(self.x))\n",
    "        #     elif self.n_in == 3:\n",
    "        #         xi = self.aug1(TensorImage(self.x))\n",
    "        #         xj = self.aug2(TensorImage(self.x))\n",
    "            \n",
    "        #     print(f\"x shape: {self.x.shape}\")\n",
    "        #     print(f\"xi shape after aug: {xi.shape}\")\n",
    "        #     print(f\"xj shape after aug: {xj.shape}\")\n",
    "\n",
    "        #     # Zero out the right half of xi and the left half of xj\n",
    "        #     mid = xi.shape[-1] // 2\n",
    "        #     xi[..., mid:] = 0\n",
    "        #     xj[..., :mid] = 0\n",
    "            \n",
    "        #     print(f\"xi shape after zeroing: {xi.shape}\")\n",
    "        #     print(f\"xj shape after zeroing: {xj.shape}\")\n",
    "\n",
    "        #     # Concatenate the augmented and zeroed halves\n",
    "        #     self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "        #     print(f\"Final self.learn.xb shape: {self.learn.xb[0].shape}\")\n",
    "        # else:\n",
    "        #     # Use the original BarlowTwins before_batch method for 'vicreg'\n",
    "        #     if self.n_in == 1:\n",
    "        #         xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "        #     elif self.n_in == 3:\n",
    "        #         xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "        #     self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "\n",
    "        #here we dont zero pad at all, just get 16x32 (for cifar, say)\n",
    "        if self.model_type == 'br_vicreg':\n",
    "            # Apply augmentations first\n",
    "            if self.n_in == 1:\n",
    "                xi = self.aug1(TensorImageBW(self.x))\n",
    "                xj = self.aug2(TensorImageBW(self.x))\n",
    "            elif self.n_in == 3:\n",
    "                xi = self.aug1(TensorImage(self.x))\n",
    "                xj = self.aug2(TensorImage(self.x))\n",
    "            \n",
    "            # Dynamically calculate the split point\n",
    "            _, _, height, width = xi.shape\n",
    "            split_point = width // 2\n",
    "\n",
    "            # Split each image into left and right halves\n",
    "            xi_left = xi[..., :split_point]  # Left half\n",
    "            xj_right = xj[..., split_point:]  # Right half\n",
    "            \n",
    "            # Concatenate the halves\n",
    "            self.learn.xb = (torch.cat([xi_left, xj_right], dim=0),)\n",
    "\n",
    "            print(f\"Input shape: {self.x.shape}\")\n",
    "            print(f\"Augmented left half shape: {xi_left.shape}\")\n",
    "            print(f\"Augmented right half shape: {xj_right.shape}\")\n",
    "            print(f\"Combined batch shape: {self.learn.xb[0].shape}\")\n",
    "\n",
    "        else:\n",
    "            # Original implementation for 'vicreg'\n",
    "            if self.n_in == 1:\n",
    "                xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            elif self.n_in == 3:\n",
    "                xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "            self.learn.xb = (torch.cat([xi, xj], dim=0),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# #TODO: \n",
    "\n",
    "# config_path = '../configs/cifar10/vicreg_config1.yaml'\n",
    "# config = load_config(config_path)\n",
    "\n",
    "# # Initialize the device for model training (CUDA or CPU)\n",
    "# device = default_device()\n",
    "\n",
    "# #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "# if hasattr(config,'splitter_str'):\n",
    "#         splitter_str=config.splitter_str\n",
    "# else:\n",
    "#         splitter_str='none'\n",
    "\n",
    "\n",
    "# # Construct the model based on the configuration\n",
    "# # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "\n",
    "# #vicreg model may require two encoders, so we need to handle this case\n",
    "# encoder_left = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "\n",
    "\n",
    "# #For standard vicreg (i.e. siamese) shared_encoder=True and shared_projector=True.\n",
    "# #This will be our control - i.e. to compare br_vicreg to.\n",
    "# if config.model_type == 'vicreg':\n",
    "\n",
    "#         if not config.shared_encoder:\n",
    "#                 encoder_right = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "#         else: \n",
    "#                 encoder_right = encoder_left\n",
    "\n",
    "#         model = create_vicreg_model(encoder_left, encoder_right, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "\n",
    "# #Assumption: for br_vicreg the arch is: encoder1,encoder2, where these are the same\n",
    "# #except for the first few layers (see `share_resnet_parameters`). If we want to change\n",
    "# #that assumption that's ok, but need to then adjust the config appropriately.\n",
    "# elif config.model_type == 'br_vicreg':\n",
    "#         encoder_right = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "\n",
    "#         test_eq(config.arch in ['resnet18','cifar_resnet18'],True)\n",
    "#         share_resnet_parameters(encoder_left, encoder_right)\n",
    "\n",
    "#         model = create_vicreg_model(encoder_left, encoder_right, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "\n",
    "\n",
    "# # Prepare data loaders according to the dataset specified in the configuration\n",
    "# dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "# # Set up data augmentation pipelines as specified in the configuration\n",
    "# #(this is same as for bt)\n",
    "# bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "# # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "\n",
    "# export=False\n",
    "\n",
    "# vicreg_trainer = VICRegTrainer(model=model,\n",
    "#                                 dls=dls,\n",
    "#                                 bt_aug_pipelines=bt_aug_pipelines,\n",
    "#                                 sparsity_level=config.sparsity_level,\n",
    "#                                 sim_coeff=config.sim_coeff,\n",
    "#                                 std_coeff=config.std_coeff,\n",
    "#                                 cov_coeff=config.cov_coeff,\n",
    "#                                 n_in=config.n_in,\n",
    "#                                 model_type=config.model_type,\n",
    "#                                 wd=config.wd,\n",
    "#                                 num_it=config.num_it,\n",
    "#                                 device=device,\n",
    "#                                 splitter_str=splitter_str,\n",
    "#                                 load_learner_path=None,\n",
    "#                                 experiment_dir=None,\n",
    "#                                 start_epoch=0,\n",
    "#                                 save_interval=config.save_interval,\n",
    "#                                 export=export\n",
    "\n",
    "#                                 )\n",
    "\n",
    "                                \n",
    "\n",
    "# # main_vicreg_train(config,\n",
    "# #         start_epoch = 0,\n",
    "# #         interrupt_epoch = 100,\n",
    "# #         load_learner_path=None,\n",
    "# #         learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "# #         experiment_dir=None,\n",
    "# #         )\n",
    "\n",
    "# vicreg_trainer.learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# #Verify that augs VICReg is working \n",
    "# dls = get_ssl_dls('cifar10',bs=32,size=128,device=default_device())\n",
    "# aug = get_bt_cifar10_aug_pipelines(32)\n",
    "# learn = Learner(dls,model=None, cbs=[VICReg(aug,n_in=3,model_type='br_vicreg')])\n",
    "# b = dls.one_batch()\n",
    "# learn._split(b)\n",
    "# learn('before_batch')\n",
    "# axes = learn.vic_reg.show(n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of barlow twins loss and sparse barlow twins loss functions, and proposes modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt(pred,I,lmb): #standard bt loss\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "    \n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs \n",
    "    cdiff = (C - I)**2\n",
    "    loss = (cdiff*I + cdiff*(1-I)*lmb).sum() \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_sparse_head(pred,I,lmb,projector,sparsity_level):\n",
    "  \n",
    "    bt_loss = lf_bt(pred,I,lmb)\n",
    "    L21 = torch.linalg.norm(projector[-1].weight, ord=2, dim=0).sum()\n",
    "\n",
    "    # print(f\"bt_loss is {bt_loss}, L21 is {L21}, scaled L21 is {sparsity_level*L21}\")\n",
    "    # print(bt_loss)\n",
    "    # print(L21)\n",
    "\n",
    "    \n",
    "    loss =  bt_loss + sparsity_level*L21 #barlow twins loss + L21 norm of last layer of projector\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_indiv_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb*(0.5*torch.abs(z1_enc) + 0.5*torch.abs(z2_enc)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1_enc.pow(2) + 0.5 * z2_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_norm_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_fun(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm_enc.T @ z2norm_enc) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    loss = (cdiff*I).sum() #standard bt loss\n",
    "\n",
    "    print(f\"invariance loss is: {loss} and sparsity loss is: {sparsity}\")\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_proj_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                           ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm.pow(2) + 0.5 * z2norm.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch in loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb):\n",
    "    \"Assumes model created according to type p3\"\n",
    "\n",
    "    if self.model_type=='barlow_twins':\n",
    "         pred_enc = pred[0]\n",
    "         pred = pred[1]\n",
    "         return lf_bt(pred, self.I,self.lmb)\n",
    "\n",
    "    elif self.model_type=='sparse_head_barlow_twins':\n",
    "        pred_enc = pred[0]\n",
    "        pred = pred[1]\n",
    "\n",
    "        return lf_bt_sparse_head(pred, self.I,lmb=self.lmb,projector=self.learn.model.projector,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "\n",
    "    elif self.model_type=='indiv_sparse_barlow_twins':\n",
    "        return lf_bt_indiv_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='group_sparse_barlow_twins':\n",
    "        return lf_bt_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='group_norm_sparse_barlow_twins':\n",
    "        return lf_bt_group_norm_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='proj_group_sparse_barlow_twins':\n",
    "        return lf_bt_proj_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='fun':\n",
    "        return lf_bt_fun(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "\n",
    "    else: raise(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt(m):\n",
    "    return L(sequential(*m.encoder),m.projector).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt_last_block_resnet50(m):\n",
    "    #Note: don't think we actually need this guy.\n",
    "    \"Freeze all but the last bottleneck layer\"\n",
    "    enc_except_final_block = sequential(*m.encoder[:-3], m.encoder[-3][:-1])\n",
    "    final_block_and_projector = sequential(m.encoder[-3][-1], m.projector)\n",
    "    return L(enc_except_final_block, final_block_and_projector).map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to use the above functions in an end to end fashion. First we get some data and plonk it into a dls, Then create an encoder, an augmentation pipeline, a learner, then fit\n",
    "the learner. This is the complete process of training BT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_bt_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "        \n",
    "    learn = Learner(dls,model=None, cbs=[BarlowTwins(aug,n_in=n_in,lmb=None,sparsity_level=None,\n",
    "                                                     print_augs=print_augs\n",
    "                                        )])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.barlow_twins.show(n=n)\n",
    "\n",
    "def show_vicreg_batch(dls,n_in,aug,n=2,print_augs=True,model_type='vicreg'):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "\n",
    "    learn = Learner(dls,model=None, cbs=[VICReg(aug,n_in=3,model_type=model_type)])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.vic_reg.show(n=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([64, 3, 32, 16])\n",
      "Augmented left half shape: torch.Size([32, 3, 32, 16])\n",
      "Augmented right half shape: torch.Size([32, 3, 32, 16])\n",
      "Combined batch shape: torch.Size([64, 3, 32, 16])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide \n",
    "\n",
    "dls = get_ssl_dls('cifar10',bs=32,size=128,device=default_device())\n",
    "aug = get_bt_cifar10_aug_pipelines(32)\n",
    "show_vicreg_batch(dls,n_in=3,aug=aug,n=2,print_augs=True,model_type='vicreg')\n",
    "show_vicreg_batch(dls,n_in=3,aug=aug,n=2,print_augs=True,model_type='br_vicreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SaveBarlowLearnerCheckpoint(Callback):\n",
    "    \"Save such that can resume training \"\n",
    "    def __init__(self, experiment_dir,start_epoch=0, save_interval=250,with_opt=True):\n",
    "        self.experiment_dir = experiment_dir\n",
    "        self.start_epoch = start_epoch\n",
    "        self.save_interval = save_interval\n",
    "        self.with_opt = with_opt  # Decide whether to save optimizer state as well.\n",
    "\n",
    "    def after_epoch(self):\n",
    "        if (self.epoch+1) % self.save_interval == 0 and self.epoch>=self.start_epoch:\n",
    "            print(f\"Saving model and learner state at epoch {self.epoch}\")\n",
    "   \n",
    "            checkpoint_filename = f\"learner_checkpoint_epoch_{self.epoch}\"\n",
    "            checkpoint_path = os.path.join(self.experiment_dir, checkpoint_filename)\n",
    "            # Save the entire learner object, including the model's parameters and optimizer state.\n",
    "            self.learn.save(checkpoint_path, with_opt=self.with_opt)\n",
    "            print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "class SaveBarlowLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        encoder_filename = f\"trained_encoder_epoch_{self.epoch}.pth\"\n",
    "        encoder_path = os.path.join(self.experiment_dir, encoder_filename)\n",
    "        torch.save(self.learn.model.encoder.state_dict(), encoder_path)\n",
    "        print(f\"encoder state dict saved to {encoder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_barlow_model(arch,ps,hs,path):\n",
    "\n",
    "    encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_barlow_twins_model(encoder, hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BarlowTrainer:\n",
    "    \"Setup a learner for training a BT model. Can do transfer learning, normal training, or resume training.\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,#An encoder followed by a projector\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 lmb,\n",
    "                 sparsity_level,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 splitter_str='none',\n",
    "                 num_it=100, #Number of iterations to run lr_find for.\n",
    "                 load_learner_path=None, #Path to load learner from (optional)\n",
    "                 experiment_dir=None, #Where to save model checkpoints (optional)\n",
    "                 start_epoch=0, #Which epoch to start from\n",
    "                 save_interval=None, #How often to save model checkpoints (optional). \n",
    "                 export=False,\n",
    "                 ):\n",
    "\n",
    "        store_attr()\n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    \n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics.\n",
    "\n",
    "        Returns:\n",
    "        - learn: The Learner object.\n",
    "        \"\"\"\n",
    "      \n",
    "        self.model.to(self.device)\n",
    "\n",
    "\n",
    "        cbs = [BarlowTwins(self.bt_aug_pipelines,n_in=self.n_in,lmb=self.lmb,\n",
    "                           sparsity_level=self.sparsity_level,print_augs=False,\n",
    "                           model_type=self.model_type\n",
    "                           )\n",
    "              ]\n",
    "\n",
    "        learn=Learner(self.dls,self.model,splitter=my_splitter_bt,wd=self.wd, cbs=cbs\n",
    "                     )\n",
    "        \n",
    "        if self.load_learner_path: learn.load(self.load_learner_path,with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir:\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export:\n",
    "            cbs.append(SaveBarlowLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "                \n",
    "    \n",
    "    def bt_transfer_learning(self,freeze_epochs:int,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is already pretrained, we can do transfer learning.\n",
    "            Freeze encoder, train projector for a few epochs, then unfreeze and train all. \n",
    "        \"\"\"\n",
    "        self.learn.freeze()\n",
    "        test_grad_off(self.learn.encoder)\n",
    "        self.learn.fit(freeze_epochs)\n",
    "\n",
    "         # Check if the splitter is 'my_splitter_bt_last_block_resnet50'\n",
    "        if self.splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "            # Unfreeze only the last bottleneck block\n",
    "            for param in self.learn.model.encoder[-3][-1].parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "            print(f'splitter_str={self.splitter_str}')\n",
    "        else:\n",
    "            # Unfreeze the entire encoder\n",
    "            self.learn.unfreeze()\n",
    "            test_grad_on(self.learn.model)\n",
    "        \n",
    "        \n",
    "        self.learn.summary()\n",
    "\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it) #lets find a good maximum lr\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley, cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def bt_learning(self,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is not pretrained, we can do normal training.\n",
    "        \"\"\"\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "    \n",
    "    def continue_bt_learning(self,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Resume training with `fit_one_cycle` after loading a learner.\n",
    "        \"\"\"\n",
    "        \n",
    "        test_ne(self.load_learner_path,None)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs,start_epoch=start_epoch,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def train(self,learn_type, freeze_epochs:int,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Train model using BT\n",
    "        \"\"\"\n",
    "        if learn_type == 'transfer_learning':\n",
    "            \n",
    "            self.bt_transfer_learning(freeze_epochs=freeze_epochs,epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        elif learn_type=='continue_learning':\n",
    "            self.continue_bt_learning(epochs=epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "        \n",
    "        elif learn_type=='standard':\n",
    "            self.bt_learning(epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        else: raise Exception(\"Invalid weight_type\")\n",
    "\n",
    "        return self.learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can inherit from the above for vicreg version. Just setting up the learner is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VICRegTrainer(BarlowTrainer):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 sparsity_level,\n",
    "                 sim_coeff,\n",
    "                 std_coeff,\n",
    "                 cov_coeff,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 splitter_str='none',\n",
    "                 num_it=100,\n",
    "                 load_learner_path=None,\n",
    "                 experiment_dir=None,\n",
    "                 start_epoch=0,\n",
    "                 save_interval=None,\n",
    "                 export=False):\n",
    "        \n",
    "        \n",
    "                # Store VICReg-specific attributes\n",
    "        store_attr('sim_coeff,std_coeff,cov_coeff') #why doesn't this work?\n",
    "        # Call the parent constructor with None for lmb\n",
    "        super().__init__(model, dls, bt_aug_pipelines,None,sparsity_level, n_in, model_type,\n",
    "                         wd, device, splitter_str, num_it, load_learner_path,\n",
    "                         experiment_dir, start_epoch, save_interval, export)\n",
    "        \n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics for VICReg.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        cbs = [VICReg(self.bt_aug_pipelines, n_in=self.n_in, \n",
    "                      sim_coeff=self.sim_coeff, std_coeff=self.std_coeff, cov_coeff=self.cov_coeff,\n",
    "                      model_type=self.model_type, print_augs=False)]\n",
    "\n",
    "        # Use the splitter based on splitter_str\n",
    "        # if self.splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "        #     splitter = my_splitter_bt_last_block_resnet50\n",
    "        # else:\n",
    "        #     splitter = my_splitter_bt\n",
    "        #learn = Learner(self.dls, self.model, splitter=splitter, wd=self.wd, cbs=cbs)\n",
    "        \n",
    "        #TODO: Implement custom splitter for VICReg\n",
    "        #splitter not supported yet for vicreg: we can do this but need a custom splitter.\n",
    "        #The issue is just that vicreg e.g. has encoder_left and encoder_right, v.s.\n",
    "        #BT which just has one encoder. Just leaving splitter off for now\n",
    "        learn = Learner(self.dls, self.model, wd=self.wd, cbs=cbs)\n",
    "        if self.load_learner_path: \n",
    "            learn.load(self.load_learner_path, with_opt=True)\n",
    "\n",
    "        return learn\n",
    "\n",
    "    # # Override the train method if necessary\n",
    "    # def train(self, learn_type, freeze_epochs:int, epochs:int, start_epoch:int, interrupt_epoch:int):\n",
    "    #     \"\"\"Train model using VICReg\"\"\"\n",
    "    #     # You can customize this method for VICReg-specific training logic if needed\n",
    "    #     return super().train(learn_type, freeze_epochs, epochs, start_epoch, interrupt_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that splitting/freezings works in `bt_transfer_learning`.\n",
    "\n",
    "It's a bit hacky but looks to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "encoder = resnet_arch_to_encoder(arch='resnet50', weight_type=random)\n",
    "model = create_barlow_twins_model(encoder, hidden_size=8192, projection_size=8192)\n",
    "dls = get_ssl_dls('cifar10',bs=64,size=32,device=default_device())\n",
    "\n",
    "cbs = [BarlowTwins(get_bt_aug_pipelines(bt_augs='bt_cifar10_aug_pipelines', size=32),\n",
    "       n_in=3,lmb=1/8192,sparsity_level=None,print_augs=False,\n",
    "        model_type='barlow_twins'\n",
    "                    )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy pasted from `bt_transfer_learning`\n",
    "\n",
    "Bit hacky, but ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BarlowTwinsModel (Input shape: 64 x 3 x 32 x 32)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     64 x 64 x 16 x 16   \n",
       "Conv2d                                    9408       False     \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "MaxPool2d                                                      \n",
       "Conv2d                                    4096       False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 8 x 8    \n",
       "Conv2d                                    32768      False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 4 x 4    \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    524288     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 2 x 2    \n",
       "Conv2d                                    524288     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2097152    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "AdaptiveAvgPool2d                                              \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048           \n",
       "Flatten                                                        \n",
       "____________________________________________________________________________\n",
       "                     64 x 8192           \n",
       "Linear                                    16785408   True      \n",
       "BatchNorm1d                               16384      True      \n",
       "ReLU                                                           \n",
       "Linear                                    67117056   True      \n",
       "BatchNorm1d                               16384      True      \n",
       "ReLU                                                           \n",
       "Linear                                    67117056   True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 174,560,320\n",
       "Total trainable params: 155,561,856\n",
       "Total non-trainable params: 18,998,464\n",
       "\n",
       "Optimizer used: <function Adam>\n",
       "Loss function: <bound method BarlowTwins.lf of BarlowTwins>\n",
       "\n",
       "Model frozen up to parameter group #1\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - CastToTensor\n",
       "  - BarlowTwins\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide \n",
    "learn=Learner(dls,model,splitter=my_splitter_bt,cbs=cbs\n",
    "             )\n",
    "\n",
    "\n",
    "splitter_str = 'my_splitter_bt_last_block_resnet50'\n",
    "#splitter_str='none'\n",
    "learn.freeze() #freeze everything up to projector\n",
    "test_grad_off(learn.encoder)\n",
    "\n",
    "    # Check if the splitter is 'my_splitter_bt_last_block_resnet50'\n",
    "if splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "    # Unfreeze only the last bottleneck block\n",
    "    for param in learn.model.encoder[-3][-1].parameters():\n",
    "        param.requires_grad = True\n",
    "else:\n",
    "    # Unfreeze the entire encoder\n",
    "    learn.unfreeze()\n",
    "\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a BT model. Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "    if hasattr(config,'splitter_str'):\n",
    "        splitter_str=config.splitter_str\n",
    "    else:\n",
    "        splitter_str='none'\n",
    "\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "    encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    \n",
    "    model = create_barlow_twins_model(encoder, hidden_size=config.hs, projection_size=config.ps)\n",
    "\n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    bt_trainer = BarlowTrainer(model=model,\n",
    "                    dls=dls,\n",
    "                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                    lmb=config.lmb,\n",
    "                    sparsity_level=config.sparsity_level,\n",
    "                    n_in=config.n_in,\n",
    "                    model_type=config.model_type,\n",
    "                    wd=config.wd,\n",
    "                    num_it=config.num_it,\n",
    "                    device=device,\n",
    "                    splitter_str=splitter_str,\n",
    "                    load_learner_path=load_learner_path,\n",
    "                    experiment_dir=experiment_dir,\n",
    "                    start_epoch=start_epoch,\n",
    "                    save_interval=config.save_interval,\n",
    "                    export=export\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = bt_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above but for vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_vicreg_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a vicreg model (standard or br) Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "    if hasattr(config,'splitter_str'):\n",
    "        splitter_str=config.splitter_str\n",
    "    else:\n",
    "        splitter_str='none'\n",
    "\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "\n",
    "    #vicreg model may require two encoders, so we need to handle this case\n",
    "    encoder_left = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    if config.model_type == 'vicreg':\n",
    "        model = create_vicreg_model(encoder_left, encoder_left, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "    elif config.model_type == 'br_vicreg':\n",
    "        encoder_right = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "        if config.share_encoder: #this shares parameters between the two encoders.\n",
    "                                  #specifically up to and including stage1. So far\n",
    "                                  #just for resnet18\n",
    "            test_eq(config.arch,'resnet18','Only resnet18 supported for shared encoder at present.')  \n",
    "            share_resnet_parameters(encoder_left, encoder_right)\n",
    "\n",
    "        model = create_vicreg_model(encoder_left, encoder_right, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "\n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    #(this is same as for bt)\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    vicreg_trainer = VICRegTrainer(model=model,\n",
    "                                    dls=dls,\n",
    "                                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                                    sparsity_level=config.sparsity_level,\n",
    "                                    sim_coeff=config.sim_coeff,\n",
    "                                    std_coeff=config.std_coeff,\n",
    "                                    cov_coeff=config.cov_coeff,\n",
    "                                    n_in=config.n_in,\n",
    "                                    model_type=config.model_type,\n",
    "                                    wd=config.wd,\n",
    "                                    num_it=config.num_it,\n",
    "                                    device=device,\n",
    "                                    splitter_str=splitter_str,\n",
    "                                    load_learner_path=load_learner_path,\n",
    "                                    experiment_dir=experiment_dir,\n",
    "                                    start_epoch=start_epoch,\n",
    "                                    save_interval=config.save_interval,\n",
    "                                    export=export\n",
    "\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = vicreg_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# #TODO: \n",
    "\n",
    "# config_path = '../configs/cifar10/vicreg_config1.yaml'\n",
    "# config = load_config(config_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Initialize the device for model training (CUDA or CPU)\n",
    "# device = default_device()\n",
    "\n",
    "# #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "# if hasattr(config,'splitter_str'):\n",
    "#         splitter_str=config.splitter_str\n",
    "# else:\n",
    "#         splitter_str='none'\n",
    "\n",
    "\n",
    "# # Construct the model based on the configuration\n",
    "# # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "\n",
    "# #vicreg model may require two encoders, so we need to handle this case\n",
    "# encoder_left = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "# if config.model_type == 'vicreg':\n",
    "#         model = create_vicreg_model(encoder_left, encoder_left, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "\n",
    "# elif config.model_type == 'br_vicreg':\n",
    "#         encoder_right = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "# if config.share_encoder: #this shares parameters between the two encoders.\n",
    "#                                 #specifically up to and including stage1. So far\n",
    "#                                 #just for resnet18\n",
    "#         test_eq(config.arch,'resnet18','Only resnet18 supported for shared encoder at present.')  \n",
    "#         share_resnet_parameters(encoder_left, encoder_right)\n",
    "\n",
    "#         model = create_vicreg_model(encoder_left, encoder_right, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "\n",
    "\n",
    "# # Prepare data loaders according to the dataset specified in the configuration\n",
    "# dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "# # Set up data augmentation pipelines as specified in the configuration\n",
    "# #(this is same as for bt)\n",
    "# bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "# # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "\n",
    "# export=False\n",
    "\n",
    "# vicreg_trainer = VICRegTrainer(model=model,\n",
    "#                                 dls=dls,\n",
    "#                                 bt_aug_pipelines=bt_aug_pipelines,\n",
    "#                                 sparsity_level=config.sparsity_level,\n",
    "#                                 sim_coeff=config.sim_coeff,\n",
    "#                                 std_coeff=config.std_coeff,\n",
    "#                                 cov_coeff=config.cov_coeff,\n",
    "#                                 n_in=config.n_in,\n",
    "#                                 model_type=config.model_type,\n",
    "#                                 wd=config.wd,\n",
    "#                                 num_it=config.num_it,\n",
    "#                                 device=device,\n",
    "#                                 splitter_str=splitter_str,\n",
    "#                                 load_learner_path=None,\n",
    "#                                 experiment_dir=None,\n",
    "#                                 start_epoch=0,\n",
    "#                                 save_interval=config.save_interval,\n",
    "#                                 export=export\n",
    "\n",
    "#                                 )\n",
    "\n",
    "                                \n",
    "\n",
    "# # main_vicreg_train(config,\n",
    "# #         start_epoch = 0,\n",
    "# #         interrupt_epoch = 100,\n",
    "# #         load_learner_path=None,\n",
    "# #         learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "# #         experiment_dir=None,\n",
    "# #         )\n",
    "\n",
    "# vicreg_trainer.learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_path = '../configs/cifar10/bt_test_config.yaml'\n",
    "# config = load_config(config_path)\n",
    "\n",
    "# load_learner_path=None\n",
    "# experiment_dir=None\n",
    "# start_epoch=0\n",
    "\n",
    "# # Initialize the device for model training (CUDA or CPU)\n",
    "# device = default_device()\n",
    "\n",
    "# # Construct the model based on the configuration\n",
    "# # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "# encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "\n",
    "# model = create_barlow_twins_model(encoder, hidden_size=config.hs, projection_size=config.ps)\n",
    "\n",
    "# # Prepare data loaders according to the dataset specified in the configuration\n",
    "# dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "# # Set up data augmentation pipelines as specified in the configuration\n",
    "# bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "# # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "# #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "# bt_trainer = BarlowTrainer(model=model,\n",
    "#                dls=dls,\n",
    "#                bt_aug_pipelines=bt_aug_pipelines,\n",
    "#                lmb=config.lmb,\n",
    "#                sparsity_level=config.sparsity_level,\n",
    "#                n_in=config.n_in,\n",
    "#                model_type=config.model_type,\n",
    "#                wd=config.wd,\n",
    "#                num_it=config.num_it,\n",
    "#                device=device,\n",
    "#                load_learner_path=load_learner_path,\n",
    "#                experiment_dir=experiment_dir,\n",
    "#                start_epoch=start_epoch,\n",
    "#                save_interval=config.save_interval\n",
    "#                               )\n",
    "\n",
    "\n",
    "# bt_trainer.learn.lr_find??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_experiment_state(config,base_dir):\n",
    "    \"\"\"Get the load_learner_path, learn_type, start_epoch, interrupt_epoch for BT experiment.\n",
    "       Basically this tells us how to continue learning (e.g. we have run two sessions for \n",
    "       100 epochs, and want to continue for another 100 epochs). Return values are\n",
    "       None if we are starting from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    load_learner_path, _  = get_highest_num_path(base_dir, config)\n",
    "    #TODO:\n",
    "    #We can get start_epoch, interrupt epoch from `get_highest_epoch_path` + save_interval (may be None!)\n",
    "    start_epoch=0 if load_learner_path is None else int(load_learner_path.split('_')[-1])+1\n",
    "    \n",
    "    if start_epoch >= config.epochs:\n",
    "        print(f\"start_epoch={start_epoch}, but already completed {config.epochs} epochs. Exiting.\")\n",
    "        sys.exit()\n",
    "\n",
    "    interrupt_epoch = start_epoch + config.save_interval\n",
    "\n",
    "    #We can also get the learn_type from the load_learner_path + weight_type. \n",
    "    \n",
    "    if config.weight_type == 'random':\n",
    "        learn_type = 'standard'\n",
    "    \n",
    "    elif 'pretrained' in config.weight_type:\n",
    "        learn_type = 'transfer_learning'\n",
    "\n",
    "    learn_type = learn_type if load_learner_path is None else 'continue_learning'\n",
    "\n",
    "    return load_learner_path, learn_type, start_epoch, interrupt_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_experiment(config,\n",
    "                      base_dir,\n",
    "                      ):\n",
    "    \"\"\"Run several epochs of the experiment as defined in the config and where we are up to. e.g. epoch 0, or resuming\n",
    "    at epoch 99 etc. Basically a stateful version of `main_bt_train` that can be resumed. And saving.\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    experiment_dir, experiment_hash,git_commit_hash = setup_experiment(config,base_dir)\n",
    "\n",
    "    load_learner_path, learn_type, start_epoch, interrupt_epoch = get_bt_experiment_state(config,base_dir)\n",
    "\n",
    "    main_bt_train(config=config,\n",
    "            start_epoch=start_epoch,\n",
    "            interrupt_epoch=interrupt_epoch,\n",
    "            load_learner_path=load_learner_path,\n",
    "            learn_type=learn_type,\n",
    "            experiment_dir=experiment_dir,\n",
    "            )\n",
    "\n",
    "    # Save a metadata file in the experiment directory with the Git commit hash and other details\n",
    "    save_metadata_file(experiment_dir=experiment_dir, git_commit_hash=git_commit_hash)\n",
    "\n",
    "    # After experiment execution and all processing are complete\n",
    "    update_experiment_index(base_dir,{\n",
    "        \"experiment_hash\": experiment_hash,  # Unique identifier derived from the experiment's configuration\n",
    "        \"experiment_dir\": experiment_dir,  # Absolute path to the experiment's dedicated directory\n",
    "        \"git_commit_hash\": git_commit_hash,  # Git commit hash for the code version used in the experiment\n",
    "        # Potentially include additional details collected during or after the experiment, such as:\n",
    "        # Any other metadata or results summary that is relevant to the experiment\n",
    "                            })\n",
    "    \n",
    "    return experiment_dir,experiment_hash #Return the experiment_dir so we can easily access the results of the experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpgrq6obbl/SSL/cifar10/smallres/d746b323 and the experiment hash is: d746b323\n",
      "Configuration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpgrq6obbl/SSL/cifar10/smallres/d746b323/config.yaml\n",
      "The git hash is: 35aa375676d83e67cb956d2f78cf8ee21be4eb4f\n",
      "Looking in /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpgrq6obbl/SSL/cifar10/smallres/d746b323 for highest num saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/11 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(config_path)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# config.model_type = 'sparse_head_barlow_twins'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# config.sparsity_level=10\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# config.epochs=100\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# config.save_interval=100\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m experiment_dir,experiment_hash \u001b[38;5;241m=\u001b[39m \u001b[43mmain_bt_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(experiment_dir))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(base_dir))\n",
      "Cell \u001b[0;32mIn[44], line 15\u001b[0m, in \u001b[0;36mmain_bt_experiment\u001b[0;34m(config, base_dir)\u001b[0m\n\u001b[1;32m     11\u001b[0m experiment_dir, experiment_hash,git_commit_hash \u001b[38;5;241m=\u001b[39m setup_experiment(config,base_dir)\n\u001b[1;32m     13\u001b[0m load_learner_path, learn_type, start_epoch, interrupt_epoch \u001b[38;5;241m=\u001b[39m get_bt_experiment_state(config,base_dir)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmain_bt_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_learner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_learner_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Save a metadata file in the experiment directory with the Git commit hash and other details\u001b[39;00m\n\u001b[1;32m     24\u001b[0m save_metadata_file(experiment_dir\u001b[38;5;241m=\u001b[39mexperiment_dir, git_commit_hash\u001b[38;5;241m=\u001b[39mgit_commit_hash)\n",
      "Cell \u001b[0;32mIn[39], line 63\u001b[0m, in \u001b[0;36mmain_bt_train\u001b[0;34m(config, start_epoch, interrupt_epoch, load_learner_path, learn_type, experiment_dir)\u001b[0m\n\u001b[1;32m     44\u001b[0m bt_trainer \u001b[38;5;241m=\u001b[39m BarlowTrainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     45\u001b[0m                 dls\u001b[38;5;241m=\u001b[39mdls,\n\u001b[1;32m     46\u001b[0m                 bt_aug_pipelines\u001b[38;5;241m=\u001b[39mbt_aug_pipelines,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 export\u001b[38;5;241m=\u001b[39mexport\n\u001b[1;32m     60\u001b[0m                                 )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Train the model with the specified configurations and save `learn` checkpoints\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mbt_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfreeze_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreeze_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m learn\n",
      "Cell \u001b[0;32mIn[35], line 126\u001b[0m, in \u001b[0;36mBarlowTrainer.train\u001b[0;34m(self, learn_type, freeze_epochs, epochs, start_epoch, interrupt_epoch)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinue_bt_learning(epochs\u001b[38;5;241m=\u001b[39mepochs,start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch,interrupt_epoch\u001b[38;5;241m=\u001b[39minterrupt_epoch)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learn_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbt_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\n",
      "Cell \u001b[0;32mIn[35], line 103\u001b[0m, in \u001b[0;36mBarlowTrainer.bt_learning\u001b[0;34m(self, epochs, interrupt_epoch)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbt_learning\u001b[39m(\u001b[38;5;28mself\u001b[39m,epochs:\u001b[38;5;28mint\u001b[39m,interrupt_epoch:\u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124;03m\"\"\"If the encoder is not pretrained, we can do normal training.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     lrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_it\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_it\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\u001b[38;5;241m.\u001b[39mfit_one_cycle(epochs, lrs\u001b[38;5;241m.\u001b[39mvalley,cbs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_training_cbs(interrupt_epoch))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/callback/schedule.py:293\u001b[0m, in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[1;32m    291\u001b[0m n_epoch \u001b[38;5;241m=\u001b[39m num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    292\u001b[0m cb\u001b[38;5;241m=\u001b[39mLRFinder(start_lr\u001b[38;5;241m=\u001b[39mstart_lr, end_lr\u001b[38;5;241m=\u001b[39mend_lr, num_it\u001b[38;5;241m=\u001b[39mnum_it, stop_div\u001b[38;5;241m=\u001b[39mstop_div)\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_logging(): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suggest_funcs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     lrs, losses \u001b[38;5;241m=\u001b[39m tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorder\u001b[38;5;241m.\u001b[39mlrs[num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m]), tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorder\u001b[38;5;241m.\u001b[39mlosses[num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:256\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:245\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:231\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:227\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    225\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:208\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_pred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb):\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_grad\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m, in \u001b[0;36mlf\u001b[0;34m(self, pred, *yb)\u001b[0m\n\u001b[1;32m      8\u001b[0m      pred_enc \u001b[38;5;241m=\u001b[39m pred[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m      pred \u001b[38;5;241m=\u001b[39m pred[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m      \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlf_bt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mI\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlmb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_head_barlow_twins\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     13\u001b[0m     pred_enc \u001b[38;5;241m=\u001b[39m pred[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[21], line 12\u001b[0m, in \u001b[0;36mlf_bt\u001b[0;34m(pred, I, lmb)\u001b[0m\n\u001b[1;32m     10\u001b[0m C \u001b[38;5;241m=\u001b[39m (z1norm\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m z2norm) \u001b[38;5;241m/\u001b[39m bs \n\u001b[1;32m     11\u001b[0m cdiff \u001b[38;5;241m=\u001b[39m (C \u001b[38;5;241m-\u001b[39m I)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 12\u001b[0m loss \u001b[38;5;241m=\u001b[39m (cdiff\u001b[38;5;241m*\u001b[39mI \u001b[38;5;241m+\u001b[39m \u001b[43mcdiff\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mI\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlmb\u001b[49m)\u001b[38;5;241m.\u001b[39msum() \n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/torch_core.py:378\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 378\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/_tensor.py:1279\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1279\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "    config_path = '../configs/cifar10/bt_test_config.yaml'\n",
    "    config = load_config(config_path)\n",
    "\n",
    "    # config.model_type = 'sparse_head_barlow_twins'\n",
    "    # config.sparsity_level=10\n",
    "    # config.epochs=100\n",
    "    # config.save_interval=100\n",
    "\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "    print(os.listdir(experiment_dir))\n",
    "    print(os.listdir(base_dir))\n",
    "    print('experiment_dir and base_dir')\n",
    "\n",
    "\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    print(os.listdir(experiment_dir))\n",
    "    print(os.listdir(base_dir))\n",
    "    print('experiment_dir and base_dir')\n",
    "\n",
    "    #get path to fully fitted model\n",
    "    path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "    model = load_barlow_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "    print(model)\n",
    "\n",
    "    #New config but the first part of experiment_dir is same - just hash is different\n",
    "    #It shouldnt find a max file path\n",
    "    config.epochs=config.epochs+1\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example for vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
