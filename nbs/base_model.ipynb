{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_model\n",
    "\n",
    "> In this module we have the base model, learner and other things we need to train encoder\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the base functions and classes to train a basic BT-style model. Note that this (mostly) all comes directly from here: `https://github.com/KeremTurgutlu/self_supervised/blob/main/nbs/14%20-%20barlow_twins.ipynb`\n",
    "but we needed to extend some of the functionality for our purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the base classes and functions needed for image augmentation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#My edited version of RandTransform\n",
    "class RandomGaussianBlur(RandTransform):\n",
    "    \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "    order = 11\n",
    "    def __init__(self, \n",
    "                 p=1.0, #debugging (bug in libraries implementation)\n",
    "                 prob=0.5,#the real probability\n",
    "                 s=(8,32), #kernel\n",
    "                 sig=None, #sig_val is either manually input OR\n",
    "                 blur_r=(0.1,2),#is randomly chosen from uniform with these bounds\n",
    "                 same_on_batch=False, \n",
    "                 **kwargs): \n",
    "        \n",
    "        store_attr()\n",
    "        super().__init__(p=p, **kwargs)\n",
    "\n",
    "    def encodes(self, x:TensorImage):\n",
    "        \n",
    "        if isinstance(self.s, int):   s = (self.s,self.s)\n",
    "        elif isinstance(self.s, tuple) or isinstance(self.s, list): s=self.s\n",
    "     \n",
    "        #Default for ImageNet from BYOL / BT papers\n",
    "        if self.sig is None:\n",
    "            sig_val = np.random.uniform(self.blur_r[0],self.blur_r[1])\n",
    "        \n",
    "        else:\n",
    "            sig_val = self.sig\n",
    "            \n",
    "\n",
    "        tfm = korniatfm.RandomGaussianBlur(kernel_size=s,sigma=(sig_val,sig_val),same_on_batch=self.same_on_batch,p=self.prob)\n",
    "        return tfm(x)\n",
    "\n",
    "#Delete later: leaving for backward compatibility for now\n",
    "# class RandomGaussianBlur(RandTransform):\n",
    "#     \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "#     order = 11\n",
    "#     def __init__(self, p=0.5, s=(8,32), same_on_batch=False, **kwargs): \n",
    "#         store_attr()\n",
    "#         super().__init__(p=p, **kwargs)\n",
    "        \n",
    "#     def encodes(self, x:TensorImage):\n",
    "#         if isinstance(self.s, tuple): s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, list):  s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, int):   s = self.s\n",
    "#         s2 = int(s/4)*2+1\n",
    "#         tfm = korniatfm.RandomGaussianBlur((s2,s2),(s,s),same_on_batch=self.same_on_batch,p=1.) #p=1. is a bug\n",
    "#                                             #kernel #sigma\n",
    "        \n",
    "#         return tfm(x)\n",
    "\n",
    "\n",
    "class RandomCenterDropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.5, min_dropout_size=(20, 20), max_dropout_size=(60, 60), fill_value=0, same_on_batch=False):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.min_dropout_size = min_dropout_size\n",
    "        self.max_dropout_size = max_dropout_size\n",
    "        self.fill_value = fill_value\n",
    "        self.same_on_batch = same_on_batch\n",
    "        #self.id_transform = tvtfm.RandomResizedCrop((256, 256), scale=(1.,1.), ratio=(1.,1.))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Check if the augmentation should be applied to the whole batch or individually\n",
    "\n",
    "        #x=self.id_transform(x)\n",
    "\n",
    "        if self.same_on_batch:\n",
    "            if random.random() < self.p:\n",
    "                return self._apply_dropout(x)\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            # Apply dropout individually with given probability\n",
    "            for i in range(x.size(0)):\n",
    "                tem=random.random()\n",
    "                #print(f\"tem is: {tem}\")\n",
    "                if tem < self.p:\n",
    "                    x[i] = self._apply_dropout(x[i].unsqueeze(0)).squeeze(0)\n",
    "            return x\n",
    "\n",
    "    def _apply_dropout(self, img):\n",
    "        for i,count in enumerate(range(img.size(0))):  # Iterate through batch if necessary\n",
    "            _, h, w = img[i].shape\n",
    "            # Generate random dropout size within specified limits\n",
    "            dh = random.randint(self.min_dropout_size[0], self.max_dropout_size[0])\n",
    "            dw = random.randint(self.min_dropout_size[1], self.max_dropout_size[1])\n",
    "            \n",
    "            x1 = int(max((w - dw) / 2, 0))\n",
    "            y1 = int(max((h - dh) / 2, 0))\n",
    "            \n",
    "            mask = torch.ones_like(img[i])\n",
    "            mask[:, y1:y1+dh, x1:x1+dw] = self.fill_value\n",
    "            img[i] = img[i] * mask\n",
    "        \n",
    "        return img\n",
    "\n",
    "    \n",
    "def get_BT_batch_augs(size,\n",
    "                    flip=True,crop=True,noise=True,rotate=True,jitter=True,bw=True,blur=True,solar=True,cutout=False, #Whether to use  given aug or not\n",
    "                    resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.025, rotate_deg=30,jitter_s=.6,blur_s=(4,32),#hps of diff augs\n",
    "                    blur_r=(0.1,2),blur_sig=None,sol_t=0.05,sol_a=0.05,min_dropout_size=(25, 100),max_dropout_size=(50,150), #hps of diff augs\n",
    "                    flip_p=0.5, rotate_p=0.3,noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3,sol_p=0.1,cut_p=0.0, #prob of performing aug\n",
    "                    same_on_batch=False,stats=imagenet_stats,cuda=default_device().type == 'cuda',xtra_tfms=[]\n",
    "                    ):\n",
    "    \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    \n",
    "    tfms = []\n",
    "\n",
    "    korniatfm.RandomHorizontalFlip.order = RandomResizedCrop.order-1\n",
    "\n",
    "\n",
    "    if crop: tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "    #Unfortunately for some reason this doesn't work, so we can't apply \"same_on_batch=False\"\n",
    "    #tfms += [korniatfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio, same_on_batch=same_on_batch)]\n",
    "\n",
    "    if cutout: tfms+=[RandomCenterDropout(min_dropout_size=min_dropout_size,max_dropout_size=max_dropout_size, fill_value=0, p=cut_p,same_on_batch=same_on_batch)]\n",
    "    \n",
    "  \n",
    "    if flip: tfms += [korniatfm.RandomHorizontalFlip(p=flip_p,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if rotate: tfms += [Rotate(max_deg=rotate_deg, p=rotate_p, batch=same_on_batch)]\n",
    "\n",
    "                                             #brightness,contrast,saturation,hue\n",
    "    if jitter: tfms += [korniatfm.ColorJitter(0.4*jitter_s, 0.4*jitter_s, 0.2*jitter_s, 0.1*jitter_s, p=jitter_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if bw:     tfms += [korniatfm.RandomGrayscale(p=bw_p, same_on_batch=same_on_batch)]\n",
    "        \n",
    "    #sig will usually be None\n",
    "    if blur:   tfms += [RandomGaussianBlur(prob=blur_p, s=blur_s,sig=blur_sig,blur_r=blur_r, same_on_batch=same_on_batch)]\n",
    "\n",
    "    korniatfm.RandomSolarize.order = RandomGaussianBlur.order + 1 #we want to apply solarization after RandomGaussianBlur\n",
    "    \n",
    "    if solar: tfms += [korniatfm.RandomSolarize(p=sol_p,thresholds=sol_t, additions=sol_a,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if noise: tfms+=[korniatfm.RandomGaussianNoise(mean=0.0, std=noise_std, same_on_batch=same_on_batch, p=noise_p)]\n",
    "    \n",
    "    if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "\n",
    "    tfms += xtra_tfms\n",
    "\n",
    "    pipe = Pipeline(tfms, split_idx = 0)\n",
    "    return pipe\n",
    "\n",
    "@delegates(get_BT_batch_augs)\n",
    "def get_multi_aug_pipelines(size, **kwargs): return get_BT_batch_augs(size, **kwargs)\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(size=size,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_cifar10_aug_pipelines(size):\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    bt_cifar10_aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return bt_cifar10_aug_pipelines\n",
    "\n",
    "#Add other augmentations here e.g. BYOL augs\n",
    "IMAGENET_Augs = dict(flip_p1=0.5,flip_p2=0.5,jitter_p1=0.8,jitter_p2=0.8,bw_p1=0.2,\n",
    "                bw_p2=0.2,blur_p1=1.0,blur_p2=0.1,sol_p1=0.0,sol_p2=0.2,noise_p1=0.0,\n",
    "                noise_p2=0.0,cut_p=0,resize_scale=(0.7, 1.0),resize_ratio=(3/4, 4/3),rotate_deg=45.0,\n",
    "                rotate_p=0.5,blur_r=(0.1,2),blur_s=13,sol_t=0.1,sol_a=0.1,noise_std=0.1,min_dropout_size=None,max_dropout_size=None,\n",
    "                )\n",
    "\n",
    "DERMNET_Augs = IMAGENET_Augs.copy()\n",
    "DERMNET_Augs['min_dropout_size']=(50, 185)\n",
    "DERMNET_Augs['max_dropout_size']=(100,190)\n",
    "DERMNET_Augs['cut_p']=0.5\n",
    "\n",
    "def helper_get_bt_augs(size,Augs=IMAGENET_Augs):\n",
    "\n",
    "\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p1'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p1'],\n",
    "                        jitter_p=Augs['jitter_p1'], bw_p=Augs['bw_p1'], blur_p=Augs['blur_p1'],\n",
    "                        sol_p=Augs['sol_p1'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p2'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p2'],\n",
    "                        jitter_p=Augs['jitter_p2'], bw_p=Augs['bw_p2'], blur_p=Augs['blur_p2'],\n",
    "                        sol_p=Augs['sol_p2'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return aug_pipelines\n",
    "\n",
    "def get_bt_imagenet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=IMAGENET_Augs)\n",
    "\n",
    "def get_bt_dermnet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=DERMNET_Augs)\n",
    "\n",
    "\n",
    "\n",
    "bt_aug_func_dict = {'bt_cifar10_aug_pipelines':get_bt_cifar10_aug_pipelines,'bt_imagenet_aug_pipelines':get_bt_imagenet_aug_pipelines,\n",
    "                   'bt_dermnet_aug_pipelines':get_bt_dermnet_aug_pipelines\n",
    "                   }\n",
    "\n",
    "def get_bt_aug_pipelines(bt_augs,size):\n",
    "\n",
    "    return bt_aug_func_dict[bt_augs](size)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_ssl_dls(dataset,#cifar10, dermnet, etc\n",
    "            bs,\n",
    "            size,\n",
    "            device,\n",
    "            pct_dataset=1.0):\n",
    "    # Define the base package name in a variable for easy modification\n",
    "\n",
    "    try:\n",
    "        # Construct the module path\n",
    "        module_path = f\"{PACKAGE_NAME}.{dataset}_dataloading\"\n",
    "        \n",
    "        # Dynamically import the module\n",
    "        dataloading_module = importlib.import_module(module_path)\n",
    "    except ModuleNotFoundError:\n",
    "        # Handle the case where the module cannot be found\n",
    "        raise ImportError(f\"Could not find a data loading module for '{dataset}'. \"\n",
    "                          f\"Make sure '{module_path}' exists and is correctly named.\") from None\n",
    "    \n",
    "    # Assuming the function name follows a consistent naming convention\n",
    "    func_name = f\"get_bt_{dataset}_train_dls\"\n",
    "\n",
    "    try:\n",
    "        # Retrieve the data loading function from the module\n",
    "        data_loader_func = getattr(dataloading_module, func_name)\n",
    "    except AttributeError:\n",
    "        # Handle the case where the function does not exist in the module\n",
    "        raise AttributeError(f\"The function '{func_name}' was not found in '{module_path}'. \"\n",
    "                             \"Ensure it is defined and named correctly.\") from None\n",
    "    \n",
    "    # Proceed to call the function with arguments from the config\n",
    "    try:\n",
    "        dls_train = data_loader_func(bs=bs,size=size,device=device,pct_dataset=pct_dataset)\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the function call\n",
    "        raise RuntimeError(f\"An error occurred while calling '{func_name}' from '{module_path}': {e}\") from None\n",
    "    \n",
    "    return dls_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base functions / classes we need to train a BT / RBT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Base functions / classes we need to train a BT / RBT model.\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "# class BarlowTwinsModel(Module):\n",
    "#     \"\"\"An encoder followed by a projector\n",
    "#     \"\"\"\n",
    "#     def __init__(self,encoder,projector):\n",
    "#         self.encoder = encoder\n",
    "#         self.projector = projector\n",
    "        \n",
    "#     def forward(self,x): \n",
    "        \n",
    "#         return self.projector(self.encoder(x))\n",
    "\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\"\"\"\n",
    "    def __init__(self, encoder, projector, cache_size):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        self.cache_size = cache_size\n",
    "        self.cached_outputs = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.projector(x)\n",
    "        self.cached_outputs.append(x)\n",
    "        \n",
    "        if len(self.cached_outputs) == self.cache_size:\n",
    "            concatenated_outputs = torch.cat(self.cached_outputs, dim=0)\n",
    "            self.cached_outputs = []\n",
    "            return concatenated_outputs\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def create_barlow_twins_model(encoder,cache_size, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    return BarlowTwinsModel(encoder=encoder, projector=projector,cache_size=cache_size)\n",
    "\n",
    "# class BarlowTwins(Callback):\n",
    "#     order,run_valid = 9,True\n",
    "#     def __init__(self, aug_pipelines,n_in,lmb,sparsity_level, \n",
    "#                 model_type='barlow_twins',print_augs=False\n",
    "#                  ):\n",
    "#         assert_aug_pipelines(aug_pipelines)\n",
    "#         self.aug1, self.aug2 = aug_pipelines\n",
    "#         if print_augs: print(self.aug1), print(self.aug2)\n",
    "#         store_attr('lmb')\n",
    "#         store_attr('sparsity_level')\n",
    "#         self.n_in=n_in\n",
    "#         self.model_type = model_type\n",
    "#         self.index=-1 #Gets updated after each batch\n",
    "#         self.acc_dict = {}\n",
    "        \n",
    "#     def before_fit(self): \n",
    "#         self.learn.loss_func = self.lf\n",
    "#         nf = self.learn.model.projector[-1].out_features\n",
    "#         self.I = torch.eye(nf).to(self.dls.device)\n",
    "\n",
    "\n",
    "#     def before_epoch(self):\n",
    "#         self.index=-1  \n",
    "  \n",
    "#     def before_batch(self):\n",
    "        \n",
    "#         #TODO: Make this nicer (possibly can load in data as TensorImage(BW) or something?)\n",
    "#         #This is a bit of a hack. Can make this more elegant later. But in new version of FastAI\n",
    "#         #seems we need to compute TensorImage(BW) here, and depends on whether color or not, i.e. n_in.\n",
    "#         if self.n_in == 1:\n",
    "\n",
    "#             xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            \n",
    "#             #print(xi.shape)\n",
    "                                    \n",
    "#         elif self.n_in == 3:\n",
    "            \n",
    "#             xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "#         self.learn.xb = (torch.cat([xi, xj]),)\n",
    "\n",
    "#         self.index=self.index+1\n",
    "\n",
    "class BarlowTwins(Callback):\n",
    "    order, run_valid = 9, True\n",
    "    def __init__(self, aug_pipelines, n_in, lmb, sparsity_level, model_type='barlow_twins', print_augs=False):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        store_attr('sparsity_level')\n",
    "        self.n_in = n_in\n",
    "        self.model_type = model_type\n",
    "        self.index = -1  # Gets updated after each batch\n",
    "        self.acc_dict = {}\n",
    "        \n",
    "    def before_fit(self):\n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "\n",
    "    def before_batch(self):\n",
    "        if self.n_in == 1:\n",
    "            xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "        elif self.n_in == 3:\n",
    "            xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "        self.index += 1\n",
    "\n",
    "    def after_loss(self):\n",
    "        output = self.learn.model(self.learn.xb[0])\n",
    "        if output is not None:\n",
    "            self.learn.loss = self.lf(output, self.I)\n",
    "        else:\n",
    "            self.learn.loss = None\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1): \n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]]\n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# #We want access to both representation and projection for variations \n",
    "\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\"\"\"\n",
    "    def __init__(self, encoder, projector, cache_size):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        self.cache_size = cache_size\n",
    "        self.cached_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        tem = self.encoder(x)\n",
    "        proj = self.projector(tem)\n",
    "        self.cached_outputs.append((tem, proj))\n",
    "\n",
    "        if len(self.cached_outputs) == self.cache_size:\n",
    "            cached_tem, cached_proj = zip(*self.cached_outputs)\n",
    "            self.cached_outputs = []\n",
    "            return torch.cat(cached_tem), torch.cat(cached_proj)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'forward returns tuple of (encoder(x), projector(encoder(x))) when cache is full, otherwise None'\n",
    "\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3, cache_size=1):\n",
    "    \"Create Barlow Twins model with caching mechanism\"\n",
    "    n_in = in_channels(encoder)\n",
    "    with torch.no_grad():\n",
    "        representation = encoder(torch.randn((2, n_in, 128, 128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "    apply_init(projector)\n",
    "    return BarlowTwinsModel(encoder, projector, cache_size=cache_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we write down standard definition of `lf` for `RAT` method: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BarlowTwins needs an `lf` method to work properly. Here we provide the `lf` of standard barlow twins. Later we can\n",
    "patch in a new defintion of `lf` that involves random functions, inner maximization etc. The tools needed to do this are provised in `base_lf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt(pred,I,lmb):\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "    \n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs \n",
    "    cdiff = (C - I)**2\n",
    "    loss = (cdiff*I + cdiff*(1-I)*lmb).sum() \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_indiv_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb*(0.5*torch.abs(z1_enc) + 0.5*torch.abs(z2_enc)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1_enc.pow(2) + 0.5 * z2_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_norm_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_fun(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm_enc.T @ z2norm_enc) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    loss = (cdiff*I).sum() #standard bt loss\n",
    "\n",
    "    print(f\"invariance loss is: {loss} and sparsity loss is: {sparsity}\")\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_proj_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                           ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm.pow(2) + 0.5 * z2norm.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb):\n",
    "    \"Assumes model created according to type p3\"\n",
    "\n",
    "\n",
    "    if pred is None:\n",
    "        return None\n",
    "\n",
    "    if self.model_type=='barlow_twins':\n",
    "         pred_enc = pred[0]\n",
    "         pred = pred[1]\n",
    "         return lf_bt(pred, self.I,self.lmb)\n",
    "\n",
    "    elif self.model_type=='indiv_sparse_barlow_twins':\n",
    "        return lf_bt_indiv_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='group_sparse_barlow_twins':\n",
    "        return lf_bt_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='group_norm_sparse_barlow_twins':\n",
    "        return lf_bt_group_norm_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='proj_group_sparse_barlow_twins':\n",
    "        return lf_bt_proj_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='fun':\n",
    "        return lf_bt_fun(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "\n",
    "    else: raise(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt(m):\n",
    "    return L(sequential(*m.encoder),m.projector).map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to use the above functions in an end to end fashion. First we get some data and plonk it into a dls, Then create an encoder, an augmentation pipeline, a learner, then fit\n",
    "the learner. This is the complete process of training BT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_bt_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "        \n",
    "    learn = Learner(dls,model=None, cbs=[BarlowTwins(aug,n_in=n_in,lmb=None,sparsity_level=None,\n",
    "                                                     print_augs=print_augs\n",
    "                                        )])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.barlow_twins.show(n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SaveBarlowLearnerCheckpoint(Callback):\n",
    "    \"Save such that can resume training \"\n",
    "    def __init__(self, experiment_dir,start_epoch=0, save_interval=250,with_opt=True):\n",
    "        self.experiment_dir = experiment_dir\n",
    "        self.start_epoch = start_epoch\n",
    "        self.save_interval = save_interval\n",
    "        self.with_opt = with_opt  # Decide whether to save optimizer state as well.\n",
    "\n",
    "    def after_epoch(self):\n",
    "        if (self.epoch+1) % self.save_interval == 0 and self.epoch>=self.start_epoch:\n",
    "            print(f\"Saving model and learner state at epoch {self.epoch}\")\n",
    "   \n",
    "            checkpoint_filename = f\"learner_checkpoint_epoch_{self.epoch}\"\n",
    "            checkpoint_path = os.path.join(self.experiment_dir, checkpoint_filename)\n",
    "            # Save the entire learner object, including the model's parameters and optimizer state.\n",
    "            self.learn.save(checkpoint_path, with_opt=self.with_opt)\n",
    "            print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "class SaveBarlowLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        encoder_filename = f\"trained_encoder_epoch_{self.epoch}.pth\"\n",
    "        encoder_path = os.path.join(self.experiment_dir, encoder_filename)\n",
    "        torch.save(self.learn.model.encoder.state_dict(), encoder_path)\n",
    "        print(f\"encoder state dict saved to {encoder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_barlow_model(arch,ps,hs,path):\n",
    "\n",
    "    encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_barlow_twins_model(encoder, hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BarlowTrainer:\n",
    "    \"Setup a learner for training a BT model. Can do transfer learning, normal training, or resume training.\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,#An encoder followed by a projector\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 lmb,\n",
    "                 sparsity_level,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 num_it=100, #Number of iterations to run lr_find for.\n",
    "                 load_learner_path=None, #Path to load learner from (optional)\n",
    "                 experiment_dir=None, #Where to save model checkpoints (optional)\n",
    "                 start_epoch=0, #Which epoch to start from\n",
    "                 save_interval=None, #How often to save model checkpoints (optional). \n",
    "                 export=False,\n",
    "                 ):\n",
    "\n",
    "        store_attr()\n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    \n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics.\n",
    "\n",
    "        Returns:\n",
    "        - learn: The Learner object.\n",
    "        \"\"\"\n",
    "      \n",
    "        self.model.to(self.device)\n",
    "\n",
    "        cbs = [BarlowTwins(self.bt_aug_pipelines,n_in=self.n_in,lmb=self.lmb,\n",
    "                           sparsity_level=self.sparsity_level,print_augs=False,\n",
    "                           model_type=self.model_type\n",
    "                           )\n",
    "              ]\n",
    "\n",
    "        learn=Learner(self.dls,self.model,splitter=my_splitter_bt,wd=self.wd, cbs=cbs\n",
    "                     )\n",
    "        \n",
    "        if self.load_learner_path: learn.load(self.load_learner_path,with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir:\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export:\n",
    "            cbs.append(SaveBarlowLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "                \n",
    "    \n",
    "    def bt_transfer_learning(self,freeze_epochs:int,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is already pretrained, we can do transfer learning.\n",
    "            Freeze encoder, train projector for a few epochs, then unfreeze and train all. \n",
    "        \"\"\"\n",
    "\n",
    "        self.learn.freeze()\n",
    "        test_grad_off(self.learn.encoder)\n",
    "        self.learn.fit(freeze_epochs)\n",
    "        self.learn.unfreeze()\n",
    "        test_grad_on(self.learn.model)\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it)\n",
    "\n",
    "        \n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley,cbs=self._get_training_cbs(interrupt_epoch)\n",
    "                                )\n",
    "\n",
    "    def bt_learning(self,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is not pretrained, we can do normal training.\n",
    "        \"\"\"\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "    \n",
    "    def continue_bt_learning(self,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Resume training with `fit_one_cycle` after loading a learner.\n",
    "        \"\"\"\n",
    "        \n",
    "        test_ne(self.load_learner_path,None)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs,start_epoch=start_epoch,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def train(self,learn_type, freeze_epochs:int,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Train model using BT\n",
    "        \"\"\"\n",
    "        if learn_type == 'transfer_learning':\n",
    "            \n",
    "            self.bt_transfer_learning(freeze_epochs=freeze_epochs,epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        elif learn_type=='continue_learning':\n",
    "            self.continue_bt_learning(epochs=epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "        \n",
    "        elif learn_type=='standard':\n",
    "            self.bt_learning(epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        else: raise Exception(\"Invalid weight_type\")\n",
    "\n",
    "        return self.learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a BT model. Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "    encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    \n",
    "    model = create_barlow_twins_model(encoder,cache_size=config.cache_size, hidden_size=config.hs, projection_size=config.ps)\n",
    "\n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    bt_trainer = BarlowTrainer(model=model,\n",
    "                    dls=dls,\n",
    "                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                    lmb=config.lmb,\n",
    "                    sparsity_level=config.sparsity_level,\n",
    "                    n_in=config.n_in,\n",
    "                    model_type=config.model_type,\n",
    "                    wd=config.wd,\n",
    "                    num_it=config.num_it,\n",
    "                    device=device,\n",
    "                    load_learner_path=load_learner_path,\n",
    "                    experiment_dir=experiment_dir,\n",
    "                    start_epoch=start_epoch,\n",
    "                    save_interval=config.save_interval,\n",
    "                    export=export\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = bt_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_path = '../configs/cifar10/bt_test_config.yaml'\n",
    "# config = load_config(config_path)\n",
    "\n",
    "# load_learner_path=None\n",
    "# experiment_dir=None\n",
    "# start_epoch=0\n",
    "\n",
    "\n",
    "# # Initialize the device for model training (CUDA or CPU)\n",
    "# device = default_device()\n",
    "\n",
    "# # Construct the model based on the configuration\n",
    "# # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "# encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "\n",
    "# model = create_barlow_twins_model(encoder, hidden_size=config.hs, projection_size=config.ps)\n",
    "\n",
    "# # Prepare data loaders according to the dataset specified in the configuration\n",
    "# dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "# # Set up data augmentation pipelines as specified in the configuration\n",
    "# bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "# # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "# #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "# bt_trainer = BarlowTrainer(model=model,\n",
    "#                dls=dls,\n",
    "#                bt_aug_pipelines=bt_aug_pipelines,\n",
    "#                lmb=config.lmb,\n",
    "#                sparsity_level=config.sparsity_level,\n",
    "#                n_in=config.n_in,\n",
    "#                model_type=config.model_type,\n",
    "#                wd=config.wd,\n",
    "#                num_it=config.num_it,\n",
    "#                device=device,\n",
    "#                load_learner_path=load_learner_path,\n",
    "#                experiment_dir=experiment_dir,\n",
    "#                start_epoch=start_epoch,\n",
    "#                save_interval=config.save_interval\n",
    "#                               )\n",
    "\n",
    "\n",
    "# bt_trainer.learn.lr_find??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_experiment_state(config,base_dir):\n",
    "    \"\"\"Get the load_learner_path, learn_type, start_epoch, interrupt_epoch for BT experiment.\n",
    "       Basically this tells us how to continue learning (e.g. we have run two sessions for \n",
    "       100 epochs, and want to continue for another 100 epochs). Return values are\n",
    "       None if we are starting from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    load_learner_path, _  = get_highest_num_path(base_dir, config)\n",
    "    #TODO:\n",
    "    #We can get start_epoch, interrupt epoch from `get_highest_epoch_path` + save_interval (may be None!)\n",
    "    start_epoch=0 if load_learner_path is None else int(load_learner_path.split('_')[-1])+1\n",
    "    \n",
    "    if start_epoch >= config.epochs:\n",
    "        print(f\"start_epoch={start_epoch}, but already completed {config.epochs} epochs. Exiting.\")\n",
    "        sys.exit()\n",
    "\n",
    "    interrupt_epoch = start_epoch + config.save_interval\n",
    "\n",
    "    #We can also get the learn_type from the load_learner_path + weight_type. \n",
    "    \n",
    "    if config.weight_type == 'random':\n",
    "        learn_type = 'standard'\n",
    "    \n",
    "    elif 'pretrained' in config.weight_type:\n",
    "        learn_type = 'transfer_learning'\n",
    "\n",
    "    learn_type = learn_type if load_learner_path is None else 'continue_learning'\n",
    "\n",
    "    return load_learner_path, learn_type, start_epoch, interrupt_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_experiment(config,\n",
    "                      base_dir,\n",
    "                      ):\n",
    "    \"\"\"Run several epochs of the experiment as defined in the config and where we are up to. e.g. epoch 0, or resuming\n",
    "    at epoch 99 etc. Basically a stateful version of `main_bt_train` that can be resumed. And saving.\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    experiment_dir, experiment_hash,git_commit_hash = setup_experiment(config,base_dir)\n",
    "\n",
    "    load_learner_path, learn_type, start_epoch, interrupt_epoch = get_bt_experiment_state(config,base_dir)\n",
    "\n",
    "    main_bt_train(config=config,\n",
    "            start_epoch=start_epoch,\n",
    "            interrupt_epoch=interrupt_epoch,\n",
    "            load_learner_path=load_learner_path,\n",
    "            learn_type=learn_type,\n",
    "            experiment_dir=experiment_dir,\n",
    "            )\n",
    "\n",
    "    # Save a metadata file in the experiment directory with the Git commit hash and other details\n",
    "    save_metadata_file(experiment_dir=experiment_dir, git_commit_hash=git_commit_hash)\n",
    "\n",
    "    # After experiment execution and all processing are complete\n",
    "    update_experiment_index(base_dir,{\n",
    "        \"experiment_hash\": experiment_hash,  # Unique identifier derived from the experiment's configuration\n",
    "        \"experiment_dir\": experiment_dir,  # Absolute path to the experiment's dedicated directory\n",
    "        \"git_commit_hash\": git_commit_hash,  # Git commit hash for the code version used in the experiment\n",
    "        # Potentially include additional details collected during or after the experiment, such as:\n",
    "        # Any other metadata or results summary that is relevant to the experiment\n",
    "                            })\n",
    "    \n",
    "    return experiment_dir,experiment_hash #Return the experiment_dir so we can easily access the results of the experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e and the experiment hash is: 00ff5d7e\n",
      "Configuration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e/config.yaml\n",
      "The git hash is: c57f28c0f63f5d1d939a24f40d27ad5691ba8db3\n",
      "Looking in /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e for highest num saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>247.061020</td>\n",
       "      <td>None</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>232.844116</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>238.653732</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>239.056427</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>238.287918</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>244.675537</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and learner state at epoch 5\n",
      "Checkpoint saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e/learner_checkpoint_epoch_5\n",
      "Interrupting training before starting epoch 6\n",
      "Metadata saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e/metadata.yaml\n",
      "Updated experiment index for hash: 00ff5d7e\n",
      "['learner_checkpoint_epoch_5.pth', 'metadata.yaml', 'config.yaml']\n",
      "['SSL', 'experiment_index.json']\n",
      "experiment_dir and base_dir\n",
      "We can keep training - resuming from the checkpoint\n",
      "The experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e and the experiment hash is: 00ff5d7e\n",
      "Configuration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e/config.yaml\n",
      "The git hash is: c57f28c0f63f5d1d939a24f40d27ad5691ba8db3\n",
      "Looking in /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e for highest num saved\n",
      "Found max file path: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e/learner_checkpoint_epoch_5.pth and max experiment dir: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>252.964050</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>211.138382</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>197.423462</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>191.324814</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>186.185959</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>183.025009</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and learner state at epoch 11\n",
      "Checkpoint saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e/learner_checkpoint_epoch_11\n",
      "Model state dict saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e/trained_model_epoch_11.pth\n",
      "encoder state dict saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e/trained_encoder_epoch_11.pth\n",
      "Metadata saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/00ff5d7e/metadata.yaml\n",
      "Updated experiment index for hash: 00ff5d7e\n",
      "['learner_checkpoint_epoch_5.pth', 'trained_model_epoch_11.pth', 'metadata.yaml', 'config.yaml', 'learner_checkpoint_epoch_11.pth', 'trained_encoder_epoch_11.pth']\n",
      "['SSL', 'experiment_index.json']\n",
      "experiment_dir and base_dir\n",
      "forward returns tuple of (encoder(x), projector(encoder(x))) when cache is full, otherwise None\n",
      "The experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/edc2faf5 and the experiment hash is: edc2faf5\n",
      "Configuration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/edc2faf5/config.yaml\n",
      "The git hash is: c57f28c0f63f5d1d939a24f40d27ad5691ba8db3\n",
      "Looking in /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/edc2faf5 for highest num saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>282.821838</td>\n",
       "      <td>None</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>277.669891</td>\n",
       "      <td>None</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>251.806763</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>273.208832</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>263.365845</td>\n",
       "      <td>None</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>261.980682</td>\n",
       "      <td>None</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and learner state at epoch 5\n",
      "Checkpoint saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/edc2faf5/learner_checkpoint_epoch_5\n",
      "Interrupting training before starting epoch 6\n",
      "Metadata saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpyd2zhxbd/SSL/cifar10/smallres/edc2faf5/metadata.yaml\n",
      "Updated experiment index for hash: edc2faf5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "    config_path = '../configs/cifar10/bt_test_config.yaml'\n",
    "    config = load_config(config_path)\n",
    "\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "    print(os.listdir(experiment_dir))\n",
    "    print(os.listdir(base_dir))\n",
    "    print('experiment_dir and base_dir')\n",
    "\n",
    "    print('We can keep training - resuming from the checkpoint')\n",
    "\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    print(os.listdir(experiment_dir))\n",
    "    print(os.listdir(base_dir))\n",
    "    print('experiment_dir and base_dir')\n",
    "\n",
    "    #get path to fully fitted model\n",
    "    path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "    model = load_barlow_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "    print(model)\n",
    "\n",
    "    #New config but the first part of experiment_dir is same - just hash is different\n",
    "    #It shouldnt find a max file path\n",
    "    config.epochs=config.epochs+1\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
