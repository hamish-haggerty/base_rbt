{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_model\n",
    "\n",
    "> In this module we have the base model, learner and other things we need to train encoder with Barlow Twins and other methods.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import importlib\n",
    "import sys\n",
    "import self_supervised\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import kornia.augmentation as korniatfm\n",
    "import torchvision.transforms as tvtfm\n",
    "from base_rbt.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the base functions and classes to train a basic BT-style model. Note that this (mostly) all comes directly from here: `https://github.com/KeremTurgutlu/self_supervised/blob/main/nbs/14%20-%20barlow_twins.ipynb`\n",
    "but we needed to extend some of the functionality for our purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the base classes and functions needed for image augmentation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#My edited version of RandTransform\n",
    "class RandomGaussianBlur(RandTransform):\n",
    "    \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "    order = 11\n",
    "    def __init__(self, \n",
    "                 p=1.0, #debugging (bug in libraries implementation)\n",
    "                 prob=0.5,#the real probability\n",
    "                 s=(8,32), #kernel\n",
    "                 sig=None, #sig_val is either manually input OR\n",
    "                 blur_r=(0.1,2),#is randomly chosen from uniform with these bounds\n",
    "                 same_on_batch=False, \n",
    "                 **kwargs): \n",
    "        \n",
    "        store_attr()\n",
    "        super().__init__(p=p, **kwargs)\n",
    "\n",
    "    def encodes(self, x:TensorImage):\n",
    "        \n",
    "        if isinstance(self.s, int):   s = (self.s,self.s)\n",
    "        elif isinstance(self.s, tuple) or isinstance(self.s, list): s=self.s\n",
    "     \n",
    "        #Default for ImageNet from BYOL / BT papers\n",
    "        if self.sig is None:\n",
    "            sig_val = np.random.uniform(self.blur_r[0],self.blur_r[1])\n",
    "        \n",
    "        else:\n",
    "            sig_val = self.sig\n",
    "            \n",
    "\n",
    "        tfm = korniatfm.RandomGaussianBlur(kernel_size=s,sigma=(sig_val,sig_val),same_on_batch=self.same_on_batch,p=self.prob)\n",
    "        return tfm(x)\n",
    "\n",
    "#Delete later: leaving for backward compatibility for now\n",
    "# class RandomGaussianBlur(RandTransform):\n",
    "#     \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "#     order = 11\n",
    "#     def __init__(self, p=0.5, s=(8,32), same_on_batch=False, **kwargs): \n",
    "#         store_attr()\n",
    "#         super().__init__(p=p, **kwargs)\n",
    "        \n",
    "#     def encodes(self, x:TensorImage):\n",
    "#         if isinstance(self.s, tuple): s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, list):  s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, int):   s = self.s\n",
    "#         s2 = int(s/4)*2+1\n",
    "#         tfm = korniatfm.RandomGaussianBlur((s2,s2),(s,s),same_on_batch=self.same_on_batch,p=1.) #p=1. is a bug\n",
    "#                                             #kernel #sigma\n",
    "        \n",
    "#         return tfm(x)\n",
    "\n",
    "\n",
    "class RandomCenterDropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.5, min_dropout_size=(20, 20), max_dropout_size=(60, 60), fill_value=0, same_on_batch=False):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.min_dropout_size = min_dropout_size\n",
    "        self.max_dropout_size = max_dropout_size\n",
    "        self.fill_value = fill_value\n",
    "        self.same_on_batch = same_on_batch\n",
    "        #self.id_transform = tvtfm.RandomResizedCrop((256, 256), scale=(1.,1.), ratio=(1.,1.))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Check if the augmentation should be applied to the whole batch or individually\n",
    "\n",
    "        #x=self.id_transform(x)\n",
    "\n",
    "        if self.same_on_batch:\n",
    "            if random.random() < self.p:\n",
    "                return self._apply_dropout(x)\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            # Apply dropout individually with given probability\n",
    "            for i in range(x.size(0)):\n",
    "                tem=random.random()\n",
    "                #print(f\"tem is: {tem}\")\n",
    "                if tem < self.p:\n",
    "                    x[i] = self._apply_dropout(x[i].unsqueeze(0)).squeeze(0)\n",
    "            return x\n",
    "\n",
    "    def _apply_dropout(self, img):\n",
    "        for i,count in enumerate(range(img.size(0))):  # Iterate through batch if necessary\n",
    "            _, h, w = img[i].shape\n",
    "            # Generate random dropout size within specified limits\n",
    "            dh = random.randint(self.min_dropout_size[0], self.max_dropout_size[0])\n",
    "            dw = random.randint(self.min_dropout_size[1], self.max_dropout_size[1])\n",
    "            \n",
    "            x1 = int(max((w - dw) / 2, 0))\n",
    "            y1 = int(max((h - dh) / 2, 0))\n",
    "            \n",
    "            mask = torch.ones_like(img[i])\n",
    "            mask[:, y1:y1+dh, x1:x1+dw] = self.fill_value\n",
    "            img[i] = img[i] * mask\n",
    "        \n",
    "        return img\n",
    "\n",
    "    \n",
    "# def get_BT_batch_augs(size,\n",
    "#                     flip=True,crop=True,noise=True,rotate=True,jitter=True,bw=True,blur=True,solar=True,cutout=False, #Whether to use  given aug or not\n",
    "#                     resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.025, rotate_deg=30,jitter_s=.6,blur_s=(4,32),#hps of diff augs\n",
    "#                     blur_r=(0.1,2),blur_sig=None,sol_t=0.05,sol_a=0.05,min_dropout_size=(25, 100),max_dropout_size=(50,150), #hps of diff augs\n",
    "#                     flip_p=0.5, rotate_p=0.3,noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3,sol_p=0.1,cut_p=0.0, #prob of performing aug\n",
    "#                     same_on_batch=False,stats=imagenet_stats,cuda=default_device().type == 'cuda',xtra_tfms=[]\n",
    "#                     ):\n",
    "#     \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    \n",
    "#     tfms = []\n",
    "\n",
    "#     korniatfm.RandomHorizontalFlip.order = RandomResizedCrop.order-1\n",
    "\n",
    "\n",
    "#     if crop: tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "#     #Unfortunately for some reason this doesn't work, so we can't apply \"same_on_batch=False\"\n",
    "#     #tfms += [korniatfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio, same_on_batch=same_on_batch)]\n",
    "\n",
    "#     if cutout: tfms+=[RandomCenterDropout(min_dropout_size=min_dropout_size,max_dropout_size=max_dropout_size, fill_value=0, p=cut_p,same_on_batch=same_on_batch)]\n",
    "    \n",
    "  \n",
    "#     if flip: tfms += [korniatfm.RandomHorizontalFlip(p=flip_p,same_on_batch=same_on_batch)]\n",
    "\n",
    "#     if rotate: tfms += [Rotate(max_deg=rotate_deg, p=rotate_p, batch=same_on_batch)]\n",
    "\n",
    "#                                              #brightness,contrast,saturation,hue\n",
    "#     if jitter: tfms += [korniatfm.ColorJitter(0.4*jitter_s, 0.4*jitter_s, 0.2*jitter_s, 0.1*jitter_s, p=jitter_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "#     if bw:     tfms += [korniatfm.RandomGrayscale(p=bw_p, same_on_batch=same_on_batch)]\n",
    "        \n",
    "#     #sig will usually be None\n",
    "#     if blur:   tfms += [RandomGaussianBlur(prob=blur_p, s=blur_s,sig=blur_sig,blur_r=blur_r, same_on_batch=same_on_batch)]\n",
    "\n",
    "#     korniatfm.RandomSolarize.order = RandomGaussianBlur.order + 1 #we want to apply solarization after RandomGaussianBlur\n",
    "    \n",
    "#     if solar: tfms += [korniatfm.RandomSolarize(p=sol_p,thresholds=sol_t, additions=sol_a,same_on_batch=same_on_batch)]\n",
    "\n",
    "#     if noise: tfms+=[korniatfm.RandomGaussianNoise(mean=0.0, std=noise_std, same_on_batch=same_on_batch, p=noise_p)]\n",
    "    \n",
    "#     if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "\n",
    "#     tfms += xtra_tfms\n",
    "\n",
    "#     pipe = Pipeline(tfms, split_idx = 0)\n",
    "#     return pipe\n",
    "\n",
    "def get_BT_batch_augs(size,\n",
    "                    flip=True, crop=True, noise=True, rotate=True, jitter=True, bw=True, blur=True, solar=True, cutout=False, half_mask=False,  # Whether to use given aug or not\n",
    "                    resize_scale=(0.08, 1.0), resize_ratio=(3/4, 4/3), noise_std=0.025, rotate_deg=30, jitter_s=.6, blur_s=(4,32),  # hps of diff augs\n",
    "                    blur_r=(0.1,2), blur_sig=None, sol_t=0.05, sol_a=0.05, min_dropout_size=(25, 100), max_dropout_size=(50,150),  # hps of diff augs\n",
    "                    flip_p=0.5, rotate_p=0.3, noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3, sol_p=0.1, cut_p=0.0, half_mask_p=1.0,  # prob of performing aug\n",
    "                    same_on_batch=False, stats=imagenet_stats, cuda=default_device().type == 'cuda', xtra_tfms=[]\n",
    "                    ):\n",
    "    \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    \n",
    "    tfms = []\n",
    "\n",
    "    korniatfm.RandomHorizontalFlip.order = RandomResizedCrop.order-1\n",
    "\n",
    "    if crop: tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "\n",
    "    if cutout: tfms += [RandomCenterDropout(min_dropout_size=min_dropout_size, max_dropout_size=max_dropout_size, fill_value=0, p=cut_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if half_mask:\n",
    "        tfms += [RandomHalfMask(p=half_mask_p)]  # Add this line\n",
    "\n",
    "    if flip: tfms += [korniatfm.RandomHorizontalFlip(p=flip_p, same_on_batch=same_on_batch)]\n",
    "\n",
    "    if rotate: tfms += [Rotate(max_deg=rotate_deg, p=rotate_p, batch=same_on_batch)]\n",
    "\n",
    "    if jitter: tfms += [korniatfm.ColorJitter(0.4*jitter_s, 0.4*jitter_s, 0.2*jitter_s, 0.1*jitter_s, p=jitter_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if bw: tfms += [korniatfm.RandomGrayscale(p=bw_p, same_on_batch=same_on_batch)]\n",
    "        \n",
    "    if blur: tfms += [RandomGaussianBlur(prob=blur_p, s=blur_s, sig=blur_sig, blur_r=blur_r, same_on_batch=same_on_batch)]\n",
    "\n",
    "    korniatfm.RandomSolarize.order = RandomGaussianBlur.order + 1\n",
    "    \n",
    "    if solar: tfms += [korniatfm.RandomSolarize(p=sol_p, thresholds=sol_t, additions=sol_a, same_on_batch=same_on_batch)]\n",
    "\n",
    "    if noise: tfms += [korniatfm.RandomGaussianNoise(mean=0.0, std=noise_std, same_on_batch=same_on_batch, p=noise_p)]\n",
    "    \n",
    "    if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "\n",
    "    tfms += xtra_tfms\n",
    "\n",
    "    pipe = Pipeline(tfms, split_idx = 0)\n",
    "    return pipe\n",
    "\n",
    "class RandomHalfMask(RandTransform):\n",
    "    \"Randomly mask either the left or right half of the image or batch of images\"\n",
    "    order = 11  # Adjust this order as needed\n",
    "    \n",
    "    def __init__(self, p=1.0):\n",
    "        super().__init__(p=p)\n",
    "    \n",
    "    def encodes(self, x:TensorImage):\n",
    "        if random.random() > self.p:\n",
    "            return x\n",
    "        \n",
    "        if x.dim() == 3:  # Single image\n",
    "            c, h, w = x.shape\n",
    "            mask = torch.ones_like(x)\n",
    "            if random.random() < 0.5:\n",
    "                mask[:, :, w//2:] = 0  # Mask right half\n",
    "            else:\n",
    "                mask[:, :, :w//2] = 0  # Mask left half\n",
    "        elif x.dim() == 4:  # Batch of images\n",
    "            b, c, h, w = x.shape\n",
    "            mask = torch.ones_like(x)\n",
    "            for i in range(b):\n",
    "                if random.random() < 0.5:\n",
    "                    mask[i, :, :, w//2:] = 0  # Mask right half\n",
    "                else:\n",
    "                    mask[i, :, :, :w//2] = 0  # Mask left half\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 3D or 4D tensor, got {x.dim()}D tensor\")\n",
    "        \n",
    "        return x * mask\n",
    "\n",
    "\n",
    "@delegates(get_BT_batch_augs)\n",
    "def get_multi_aug_pipelines(size, **kwargs): return get_BT_batch_augs(size, **kwargs)\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(size=size,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_cifar10_aug_pipelines(size):\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    bt_cifar10_aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return bt_cifar10_aug_pipelines\n",
    "\n",
    "#Add other augmentations here e.g. BYOL augs\n",
    "IMAGENET_Augs = dict(flip_p1=0.5,flip_p2=0.5,jitter_p1=0.8,jitter_p2=0.8,bw_p1=0.2,\n",
    "                bw_p2=0.2,blur_p1=1.0,blur_p2=0.1,sol_p1=0.0,sol_p2=0.2,noise_p1=0.0,\n",
    "                noise_p2=0.0,cut_p=0,resize_scale=(0.7, 1.0),resize_ratio=(3/4, 4/3),rotate_deg=45.0,\n",
    "                rotate_p=0.5,blur_r=(0.1,2),blur_s=13,sol_t=0.1,sol_a=0.1,noise_std=0.1,min_dropout_size=None,max_dropout_size=None,\n",
    "                )\n",
    "\n",
    "DERMNET_Augs = IMAGENET_Augs.copy()\n",
    "DERMNET_Augs['min_dropout_size']=(50, 185)\n",
    "DERMNET_Augs['max_dropout_size']=(100,190)\n",
    "DERMNET_Augs['cut_p']=0.33\n",
    "\n",
    "def helper_get_bt_augs(size,Augs=IMAGENET_Augs):\n",
    "\n",
    "\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p1'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p1'],\n",
    "                        jitter_p=Augs['jitter_p1'], bw_p=Augs['bw_p1'], blur_p=Augs['blur_p1'],\n",
    "                        sol_p=Augs['sol_p1'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p2'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p2'],\n",
    "                        jitter_p=Augs['jitter_p2'], bw_p=Augs['bw_p2'], blur_p=Augs['blur_p2'],\n",
    "                        sol_p=Augs['sol_p2'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return aug_pipelines\n",
    "\n",
    "def get_bt_imagenet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=IMAGENET_Augs)\n",
    "\n",
    "def get_bt_dermnet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=DERMNET_Augs)\n",
    "\n",
    "\n",
    "\n",
    "bt_aug_func_dict = {'bt_cifar10_aug_pipelines':get_bt_cifar10_aug_pipelines,'bt_imagenet_aug_pipelines':get_bt_imagenet_aug_pipelines,\n",
    "                   'bt_dermnet_aug_pipelines':get_bt_dermnet_aug_pipelines\n",
    "                   }\n",
    "\n",
    "def get_bt_aug_pipelines(bt_augs,size):\n",
    "\n",
    "    return bt_aug_func_dict[bt_augs](size)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_bt_predhalf_aug_pipelines(size):\n",
    "    # Augmentations for the masked view\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=False, crop=False, noise=True, jitter=True, blur=True, solar=True, half_mask=True,\n",
    "                                                    noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                    bw_p=0.2, flip_p=0.0, noise_p=0.5, jitter_p=0.5, blur_p=0.5, sol_p=0.0, half_mask_p=1.0,\n",
    "                                                    stats=cifar_stats, same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    # Augmentations for the full view (keep all augmentations)\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True, crop=True, noise=True, jitter=True, blur=True, solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0), rotate_deg=45, noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1, sol_t=0.01, sol_a=0.01,\n",
    "                                                    bw_p=0.2, flip_p=0.5, rotate_p=0.25, noise_p=0.5, jitter_p=0.5, blur_p=0.1, sol_p=0.2,\n",
    "                                                    stats=cifar_stats, same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    bt_predhalf_aug_pipelines = [aug_pipelines_1, aug_pipelines_2]\n",
    "\n",
    "    return bt_predhalf_aug_pipelines\n",
    "\n",
    "# Add this to the bt_aug_func_dict\n",
    "bt_aug_func_dict['bt_predhalf_aug_pipelines'] = get_bt_predhalf_aug_pipelines\n",
    "\n",
    "#Test\n",
    "# dls = get_ssl_dls('cifar10', bs=32, size=32, device=default_device())\n",
    "# aug = get_bt_aug_pipelines('bt_predhalf_aug_pipelines', 32)\n",
    "# show_bt_batch(dls, n_in=3, aug=aug, n=10, print_augs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_ssl_dls(dataset,#cifar10, dermnet, etc\n",
    "            bs,\n",
    "            size,\n",
    "            device,\n",
    "            pct_dataset=1.0):\n",
    "    # Define the base package name in a variable for easy modification\n",
    "\n",
    "    try:\n",
    "        # Construct the module path\n",
    "        module_path = f\"{PACKAGE_NAME}.{dataset}_dataloading\"\n",
    "        \n",
    "        # Dynamically import the module\n",
    "        dataloading_module = importlib.import_module(module_path)\n",
    "    except ModuleNotFoundError:\n",
    "        # Handle the case where the module cannot be found\n",
    "        raise ImportError(f\"Could not find a data loading module for '{dataset}'. \"\n",
    "                          f\"Make sure '{module_path}' exists and is correctly named.\") from None\n",
    "    \n",
    "    # Assuming the function name follows a consistent naming convention\n",
    "    func_name = f\"get_bt_{dataset}_train_dls\"\n",
    "\n",
    "    try:\n",
    "        # Retrieve the data loading function from the module\n",
    "        data_loader_func = getattr(dataloading_module, func_name)\n",
    "    except AttributeError:\n",
    "        # Handle the case where the function does not exist in the module\n",
    "        raise AttributeError(f\"The function '{func_name}' was not found in '{module_path}'. \"\n",
    "                             \"Ensure it is defined and named correctly.\") from None\n",
    "    \n",
    "    # Proceed to call the function with arguments from the config\n",
    "    try:\n",
    "        dls_train = data_loader_func(bs=bs,size=size,device=device,pct_dataset=pct_dataset)\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the function call\n",
    "        raise RuntimeError(f\"An error occurred while calling '{func_name}' from '{module_path}': {e}\") from None\n",
    "    \n",
    "    return dls_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base functions / classes we need to train a BT / RBT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Base functions / classes we need to train a BT / RBT model.\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "\n",
    "# class BarlowTwinsModel(Module):\n",
    "#     \"\"\"An encoder followed by a projector\n",
    "#     \"\"\"\n",
    "#     def __init__(self,encoder,projector):\n",
    "#         self.encoder = encoder\n",
    "#         self.projector = projector\n",
    "        \n",
    "#     def forward(self,x): \n",
    "        \n",
    "#         return self.projector(self.encoder(x))\n",
    "\n",
    "# def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "#     \"Create Barlow Twins model\"\n",
    "#     n_in  = in_channels(encoder)\n",
    "#     with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "#     projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "#     apply_init(projector)\n",
    "#     return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "\n",
    "#We want access to both representation and projection\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        \n",
    "    def forward(self,x): \n",
    "        tem = self.encoder(x)\n",
    "        return tem,self.projector(tem) #get access to both representation and projection if needed for loss\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'forward returns tuple of (encoder(x),projector(encoder(x)))'\n",
    "\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    " \n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "\n",
    "#Note: this requires an lf (loss function), which is patched in later.\n",
    "#The reason for this is we can specify via a string argument (e.g. via\n",
    "#a config file) what loss function we want to use. lf_bt is the default\n",
    "#(standard barlow twins loss function).\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines,n_in,lmb,sparsity_level, \n",
    "                model_type='barlow_twins',print_augs=False\n",
    "                 ):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        store_attr('sparsity_level')\n",
    "        self.n_in=n_in\n",
    "        self.model_type = model_type\n",
    "        self.index=-1 #Gets updated after each batch\n",
    "        self.acc_dict = {}\n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self.index=-1  \n",
    "  \n",
    "    def before_batch(self):\n",
    "        \n",
    "        #TODO: Make this nicer (possibly can load in data as TensorImage(BW) or something?)\n",
    "        #This is a bit of a hack. Can make this more elegant later. But in new version of FastAI\n",
    "        #seems we need to compute TensorImage(BW) here, and depends on whether color or not, i.e. n_in.\n",
    "        if self.n_in == 1:\n",
    "\n",
    "            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            \n",
    "            #print(xi.shape)\n",
    "                                    \n",
    "        elif self.n_in == 3:\n",
    "            \n",
    "            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    " \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1): \n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]]\n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the above for vicreg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Base functions / classes we need to train a \n",
    "#  model\n",
    "class VICRegModel(Module):\n",
    "    \"\"\"VICReg model with options for shared or separate projectors\"\"\"\n",
    "    def __init__(self, left_encoder, right_encoder, left_projector, right_projector):\n",
    "        #may have right_encoder = encoder_left and right_projector = left_projector.\n",
    "        #or e.g. encoders may have shared weights.\n",
    "        self.left_encoder = left_encoder\n",
    "        self.right_encoder = right_encoder\n",
    "        self.left_projector = left_projector\n",
    "        self.right_projector = right_projector\n",
    "        \n",
    "    def forward(self,x): #x is stacked xi,xj the two augmented views of batch\n",
    "      \n",
    "        x1, x2 = x[:x.size(0)//2], x[x.size(0)//2:]\n",
    "        \n",
    "        z1,z2 = self.left_projector(self.left_encoder(x1)), self.right_projector(self.right_encoder(x2))\n",
    "    \n",
    "        return z1, z2\n",
    "\n",
    "#override fastai method basically\n",
    "from fastai.vision.learner import in_channels as fastai_in_channels\n",
    "def in_channels(m):\n",
    "    try:\n",
    "        return m.in_channels\n",
    "    except AttributeError:\n",
    "        return fastai_in_channels(m)\n",
    "\n",
    "def create_vicreg_model(left_encoder, right_encoder,hidden_size=256, projection_size=128, bn=True, nlayers=3, shared_projector=True):\n",
    "    \"\"\"\n",
    "    Create VICReg model with flexible projector configuration\n",
    "    \n",
    "    Args:\n",
    "    - left_encoder: first encoder model\n",
    "    - right_encoder: second encoder model (can be the same as left_encoder for shared encoder)\n",
    "    - hidden_size: hidden size for projector\n",
    "    - projection_size: output size for projector\n",
    "    - bn: whether to use batch normalization in projector\n",
    "    - nlayers: number of layers in projector\n",
    "    - shared_projector: if True, use the same projector for both branches\n",
    "    \"\"\"\n",
    "    n_in = in_channels(left_encoder)\n",
    "    with torch.no_grad(): representation = left_encoder(torch.randn((2,n_in,32,32)))\n",
    "    \n",
    "    left_projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "    apply_init(left_projector)\n",
    "    \n",
    "    if not shared_projector:\n",
    "        right_projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "        apply_init(right_projector)\n",
    "    else:\n",
    "        right_projector = left_projector\n",
    "    \n",
    "    return VICRegModel(left_encoder, right_encoder, left_projector, right_projector)\n",
    "\n",
    "#helper function to compute vicreg loss.\n",
    "def off_diagonal(x):\n",
    "        n, m = x.shape\n",
    "        assert n == m\n",
    "        return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "class VICReg(BarlowTwins):\n",
    "    def __init__(self, aug_pipelines, n_in=3, sim_coeff=25, std_coeff=25, cov_coeff=1, \n",
    "                 model_type='vicreg', print_augs=False):\n",
    "        super().__init__(aug_pipelines, n_in, None, None, model_type, print_augs)\n",
    "        self.sim_coeff = sim_coeff\n",
    "        self.std_coeff = std_coeff\n",
    "        self.cov_coeff = cov_coeff\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.learn.loss_func = self.lf\n",
    "\n",
    "    def lf(self, pred, *yb):\n",
    "        x, y = pred  # Assuming the model returns two views (see VICRegModel)\n",
    "\n",
    "        # Invariance loss\n",
    "        repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "        # Variance loss\n",
    "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "        # Covariance loss\n",
    "        x = x - x.mean(dim=0)\n",
    "        y = y - y.mean(dim=0)\n",
    "        cov_x = (x.T @ x) / (x.size(0) - 1)\n",
    "        cov_y = (y.T @ y) / (y.size(0) - 1)\n",
    "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(x.size(1)) + \\\n",
    "                   off_diagonal(cov_y).pow_(2).sum().div(y.size(1))\n",
    "\n",
    "        # Total loss\n",
    "        loss = (\n",
    "            self.sim_coeff * repr_loss +\n",
    "            self.std_coeff * std_loss +\n",
    "            self.cov_coeff * cov_loss\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def before_batch(self):\n",
    "        #if self.model_type == 'br_vicreg':\n",
    "\n",
    "    #         # Create two copies of the input\n",
    "    #         x_left, x_right = self.x.clone(), self.x.clone()\n",
    "            \n",
    "    #         # Zero out the right half of x_left and the left half of x_right\n",
    "    #         mid = x_left.shape[-1] // 2\n",
    "    #         x_left[..., mid:] = 0\n",
    "    #         x_right[..., :mid] = 0\n",
    "            \n",
    "    #         print(f\"x shape: {self.x.shape}\")\n",
    "    #         print(f\"x_left shape: {x_left.shape}\")\n",
    "    #         print(f\"x_right shape: {x_right.shape}\")\n",
    "\n",
    "    #         # Apply augmentations\n",
    "    #         if self.n_in == 1:\n",
    "    #             xi = self.aug1(TensorImageBW(x_left))\n",
    "    #             xj = self.aug2(TensorImageBW(x_right))\n",
    "    #         elif self.n_in == 3:\n",
    "    #             xi = self.aug1(TensorImage(x_left))\n",
    "    #             xj = self.aug2(TensorImage(x_right))\n",
    "\n",
    "    #         print(f\"xi shape after aug: {xi.shape}\")\n",
    "    #         print(f\"xj shape after aug: {xj.shape}\")\n",
    "\n",
    "    #         # Concatenate the augmented halves\n",
    "    #         self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "    #         print(f\"Final self.learn.xb shape: {self.learn.xb[0].shape}\")\n",
    "\n",
    "        # The above splits x into x_left and x_right, with padding, then applies\n",
    "        # aug1 and aug2. Alternatively, we could compute aug1(x) and aug2(x). \n",
    "        # then zero pad the right half of aug1(x) and the left half of aug2(x).\n",
    "\n",
    "        #zero padding approach:\n",
    "        # if self.model_type == 'br_vicreg':\n",
    "        #     # Apply augmentations first\n",
    "        #     if self.n_in == 1:\n",
    "        #         xi = self.aug1(TensorImageBW(self.x))\n",
    "        #         xj = self.aug2(TensorImageBW(self.x))\n",
    "        #     elif self.n_in == 3:\n",
    "        #         xi = self.aug1(TensorImage(self.x))\n",
    "        #         xj = self.aug2(TensorImage(self.x))\n",
    "            \n",
    "        #     print(f\"x shape: {self.x.shape}\")\n",
    "        #     print(f\"xi shape after aug: {xi.shape}\")\n",
    "        #     print(f\"xj shape after aug: {xj.shape}\")\n",
    "\n",
    "        #     # Zero out the right half of xi and the left half of xj\n",
    "        #     mid = xi.shape[-1] // 2\n",
    "        #     xi[..., mid:] = 0\n",
    "        #     xj[..., :mid] = 0\n",
    "            \n",
    "        #     print(f\"xi shape after zeroing: {xi.shape}\")\n",
    "        #     print(f\"xj shape after zeroing: {xj.shape}\")\n",
    "\n",
    "        #     # Concatenate the augmented and zeroed halves\n",
    "        #     self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "        #     print(f\"Final self.learn.xb shape: {self.learn.xb[0].shape}\")\n",
    "        # else:\n",
    "        #     # Use the original BarlowTwins before_batch method for 'vicreg'\n",
    "        #     if self.n_in == 1:\n",
    "        #         xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "        #     elif self.n_in == 3:\n",
    "        #         xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "        #     self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "\n",
    "        #here we dont zero pad at all, just get 16x32 (for cifar, say)\n",
    "        if self.model_type == 'br_vicreg':\n",
    "            ### Original implementation for 'vicreg'\n",
    "            if self.n_in == 1:\n",
    "                xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            elif self.n_in == 3:\n",
    "                xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "                   # Randomly apply left/right masking with 50% probability\n",
    "            # p = 0.5\n",
    "            # if random.random() < p:\n",
    "            #     # Calculate the split point\n",
    "            #     _, _, _, width = xi.shape\n",
    "            #     split_point = width // 2\n",
    "                \n",
    "            #     # Zero out the right half of xi and the left half of xj\n",
    "            #     xi[:, :, :, split_point:] = 0\n",
    "            #     xj[:, :, :, :split_point] = 0\n",
    "                \n",
    "            self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "\n",
    "\n",
    "            # # Apply augmentations first\n",
    "            # if self.n_in == 1:\n",
    "            #     xi = self.aug1(TensorImageBW(self.x))\n",
    "            #     xj = self.aug2(TensorImageBW(self.x))\n",
    "            # elif self.n_in == 3:\n",
    "            #     xi = self.aug1(TensorImage(self.x))\n",
    "            #     xj = self.aug2(TensorImage(self.x))\n",
    "            \n",
    "            # # Dynamically calculate the split point\n",
    "            # _, _, height, width = xi.shape\n",
    "            # split_point = width // 2\n",
    "\n",
    "            # # Split each image into left and right halves\n",
    "            # xi_left = xi[..., :split_point]  # Left half\n",
    "            # xj_right = xj[..., split_point:]  # Right half\n",
    "            \n",
    "            # # Concatenate the halves\n",
    "            # self.learn.xb = (torch.cat([xi_left, xj_right], dim=0),)\n",
    "\n",
    "            # print(f\"Input shape: {self.x.shape}\")\n",
    "            # print(f\"Augmented left half shape: {xi_left.shape}\")\n",
    "            # print(f\"Augmented right half shape: {xj_right.shape}\")\n",
    "            # print(f\"Combined batch shape: {self.learn.xb[0].shape}\")\n",
    "\n",
    "        else:\n",
    "            # Original implementation for 'vicreg'\n",
    "            if self.n_in == 1:\n",
    "                xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            elif self.n_in == 3:\n",
    "                xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "            self.learn.xb = (torch.cat([xi, xj], dim=0),)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New idea / method: PredHalf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of barlow twins loss and sparse barlow twins loss functions, and proposes modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt(pred,I,lmb): #standard bt loss\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "    \n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs \n",
    "    cdiff = (C - I)**2\n",
    "    loss = (cdiff*I + cdiff*(1-I)*lmb).sum() \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_sparse_head(pred,I,lmb,projector,sparsity_level):\n",
    "  \n",
    "    bt_loss = lf_bt(pred,I,lmb)\n",
    "    L21 = torch.linalg.norm(projector[-1].weight, ord=2, dim=0).sum()\n",
    "\n",
    "    # print(f\"bt_loss is {bt_loss}, L21 is {L21}, scaled L21 is {sparsity_level*L21}\")\n",
    "    # print(bt_loss)\n",
    "    # print(L21)\n",
    "\n",
    "    \n",
    "    loss =  bt_loss + sparsity_level*L21 #barlow twins loss + L21 norm of last layer of projector\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_indiv_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb*(0.5*torch.abs(z1_enc) + 0.5*torch.abs(z2_enc)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1_enc.pow(2) + 0.5 * z2_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_norm_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_fun(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm_enc.T @ z2norm_enc) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    loss = (cdiff*I).sum() #standard bt loss\n",
    "\n",
    "    print(f\"invariance loss is: {loss} and sparsity loss is: {sparsity}\")\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_proj_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                           ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm.pow(2) + 0.5 * z2norm.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def lf_predhalf(pred_enc, pred, I, lmb):\n",
    "    bs = pred_enc.size(0) // 2\n",
    "    z1, z2 = pred_enc[:bs], pred_enc[bs:]  # encoder outputs\n",
    "    p1, p2 = pred[:bs], pred[bs:]  # predictor outputs\n",
    "\n",
    "    # Prediction loss\n",
    "    pred_loss = F.mse_loss(p1, z2)\n",
    "\n",
    "    # Variance loss\n",
    "    std_z1 = torch.sqrt(z1.var(dim=0) + 0.0001)\n",
    "    std_z2 = torch.sqrt(z2.var(dim=0) + 0.0001)\n",
    "    var_loss = torch.mean(F.relu(1 - std_z1)) / 2 + torch.mean(F.relu(1 - std_z2)) / 2\n",
    "\n",
    "    # Covariance loss\n",
    "      # Covariance loss\n",
    "    z1 = z1 - z1.mean(dim=0)\n",
    "    z2 = z2 - z2.mean(dim=0)\n",
    "    cov_z1 = (z1.T @ z1) / (z1.shape[0] - 1)\n",
    "    cov_z2 = (z2.T @ z2) / (z2.shape[0] - 1)\n",
    "    cov_loss = off_diagonal(cov_z1).pow_(2).sum().div(z1.shape[1]) + \\\n",
    "               off_diagonal(cov_z2).pow_(2).sum().div(z2.shape[1])\n",
    "\n",
    "    # Combine losses\n",
    "    loss = pred_loss + 25 * var_loss + 1 * cov_loss  # Adjust weights as needed\n",
    "\n",
    "    return loss\n",
    "\n",
    "def off_diagonal(x):\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch in loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb):\n",
    "    \"Assumes model created according to type p3\"\n",
    "\n",
    "    if self.model_type=='barlow_twins':\n",
    "         pred_enc = pred[0]\n",
    "         pred = pred[1]\n",
    "         return lf_bt(pred, self.I,self.lmb)\n",
    "\n",
    "    elif self.model_type=='sparse_head_barlow_twins':\n",
    "        pred_enc = pred[0]\n",
    "        pred = pred[1]\n",
    "\n",
    "        return lf_bt_sparse_head(pred, self.I,lmb=self.lmb,projector=self.learn.model.projector,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='indiv_sparse_barlow_twins':\n",
    "        return lf_bt_indiv_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='group_sparse_barlow_twins':\n",
    "        return lf_bt_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='group_norm_sparse_barlow_twins':\n",
    "        return lf_bt_group_norm_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='proj_group_sparse_barlow_twins':\n",
    "        return lf_bt_proj_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='fun':\n",
    "        return lf_bt_fun(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "\n",
    "    elif self.model_type == 'predhalf_barlow_twins':\n",
    "        pred_enc = pred[0]\n",
    "        pred = pred[1]\n",
    "        \n",
    "        return lf_predhalf(pred_enc, pred, self.I, self.lmb)\n",
    "\n",
    "\n",
    "    else: raise(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt(m):\n",
    "    return L(sequential(*m.encoder),m.projector).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt_last_block_resnet50(m):\n",
    "    #Note: don't think we actually need this guy.\n",
    "    \"Freeze all but the last bottleneck layer\"\n",
    "    enc_except_final_block = sequential(*m.encoder[:-3], m.encoder[-3][:-1])\n",
    "    final_block_and_projector = sequential(m.encoder[-3][-1], m.projector)\n",
    "    return L(enc_except_final_block, final_block_and_projector).map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to use the above functions in an end to end fashion. First we get some data and plonk it into a dls, Then create an encoder, an augmentation pipeline, a learner, then fit\n",
    "the learner. This is the complete process of training BT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_bt_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "        \n",
    "    learn = Learner(dls,model=None, cbs=[BarlowTwins(aug,n_in=n_in,lmb=None,sparsity_level=None,\n",
    "                                                     print_augs=print_augs\n",
    "                                        )])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.barlow_twins.show(n=n)\n",
    "\n",
    "def show_vicreg_batch(dls,n_in,aug,n=2,print_augs=True,model_type='vicreg'):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "\n",
    "    learn = Learner(dls,model=None, cbs=[VICReg(aug,n_in=3,model_type=model_type)])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.vic_reg.show(n=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide \n",
    "\n",
    "#dls = get_ssl_dls('cifar10',bs=32,size=128,device=default_device())\n",
    "#aug = get_bt_cifar10_aug_pipelines(32)\n",
    "#show_vicreg_batch(dls,n_in=3,aug=aug,n=2,print_augs=True,model_type='vicreg')\n",
    "#show_vicreg_batch(dls,n_in=3,aug=aug,n=8,print_augs=True,model_type='br_vicreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SaveBarlowLearnerCheckpoint(Callback):\n",
    "    \"Save such that can resume training \"\n",
    "    def __init__(self, experiment_dir,start_epoch=0, save_interval=250,with_opt=True):\n",
    "        self.experiment_dir = experiment_dir\n",
    "        self.start_epoch = start_epoch\n",
    "        self.save_interval = save_interval\n",
    "        self.with_opt = with_opt  # Decide whether to save optimizer state as well.\n",
    "\n",
    "    def after_epoch(self):\n",
    "        if (self.epoch+1) % self.save_interval == 0 and self.epoch>=self.start_epoch:\n",
    "            print(f\"Saving model and learner state at epoch {self.epoch}\")\n",
    "   \n",
    "            checkpoint_filename = f\"learner_checkpoint_epoch_{self.epoch}\"\n",
    "            checkpoint_path = os.path.join(self.experiment_dir, checkpoint_filename)\n",
    "            # Save the entire learner object, including the model's parameters and optimizer state.\n",
    "            self.learn.save(checkpoint_path, with_opt=self.with_opt)\n",
    "            print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "class SaveBarlowLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        encoder_filename = f\"trained_encoder_epoch_{self.epoch}.pth\"\n",
    "        encoder_path = os.path.join(self.experiment_dir, encoder_filename)\n",
    "        torch.save(self.learn.model.encoder.state_dict(), encoder_path)\n",
    "        print(f\"encoder state dict saved to {encoder_path}\")\n",
    "\n",
    "\n",
    "class SaveVicRegLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        left_encoder_filename = f\"trained_left_encoder_epoch_{self.epoch}.pth\"\n",
    "        left_encoder_path = os.path.join(self.experiment_dir, left_encoder_filename)\n",
    "        torch.save(self.learn.model.left_encoder.state_dict(), left_encoder_path)\n",
    "        print(f\"Left encoder state dict saved to {left_encoder_path}\")\n",
    "\n",
    "        right_encoder_filename = f\"trained_right_encoder_epoch_{self.epoch}.pth\"\n",
    "        right_encoder_path = os.path.join(self.experiment_dir, right_encoder_filename)\n",
    "        torch.save(self.learn.model.right_encoder.state_dict(), right_encoder_path)\n",
    "        print(f\"Right encoder state dict saved to {right_encoder_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_barlow_model(arch,ps,hs,path):\n",
    "\n",
    "    encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_barlow_twins_model(encoder, hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_vicreg_model(arch,ps,hs,path):\n",
    "\n",
    "    left_encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    right_encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_vicreg_model(left_encoder,right_encoder,hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BarlowTrainer:\n",
    "    \"Setup a learner for training a BT model. Can do transfer learning, normal training, or resume training.\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,#An encoder followed by a projector\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 lmb,\n",
    "                 sparsity_level,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 splitter_str='none',\n",
    "                 num_it=100, #Number of iterations to run lr_find for.\n",
    "                 load_learner_path=None, #Path to load learner from (optional)\n",
    "                 experiment_dir=None, #Where to save model checkpoints (optional)\n",
    "                 start_epoch=0, #Which epoch to start from\n",
    "                 save_interval=None, #How often to save model checkpoints (optional). \n",
    "                 export=False,\n",
    "                 ):\n",
    "\n",
    "        store_attr()\n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    \n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics.\n",
    "\n",
    "        Returns:\n",
    "        - learn: The Learner object.\n",
    "        \"\"\"\n",
    "      \n",
    "        self.model.to(self.device)\n",
    "\n",
    "\n",
    "        cbs = [BarlowTwins(self.bt_aug_pipelines,n_in=self.n_in,lmb=self.lmb,\n",
    "                           sparsity_level=self.sparsity_level,print_augs=False,\n",
    "                           model_type=self.model_type\n",
    "                           )\n",
    "              ]\n",
    "\n",
    "        learn=Learner(self.dls,self.model,splitter=my_splitter_bt,wd=self.wd, cbs=cbs\n",
    "                     )\n",
    "        \n",
    "        if self.load_learner_path: learn.load(self.load_learner_path,with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir:\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export:\n",
    "            cbs.append(SaveBarlowLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "                \n",
    "    \n",
    "    def bt_transfer_learning(self,freeze_epochs:int,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is already pretrained, we can do transfer learning.\n",
    "            Freeze encoder, train projector for a few epochs, then unfreeze and train all. \n",
    "        \"\"\"\n",
    "        self.learn.freeze()\n",
    "        test_grad_off(self.learn.encoder)\n",
    "        self.learn.fit(freeze_epochs)\n",
    "\n",
    "         # Check if the splitter is 'my_splitter_bt_last_block_resnet50'\n",
    "        if self.splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "            # Unfreeze only the last bottleneck block\n",
    "            for param in self.learn.model.encoder[-3][-1].parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "            print(f'splitter_str={self.splitter_str}')\n",
    "        else:\n",
    "            # Unfreeze the entire encoder\n",
    "            self.learn.unfreeze()\n",
    "            test_grad_on(self.learn.model)\n",
    "        \n",
    "        \n",
    "        self.learn.summary()\n",
    "\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it) #lets find a good maximum lr\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley, cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def bt_learning(self,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is not pretrained, we can do normal training.\n",
    "        \"\"\"\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "    \n",
    "    def continue_bt_learning(self,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Resume training with `fit_one_cycle` after loading a learner.\n",
    "        \"\"\"\n",
    "        \n",
    "        test_ne(self.load_learner_path,None)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs,start_epoch=start_epoch,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def train(self,learn_type, freeze_epochs:int,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Train model using BT\n",
    "        \"\"\"\n",
    "        if learn_type == 'transfer_learning':\n",
    "            \n",
    "            self.bt_transfer_learning(freeze_epochs=freeze_epochs,epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        elif learn_type=='continue_learning':\n",
    "            self.continue_bt_learning(epochs=epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "        \n",
    "        elif learn_type=='standard':\n",
    "            self.bt_learning(epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        else: raise Exception(\"Invalid weight_type\")\n",
    "\n",
    "        return self.learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can inherit from the above for vicreg version. Just setting up the learner is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VICRegTrainer(BarlowTrainer):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 sparsity_level,\n",
    "                 sim_coeff,\n",
    "                 std_coeff,\n",
    "                 cov_coeff,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 splitter_str='none',\n",
    "                 num_it=100,\n",
    "                 load_learner_path=None,\n",
    "                 experiment_dir=None,\n",
    "                 start_epoch=0,\n",
    "                 save_interval=None,\n",
    "                 export=False):\n",
    "        \n",
    "        \n",
    "                # Store VICReg-specific attributes\n",
    "        store_attr('sim_coeff,std_coeff,cov_coeff') #why doesn't this work?\n",
    "        # Call the parent constructor with None for lmb\n",
    "        super().__init__(model, dls, bt_aug_pipelines,None,sparsity_level, n_in, model_type,\n",
    "                         wd, device, splitter_str, num_it, load_learner_path,\n",
    "                         experiment_dir, start_epoch, save_interval, export)\n",
    "        \n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics for VICReg.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        cbs = [VICReg(self.bt_aug_pipelines, n_in=self.n_in, \n",
    "                      sim_coeff=self.sim_coeff, std_coeff=self.std_coeff, cov_coeff=self.cov_coeff,\n",
    "                      model_type=self.model_type, print_augs=False)]\n",
    "\n",
    "        # Use the splitter based on splitter_str\n",
    "        # if self.splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "        #     splitter = my_splitter_bt_last_block_resnet50\n",
    "        # else:\n",
    "        #     splitter = my_splitter_bt\n",
    "        #learn = Learner(self.dls, self.model, splitter=splitter, wd=self.wd, cbs=cbs)\n",
    "        \n",
    "        #TODO: Implement custom splitter for VICReg\n",
    "        #splitter not supported yet for vicreg: we can do this but need a custom splitter.\n",
    "        #The issue is just that vicreg e.g. has encoder_left and encoder_right, v.s.\n",
    "        #BT which just has one encoder. Just leaving splitter off for now\n",
    "        learn = Learner(self.dls, self.model, wd=self.wd, cbs=cbs)\n",
    "        if self.load_learner_path: \n",
    "            learn.load(self.load_learner_path, with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir: #same as for barlow\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export: #different to barlow. Clearly we in principle want this \n",
    "                        #more abstract so it just works. But ok.\n",
    "            cbs.append(SaveVicRegLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "\n",
    "    # # Override the train method if necessary\n",
    "    # def train(self, learn_type, freeze_epochs:int, epochs:int, start_epoch:int, interrupt_epoch:int):\n",
    "    #     \"\"\"Train model using VICReg\"\"\"\n",
    "    #     # You can customize this method for VICReg-specific training logic if needed\n",
    "    #     return super().train(learn_type, freeze_epochs, epochs, start_epoch, interrupt_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that splitting/freezings works in `bt_transfer_learning`.\n",
    "\n",
    "It's a bit hacky but looks to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "encoder = resnet_arch_to_encoder(arch='resnet50', weight_type=random)\n",
    "model = create_barlow_twins_model(encoder, hidden_size=8192, projection_size=8192)\n",
    "dls = get_ssl_dls('cifar10',bs=64,size=32,device=default_device())\n",
    "\n",
    "cbs = [BarlowTwins(get_bt_aug_pipelines(bt_augs='bt_cifar10_aug_pipelines', size=32),\n",
    "       n_in=3,lmb=1/8192,sparsity_level=None,print_augs=False,\n",
    "        model_type='barlow_twins'\n",
    "                    )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy pasted from `bt_transfer_learning`\n",
    "\n",
    "Bit hacky, but ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BarlowTwinsModel (Input shape: 64 x 3 x 32 x 32)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     64 x 64 x 16 x 16   \n",
       "Conv2d                                    9408       False     \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "MaxPool2d                                                      \n",
       "Conv2d                                    4096       False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 8 x 8    \n",
       "Conv2d                                    32768      False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 4 x 4    \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    524288     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 2 x 2    \n",
       "Conv2d                                    524288     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2097152    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "AdaptiveAvgPool2d                                              \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048           \n",
       "Flatten                                                        \n",
       "____________________________________________________________________________\n",
       "                     64 x 8192           \n",
       "Linear                                    16785408   True      \n",
       "BatchNorm1d                               16384      True      \n",
       "ReLU                                                           \n",
       "Linear                                    67117056   True      \n",
       "BatchNorm1d                               16384      True      \n",
       "ReLU                                                           \n",
       "Linear                                    67117056   True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 174,560,320\n",
       "Total trainable params: 155,561,856\n",
       "Total non-trainable params: 18,998,464\n",
       "\n",
       "Optimizer used: <function Adam at 0x7fae8d0abeb0>\n",
       "Loss function: <bound method BarlowTwins.lf of BarlowTwins>\n",
       "\n",
       "Model frozen up to parameter group #1\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - CastToTensor\n",
       "  - BarlowTwins\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide \n",
    "learn=Learner(dls,model,splitter=my_splitter_bt,cbs=cbs\n",
    "             )\n",
    "\n",
    "\n",
    "splitter_str = 'my_splitter_bt_last_block_resnet50'\n",
    "#splitter_str='none'\n",
    "learn.freeze() #freeze everything up to projector\n",
    "test_grad_off(learn.encoder)\n",
    "\n",
    "    # Check if the splitter is 'my_splitter_bt_last_block_resnet50'\n",
    "if splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "    # Unfreeze only the last bottleneck block\n",
    "    for param in learn.model.encoder[-3][-1].parameters():\n",
    "        param.requires_grad = True\n",
    "else:\n",
    "    # Unfreeze the entire encoder\n",
    "    learn.unfreeze()\n",
    "\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a BT model. Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "    if hasattr(config,'splitter_str'):\n",
    "        splitter_str=config.splitter_str\n",
    "    else:\n",
    "        splitter_str='none'\n",
    "\n",
    "    if hasattr(config,'nlayers'):\n",
    "        nlayers=config.nlayers\n",
    "    else:\n",
    "        nlayers=3\n",
    "\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "    encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    \n",
    "    model = create_barlow_twins_model(encoder, hidden_size=config.hs, projection_size=config.ps,nlayers=nlayers)\n",
    "\n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    bt_trainer = BarlowTrainer(model=model,\n",
    "                    dls=dls,\n",
    "                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                    lmb=config.lmb,\n",
    "                    sparsity_level=config.sparsity_level,\n",
    "                    n_in=config.n_in,\n",
    "                    model_type=config.model_type,\n",
    "                    wd=config.wd,\n",
    "                    num_it=config.num_it,\n",
    "                    device=device,\n",
    "                    splitter_str=splitter_str,\n",
    "                    load_learner_path=load_learner_path,\n",
    "                    experiment_dir=experiment_dir,\n",
    "                    start_epoch=start_epoch,\n",
    "                    save_interval=config.save_interval,\n",
    "                    export=export\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = bt_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above but for vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_vicreg_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a vicreg model (standard or br) Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "    if hasattr(config,'splitter_str'):\n",
    "        splitter_str=config.splitter_str\n",
    "    else:\n",
    "        splitter_str='none'\n",
    "\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "\n",
    "    #vicreg model may require two encoders, so we need to handle this case\n",
    "    encoder_left = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    if config.model_type == 'vicreg':\n",
    "\n",
    "        if not config.shared_encoder:\n",
    "            encoder_right = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "        else:\n",
    "            encoder_right=encoder_left\n",
    "\n",
    "        model = create_vicreg_model(encoder_left, encoder_right, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "    # #At present, the arch is: encoder_left = encoder_right =  Transformer(CNN_Left(x),CNN_right(x)).\n",
    "    elif config.model_type == 'br_vicreg':\n",
    "        #Same as above for now since we are using left/right split augmentation\n",
    "\n",
    "        # res = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "        # encoder = BinocularEncoder(res)\n",
    "        # model = create_vicreg_model(encoder, encoder, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "        \n",
    "        encoder = BinocularResNet()\n",
    "        model = create_vicreg_model(encoder, encoder, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "\n",
    "\n",
    "    #     test_eq(config.arch,'cifar_resnet18_swin')\n",
    "    #     swin = BinocularAwareSwin()\n",
    "    #     cnn = resnet_arch_to_encoder('cifar_resnet18', n_in=96)\n",
    "    #     encoder = BinocularSwintoRes(swin=swin, cnn=cnn)\n",
    "\n",
    "    #     swin = BinocularAwareSwin()\n",
    "    #     cnn = resnet_arch_to_encoder('cifar_resnet18', n_in=96)\n",
    "    #     encoder = BinocularSwintoRes(swin=swin, cnn=cnn)\n",
    "    #     _x = torch.rand(1, 3, 32, 32)\n",
    "    #     _x = encoder(_x)\n",
    "    #     model = create_vicreg_model(encoder, encoder, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    #(this is same as for bt)\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    vicreg_trainer = VICRegTrainer(model=model,\n",
    "                                    dls=dls,\n",
    "                                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                                    sparsity_level=config.sparsity_level,\n",
    "                                    sim_coeff=config.sim_coeff,\n",
    "                                    std_coeff=config.std_coeff,\n",
    "                                    cov_coeff=config.cov_coeff,\n",
    "                                    n_in=config.n_in,\n",
    "                                    model_type=config.model_type,\n",
    "                                    wd=config.wd,\n",
    "                                    num_it=config.num_it,\n",
    "                                    device=device,\n",
    "                                    splitter_str=splitter_str,\n",
    "                                    load_learner_path=load_learner_path,\n",
    "                                    experiment_dir=experiment_dir,\n",
    "                                    start_epoch=start_epoch,\n",
    "                                    save_interval=config.save_interval,\n",
    "                                    export=export\n",
    "\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = vicreg_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_experiment_state(config,base_dir):\n",
    "    \"\"\"Get the load_learner_path, learn_type, start_epoch, interrupt_epoch for BT experiment.\n",
    "       Basically this tells us how to continue learning (e.g. we have run two sessions for \n",
    "       100 epochs, and want to continue for another 100 epochs). Return values are\n",
    "       None if we are starting from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    load_learner_path, _  = get_highest_num_path(base_dir, config)\n",
    "    #TODO:\n",
    "    #We can get start_epoch, interrupt epoch from `get_highest_epoch_path` + save_interval (may be None!)\n",
    "    start_epoch=0 if load_learner_path is None else int(load_learner_path.split('_')[-1])+1\n",
    "    \n",
    "    if start_epoch >= config.epochs:\n",
    "        print(f\"start_epoch={start_epoch}, but already completed {config.epochs} epochs. Exiting.\")\n",
    "        sys.exit()\n",
    "\n",
    "    interrupt_epoch = start_epoch + config.save_interval\n",
    "\n",
    "    #We can also get the learn_type from the load_learner_path + weight_type. \n",
    "    \n",
    "    if config.weight_type == 'random':\n",
    "        learn_type = 'standard'\n",
    "    \n",
    "    elif 'pretrained' in config.weight_type:\n",
    "        learn_type = 'transfer_learning'\n",
    "\n",
    "    learn_type = learn_type if load_learner_path is None else 'continue_learning'\n",
    "\n",
    "    return load_learner_path, learn_type, start_epoch, interrupt_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_experiment(config,\n",
    "                      base_dir,\n",
    "                      ):\n",
    "        \"\"\"Run several epochs of the experiment as defined in the config and where we are up to. e.g. epoch 0, or resuming\n",
    "        at epoch 99 etc. Basically a stateful version of `main_bt_train` that can be resumed. And saving.\n",
    "        \"\"\"\n",
    "    \n",
    "        \n",
    "        experiment_dir, experiment_hash,git_commit_hash = setup_experiment(config,base_dir)\n",
    "        load_learner_path, learn_type, start_epoch, interrupt_epoch = get_bt_experiment_state(config,base_dir)      \n",
    "        \n",
    "        if 'barlow' in config.model_type:\n",
    "        \n",
    "                main_bt_train(config=config,\n",
    "                        start_epoch=start_epoch,\n",
    "                        interrupt_epoch=interrupt_epoch,\n",
    "                        load_learner_path=load_learner_path,\n",
    "                        learn_type=learn_type,\n",
    "                        experiment_dir=experiment_dir,\n",
    "                        )\n",
    "        elif 'vicreg' in config.model_type:\n",
    "                \n",
    "                main_vicreg_train(config=config,\n",
    "                        start_epoch=start_epoch,\n",
    "                        interrupt_epoch=interrupt_epoch,\n",
    "                        load_learner_path=load_learner_path,\n",
    "                        learn_type=learn_type,\n",
    "                        experiment_dir=experiment_dir,\n",
    "                        )\n",
    "\n",
    "        # Save a metadata file in the experiment directory with the Git commit hash and other details\n",
    "        save_metadata_file(experiment_dir=experiment_dir, git_commit_hash=git_commit_hash)\n",
    "\n",
    "        # After experiment execution and all processing are complete\n",
    "        update_experiment_index(base_dir,{\n",
    "                \"experiment_hash\": experiment_hash,  # Unique identifier derived from the experiment's configuration\n",
    "                \"experiment_dir\": experiment_dir,  # Absolute path to the experiment's dedicated directory\n",
    "                \"git_commit_hash\": git_commit_hash,  # Git commit hash for the code version used in the experiment\n",
    "                # Potentially include additional details collected during or after the experiment, such as:\n",
    "                # Any other metadata or results summary that is relevant to the experiment\n",
    "                                })\n",
    "        \n",
    "        return experiment_dir,experiment_hash #Return the experiment_dir so we can easily access the results of the experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full end to end example with BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     config_path = '../configs/cifar10/bt_test_config.yaml'\n",
    "#     config = load_config(config_path)\n",
    "\n",
    "#     # config.model_type = 'sparse_head_barlow_twins'\n",
    "#     # config.sparsity_level=10\n",
    "#     # config.epochs=100\n",
    "#     # config.save_interval=100\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     #get path to fully fitted model\n",
    "#     path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "#     model = load_barlow_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "#     print(model)\n",
    "\n",
    "#     #New config but the first part of experiment_dir is same - just hash is different\n",
    "#     #It shouldnt find a max file path\n",
    "#     config.epochs=config.epochs+1\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full end to end example for vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     config_path = '../configs/cifar10/vicreg_test_config.yaml'\n",
    "#     config = load_config(config_path)\n",
    "\n",
    "#     # config.model_type = 'sparse_head_barlow_twins'\n",
    "#     # config.sparsity_level=10\n",
    "#     # config.epochs=100\n",
    "#     # config.save_interval=100\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     #get path to fully fitted model\n",
    "#     path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "#     model = load_vicreg_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "#     print(model)\n",
    "\n",
    "#     #New config but the first part of experiment_dir is same - just hash is different\n",
    "#     #It shouldnt find a max file path\n",
    "#     config.epochs=config.epochs+1\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify runs with br_vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: cifar10\n",
      "arch: cifar_resnet18\n",
      "train_type: SSL\n",
      "weight_type: random\n",
      "size: 32\n",
      "n_in: 3\n",
      "bs: 256\n",
      "ps: 512\n",
      "hs: 512\n",
      "bt_augs: bt_predhalf_aug_pipelines\n",
      "model_type: predhalf_barlow_twins\n",
      "lmb: None\n",
      "sparsity_level: None\n",
      "wd: 1.5e-06\n",
      "freeze_epochs: None\n",
      "num_it: 100\n",
      "pct_dataset: 0.01\n",
      "epochs: 500\n",
      "save_interval: 500\n",
      "encoder_dimension: 512\n",
      "The experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpjsxe2lxj/SSL/cifar10/cifar_resnet18/97f42507 and the experiment hash is: 97f42507\n",
      "Configuration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpjsxe2lxj/SSL/cifar10/cifar_resnet18/97f42507/config.yaml\n",
      "The git hash is: 454ad8efbc9b87f4ddb443b9b5c80e3e9feff9b1\n",
      "Looking in /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpjsxe2lxj/SSL/cifar10/cifar_resnet18/97f42507 for highest num saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/101 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_loss is 1.7365665435791016, var_loss is 0.6704202890396118\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#config.model_type = 'br_vicreg'\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#config.arch = 'cnn_lr_cifar_resnet18'\u001b[39;00m\n\u001b[1;32m     11\u001b[0m pretty_print_ns(config)\n\u001b[0;32m---> 12\u001b[0m experiment_dir,experiment_hash \u001b[38;5;241m=\u001b[39m \u001b[43mmain_bt_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 16\u001b[0m, in \u001b[0;36mmain_bt_experiment\u001b[0;34m(config, base_dir)\u001b[0m\n\u001b[1;32m     12\u001b[0m load_learner_path, learn_type, start_epoch, interrupt_epoch \u001b[38;5;241m=\u001b[39m get_bt_experiment_state(config,base_dir)      \n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbarlow\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[0;32m---> 16\u001b[0m         \u001b[43mmain_bt_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43mload_learner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_learner_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlearn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexperiment_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvicreg\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[1;32m     25\u001b[0m         main_vicreg_train(config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m     26\u001b[0m                 start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch,\n\u001b[1;32m     27\u001b[0m                 interrupt_epoch\u001b[38;5;241m=\u001b[39minterrupt_epoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 experiment_dir\u001b[38;5;241m=\u001b[39mexperiment_dir,\n\u001b[1;32m     31\u001b[0m                 )\n",
      "Cell \u001b[0;32mIn[31], line 63\u001b[0m, in \u001b[0;36mmain_bt_train\u001b[0;34m(config, start_epoch, interrupt_epoch, load_learner_path, learn_type, experiment_dir)\u001b[0m\n\u001b[1;32m     44\u001b[0m bt_trainer \u001b[38;5;241m=\u001b[39m BarlowTrainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     45\u001b[0m                 dls\u001b[38;5;241m=\u001b[39mdls,\n\u001b[1;32m     46\u001b[0m                 bt_aug_pipelines\u001b[38;5;241m=\u001b[39mbt_aug_pipelines,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 export\u001b[38;5;241m=\u001b[39mexport\n\u001b[1;32m     60\u001b[0m                                 )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Train the model with the specified configurations and save `learn` checkpoints\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mbt_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfreeze_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreeze_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m learn\n",
      "Cell \u001b[0;32mIn[27], line 126\u001b[0m, in \u001b[0;36mBarlowTrainer.train\u001b[0;34m(self, learn_type, freeze_epochs, epochs, start_epoch, interrupt_epoch)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinue_bt_learning(epochs\u001b[38;5;241m=\u001b[39mepochs,start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch,interrupt_epoch\u001b[38;5;241m=\u001b[39minterrupt_epoch)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learn_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbt_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\n",
      "Cell \u001b[0;32mIn[27], line 103\u001b[0m, in \u001b[0;36mBarlowTrainer.bt_learning\u001b[0;34m(self, epochs, interrupt_epoch)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbt_learning\u001b[39m(\u001b[38;5;28mself\u001b[39m,epochs:\u001b[38;5;28mint\u001b[39m,interrupt_epoch:\u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124;03m\"\"\"If the encoder is not pretrained, we can do normal training.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     lrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_it\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_it\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\u001b[38;5;241m.\u001b[39mfit_one_cycle(epochs, lrs\u001b[38;5;241m.\u001b[39mvalley,cbs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_training_cbs(interrupt_epoch))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/callback/schedule.py:293\u001b[0m, in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[1;32m    291\u001b[0m n_epoch \u001b[38;5;241m=\u001b[39m num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    292\u001b[0m cb\u001b[38;5;241m=\u001b[39mLRFinder(start_lr\u001b[38;5;241m=\u001b[39mstart_lr, end_lr\u001b[38;5;241m=\u001b[39mend_lr, num_it\u001b[38;5;241m=\u001b[39mnum_it, stop_div\u001b[38;5;241m=\u001b[39mstop_div)\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_logging(): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suggest_funcs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     lrs, losses \u001b[38;5;241m=\u001b[39m tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorder\u001b[38;5;241m.\u001b[39mlrs[num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m]), tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorder\u001b[38;5;241m.\u001b[39mlosses[num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:256\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:245\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:231\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:227\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    225\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:212\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb): \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBackwardException\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_events(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m, CancelStepException)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._backward\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backward\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/_tensor.py:479\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/overrides.py:1534\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1530\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/torch_core.py:378\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 378\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/_tensor.py:1279\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1279\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "    #config_path = '../configs/cifar10/vicreg_test_config.yaml'\n",
    "    config_path = '../configs/cifar10/bt_predhalfconfig.yaml'\n",
    "    config = load_config(config_path)\n",
    "    config.pct_dataset = 0.01\n",
    "    #config.model_type = 'br_vicreg'\n",
    "    #config.arch = 'cnn_lr_cifar_resnet18'\n",
    "\n",
    "    pretty_print_ns(config)\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: RandomHorizontalFlip -> ColorJitter -> RandomGrayscale -> RandomGaussianNoise -> RandomHalfMask -- {'p': 1.0} -> RandomGaussianBlur -- {'p': 1.0, 'prob': 0.5, 's': 5, 'sig': None, 'blur_r': (0.1, 2), 'same_on_batch': False} -> RandomSolarize -> Normalize -- {'mean': tensor([[[[0.4910]],\n",
      "\n",
      "         [[0.4820]],\n",
      "\n",
      "         [[0.4470]]]]), 'std': tensor([[[[0.2470]],\n",
      "\n",
      "         [[0.2430]],\n",
      "\n",
      "         [[0.2610]]]]), 'axes': (0, 2, 3)}\n",
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> ColorJitter -> RandomGrayscale -> RandomGaussianNoise -> RandomGaussianBlur -- {'p': 1.0, 'prob': 0.1, 's': 5, 'sig': None, 'blur_r': (0.1, 2), 'same_on_batch': False} -> RandomSolarize -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0} -> Normalize -- {'mean': tensor([[[[0.4910]],\n",
      "\n",
      "         [[0.4820]],\n",
      "\n",
      "         [[0.4470]]]]), 'std': tensor([[[[0.2470]],\n",
      "\n",
      "         [[0.2430]],\n",
      "\n",
      "         [[0.2610]]]]), 'axes': (0, 2, 3)}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAkaCAYAAAB06IPxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOz9Sc9ka7rmed2rt/ZtvdltREZkxGl0slXBjO+CmDAAPgIDEKqaIqY1QVUCIb4CEgKEigJRSSrzZJ2Tp82I2P327u2sXR2DfU6SVF6XuZn7s7fvHf7/DW+zdy2zZbbW7Ut+Pbdl4ziOAQAA3lr+rl8AAAC/L2iqAAAkQlMFACARmioAAInQVAEASISmCgBAIjRVAAASoakCAJAITRUAgETKY59Y1/qpWZbJel7ofl0U+vlZrusREWGGPg3DcFLdDY8aB1MPM2xq1K91jEPvwT1gtmXfs3mtDMb6Qb0vx9ud38D76JjznjtVAAASoakCAJAITRUAgERoqgAAJEJTBQAgkaPTvy4EmJm2nNu6Sf+mC876uttQooDjm2zmfUmR4qcpK92Jr8v2+6wD+b4O/ABO7WvH4E4VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBI5Oj0r5vZ69K8pXm+246dsxsRnZl3a+O8Lobr/gnhNmNm/Pp08aEk72mpZzfjN8vc7N8DuwbekBvJ7WYCu6/h4L637/Kf9aeuHngT3/d5eeKlMaVkh+mH+BxO3cdb7Js7VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIJGj07+1mQHq0oFlYdKruR722R+Ir+ZmQOhgIm7ZidE3l2R0CTAbDDuw21P/pndPN4lk954JBeOtnBgrt+eeS9gfSFnaYKadO6zrQ6rk56kzxQ899j2fmCde0g477SNN9t6SzXxPue8jcKcKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkcnT6d1rr/uvSv4WZ9Rkmyevn+0acOuN3tLHd0+YXu1SwHS18KMnoZp/qwxFtpx/Ymj/Ym+0Q/8XbsCnSE2dQH0r5nrpv/wem7s6BVCnSNznHEu3DXXPs3VLC12rT1qce71NfU8qZwM5bXDe5UwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkMjRS2oWTSHrhRuof2Kmuz2wpGZvlpd0Zuq8i3q7pTNFrl9sUZr3XJjnH1hT45YHdL1+b6tNK+vDoOtdrw9Gz5IavIU3WQrzfW7n4LZOXcrhfrXC1d9kScj3vDzHLu9zz7fXxgP7OHHpkfnNj8jMPsyly38Mp37OBx5ybWdwSxSPwJ0qAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQyNHp3/NZpTdgEq916YbX6+23B2KqLv3bm4jWaOK/Lv1blvowVFUt63Wtj0VV6+dH+ITxdqfTvM9erWR91+r61kzU75moj7fgfvDBPv/Er9uh57vH3J/Y4fInRmTtazrx9Rx88MQEa6UXIoT5nZOoT1yVUelL2t89ZlZNFPpFuR8iGd3Kj73O+badfj3DePq94GB6RW/ivy6RfAzuVAEASISmCgBAIjRVAAASoakCAJAITRUAgESOTv+emfRvbYb/ziY6GVaa+JkJ+EZERGuiWIOpjyay6FJphUv/NhNZn04Xsj5b6HpERFU1sv6w2sr6GM9l/eZBp4XvV7r+VjE2wJyXbh6sS86+ySxVt1LApXndHFd3CthQsJtde+IM3EPbcu/NzQ93181Zod/c1KR5a3PFd9uPOLDawayOqCq9k9y8aZcwH13Kd9S9Zbff6edHxH6/P6netuZ6egTuVAEASISmCgBAIjRVAAASoakCAJAITRUAgESOTv8uTZq3qXRfXri0cK23MxyYoNn3Zm5jr4dDjub5dg+FSbdNprK+ODuT9fOLa7eHmExmsn57v5b1u5V+b9Nv72U9zzdmz6R/8RZOnOVrZ8ua83461edYRMRiMdfbMunSrtPf9d1OJzzdPO6+0+feeq3P1a3ZfoQPBruUb20StbOpri9r/Vpnla67GcKZiyNHRNPofZ+Z6+D1lb4O1mY7242+dnUugWu+k7udXkkREbHd6se2W31A9jtzoI7AnSoAAInQVAEASISmCgBAIjRVAAASoakCAJDI0enfaanTai79O29MWtikiA/Nz+zN8E4T/rUpwGEwv0hfmqTyVM/+nZsZv8uzc/2Cwqd/B/MRzBe3+jU1eobwofQe8KbcvFszDjaWS31uXF9dyfrV1aXdt/ubZqLPAXedaE06tzIzvzdrnUb96uuvZf35Mz2nOyJiszWpfHNcZ+aa8/iRPhaXE73SoSlMInnQidqdmYEbEbE017tPPvlI1n/9q1/J+nyut/P82Te6/lzXHx5eyfroBh5HxNDr6+Nup+vbzYGG9BpciQEASISmCgBAIjRVAAASoakCAJAITRUAgESOTv8WJgxl66Zdl+YPXMowIiIzUbmx10Mg3aYyM28zL/RhKGudMqwandDLzdzOiIgoTOrZ7LswieTcbCc7dACBNzSb6e/nk8c6jfrpJx/K+icffiDrbo5vRMRkos+zonRzWfX1YGoS8+6OYhx0ovYPf/2xrH/77IXZUsTnX3wh6ysz73axWMr6p59+KuvXE338qkGnebfrB1n/+uuvZD0i4unTJ7L+B7/UKd8/+oM/kPWLS/2deXjQ88z/4i//W1n/l//y/yXrxYFB1W41yizXx2/V6u/AMbhTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEjk6/WuZwNU4mAdMqGo80N4Hs63OpH97uw+dkC3M3FyXCh7Nv0V2ezOMOCJ25qGHjf5F+s1ez+jszJsbR598A97Ur/7g17L+6ErPcb06n8v6pNbf26rQ3/MIn+bMM53kLE0yftqY87jX+3bXrqY2CdLZY1mPiHjywZmsb1t9QRhGfY2qzGqAeamTzYtCP798pN/bo8dPZT0iYjrR25rO9Hdgs9HHdb3Rs3yncz0X/eJaJ8Y/+OQXsn5vZgVHRBStTluX5rJZ1gdWcrwGd6oAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiJ6R/df8dzaTdvtdb6ToTtzLJ3O/+Rtf7Qf+NKUdm0oF5aQ6DmafbmuTe/n6ltxMR+1a/75v7ta7f6Bmd262e6TmYeaXA25jNprI+n+uU78IkOWcmOTv2+vscETEOOkXat+biMup9bDYmRTzq7bjZv2Omr4FuFnhERFPr5Gxl0qVuH/udPk5dv5P1NtfvrTLzzJeNTvJGRMzm+jswWejPujVLPNwKhcKksMOsynCp4xfdl3o7EVGY4zqb6e9xOfOf6etwpwoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIJGjl9TkuY6rZ3ZJjY5Pty4Ob5avRES42fyZeU12QH5lhkzX+jCUpVlGNOrI+Haj4+0REXf3+rEXr+5l/cbUN1u9nd79igDwFu7v72R9MdHnXjvR59JQ6CUk2YEfgnBLMPpBL2nr3Do+c27kbumHW1Kjt26H4EdE7M3yO/djIGGuabm5pnWF+bGRTNfHUn8OU7NEKiJisVzKuluOUpllRL05ruZTi2qil/88faoH7T//+nOzpYh2dSvrO/Oayka/h2NwpwoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRydPq3yN3QeZPQ63Sqam+Ss1nhE3S5SeGWpUkkV6cNzq/M8ycmFVyY7Ywu0RcRo/lVgP1mK+vbta53e70dl5QE3sbtqxtZn9dmQHmtz+My9PD1pvL/rncLAoZB50U7N7Dd1EuzA5f+7dyPVow+9e/S+i4VnJmU78ykc8fS/KiI+fGQPtPvYThw/V3t9TD/vVn50XR6GH1nroG5+TGV2lz35wudRr64uJT1iIhvTfr3frORdbfC4xjcqQIAkAhNFQCARGiqAAAkQlMFACARmioAAIkcnf614VITkhpcmMxsyM0QjogoCt373YzfzKTJItf7zk29MnM1m8a8nsz/G2U304f6zqQlTSA53FvzRw94c+68HFxCtm1l3aXcoz1w3pt0/+hOAjOdtzPzxiszC9ydTe69DQfmbpdmlu9kptPQZaVn8w5u8rBJqe5N0vZuvZb12wefYH7x4kbWO7PCYz7X6dzWJJ4fXV/I+vlcH4u814ndwiSeIyKaqU4kr1u9rYed+b4egTtVAAASoakCAJAITRUAgERoqgAAJEJTBQAgkaPTv8NgUrsuaGtmSboQcX6gv+dmJzYD2OuUmXkLoTN9ETsz77jMdMqsKnTCLCLiYqm3tbmYyvrNnd7W81u9nXxljt+BZCLwOi5R2dSNrE9M3Z3D6wedRo2IqBr9XZ8tF7J+ttSpUzeTu9/rM7/d6euHq/e9T4o+un4k60vzHtz1sTfn8fn1uayXtU7O3t6tZP3f/e4Ls+eILz//RtYnUz2P+NNP9Qzev/iLv5X1zSf6+I0f6Pc2LfXn1rc+wbww343lQl9ns1F/1sfgThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjkrdO/7lfbXb92z3fzfSMi3EjdzMy9HDo967MbTN2l+ra63u10+mw604m+iIi60imzywtdv77X2/rqxb2sF4VJUbpoM3AEl6h1KV83/7ow5/3yzJ8z46lzwk101s34Hc1MYJe0dcsHnj56op8fEVdXOgk7nbiVAiapbGb5rlf6vH/27QtZv7nRz98+7M3rieh2+jVtO522vXtxJ+tNoT+Hy4X+DlwsdLq4DP0eqqWb5Rzx4sVXsr7b6dm/04lOTx+DO1UAABKhqQIAkAhNFQCARGiqAAAkQlMFACCRo9O/mRtKaf/AzOs1Kd/MzAo+sCmbxhtNem8wv1Tf9ToF2OYmLbw3qWAzSzQiYrrQKco8dGKtrvVxKqvTUtXA26hLk6g0ydzdVs9xHXb6XFrO9ezriIiy0penwZzf92au7WKmU6S9mQmchZ53PDezbp8+firrERGL+czsQ7+H3VanUTcbXX+410nb1Vp/Dv1W77c1z4+IGN2M5NDXwdXtS1k/n+nP8x98/FjWf/3LD2W9zMyxWN/KekTE/Z2eX7x+0AlmE7Y+CneqAAAkQlMFACARmioAAInQVAEASISmCgBAIsenf0241GVOMzPD0m7nQHh1NNsaTALRjASOGEwi2SWbzXY6Ew3bbMz83YjozWvtTPp3tzPpvV7v281JBd5Gu9czYftWJ2Q7cyIPvd5Oc2Dmt5uDmxX6sjWaBLybW77bmnm35vlzNwfZzvGNGM3Kgs1GJ5Xvb29k/ebVK72DXF+k5mbe8czMIO/XOgUbEbEp9PFoW32Nyjv9mf7i45/L+s8/Opf1p1c6Od2ZJLlL8kZEVOY9FPprHF3nZyG/DneqAAAkQlMFACARmioAAInQVAEASISmCgBAIkenfwuT0svz01K+9vlvMLt2GE3az/xbIct13YzTjcz9k8O8h8HGjiO2Js277XRibbXS9b1JYw6D3zfwplarB1m/mDeyXpt0qUtZZgdi/9uNPmemM50Kvb46k/XRzPK9a82AVzNb2L3Sh7t780jE3qR8H271nNq7uxtZX5sZv0+e6uTs5YWeqVxV+nNbVo9kPSKiyfVxWq/1d+PySs9I/u//81/K+tlMp3m//vyvZP2bL7+S9duVSUhHxL7T84KrUn+q+52f4/463KkCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjk6CU1k4ke0OxWwpSlXnZSmvUrWeGj9YMbqO8m3o96H4V5sa6em2HVQ+gIeO9eT/jX2pv4fmsGOvuB+iypQXrLuR4iX7mh9p0+N/Zm6dhovs8REUWpl8K4347oO3Mu7fXyiPOlXoLjfkTg+bfPZX19YElNYc77/VYvF9o86KUfu51+TeuV3ndT6/0uFnoJzodPP5D1iIhPP9HLbRZLvbTpyRN9XC+u9HKrv/2rv5D1v/pzXf/qs69lfTBLHSMiZkvzowem72x3fjj/63CnCgBAIjRVAAASoakCAJAITRUAgERoqgAAJHJ0+nex0Emv0rTlSoeFIzeDtfsD6dW9SRQOo65nJh5YmIH6tXkTeWYSu4NJmR0Yau9yaS49ffrPCwDpDZ3+5k5KfYJfL/Ug91mlE6Hziyu7729fvJT1uxs9XH51+7msL8914nW90QnPuxs97H5j6hPzYyMREfOJHmBvLkX2RzkeP34s6//kn/2BrH/wkU7sDoNZuWCusRERi/lC1ieTWta7Vieb/9//9b+R9a++1J/b6l4P7K9q/R27u1vLekTEvfnsZjP9PX786MJu63W4UwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABI5Ov27XM71BkyatzZbdvN0296nzzZ7N+9Wz8NsR/380qT06kq/WPdaO5OU61uf2c16naLMTJLYbYlUMH5IWea+t/rcG/b6nNmY+u7AyOrNRs/BLcx5vDBp1NK8h6bSZ1Nj5pNvzWoDN683IkK/oojpTKeCm6meUXtl0r9nl9eyfnmtn1+ZlQ4vX+i5xhERm81K1l+8+EbWX73U2/ryi89k/f5OJ3PdKo6m0seuyA7cI5r2MrZmFn13dGv8j3CnCgBAIjRVAAASoakCAJAITRUAgERoqgAAJHJ0xKk0ibjKpn/N/N1C/0EdZkMRUZsocWVSgNutTia6Abwu7ZebAZ15uFSwjzL2vUkwm9mq0ZttmUQcqWB8H8pKfw8nE/2NmzS6Prrvc+5T/5OpPu/LQs9rXTRmFm3f6u2YpQtV6Nmy07iQ9WGnz+2IiMePdDp3eabn6Q6lPn7bTl/TfvOZSdSudaJ22uhj9/y5TvJGRGw3eqbudq1n867u9Wzm7VZvZzTziOtSf/61+dxmM5e1jqjM32Tmynl/INH9OtypAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAiRyd/u1Ngs515SHXKVWX2C0rnUqLiJiZxNq01omujam3rU/pKW7uaYwmlVb49G9noseZSwW7tKSZFQx8H4pCf9/OzvSM2qfXS1kvzfWgXl7afT/s9DVns9Yp0mG/k/V5o68HozmXxkq/t8upTpfWpb92ffLJJ7J+dnkh6w87/R7+n//iX8j6F9/8VtbzTCdqc7NM4P7ulX4gIpZznYZeLPRxqs1qijDfpaY21/dKH++pSX9XBz6HcXQrRfTxvrvTyeZjcKcKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkcnz6d9Ap1SIzsz5PTKkWmU/ONpV+mY1JDNeFfk2bra7vW50y7Hszv9jMBD6UAuzNLOQ618e1NMfVpfeA78No5lxn5p/jzUSfA3Mzl3c0yf6IiLxpZL0y14PWzKJ9fKETyW6+9mat576uH1ayXlf6dUZEZObtFWae+flcJ2o/+uQDWf/db7ey/nCvZ//GqFPB7hoYETGM+v1NJvozvbiYm33o15oN+nMo3AoIs2JiPtPzlCMiukFfOLNCfw7Fgc/0dbhTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEjk6/VvVOg1lflA9ytIkukwyNz8Qa83N3xRmjnBmttWblJmbCdx1OilnNhO5SexG+PmWk4neR1PvZb0o9AE/tG/gTZ2Z2bxZ6O/zOOrv53R2pp9fz+y+t/d6xu9sotO8jz/4SNYfXjyT9btbPe+2N+f95cUjWf/lr34t6xERi/NzWV/v9fn9m9/9Ttb//M//Sm/nQad8ZzaZqz/Pp4+vZD0iYuj1fNyu09fN7UanfHOzwiMLk0je6u3c3+v65aVpRhHRm1aXmznCZxf6czsGd6oAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiR6d/y0an9Erza+6FTf+6Hfj+PuTmZZoBpL351ftu1PMtt61+rauNTrcNZq5xaeZIRkQUJiZdT3Squp7o11qWei5pkP7F9+DuTn/fNkt9Pdis9bl3X+jEZrWc+n3fmlmx5vmTXCc513c6vbozr9XtoO/19Wa11q8zImK109eQl7c3sv67332mX5KZXXt+plPVi5lO/86mZhXCgRnMfavft0vzlrm+1u025tpl5so3pllcPNEp7OnczHiOiCzTx8Nf+/1n+jrcqQIAkAhNFQCARGiqAAAkQlMFACARmioAAInQVAEASOToJTX3Wx09rkod9e4G3a9b8/zcPD8iIu/034yjjsTvtno5yv29jtbf3uj6aq3rTqNXx0RExKTR72/njpMZTN7bfwexpAbptXu9fKwq9ZKaSa2XNbhB+6sHf449f66Hxbc7M+DdLG2pez28vjLD1MtK1wdzjr14dSPrERFtr69Rr270MP9bU78618fVzM2PojDLhQZ9bYxOf84REflolk26P+h0rxj2+jW57VeV3sNioZdhTWcT94oiz/XFef/qQdZfPn9ut/U63KkCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJHJ3+/eLbe1mvzSD8WWMGyNe6nuW+v48mHdZ3ehDzbqvTfg8Pa1m/v9P13c4NtdfvYTK1ebiYmsHNnRnO/2DS1nuT0hvMMQLexmw2l/XFXNfPzID3iUlyfn2zsvt+eNCP3d/pVHC/1c+/munk58WZTtTm5rUOZoD8w1ZfGyMi2k5fi3Z7/Tdlpp8/m+uYb2Z+JGQwiefOvB5zKf27jelri7vimNn/kZsfJKhr3YYq90MqZtVHZa7LERHjaIb/m890bl7TMbhTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEjk64nT7YOZqmvRv2+lNN63ZZeb7ez+Y5Gyrk28u/bs2c0YfVno7XasjcVWl421Drl9nRMSQ6cRab5J1W5cW7nWd8C++D+fnC1kfQ3+fx1GfM0uTtL0z51hERGEuFW2nr0UPKzPjd9TJ2XE0SdvBzDVe6pmz+YGx2/tWryyIUSeVp7Wbzau3s9267esLQlPrY9G1ZlZwRIy93lZn6mOvD8ik0ftuCp3OdmneLNPbbyrfzlYr/Z25utAp9j/81c/ttl6HO1UAABKhqQIAkAhNFQCARGiqAAAkQlMFACCRbHSDdQEAwEm4UwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkQlMFACARmioAAInQVAEASISmCgBAIjRVAAASoakCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkQlMFACARmioAAInQVAEASISmCgBAIjRVAAASoakCAJBIeewT/7f/h/+TrPfjKOv7Tte7XtezA/uuCl1vCv1XtXl+Wep/Q+S53s4wDrLedq1+/qCfHxFRFvpFbTdrWf/Lv/gzWf+v/u//V1n/N//mX8n6zc0r+5rw5kbzvf9989/81Veyvu70879+2Mn6ttPnRnXgn/XmdI2dubbse72PotAbmpodfL7ay/o3W/2mV+ZYfLcPfd5fzhtZP5/p+sfLiaz/+lLXf3mh69u2l/Xn9/pzi4j4+kZfo17dPuh9bLey3u83sp7vVrJe5vpz3q318z//3b+T9YiI3/ztX8r65v5G1nvzmf6X/7v/wu7j73GnCgBAIjRVAAASoakCAJAITRUAgERoqgAAJHJ0+vdhrZNbJnAXJmTm07+Zz/+69G9f6r/pzbuqXErP7Lrr9B/s9jop15vnR0SUJgW42+rjul7rxJ1LHr8vaVT8sP722Y2sj5O5rK9HfTLtB/39XJtUcEREbVL5Za7vBSbmHLua6gvC1VwnZKeTWtbbl/qcvL/1ydm7jX5stdX1r17q7Tyb6df66nYh65+dTWX90zP93p4sKr3jiPjVk8ey/u3dUtZvV/oa1Zqm0O70NbDd6RTx3tQX85msR0RMJvp4fPZbnRi+v72z23od7lQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEjk7/PntxK+s+/auTe51JB+Ym0RfhZ/xOTWBtUpgZoJlOn/W9TqutzVzelZk92ZlUcISfO9ybNO/zZ9/q12RSwX1v4tbAW/ibz7+U9fkHH8t6Vul0aW/+/e6zvxFmxG8szEqBqVkmcD3RF4qrRj+/NgOJ71v9atemHhFxp4Oq9nzNXYq/1deJvbkW3fd6x79b60v+F7lZYhERdaX/5pMrnbb96EonbRvz+aw2ejtrk5ze7fRs5uXCp3/zUn8HikrPWr691f3uGNypAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAiRw/+/dBz2d0ozt3g0n7jbpeFL6/t+YX4LtCz9rdjjodNnY6Ebde61+wv73TCbCHBz0X0qWIIyKaWiffsky/t5cvnsn6xqT9hoH0L9L79svPZf2i1JeOZnkm68VEJzOz3F+C+kxfE1qzUmAws4LNQoTIzHXlzFyLfjbXr/V+7ZOzY6uvRW6dQJ3pbZ2ZOefzTF+A61HXt+Y6frfRrzMiwoWbb83c4dtHF7L+9ELPi15M9Ht+cqmf34/6u7Q518+PiGimOpG8WOr5xS9fvbLbeh3uVAEASISmCgBAIjRVAAASoakCAJAITRUAgESOTv8OZialm/3bmQd6M9ry0OzacdRZubbTc3CzVidk91ud8n241ynfV7c3+vkmgXtokulyMZH1iUkFt3v93oZBJ4xHNzMUeAubL38j67tbPZt68eSJrC+f6FnBxUynLyMi+lonNgczx3VY6XOj16d9bJZ6++eN3v7UJHM/aky8OCJePtc7327Na631LNox9EzlvUn57sxChK7VKyYeDqR/HzY6Mby+e6n3/XAj65tHl7J+sTSp4Jm+Zi6m+hhNGt/Ofv0z/b18bBLJL27u7bZehztVAAASoakCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJHL+kZtDR7WEww+7NCpm9mc48tHrYfUTEuNVLXsaNrg87HWNvd3qZymar6/drXV9vdcQ8NwO9IyLqSj82qXVsvCz080uzD79n4M2d7/W5dP/wQtZfPftM1u/+5s9lvbl+avc9eayX4ZTTc1kf7/QQ9K/Nj1Z8aZZmPDnXg+InjV7W8vzWLbGLWD3Tr2m7MUvjCn1Jbmu97xszy39m6mWuH9gduII8//ZLWc8H84Mm11d6Q7uf6edf6M9zMdOD88tSv4cxO3D9NcfvbK6vv0+u9Ws6BneqAAAkQlMFACARmioAAInQVAEASISmCgBAIkenf/d7nc7dm5jvxgyMXm30dnZrP8C4e9CDm4e1Sf+2Op07Dvq1DuF+LMAMyM/Mv0UOpM8yk7qrzHDwutJ1l3zLDuwbeFMX5vtWmkvH3cYk7M2PUIz2xykids+eyfpQ6CTn2OprTmZ+bOJZrs/jlxd6yP9sos/Juwd9vYmIuDGPrXb6R0Iycz24NT84sjHXzabSx2g20wPkV2ZofkTEw62+/mYm/fvSpHn36ztZv77UaeHpRCdzB/MjAvu9fj0REY1JEl9dX5vXpIf//w/+e39i9/H3uFMFACARmioAAInQVAEASISmCgBAIjRVAAASOTr9e3+vZ1ju9jpxd3dvZobe6wTY9kD6t9/obYVJ+YZJ+WZmbm5e6sPg6qWZI1kWZuBmRFS1njNaupSv2VZmkseEf/F9uDjXSdipScbPz3S6dLfRadf2QGJzHEyaN/T5ve/0850m1+feeKfTrvc3+rWacPF3+9iZ17Tby3JW6PO7Ne+t2JvtmGvjfquvs8VohrVHxGzUn93KXLNf7XT9t+Zz+7LR18beJJ4nJhVclno7ERGTmf4eXz35QNZXH3+iN0T6FwCAHw5NFQCARGiqAAAkQlMFACARmioAAIkcnf5dmfTvxsyMvL0xCbo7Pa+33emZwBER0ZvkW6Zjdy4Ia0LBkZmUWd7rhKNL7Fa1T/8WNhmsX+1gEoWjiRoeCCACb2x5qee4uvTvwsxl3T3omcB7kwqOiGhdctbI5vq8dMl4d87MJjpF6u5A1ms/N3dnzu/MXCtaM794MEnlvNErEXpznRjcxdF8bhER2Zmem1v97CP9/Il+TRuTeN6Zem9eq5tFvNv5BPOQ6eP34pWZH38o0v0a3KkCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJHJ3+bc0syXavU3277eqk+tDqBFhEhBmHGVluErUmNdabNG+7MzM9zVzjqtLpwCz3/0bZtzqZtjOzT13dvYe3CKsB1vL6Qtb3ZuZsZ763jTlX20onRSMiepeENUHVwZwb7tbBzdmtzGvdmATzoTuT2lyLsk6/1sKcyLm5qBXuWJjIs1s9kGe+FdQznf6dPrrQ21rq57trl5sf/80LveLk82+ey3p54D08rPRn99WzF7K+WevnH4M7VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIJGj078u2JqZAG5empmXhYnD2aGUYdO8bluZSb5lJjbYm6HAbW8SuCZxV5mZwBERm62ZXxx6Y2szE3XfmqQy8V98D3Jz4pe1Tu1OTFJ0cPNdGz83151oLmHcmRneo7l+5KW+eI3uBDfTgrOtv3YNjb4m1JW+9G7v72W9M8njzAzIzXN3nT1tnnlExHQ2lfXJXH/WeaNXR7jPZ2dWRnz9Qs/l/c2X38r6futXkExMynw0n+mXnzP7FwCAd46mCgBAIjRVAAASoakCAJAITRUAgESOTv+Oo/tVdZOIM+kzV3cJ3+/2YPZh/qZ0w4LN2+3sPF39nu1bOJDA7U3ybWt+rX6zPS39O7iBqMBb2G906rRoTJrSzPDOO/29NYsH/m7nJjE/6POsNmnewawSKEzitTMp0tGc+HntL6NZoR8rTKq6qfVrGq4u9WvqTOLZjUE218ai9PdX5VSneau5TgW7C3NvrlF7Mwf5q+d69u/tg06Mr1d6rnxExNIkmBdTXc/Md+wY3KkCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJHJ3+3e+2st7tdUp1NPN0XTA3s4ndCDcueDrRCcTZdKJfk4kYN2v93tYbM0vSDDyemjmfERGFSQ72Zr5wa1K+LkXM6F98H0Yzm3p7eyfr+1d6dm1uEp5uBm5ERFnq88ldKVxis8zNdszzBzNbuDD18kDyPjfnd17oa0hjkrbFUs/ZdYlkO//c7PfQ7PAxM4+ZfbhtDWa++/rElQ4zM1+6LP13aW7S6o35G3edPQZ3qgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEjl6SU1hJjRXZrnLvDKRcTeEedTLYCL8oOzlYi7r58uFrGdmiPXN3YOu3+jlAftWx63LA8sD3Iqh3iw1cMOnBxt9Z00N0nM/ZtFu9TK0nRlqPqz18rT9gXNmPtfnd1Xr5RG5+9EPs7yvN/se/C91yHLR+nMvMz/W4QbbV2bI/2S5lHW3pMZ9bk5/YElN1+ofNvAD8s2Ph5glMndrPSD/7OxM1icz/b3IswM/CmDWZbrVQne3t3Zbr8OdKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkMjR6d+lGV4/1DoR1ze67ia/5ybFFuGHbi8XOuW7XOp0mJ97rfe92+rE4jDotNpghmdHRLQmPd33Olk3uBdLyBc/oP1GDzsPM5i9OtPn5Fjrc6k8cN7ntU7CusH5w1q/1qzW9w5Zr68r7oc3wg3sr/UQ/IiIzKyCGM3Adpfu780w/9wkkjNzXAf3wx4HfhRgb1YoPKzWum7SvDd3Ohn+5bNXsu5C1ZlJSO925gdQIqJu9KqT+VTXV+Y9HIM7VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIJGj07+VmZ04mnmLg9u0Sbdlbt5mRJS5TrgNZq7mxiQW92b25MODTrGtNjoB9rDWzx9MOjAiojBpyczEeXuTDhwPzOgEUnv2Qiczl2YuazHVSdjS1GuT5IyIyF3606RRMzdH2M0EdisRzHWlcKde51P/XWtmHu91vb+7k/XpRl9zstIcv0Yf796kkTfmehMRcWdSvje3+rXeP+jr5qt7nf59dae3//xOz16/udNzeftOr6SIiJibJHln/qYqjm6N/xHuVAEASISmCgBAIjRVAAASoakCAJAITRUAgESOjji9eKlTgKOZGdmbRNxoErKHfqk+M7M480L/m2A0SeKdSf/em3TbyqR821Ynxg4lmCuT0ivNe+jM8XMzgQkF4/vwp3/+V7L++NG1rF+eLWX9bKlnAs9NKj4iYiz15Sk3ieF8pue4jm4mtzmXMpOELVozr9fUIyL67VbWt2udhF2/eCnrG5Pm3eX6+rE3x2g/nejtmBnCEX7G73qlU77bnb4+rsz84pWZse7m767M6xk6P/t3r//EJoabWs+6PwZ3qgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCJHp3+/fvZc1geTlOs7k5Q7MGPScclWlxjuTcK4Nfveu6TtaNKB+uXY+b4RES7cPHR6a/u9TqUxExg/pH/7Fzr9+5vffibrHz55LOtPH+v640eXdt9ny7msL+czWa8rndjMTULWzgo283Gz2pxjZlZwRERR6X3X5toS5hqyWum08HMzK/jGrHQY5vqY9iZpHRGxN6sd9ibl27prv7mHa81r3e3M3OSdnu0+rQ+0M3O8CzPj163KOAZ3qgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCJHp39bMyPRzv51KVWTzPVTcyPCzNR1iddhMIlkMwN0MPXebN/NInaBvu8eM9sy+2j3OuHWupnKpH/xPege9PzVbqe/h59v9ff2y2++lfWlSfhGRHz05JGsf/hUJ4kvLi5kfTbRM4ErN0PYJD9LMx+3cCniiCgyva2pSZ1OzOzk1fMXst6aZQWd+Rw6d+06ML+4M+nc1s1Uzs3V3FyiMvOAneVr9lsWfl5v1+t9uM+0MUnyY3CnCgBAIjRVAAASoakCAJAITRUAgERoqgAAJHJ0+vfyTM/b7M3cy77T9cGksDKT8I2IyM1j7m96k/7dmJmRD5utrK9Ngs7NthxHn6DLWvMe3PziViffOrtv0r9Ib2ESlaX5vq23+nu7M+fe5uHB7vvVM514/Zu/+ney/sTMF/7w4w9l/ekHT2R92jSyXtc6LVyZBGlERJmbxLCZ8WtGgcfOPH9vUsTtqFdrOINZxRFx6BqvU7jNTPeKuUlhu3nwr17og9Ga2czDYNLIEVGZRLf7rMtDc9xfgztVAAASoakCAJAITRUAgERoqgAAJEJTBQAgkaPTv9eXeiZla2ZGbjbmV9v3bnat33dlklgujVeY2ZPbvX5Nea7/bdGZVJpL/7qU3CG5m1/stmUPFOlfpLdYTmR9b5LxtTlnCpP63+59SvW+Xem62cf9qztZ//LLb2R9uljI+gcfPpX1j0xa+KPHV7Ie4VOkmbnm3K7Xsv7qXqekV2u9cqFtT0v/uhUTERE7M4d8b/ZRmWuXazaXCz3/2R3XbzOzsuTA8PXpTCePH13rfby61d+lY3CnCgBAIjRVAAASoakCAJAITRUAgERoqgAAJEJTBQAgkaOX1Dy5upD17U7Hql/Fvay7Qfu9iclHRBRmGPJyrmPSy7ke6NyZ2Hhd6cPgXpNbRjT0eslOxIGVMJn7gQG7KeAHc/FEL6V79Uo/f1zp5ReZOwE6vxQsM+dfb5ZyPLR6GcS9Gdqf1XqY+jPz5v7md5/L+vXluaxHRHz6gR7y//SJrt+bHx5wSzxWa/18t7wvM7dRbnlMRMSDWeaz3unr3WqjX9N2vZH1Samvv5dzvdRmNtE/8tDUuh4RUZsh/I+ePJL1P/vLv7Hbeh3uVAEASISmCgBAIjRVAAASoakCAJAITRUAgESOTv9+/FQPmd66wdqFHnZf5reyvj8wWHtuhiE/eXQt6y6N5wYuVyb9u9rqYdWrja53nf6xgAg/nN/NwR9NWnI0f8A4fXwf/vDnH8n6VwudkP3qm5ey/vULncA1v7sRERH9oL/Veeho/GDS/V2vz8vMJO/be72dl3c6gfv18+eyHhHx+TffyvriTA/zryc6kVyY62ldmcTriRcENzQ/ImK10unfl2bIv9v1/b1eETJv9Hu+uNDX8Y8/+kDW/9Ef/trsOeIf/uLnsv6t+ezubhioDwDAO0dTBQAgEZoqAACJ0FQBAEiEpgoAQCJHp38fmSSWS+1Wue7XdaFnMG4PpM/mMz0D8sljnf69uDgz+9CvdXanU2lVpRN3eW4G85o04SE2zetm/zIUGD8gNzP18aU+x6a1PmeWCz2P+7ffmCHCEfHZNzq1u97put5zRGnO17rU16i80M/fmTnnd7d6pm1ExM16JevFc33pnUwnsl6bubbTRj9/PtUrJiZm3nFhrtcREeOgV02MJm29a3Wke7vVKeJXZiDxzmz/3PSi8sDs3w/N6pXSzB3+R3/0x3Zbr8OdKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkMjR6d9ur+fdjp1OaJUmCdtUOlnX9QfSZ2Zm73anE8OvTJrXzex9eXva890c3/xAMrcyKcrM/Lumz/R7Hjr9/M7sm5nAeBuDmUHtUsHnS53ybUwqeDLVadSIiLMzva0vn+v54S9f6Xmt642+TrStPscac+4VJi0cnT/L2l4nhjdmtcPa1PNSH7/GzP6dNbo+Mc+vzUqHiAgzajnmE72tyqSn71Z6VvCDWZUxPD9t/nlz4D0Mpk9t9jqp/M3zF3Zbr8OdKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkMjR6d+7W524600SdrPVydnNRs9/XG91CisiYmW29WDqWa6TieutTta9vNHvrev0jNGpSb1NG58+c+lf96+arTlOL0edlOtManAwnw9wjN4GW3XC081SXRYmvWpm0UZEXC31zO/rM13/7Fs9B/eLF3q+sEsFr01S1IyojcnEn/e9mZu7a/Xxa03a2l2LBrP9rtXXiYdMX1dKM5M9ws9An5iEsZuNXpnvQDXT9X2v39vvvvhS1r/44itZj4j40z//t7K+WC5k3XwMR+FOFQCARGiqAAAkQlMFACARmioAAInQVAEASOTo9O9krhN3NpVmErjzzMzArXVaLSKiG9wMSDPv1iS3ajN/9NL8kvxioZNhmZk9WbnZoBHR1PpQu3Tu82fPzfP18V6vdaqvNSlA4BiDOffclOvBPFCYROis8enf+UQ/5lKnFws9K/jDa31+f/Fcp4I/f3Ej6y8eNrJeHZj5nZuLUWHqo7k+jrm+tlSmnptPqHVpZJN4jojIzHzctVl90dQmFWwO09bMle/NMRpGMz/+wOfwmy91YtjNay+KN7/f5E4VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBI5Oj076/++B/Lem/SqPudnqu5M7/y3h6YUdu79K9Nh7m63r7bTmYSdIX5ZfuyPDA/0ySD16uVrP/VX/+trN/cP8j6sxcvZX2z0ck64Bg2UGkSmO6ccYl8d65GRBRmHu1iNpV1lyS+NCsXzs12FlNd/9tv9Dn27c2drEdE7PanXVsyk+ZtzGqKSW4u4Sa96lYurHd+9rpb4dG2uu7mHbsVEI2ZLey2s291r9geeA/u2jyZuoS5n+f8OtypAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAiRyd/v1H/+w/kXX3y/MuFdyblK9L4B4ymiSbLZ+4i8xEHzPzTxE3R/LQtl6+0onCbtRptb/4m9/Ielm+eVoNcA58pc0fuO24VLC+fkRE9L0+YcvCpEjNzNnKJGdLN0/XnEudeandgZULz251Wn9vErW5OR6Duf8ZM5MutnFrd7327yF3Q3vNLjqzj8o8vzLp3zOT5nafz8rMP4+IuDePdWausc8Rvx53qgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEjl6Sc3HP/sHsu6Wwvio/OlLZ6yEm0ri1OUHETH99pms//azr2R9NlvIuhs+DrwV8ysUbplFYZapZGYdWuaWa4RfomaX55ilHG4t3aTWSzOeXixlfWeWwQwHlgXl5ni8XOklHhszpH5nlii6JU+5WUbkfrikOnDtKs1w/tGunzIbMp+DO0YX5/pzeHx5LetffPO12XHEEG44v/6Bl3F4g4v53+FOFQCARGiqAAAkQlMFACARmioAAInQVAEASOTo9O90Nvs+X0ccjPKemPL9sYWCD5nNN7LeTCayXpT6I3OJSOBt3D6sZL02Q81L8/0sTTq9rg5cgkwq1KVFXcJ4dPPgTbLZpV2fXujk/YEAc0wnesj/l6/uZf1bM4D/zqSFWzc436R8+16nXSfmc4uIqM3A+9x9prUehD8p9fPP5rq3fHh1JevFoe+MMZjPujfB7d1eH6djcKcKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkcnSM6vtPlx7Y/om7ztw84tM2c7I3OUbub+ysVFK++AH95e++kfXKJDBLU582OgU7N+nYiIjKpEunjU6XzswsX5f8HMx1ws3H3ZvZv8uZTupHRPzRYi7r5ws913Y2eSnrnz3T9ZuVTme79GpmroJulnOEn+fs0r8fPdap3T/69CNZf3J1KevzhU5b//lf/zv9esznHBHRdTrmu97uZX1wc6SPwJ0qAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQSDaObngkAAA4BXeqAAAkQlMFACARmioAAInQVAEASISmCgBAIjRVAAASoakCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkQlMFACARmioAAInQVAEASISmCgBAIjRVAAASoakCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEimPfeI/+Sf/RNbzLNMbLgpZL0q9y9LUIyKayVTW54uFrE+mE71v80+Irt3L+nazlfW1qW+3uv7dPjpZb9tW1u8eHmT91atXsn5/d6f32+n94u2M4/iuX8IP4h/9s1/Jujvvx1GfZMOgz7Gq8+f94uKJrP/81x/J+pPza1n/i//2X8n6y1t9LuU7fe3qsl7WN4N+fkREka9lPdvXst5k+vg1F/oa2O71cW1zfd5Xg/l8Mr39iIgqu9f7KPU++gf9me5qfc5MmjNZb5b6NV3P9Pfi4uyprEdELK71a6rPlrLe7/X3+3/zn/2ndh9/jztVAAASoakCAJAITRUAgERoqgAAJEJTBQAgkaPTv+Ogk1sm7BfDOMh6Puh6hE5bRUTkJhHn/mYw+xh7XW9NMrfrddrPbT8OBEJNWNI/3x2P9yN0ih+JOtfnQB8zWR9bnYDPSp3IX4VPzP/ikytZP798JOttp0+Ou51+D/udfn5dvNT17lzWq8lG1iMiojerIGb6GrI16dxOh3yjyfV1oi715zOYS37W+1UCba//ptmb9jHo1zQb9Odws9bp4kI/PXb7Z3q3o/8cXhV6pcjsTqezx0llt/U63KkCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJHJ3+HUwSdjRJrzCzUYvcpOFMPcLPBXYJ2Xav5+l2JkJn52e6VHBn0sWHkrmjfq3uPWQnp3xPjBcDR+hDpyCn5hxbDbruUrDL0kQ8I+Jqpme5Pq50/dt4LutFpfdRhT7v81zPos0r/d6ymMt6REQ77HR91LN/i0q/pjrT2+kGfW2szMVoMKs4iqnefkREtTUzfnud6N7M9HGqe30Pd17qa1df6/2Ooz5GD4P+/CMi2ucvZH1b6dm/5fyx3dbrcKcKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkcnz614y7zXKTJjPDbsvKzJFsdBouIqIyf+PmC+9Nmne31bMh21an1dy8Yzd/187rjYjcpJvzXL+HLNf/3jm0DyC1mQnl3+b6nJmYYeB5rpOc59Nru+/rKz2vdfHBhay//PxW73tsZL03qdP9Vidh67mZFVz6ubmDWbkw7vQ1qprqA952+rgOZtd2lK9J1OZrf13ZD/ra3Bb6eExHc73O9XvOdvq9XZh09nCmE+l3969kPSIi7/R7WJvbyrP2ze83uVMFACARmioAAInQVAEASISmCgBAIjRVAAASOTr9mxe6/xam3jR6LuR0qn+Rvpno50f4JOy+1emwrUn5ulTfYKLNbh5xVer0WVn6+cXu+Lnk8d7U7Rxkk7YG3kY50anJSauTn9v9StbPrx/J+uLyyu57vtAzdWtzK5B3+hpShz6/e5Puz/IHWV/dmxm/jb4ORUS0c5OGzvQ84tzMWJ9keju7Qr+3Zq8/t8HMP19n/tpVZeb9VW4GulnhsTOz1Gt97VqbzzO/eynru81W1iMi9nEv65OFPt7b26nd1utwpwoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIJGjl9TUZuB9ZZZ4zOd6GPZ8rpfUuKUiERH7Tkex9zu9RKY1A/VHM4C/KvS+J2aZz2ym38Nk6pcFuR8S2JnX2o867n9zeyPruVl2BLyNOtPf23amh5fnc3M9yNay/uj80u57Pj2X9VGvNov1/gv9QKOXbExLfU3btnoAfx76PTyM+noQETHd6OV32VSf322vX1NulqlEr+vbUl/rtplZphT6WhoRsTHX5slefxDZw52s7yq9TCXb6aUweaP32+e6t5Tmx0kiIh5q/Rn193r55bb9ym7rdbgSAwCQCE0VAIBEaKoAACRCUwUAIBGaKgAAiRyd/p3NdHKrrnRazaV861on6zozSDoiYr/TCVk3UD9Mcrap9WudmSH/bqD3YrnU2zGp4IiIqtYpwI0Z/r8xibjaDDjPCwbqI72HUn8/s0Z/188LnQgdc33eP/oHP7f7rpozWd91euD9sDPXkJU+l6q9eW9m+6tcXw8mW3/tqib6vqXa6/qQ6221mV4BsTOD+auVHpA/L/Rg+ctr82MBEXFtrvGLWn8+cakT3cOg38MYF7L+4K6NvU5ht+a6HxHRrfQQfvfJbU2C+RjcqQIAkAhNFQCARGiqAAAkQlMFACARmioAAIkcnf5dLMy8xVKnWutGp/0idEq1bc1Az4jYm/m4g0kMl5VJvplE8mKh07zzmU7ETU0SejJx7zmiMPMzWzPXuCz0v3fyzKV8Sf8ivak5xwbzfctafT2YPdHnzAePP7H7Lic6zfnyM53O3ex1yvdhr9OiUzNPd6yuZX1mFhuESeZGRPTmfM1bPae2H/W2ukwncCcm/Xve6Ovp0wt9TfvHHz2S9YiIq3M9g/nKzHkuW/25bRv9ns3T47lZ3fH1l9/K+quvdD0iYtbrz+FVpr8zcev70etwpwoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRydPp3auba5plO2ma5SfmaX4t3Cd+IiK43SSwTeK1q/bYak85tGp2sK0wC16WOd7udfkERkZl089bMt3THo+/Nr9sfmHsJvKnJRJ/fY69TqrO5Ts5+8PjXst5MdSo4ImJ9q5OZu80rWV/d6nmt00yfM1mmz5nCnEuVuQXZlX727/igrwm5ed9VpdO5V4sLWZ8X+nN4MtEXx199qJO8f/jRY1n/bh/6O9BkOukdub7WXZoVEHeZPrCL0O9taQ73c/N5RkQ8OdfX2W82eh9fl7d2W6/DnSoAAInQVAEASISmCgBAIjRVAAASoakCAJDI0enfstQJWaczCdl9p5NhbgZuRMRo0ngunVualFll6m6ebm/eQ9eZ+Fnm078ul7bd6oTjfqu35ZLH7hgBb6OZ6HNmrcfpxvWFTpH+4pe/kvXu3qcsv928kPWbl89lPdvcy/o4mNUDtV4NkA86mdv3+rUWJkEaEbF383FzM598qa+zHz8x9cmZrP/sTCdzrxb6vV2beeYREZt7vRJhtdOfw2TU19M7cw93W+tjkS/M9fpqIusf7C9kPSIiu9Kp9Ks7nQquzOdwDO5UAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARI5O/44mv+pSp72ZDWpn15o5vhERRamTbGWpU2N1pVN9LhVcmNmW7kV15r21rU8BDuY47c1M4H44Lc1rAszAW9mtdTp9Ui5kffHoqaxfXen6/+df/z/svp9985msrzYPsr5udfp3u9bn96zR9aLR6dK8X+l67pOzhTkvR7Oaosr1NeTRoK+bP5vpa9p1od9DY+6jnq90CjYi4matU8+bjf5uLDZm3rEZ794u9Tzi3Uofi8/v9IaejP7625jPdDnRf3Pemj51BO5UAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARI5O//ZmNq9L/44m5ZubNFxdmV+Rj4g8172/rnWCbjrVSa9Jo1N6bjs+2azn7w4moRcR0ZvH3MjezMR5Xf1gfBp4Q882+nv18ZMrWV8uZrKeDSZ1+vkzu+/7+5eyXhX6/FvOdYq0bHV6dQy9nSzXqdaY61UF/b1P6pstRTXTx2MaOpE8tjpRWw/6PdShr6d3Zk7x3774QtYjIjajmWne6O/GtFyafevnP8r19Xe30vWXNzeyvrr7WtYjIn759GP9wJlJgJsVJ8fgThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjk6PRvZ2bUmpHAMY467VqY+G9lZmFGHEr56jSvS//WtZkJXOh/W3Qm8exmBRe5myEckWV6H+OBeZX6+afNBAbexu1Gz1n9x9dPZP3xhZ7xu7/Vc3PXO53MjYgoKn0+9Z1OZlaFvuZUZka4S5fuRp3Z3ZtzbzDXiYiI2SM9I/nR9ELWLy/nsn5W6uvvMNHX09Wgj+vXN/q9ff6tT2HPr/X1NIoLWX6218f1mxs9m/mm1AnmeWWu40udMC/u/fV3G/p73LQmrT7qz+EY3KkCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjk6CU1u60ZDW3muOdm8HthhuO7ZSoREXWtI/Ru6cx0qmPSlRna74fU69daVWYQt1k2ExExmJUwm81GP+Di+3YwP0ttkN7loM+xTz79RNYvzvRQ+y+/Mks2Wn/eF4NeBrFt9TKVeq+X7fR7fc4M2VrWbzt9rdvYufL+MvrJ7JGsP350KeuPZvq1llt9jRrM4dve6WvU3cOdrBdmqH1ExLS+1vsY9Xdjc6+P3y7Ty4Je3ut9Z2f6Pfys0a+n/FB/XyIiioVeftm7C3PPQH0AAN45mioAAInQVAEASISmCgBAIjRVAAASOTr9u9nopJxLzpZmiHVZ6F1mZqh9hE+2ZmY4f16c+JpKnfRqGj2Af2IG+Q+DTqt995hO9d3d6df06qXet0tPA9+HDz75pax/+vhnsp5dnsn6q3/zp7I+PfB1XpnzPh8eZP12o9Ol494Mo891erXs9TVqCL2dZuITzMtrvRLhg7kZ2L7X721Smkv1Sh+jtfkhhM4s1/j0F7/W24+IyZV+D7c3+vm/zXXSu1voa9q+1691P+jnj3P9eq4vfqVfUEREpRPJ41Yf74f8zVdTcIUGACARmioAAInQVAEASISmCgBAIjRVAAASOX72714PvszNvNvBDKUcKpPkbX1/b3udumu7Tta7XtfrTM+YnEx1ymw+1zNGXVp4NAnfiIiu08ngmZlTvHrQc0y/+OILWT80Oxl4U//4n/8nsn71+ANZX93cyPrDq+eyPgxmoG5E9GZ+bb/VadHWzHF15+Vdeyvr5U5fDzJ3nZjoWbQREWezK1lvTBK2u/lW1vNCp4WzylyXl/p6cL3U6ewnf6jT3BERxaivm212I+vztX7P+/t7We8Lc92sTAq7NnOKp/4a2Ay6J+wnS1m/KPwc4dfhThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjk6PRvbxJ0ox4lGdmgH8h6nejrTD0iom11cmu31wmt0qTGJhM967NpdJrs+upS1hdznRjLTBI6IqI372+x0Anj+wc9k3Kx1Psm/Yvvw5/88o9kvTdft22nE7W1Dp1G+Vyf2xERRa4f6zf6fM1KnS7NK73z2aDnmT8UOkXcmPm7Vx/r60RExMUTfb4ua30A9w/6+ftcz659EXolwvnkXNYfX+rrzVeffSbrERFf3+nP9KWZkTyZPpX1p2cfy/o0c/PPv5b1f/lnfyvr3c8vZD0i4hfnZuXHTF+Xdwe+l6/DnSoAAInQVAEASISmCgBAIjRVAAASoakCAJDI0elfl2zNMhP/Nb8wb8ZzRt+fPjfXpYI7Ux/NzsvCpNgaPZ9zMddzOMtKJ/G+42LSur480ylAl1TOc/59hPTyhf4e3r98Juuvnt3Jehdmnq6LEUfEfmPminc6tZuZcywf9SqBodSvKe/0OVbmul7P9PUgImJe6tneTa2vd825niN8f6eTsLNyKutPH+mVDudmZvPd7neyHhGxedDXzc1Kz2Q//5U+Hn/0R3+g9/3iRtaLViee843+7n3y9ELWIyKezvQ1fmf28U2u39sxuBIDAJAITRUAgERoqgAAJEJTBQAgEZoqAACJHJ3+Lc1sWZf+zUwa1SX0wqSCIyIGkwweTCp4NEHi3CWYXVLZpIX7XqeLD83fzc1jeWESi7lLC9tdAMn1ob+3Y6YvHXWnz41nX30l68Poz5lpptO541Sf93mtz++VmUM+7vVrzcy5Opnq68Gy0vN0IyIqM9f26Vyngluz762Zgzu70u/t4kM9j/gjM6c4Cz/rdux0EvbbjVk1UelEbfHwStbnM73vnz3RyeafXXwq67/4hzrZHBGRrfQ+1s/1cR3MrOVjcKcKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkcnT6t6qOfurfMalgN5/TzhCOyEwy2NULk/Itcp80VLpWp962u515QX5b5ajnAvcmLTn0Ltl8ICYNJDaW+hyYzfX3+atCz+V99fyFrJe5/p5HREyWet/VvZ7BO1b63CjW+nqw2ZuZwIXejhnXG5MDc2JnM31R2DT6NU12+nqQm+N9NujtXJhL+5OJTtQu/qFO1EZEnD36UNZfrPSc51Wrj19uLpDzWr/W6S9/oZ9f/VrWHy39Bfirv30p6zdf68+ufeXT0K/DnSoAAInQVAEASISmCgBAIjRVAAASoakCAJDI0ZFeN9d2dGFU94CbFXwgOevmC+eF/jdBWerXWpi6235vhgj3g6v7ZK470HYesa0z/Bc/nJlJbL5aPcj6aq0TodlaJ+bLpT9nqp1OvI4zfR5Xoz7Luom55qx1UnkczXWl1bOIu9EnRYdB7yNudPL4ZqtT0qs7XR9nF2a/OtU6ZveyfvHBE1mPiLj6Y72PMHONY6WP37cb/ZoeXZzJen410dvfmWvgvU74RkTcfKG/l5vQn+mr7cZu63W4UwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkMjRS2oGu1zktAHvbqjyoaUidumMWeZT1TqK734UIDPb9/R7Pvwe9L7L0tTN891SG+D78Mkvfy7rv/nL/0bWP/s3v5X1vjSD4s1A84iI3bU+nxbFhazXxUzWb1q9jGQxWerXVOrzu6z1sqCuvZH1iIjdrV4W8swsw7l9divr27V+/vhgfvTjlV5Ccv/sXNanjw+0glofp+7yI1nvzY8FPBn09Xrf6eVF9U6/h9jp50etf2ghImI61Y+VZulntzVLoY7AFRoAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjk6PTvvtWJK5d4LXKd9MpLMxzfPD8iosz1y6wqneiqTQrMpX9z8x5Gk3juOz1Q3z0/IkzmOSLLTxuczzh9/JAevvlW1j//7BtZf/Wg07/DWqdU11OdqI2IeDQu9N/k+m9uOp2QLWa6fh+9rGdbfU4Whb6utL0/729u9Q8PnI/6Pez2+vnTTO977PVrzQvzYwSDTiOPL/V+IyKG0Onp8tW/0/u+0kPqx04nj+t4LuubO32d3T3owflL832JiJhWur9cLXSy+cNzv63X4U4VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBI5Oj0b9ua2Z0uvVqdlmotDszfdfNxazPj16V/CzNP1+l7/Z77TicZ+16nCSMihtEkhu3s5DSzloG38W//TM/4vf/sr2U9N4nNuTmHm6XPs2e1TmwWhT7PupVO1I6NTqOaxQAxmmtRXm30dnZTvaGIyAZ9jbrf6uPUmtN7XunjNL0+k/VmoetVo6+N616ngiMi6o0+rvvQx6N90MdjstDzdPNWH4vVnU4kr25NGrnwSfLejBE+b/R37Iz0LwAA7x5NFQCARGiqAAAkQlMFACARmioAAIkcHYf1GT0dVxvNL6q7DeXFgdm/Zm5jVelkXVnqupsv7F5rN+hUWj/o9OEw+vSvO072uDLkFz8Cf/Yv/qWsrx9uZX2+0P9On4ROnfYmFR8RMZ3qFOkin8l6k+tUaDfoy9zLXL+mbqrT/XuT5J1UOl0cEVGY11rlepb6MG71dhqdtB1qM0vdrIwoJ+Y6mx1qBToZ3Ez032z3et/93qSIzfW0zPV7m4T+znQPJuIbEVvz3diN+rOeTS/stl6HO1UAABKhqQIAkAhNFQCARGiqAAAkQlMFACCRo9O/tUnaukm0bpZvZmYF54WPu7pksK2bfYSZO+zyh+Og350pH2b2bY+HSSq752fEhfE9+O1f/5Wsz8383Wmpk6LjWidtaz82N+b1haxXjU7UTub6+auVTngOw42s3+11irRf6cTuJPcXhGqiX+tiov+m/3KlN9TrA1WZ99ZkJiHb6uefTXQ9IiIm5tqyvJLleaZ7RTboWepjp493bZ7fnOljutno5HRExP7OzAUu9edQ+VHIr8WdKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkMjR6d+m1um98cRZvnWld1kcmP2bm+RsmJm9bpbvaGb52pSvqdvtH0oF21HIJhWcmZSvqRP+xfehz3XKtw9dz8Kk1judzJzU53bfTaXP19rMoo3QadEPzvQ50xd6Zu/9izNZL/Jnsp4X/jJam2vIYjDv4UwnapdulUCj38O+07Num1YnZ1cHLl6zXL/WbKJfU31xqTd0o5PN3cODfr757hWFSRcXPkqemznS5Z1OdJeZSQsfgTtVAAASoakCAJAITRUAgERoqgAAJEJTBQAgkePTv41O/7qZtnmpN12aemFm3Ub4tG3f63SYm2/ZdTodWJj0nks+dp2ut63e/nePmRRlbxLJbzJfGEisHHRiMzNpyt7May2XZvbv3H/Ru51+bLPVKdz1qPddm5RqPur6mbnU7U1ytm/8ZTSv9XvozO3MVaHT0PO5TrxeXOvXNBT6Tey3JlE7bvQLiojdWidhGx2Sjmynj8d21Pve7039pX5N7d7MEO7951CW+vjVZ/p73LgVJ0fgThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjk6PRvYdJTWa5TUoVL+RYmiXcgbTUMLjWm5zZud3rOaFWb92Dm6bpcYmbmcLpkc0REWek0XrvXSeXdXifuXOLZJaSBt7E339vcJHOLTJ8DuZmzu/567fc91edGM9Gvqej0vu9MijRmesXB0Jl53GbQeaFPye92Uer3PTvT16Km1a/pfKnf22Cuy24c8TrXz69u9SqEiIi60rN5s/Za1sdKf6Z5qffRr/R1fP+gr+Ox0unfftRJ9YiIjUkYd7X+TJdzN1/69bhTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQyNFLakaz5MUtR8nc88MtnfFLQsZBR7HbVkexNxsdxc4LE6E3u27MUp5xdPFz/x4Gs+Rlt9VLZ+5u72R9u9XvbTDHCHgbC7NMbFfo77Mbau/WnfRm+UpEROl+oKKcy3JV6eUrxV4vCVn3ZmlOZpa5NXr7dZgJ/BHRF3oJy6K5kPVqrq+nhVu3U+jXuur0MSoX+vV0g74ORUQ0M3ONH8yQ+l4P+Y+9XmozMe+tq/T1el3oa+Duzv+gyV2me8XQ6+9f1x7dGv8j3KkCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJHB1x6nqdLjUhQDs43/MpQDcrvut0amyz00m2zL0mm1Q+LeXrU8F++P/qQSfiXr16KeubtX6+G7QPvI2pGcA+Djp1mpmE7JDrhGxz6EcozHk5N39S1nofu/pK1sdMv7f9Rg9mn3TmRy72PnVqdhFR6fc2ZDrxOi11vXQ/dNLogfBr84MHFxdTWY+IGKszWa/NjwLYq2BjDoa5du07fc3M9Vcv+plffVHf61e1MfeV28b3o9fhThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjk6PSvmy3rZvy6xO6bcJty83R7M7PXpYX7Tqf3+kEfnsFu36cA+86kzzY6zbvdbGS9NfsYUx5w4O9klf6+Xe70ObAzc3n7WqdRi9KfM0Orz5l1qxPGc3NeTuZmVnCuZ8juM/MeVnq/rRseHhH5Vt+3tK2+btalPu97kwouR7396VQnocv5uaxXS12PiJgWC1nPxqX+g0Yfv7rVqeq9mY/cmLny21JfM2PvZzBv9UuKnfnoyl5/N47BnSoAAInQVAEASISmCgBAIjRVAAASoakCAJBINhIbBQAgCe5UAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkQlMFACARmioAAInQVAEASISmCgBAIjRVAAASoakCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkQlMFACARmioAAInQVAEASISmCgBAIjRVAAASoakCAJAITRUAgERoqgAAJFIe+8T/4X/+r0/acJZlsl7kuo9Xpe/v7rHcbGsYRlnv+l7WZ5V+rT+7LGT9H57tZX2+/VLWIyJefPaXsv7Xf6nrf/rnfy3r/+rP9PN/89kXsr5ab+xrwpsbR/0d+33zP/sf/49kvSj0uZHXc1nvy6Ws7zNdj4jYjo3+m17vOzP3COOoz2/3GQ6m7j/xH+C7oN/CAeY1mWNx+vb9LuymTnzAPz3dexjdtoz/4//6f/La53CnCgBAIjRVAAASoakCAJAITRUAgERoqgAAJHJ0+jcdk6w7kKZ0abxIlN47vW7ShOb5ET4NnTLJBqQ2mm/1MAyynnVbWS9yndgtisruu8z03/TmnOl0uD/syWSSsJk9+U5NBR/wjk77lOFfe+1yTz95++6BNzji9rWmP+LcqQIAkAhNFQCARGiqAAAkQlMFACARmioAAIn84OlfF+TtD81SNUnD3PyJfrbPjA0mAdabqJx7fmQH/o1iHnNJQ8K/+HE4La0/DJ2su1RwfuASVBX6scEkifvepfLd+arfg0//uhTxgWtXqhM5UXQ2s1fBQzv4nlO+J27nTdLW/n2778Cbz3PmThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjk6PSvnV174vPd7MlDs397E+cdMv3AaJK2LgXoRoa6FLFL/45mVmlE+GTwDziTEjjZieermwmcdztdP3DOVMVE7yOvZb0r9DnW9ibh6RL5h1L8wqGVC/a6luj0TnaVMEnow3s5ce+HUtL6D/Re32xQsdkW6V8AAH60aKoAACRCUwUAIBGaKgAAidBUAQBI5AdP/75RXM0EsU6b5nho52bG74mzf8dDx8geD1K++PHKc3MOmEStC3iOg36gGPWs4O/+SM8LLjOd/q3cTGC35MCwQX0bhfb3Jr1JQ9u07amh03Tx31QbeoNdnPam3edw4sf8d9sy9bc4HNypAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBI5K2X1CRbanPob0zdDci30fdE9dFkt93r+W5T7t8vLKnBj1dlhtTvBv0zFG7pzGiWTfTd3u47i5Ws55W+bJW5q5tB+2YpjBum/iY/BmJPe7ei5tSViCdfPt7g2mX/5rTj54fUp7kGHtzKyX3nzV8Td6oAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiR6d/8+Lop0bE6dmpN8la+VTwaf9WyGys76Ty4YQZA/XxE9Q0laz3vR4U35ok7ODOGjdwPiLyXieDi8IM2s+nsl7l+j0Mg75OmN8KsD8W8EYS/d6IXelw6oYOvDf3AyKn81fsU57tHkn4Wy1vuLXvcKcKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkcnz6Ny9O2rCf83h6hM7PpTx19q9JmSVK4B58Zzb8SyoYP17zxZms7/cvZb0fOlk3I4EPnzSjSQYPJhU8ulSwTv92mb78de7FvtEA3jSR4dN3feo10L/OYtRzntPN03131zrfK94cd6oAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiR6d/R/MT9qf+yrsLjL3RL8+7mb1mJy7pZUNsNpl72ns7uKkTR3eSCcYPaTpbyPpms5H1fljJetvpJO+hebqjS+F2J84EzhpT15e/Pq/1bsfT70H8yoITB4ufeOK766nbTJEdmMFsHhvM3Gb7mZoeEiadbXuC/c4cmuR76oxkZv8CAPDO0VQBAEiEpgoAQCI0VQAAEqGpAgCQyNHpX5t4DZ0AyzM9LzJ3Ca0D0dlh1HOHB/M346kzKU9N5poH8gP/RMl9xFhW001OBt5cPVnK+nKpE7jtXte7XtfHA/Hf0cz+HQZzbel2sl7kbiawSfmaNKoJux5euWCvmyfO5rXPPu1a51cb+M+h3+uk936nk95Drw9UUU1kvZlf6P2GmTd/4rX0EPc5uIUlx+BOFQCARGiqAAAkQlMFACARmioAAInQVAEASOTo9G+Wtbo+dLKem7RfEeZX5E3iLiIiMym9yMzMyBPTYUWuk29lof/NURV6O+WBf6PkJhpsQ2YuFXloWCqQWF7PZX0y19eD+U4nbbv+VtZ3O72diIjBngM6XZr1Ov2b924msL6ulCZ1OuR6hnBvVie8mROXIpw6Jdwc07431+WIWN/fyPrti6/0tsxs5qqZyvrZ1YeyPj1/ol+Q6Qc+UR0nB4PfZsY6d6oAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiR6d/i36tH9ibtN9ap/36Xqf98mbm9z270HWTTHTzM02YN2bmKMxKneqbmufXB/6NUphfvU8V6gO+D9tenwNNo8+9+fJC1jcbPT+27XzqtDczZN284NEM5x1NKtjNBK4KnS7tzeVyODAodnDXBPs3Zhate/6p1wNzwel7vYojImKzfpD1V8++lvWh1Z91PdGzf93c4Wam506Xjf4cxsynsP3RTnRc/wPcqQIAkAhNFQCARGiqAAAkQlMFACARmioAAIkcn/7d3Mv6fqVTvqtvfifr3VaniKcXj+2+Fx/o3l9X+uWXuU6BVaNOuM0HnUCcDXr79aC3n5uZpBFx8sxeQr74MVhtzVzsmU7IVhOdCl6cnct6dyD9u9nq1O446Nc0mPM4M3PIs0KnVEszh7w06dL+QOp0GEya157hp93n+OuEu97oul2FcGAfmbmexmA+t71+fr81K0U2r2S9merv2GBmNh9mjoc9fq/HnSoAAInQVAEASISmCgBAIjRVAAASoakCAJAITRUAgESOX1Kz00thhvuXsv7w1W9lfb++k/Ws0zHsiIjluY7jT+Y61l+a5Sv5Xg+GzkJH64doZL2vFroe+scCIiKGXsf9R7MMZ3yLSDeQyvM7vRylqfS5Ma/1D2PMF/oc3ppB+xERnTln2lYvzXCr1sbRLbXR+y7MQP0i0++5yPTzIyIGs9xmMAtVMvMmTl06k2Wnbaco/B5mE/2+Ly8vZH31yixVKvRrmuT6ulkO5vMx9fzAe3A/SOCO09vgThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjk6PRvk+uUapfpZF09mqHKnU7g1q0eqhwR0exfyHqxMoO1u62s7x90UnkYdLL5YasHN6+Lp7KeN3oQd0REu9cpyt4kHAc7nN/VSQsjvfu1/n7eTnW9LHTatXSp4KVOBUdE7Pf6GtL3+rvuB+2b5/dmILy5fuSFS//6834w9y2ZGf7uBrln5ry3d0Xm+lHk+i+G3F8/zpb6syv7S1k/n5gfSTA/bNBM9XGdFPr5Za97yGivjRFZpt9335nvQP7mP2nCnSoAAInQVAEASISmCgBAIjRVAAASoakCAJDI0enfs8VU1utBz8HNn+hk2G6iE13TqU9u1dtnst61r2R9s9LpsHatE8Yu2bzMr2R9ezaR9WrQKbmIiHank4xdp+deDoObFUzKFz+cbtD/7n51r7+3s0YnOc+m+pyZzHXCPiJittXnU9/r83W/00nOYTDztc123CzwLPSM39zM942IyEaTLjXH1aX4B5OcdXON3ezwnVltcGj1QNbp49FU+n0vL/W1v8z0d8atgMgzfeyy/Y2sd72eKx8Rsd2bbZlUcG5S0sfgThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjk6PTvfK7Te9NsqesfPpL1/VSn2IZWp2MjIrqVTv+uNnpG52q10vswSdtsphOL/V4nEzszk3Rf+H+j7Pf6tfbmNY0m/Rsu/UsoGN8DN4J6u9NfuJsHnbKsSp0UndZ6VUFExPxMX1t2Wz2ru93rea1uJnBkrm7OvU7vtzgwJ3bcm9famlnq5jrYt/r6EYNJPJsPbgz9Wt185IiI0exjMdHXu2aq20pVm/S0mb/bmsRzmDR31/kVJN1Wb8ulf4sD1/LX4U4VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBI5Oj0b9aa5NvoZoDqTdcTnQDb9nq+ZETEbq1n+W7v7vXzTSo4MpN8a3Qy0c0YbVv9nneFTwHuTWLY/vK8SbgBPyjzlXZh0TuT/p1NzPVgqa8HERHNVM8VX567c+lG1h/MbFmXsM/cuTfq60qW++RsOeoDuG91GrXb6n10OzOP2MwWtmFeM6e4P5D+dUsLtr1+b5NSz2yuiuqErYe9Bma5mRXsouoRUZn57uOgr+WFnc38etypAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAiRyd/l19+5ms54NO4lWtTuaGmeeYuVm3ETGYhOxgU30uNab/DdGbmZG7nX6tG5PQi/DvYW9meg69fm+jnfHLkF/8cExg3s6QNSNt426lv+eTSqdRIyIu5nr29vm53sl+a2Zyt2a2bOvOJV3PQu83H/3c8kmhL7Fdbl5TptOoYRKvMep6Yd7DaBKyh2bdujB03+vXut/pz7Q0s5bdvgtzvXZfygOLL2Jwj9m/8dfy1+FOFQCARGiqAAAkQlMFACARmioAAInQVAEASOTo9O/dF38t60Wmo2GTQqfbisHMvDQJvQgfeM1y/fKLQr+mwWzI/WL81vxa/Gpl5hSbOZwRfl7wYOeMnlQGvhdj6CTnaJKcbvzq3VqnKRcT/+/6xVTPim1qPVt2sTyX9e3GXHNOnAk8mvRvdiCRn5t0aVPrB7peH+/MfA5h5pPb92AXFfi5uaP5iEZzT+bmGpcmnlsN+r3lJuXrVnEM5lhE+BUhbpXFcHAW8mHcqQIAkAhNFQCARGiqAAAkQlMFACARmioAAIkcnf5dv/xK1gsTb+srXXfjHLsDya2dGSjq5o9GbpJyJgHm0796pudqtda7jUbvNyJ6k252KTM/+/ekMvBWRjf81517ZjWAC1Oudz4x3w/68lROprI+nepZwdPpg6zvTEp1v3epYJMUPXD2ZWbobF3pZHPr0rwmnetm2g6dvtCemoKNCD8fN3OxYL0tuwKic3ONT7s2jqMf/useysx7aN1rOgJ3qgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEjl6Sc12rWPpbujxtjCRbrP9/kCku+v1Y72JuLvlOV3n4vtm+H+pl+ZMJ3rpjPtxgYiIbNBx8t4OxNbb8YeJRTX44bjFC7kZtF/kZhi93ZL/sYnWrHao6omsLxZnsr5arWR9n+mldKM5xw4tR7Hvzwy8ryp9SXZLYVq3JM+udnFD6g+9B/eA2ZY7Tuaa1pkfInHLDTuz3MUN2o+IKMtavybzfe0YqA8AwLtHUwUAIBGaKgAAidBUAQBIhKYKAEAiR6d/Nzs9fNplwwaTDOtMUs4lvSIOJV613iXl9vo9uJSh2/Gk1kmy8sA/USqTfnRJNns8Thy0D7yNPExq16V8M/19bkpdL0Y/uPzViztZH8/0QP15rS9nda3T+rOJHsC/2+v07743KdVD6V+T8s1MCrcszCW50CsRRrNCYej1ft3RzuwPJ/jHfHL7xIuR27eLC5unux8jiPBpaLfv/sBw/tfhThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjk6PTvemfm5pr01GAiWmaM78H5mX7GpNabRO1u5+bv6ue7ucbrzVbWp41O4kVEjKU5Hp1OrLlE8luMpARO1pT6vM9MMrMwM2RnlZnfvb+3+35++0zWN3c6ff/40ZWszycmLTxfyPrt3Y2sZ5m+B8lMQvq7x9wFz6SCB32dqCp9bel7/Zpac+1y19nxwAxmd6V1oV2XCnb7dnseTAK3M4e0M8cuIqIzA6Mrs5IjP7SU4zW4UwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABI5Ov3bZTolleXul+R1vy5sZOzQ7Ekz99Il2XI94zcz0eMsM8nmvJJlNxeyNUneiIjMpHl3rU4kt3YmsN4OoWB8H84nbi62/n6WhT43tis9x/fh5dd237vNra6v9D4mEzP718zNLczcXJcK3t/q1P/hKbHmzLTn8WkrEYpCX2dzc/11c3x7tywjIgbzmnzK17y3U9O/dgWJSQWb7Xy3c308ylx/Z1wq+BjcqQIAkAhNFQCARGiqAAAkQlMFACARmioAAIkcnf5tLp7KukuZ5SZZl5d6l1mhk7bf7cP8uv2gU2n79YPex0rPGe07ncBtav2aymmjX0/mE3Tbdi3rKzNHeL3dyXrb6YzbwdnJwBuqBp3aXa9Wsv6w1d/n3qRd1yYVHBERgz4vq1Kfl+uVPu9nE32+zpqZrE/nelbw3YO5DvU+d2rPSpeQdQsITGq3MtfTstTHruz09doldiMitlu9mqI1KxcK85oKcx23R8k8Pzeff2VWiXz3mvR3wKV8x+Fglvgg7lQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEjk7/nv/sj2Xdzvit9KbzyswQLv2sRZv+bXXScHP7XG/H1LtWp9smtU6MNY1JmXU6XRwRsd3oZOL9Sr+HB5MK3rU6lTYMpH+R3ur2W1m/u72R9XZvvp8mnd6bNHtERJHrv3Hf9fV6I+sPjU7eu5nizmSq08L7vU7qR/i5tj4V7GYFmznnZi6vSwV3pZlBvtfXm4iI/d6kf8188tLM5h0K/R5yN5s5071lMtOfQ9XMZT0iYrvTn9H6QV+ziwMrOV6HO1UAABKhqQIAkAhNFQCARGiqAAAkQlMFACCRo9O/Zz//Q1l36d/MzGcMM+PXPj8O/Fr9xszyLfTb2pv5o5lJIE7nC1mfTXRabbz3acKHmxeyvt7pZB2zf/FjMJ3o8/L+Rs99jdF8P3uT/HTx2PDnfWdSp9uNPmduMj1fuDTXHDfzuzIrF6pKrxKIiOhakwx2tzNmBK+bc+4OX2EObFmY67XPI9vPwaV2XdI7M+8tN6+pMMe1MNf3nVlhERGxczOpzcqP8cDxeB3uVAEASISmCgBAIjRVAAASoakCAJAITRUAgESOTv/W1x/KukuGhUlojWaO72hSxBERbgyj/Zv7G1keCp0mG0On/cr5haxPFhO9nczPMS2ff2n2beZk9joq5+aevk1aDXAWcz1ndXt+Juurh5Ws781M4M7Mso6I6Hs351qf96M5N1aDfk2luUYtFnqGbG6uN5PJVNYjIh46l5I257eph1m54GYCu2RuVZ1WP/RYMerj0Zukd5hZvoVJYbtk7sokqvMDUfLRrJooTXPJSf8CAPDu0VQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEjl5SkzcuNm5izHbpjH5+ZuLW3/2RjpOPpR5wPRa63mfm+WbSc1bpaH0zX8p6kZnh2RGxPruQ9dlML1mozVDvojDHz47WBt7cfKKXj7VmSc3O/ECEW1JzaOGCWyIzuqnzZmPDoJe1vHz5Um/GbGc2M4PzD1y7SnON2u/0gHf3wxiunpljMQ76elCYpTaTRr/OCL+aZ7vXQ/4H80F0ZlnLbruRdbdExv1YQGYG80dE1KdeN93SpiNwpwoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRydPo3y9xTTXrKDNrPzfNHN5g/wqfrTMI4Cp2cjdykf0edYguTIi4nOhU8LS70diLi/EI/dn6mU5TzmU5b15V+b4eGSQNvKjfnXlPr7+d0otPsu41OBXfhB+q7FQEuCeuuOe75rRnmf3d3Z7azkPVDw+jd9dGmns17cJdHdygGE9l1Vwm32iAiYt/p62NhBudX7scCzGV2MD+ckIU+rplJMB8agl+5vzEHxP1wyTG4UwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABI5Pv17cv91ObPTU6qnJuV8KtjUR7cdfXjyUiflqszMBo2IptEzVJuJ/hs/+9ck4g6lp4E3tN3puayl+R4u5johe3d7b/bgv7cu/euS7u4ccLNo+16nVLc7PcPbvZ6m9pdRPxbYzEZ3cV7zHoZeR2rdVnJzbcxL/zm499ebVLBLVY8m/tub92A/Z3Psitz3KDcv2KV/3+Zqyp0qAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQSDb6uBkAADgBd6oAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkQlMFACARmioAAInQVAEASISmCgBAIjRVAAASoakCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkQlMFACARmioAAInQVAEASISmCgBAIjRVAAASKY99YpZl3+frwH9Hbo53Xpg6n88Parfv3vVL+EHMZvW7fgnAj8Z6vX/tc7hTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkcvSPlAMA8O6NJ1T//rFM1nU1IncPHIE7VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIBHSvz81LuL2Fmk1AHhnzLUrMxe7zFwDu9HnfwdTLzK987e52+ROFQCARGiqAAAkQlMFACARmioAAInQVAEASISmCgBAIiyp+bFyS2ROXDqTmci4DZ8fmkptvdEfAYC9pJXmkcpcb7a9WzgT0een3T+O5rp5DO5UAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCAREj/vmM25GvSZ0Ve6OfnZktuyLSpk+MF8H0YzdWlKnUb+uDqWtZ/8eSxrL+8u7P7fnajH7tZr2R927Z2W6/DnSoAAInQVAEASISmCgBAIjRVAAASoakCAJAI6d93zaR8y0J/NHVTy3puZlv2fS/rXafTbePg52f6aZhvPifzbYwu2QzgJC6ZG5HuvPcLEfR26slU1q8+/EjWLx4/sfu+ur+X9ee3OhX8yjz/GNypAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAiZD+fcfcjN+y0h/NdKoTcVVVyXq71ynfzXajn9/uZf2Q3LwHZxjM3OHRJ4+B99mpOffMJHNzMyPcXYciIgazIsCl791rzcw93HyxlPXp4kzW20KvgJhWE7PniOtaP5ZVjd7HW1yKuFMFACARmioAAInQVAEASISmCgBAIjRVAAASIf37I5XnhazXtU6ruVRw33R6BybsdyjH69J+LjnoZ/Pq19T3bu/M+MX7wX3T3Xxcd8bWtV4NMJvNZN3NDo+IWK9Xsr7d7U56Te4a9eEHepbv5fVjvd+9Pkp9HJhbbhLMm7V+D3dmJvAxuFMFACARmioAAInQVAEASISmCgBAIjRVAAASIf37E+NSek2jU8FZ5uZhutmg/t9ZXadTu6NJ1rnn+5Qv8GNmUu6HUqemPrptmZSvG4tdlnqVwNXVI1n/2c9+Jutuvm9ExG9+8xtZ3+1emNek28pHH30s6x9+qNO/y7me/dtv9Wt16eKIiJev9Gt99uJW1r/+6mu7rdfhThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiE9O875ubmurpL51aVnvXpknhm85G7ByJiu9vK+t7MALVpYTsTmBm/+OG4c2wy0SnS+VzPzd1sNnYf260+Z7qu16/JpfILXX/0SKd8P/nkE1l//FjP0/3qq69kPcKfx+6a4/bhksfz+VzWC3OtKyfmWlfpJHRExMNaz/K9X+n0bxRvfi3iThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiE9O875hKIRaGTbKemfF09Qs8E9slcn831KV+znQP7AH4oo/tGm+9nac7Jp0+f2n3c3enU6e2tru/3raxfXrqU76ey7hK4jnudEf58vb6+lvWf//znsm5Tvua4us8nz/Xs3+1+LesREbcPr2R9tdHv+9A859fhThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCIsqXnHTh2c7+rpBvPXsh4R0TQ6Zr7f7/U+Cj1o370muwTHviLgzbnh9a1ZIrZa6SUbVe3PmelUD+Efzb63G33OuGU719dX+jWZpXe3t3qA/Hrtl6Ocn5/Lulu2c3WlX5NdOmNOfPfjHpmZmz+M+nOLiGg7fVz3nb52saQGAIAfAZoqAACJ0FQBAEiEpgoAQCI0VQAAEiH9+3vCJehc3SVwy9JE6yKiNinH6VQP529bPRy873VKr927+K9O4pEKxtvR50DX9bL+8LCSdZfkjYh48uSJrD+aL2TdnTNPnuik7WSiz72+1+/BbX820ynlCD8436V8/Y94aPYHNsxhzQtzL9j7K0J24mqKt8GdKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAjp3x+pU9O8jkv5HvgL+4hLytV1I+vTqU759p1OIA6DTix27ZvP4QQcO2vanWKZS5D6y+h0Opf1s7MzvQtz+i0WOi18anp1uVyeVI/wc4RPneXr2GuUKXe9ntf7cP9g9zEO+jWVhX5v2ahnBR+DO1UAABKhqQIAkAhNFQCARGiqAAAkQlMFACAR0r8/Ui4R5+ouBegSem42qKtH+Lmhw6DTuaXZd2VmCJd7nerrzSzW0cwEZiowjmNjvvrZJtXadTrlHuHPmUN/o9zd3cn6dDqV9aZxiXz9/ENOTfOeuh13Tdub68HNzUtZ/9M//dd2325us7venb5q4v+HO1UAABKhqQIAkAhNFQCARGiqAAAkQlMFACAR0r8/Ui595tK8p9bfZLawSzK6lF7f64SjSws7djSoqScKK+L33mlpVDfj+oMPPrB7uLq6kvXJZCLrLhXszpn1ei3r7px0c3zd64nwKwveJiH7HypL3Ybc9WOz2cj6dqvrh7bl5gtnB2agvw53qgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCKkf39iTp0JfOqsYJfEO7St3iQWt7udrLd7XXdzOG0imZQvjjC6lK+5p5hOZ7L+6NFjWf/oo4/svufzud63OZdcwt5x54xLEbv6of3WZla3q7uEsbu2uO242d5urnFRHLp2nXZc3wZ3qgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCKkf98xl2x1qb621TM9u06n26pKf8RFof895ZJ4ERHT6dS8Jr1vl/7tOv3eTk7/GoemdtotuT8iYfx7qzYp0qvra1n/9NNPZX25XNp9uHNjZ84N910/Pz8/6flu9q/br3t+hD8vTz1fZzOdqnZpYXeNuri4lPXzc12PiOg6nSTem5UIb4M7VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIBHSv+/YMOhUmksNrtf61+0nk4msF0Uh63Xt5nPq53+3D53+dcm6tjVzRk3SsDcJZhfA9cHcA/nfjDjv7ysXEndzrs/PdKL2yWM94/fi4kLW1+u1fU3ffPONrG82+jx2SeLLS51sdee3P+91un+73cr6ocfce3CpYDf7160qcNebR+bz+fnPfyHrERFtq69RL148l/Vh0O/hGNypAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIhCU179ipA7HX65Wsu8H5WaaXlwyDXoJTFn6gfp7pmL5faqOX1PSmHqMZem1mXvcm9j6cOIAfPzX68zVf9SjNwPaLywtZb8ygfbc85vPPP9c7joibmxtZd0tnPvroI7stxS3Jc+e9W9ayWCzsPtzxcEtt3NB+dyzc8h+31ObxoyeynmW+nZnDZLmlNsfgThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiE9O875tK/fa8Tsi5x5xJ0o0nU7nY6Wdc0OhUcEVFV+jGbCjbbGlzS0LzWzByjnUlIj+bYRRwawo+fjgM/mCC4FPq3Js376uUrWd/t3I9c+IH6V1dXsv7xxx/Luhva79K8PwQ3hL8yqWqX2nUD+J8/10lbd1wfPXok6+fm2EVE/Mmf/LGsX13pv/niiy/stl6HO1UAABKhqQIAkAhNFQCARGiqAAAkQlMFACAR0r8/Ui4V7JKMG5OU88/XSbz6QPp3Op3rupn9W5pEcmNSg61JGbY7/TXdtzqNaYfARkQwF/i9Mw76M79/eDB/YL4/pr5Y+rm5H374oaw/fvxY1t1s3lO5tLCru+tNhE/hujSvm/3r6q05j92KBjdD2B3TiIjZbCbr5+fnsj6Z+Ovg63CnCgBAIjRVAAASoakCAJAITRUAgERoqgAAJEL698fKhPEG8xP2LkHnZgjvdzpZV5qE3qF9DJ2uT5pGP7/vZb03SeXevOfBJRZJ+P5kHPqk7L/4TTjXZb7dPlwyPs/1ZXEx1+n3n336c7MHn0idTl26NM13150znTmHH1wSOvxs3ru7O1nfm5nc/aDPeyczn6hLBbvXGRFxfa1nMF+aecFzN5/8CNypAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAiZD+/akxydZx1Gm/vtcJOpciHg4k9Nw+RvM3+52e8TuafW/dzNC9rrs0Idnfn46DQW0T583NH7n0b2cecXNw53M9J9bN8f30k5+ZPUdUjbvEmnMp03WXhHW2Zi7vixcvZP3rr76y23r56qXeh5kJ7FL57qPO7Zxi/fws0/eCt3c3Zg8Rd/f6sZsLPft3uTyz23od7lQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBESP/+nstc5u7E2cIREW2rZ3q6NO/OzOh0z+86MxPYzAoebcqQ/O9PxXgg1GrTn+7jPfH70Ex0yvfx46ey/suf/1rWZ7WfEzuYlO8QegbviSHfyHN9X7Ra6Vm+f/3Xfy3r93e3dh8u9Z/lZjbvqW/C79m8Hn092G5Wdku7rU5Dv3yh5wVXVf2a1+ZxpwoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRC+venJlWwzjiUmx16nQLcjzrJmHWd2YlL9Z1Wx/upMKnyptKzpodSX+aurnXK99HVE73jXt+DrO+3+vkR0UxNitSmdu9k/dtn38j6bD6X9Y2Zy5ubxO5Pi5kVfOC9udnJbmVBP+i08DG4UwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABIh/ft77uTc7IE/sHNah0QzeEn54gjT6VTWnzx6LOvNYinry4tLWZ80OlHrZuB2JhUfEbG91ync+9WNrH/74mtZf/nqpayXpU5CD+acXJtU8HDg3Ht3eWGT8rXDnxO+0re4FnGnCgBAIjRVAAASoakCAJAITRUAgERoqgAAJEJTBQAgEZbU4L/j0Jqa07b0fUfxWYDz0/cm35F+MD/s0OkfdpiaAfzziR52P230ZXG/3cv6q9VK1iMiXt7opTAvb5/L+t3djazvdju7D8UNkHfL3A79aMWhQfXvxg/xet58H9ypAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAiZD+xVv7sWUD8dNx6Lvj8qib7VbWv/72W/38fSfrjRnMXp2f69djflHi2Us9BD8i4qtn+rH1w4OsZ6GTzVlmjpQN7ZrtmGfb7eNk3KkCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJkP7FW2MGL97UwfSv+WK1dvavTgWvv/pSb//hXtY311eyPj0/k/UXZo5vRMR6u9b7HntZLzN9nzOcGv4lk//OcKcKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkko2HfvIdAAAcjTtVAAASoakCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkQlMFACARmioAAInQVAEASISmCgBAIjRVAAASoakCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIpDz2iVmWfZ+v4721WExl/Ve/+kjW//k/+5Ws/8NffKi3P5/I+jiMun7oYz7xOzAMg6z3pu5eU/S6PvR6O13f+ddk/mY0u3b+F//Z//60P/iJ+l/9L/+nsp7lhf4DcxxHc4CHAwfefkfN34zue+X2MZ72PTy1fugxd26MoethTj13XXanqnulB89s80duH0Wu79XyXP9BWejvkqsXhdu+v0fMMv2Yuxa1bSvr//P/9D+3+/j3r+O1zwAAAEehqQIAkAhNFQCARGiqAAAkcnRQCd8PHzTQdfef9GWp65V5/pibAIWs/vsXpbflggyHtnXCdsZCP5DZPfjgSG/ew3AgbPJec6EgGzAy3xH3PT+0bxNsydzna77rJ7+HUwNSJkj33WP6jLJBJReesmkhs2N7apwetvLHzz3fvbfTrh/+49EPmFxTRES4XJ27puWHNvYa3KkCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJkP59x9yor9IkGZtKf2SzptL1ia67BN2hsXEuGWxTer1O0JlAZIxu8p1NDZoxiOOhMYW9rp+Y+Hxf+ISsSXjaUZan1v1DNjHvt6S5VKtJxtuEbHYg/etG9pnvofuuu0S7SwXbYK45Zw6l/u37tmU3mtE9/7TxkoO5UBy6dhXmbw6NNnxT3KkCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJkP59x1zWrzBzT2sz43dS6XTb1KSCXUKvH3QqMSKiM4nFzv0Qs5tfPOqv3Wi+jj5Rqg3h38Ng3p+b0fqeh38PJDxPq1tv8uvY9kezT/vB7pO5H/4+kP7N3GMmYeyefvJbcDOuR339GA4lmO3M7xNnArvtnzjjdzTnt5un/N0+3Lxgs+TgLb403KkCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJkP79kcpMWi03sztLM8NyMqn1dkzqre929jWtNytZ7/Ybva3epAbziX5NpX5NRakTzJmZj3wog2oTi8z+lbKTZ/aaz9zt4A2Or593axK17jWZc2k0CfHezY3ufNrcbSvMttw32o2odbNr88zNunUDlf391WAe8rN5T3u++wq4z9P9wXDgvDeH276mt5kJzJ0qAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEWFLzrtklHi4DruuVWY6yXJzJejPRy1ravV42ExExdHrpzOpO/81mrZfnDJnedzXVr7We6XpV6e1k+YGv9anDu9/vFTV2acFolmCMJy6pObRkyS15yU4c5z+45VJ9J+td1+p6u9f1va5HRPSt3lYebmmcPn5Vpb/TRWWWzGWmnuvlaXbNToR5pYeWwpz4/JPPyTf48Qv3YwhueY5bF3QE7lQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBESP++Y3Y4uEn5unnY09lU1i+vHsn6bK4Ttdv1rd5BROy3d7J++1K/1najt7Vt72W9MklJ96aLUv+bsMgavZ2IGM2/I4dTB8G/JzKT8nX1yNzwejcE33OfiY+L6lRob9K87V6n09udTrm3263e/oH0bww6Yex+CyKvzCD8Yqa3k+k0b21WA5S1TgUfCrv25kGbkHW/tWDOvdE836a27SD/N/ghje8h3s+dKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAjp33fNpM9cgK4wscGJmeU7W5zL+tTM0z00QHPSLGS9MfNHMzO/eLfWs4L3nU5v5qX+mlaVTj66ebUREWOmtzWOJpn4vsd/TzwAJvxrH/BzfP054FKhXaeTtnuT2t1uzPfQ1G3K1+w3IqI0b6JodDq3KfW5NGl0fTab6+fPl3q/lU7G972b8Bux3eqU9N6kp93859wtXTDn62BOY7di4tC83sEkw/3sX388Xoc7VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIBHSv++am5Vq6/rfQfteP/9ho+ee7jqTiFzpekTErjXputykf3Odzu07na7sTL2s9czhZmrmoZqEY0REYWaiun9duiTj+8KlQjOT5Mzt8Tr9OGYuzGmSmZ1J5+42a1nfrsz3cKfPgbHXafbiQIK5qPUldjrR39HFQqd5Zwud1p+fXertm9S/m/27MwnfCJ+EdbOTR5ectQlwU7dzpF3dJ3ZPTfm+zUxg7lQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBESP++cyYVaWbU7gddf3Vv5pJ+8UKWh/6Vrrc6KRkR0e91KnLX65TvWOh07pjp1GXb6qTydruR9b2pT2d+Fmuhw49RmFS1Sxq+L1wKcjRzncfBJTn19g8dXbePznxP2p1Oo+42+nvSupRvp/frQr6ZmU0dEVE1eiZ3MzNztGd6Zq+tz81sb5MWrhudOi4Kf95vTXo6Nwek7/Xn09vvjJnHbb4dvZv9bNLZ370m/djbzPh1uFMFACARmioAAInQVAEASISmCgBAIjRVAAASIf37juXmV++LWqcG81qnBh92ejv3X9zI+natk4+T2s+8PFvoNF7R6KRhM9NpzKoxKeL2Vtb7Vqd5e5MCjQMpwMLEUPPC/fvy/U7/Zub7aVPBZv6qHaV6IH05DPpzdzNnXZq3b00y3uzbveci15fLqjGR8oioZ2Y+dT2V9T7T2+pGve/eXMLHTCfyI9Ozr208OyIKO+fZzNNt9efTuZm95rj25p7PpXwPpX87k+geXCKZ2b8AALx7NFUAABKhqQIAkAhNFQCARGiqAAAkQvr3HcsL/RFMpzpRuzh/Iuv19FrW7+/13NPVRicfm0anEiMiludmzuhEJ+WyXCcQ1yuT/jXpzcwkSgeX6OsPzPM0c0Oz3KX93u/0b1notOhgZwKbz8qkLAfz2Ub4ea1u9m9nUr5Dr1PEmUm8lqWZ1zvVSd7pzJ8zzVSneftcH9etCbS3azNPt9DnTJQmXWy+//udSUhHRNfp4ze4Gb+d+XzMvvvMfM4mLbxv9fP3bjVA+Lniru6+x8fgThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiE9O87lpu5l9PZUtavrj6U9acffGq2s5b12VTP2b2+mst6RMRHn+qEcWPmBbu5xrcvX8j6w52ud4NL9el04GBShhERvUkMR5h69uYpwN8HRaUT3LlL8/b6M3FJ2+zAiNU+dOrUzxc+7bMqTPJ+YlK+i4srXT/T52pERFXpfbRmnvVmq+sPDzqdu27vZH3b6mMxM2nkfNDzeiMi2o1eQbDf69fUmhS2m+U7uoS5+TjdHN/N1r+HzVq/h9a8h77zaejX4U4VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiLKl5x/JM/7umrvRQ77Plpax//KFeUvPhB3q/m/VK1peLRv9BRFw/MsttBh1X3zzcyPpkpvdRNnr5RphlGmWjt+OWSnxHb2s0A+LD1d8TZamP5TDo45jnZrmLG6ae+x8sGAa9vMQt1XLLdgqzZKOq9Tk2P9M/HHFx/UjWl+f6xy8iIgpz/DYbvWRj1z/I+vpeL51p1+b5O70MbWnOvaZwS80ihp1bUmMG57sftDCftbsGVubY7TvzYw6jv0c0v80QrVme05v3dgzuVAEASISmCgBAIjRVAAASoakCAJAITRUAgERI/75rJrGYZzqxOKmnsv7oSg+7Xyx1MrE1A6PL0qcx60Y/tlu/lHWXrizNkPaq0cO+y0wnFmfzhaxPZnogekREVZl0s/kc3neFGQifD2Y4uklLj2Y6etb54953OoGZl/rcyAqTCjb1yqTH52f6nDm/cgP1dVo4IiLL9WuNXCdqi3t9nPpRp/W3JqU6Zvr8rk3CvjiYwtb1ziS6XfrXpXwLk+auzbk65qae6etHRERpVlPsNvq4djv9QyTH4E4VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIhPTvj5WdY6r/HTSd6HTb5YVOJrpZrJH5Wbdj6FmsQ7uV9arSSeV6otO5k/lS1t381OW5noM8n/tZrHmh0482tfp+j/61x34cTSTUHS/zfDevNyKi60zy2MzyLUr92bpZwdOF/r659K+rz0zCPiJiNPct+87MI57udN2cM41J1E7NjN/5wiTmSz/7t830ed+ahOwQOtk8dCYVbNLCRaOP0XSuryuzM70CIiKiM0nybq+vXaR/AQD4EaCpAgCQCE0VAIBEaKoAACRCUwUAIBHSvz9SLhPp6m5+ZlWY9Kb559SYmVRnRAwmMVwWeuZm08xlfT7XM1TPL3Tirqh0CnB5prczmer9RkSESUu69+ZSwe8Ll7S1XyAX/x3Ndg4oO53mtbOja514zcy5sTjT6XGXKp+ZtHA91WnUiIhh1GfspNf180udwu3MdnZ7nRaez/RrujzX50Yx6u1ERDzk+pqwW9/L+rDWn/XezCneDzotXIe+rszPdBJ6aWaBR/jvRlXo4+pWNByDO1UAABKhqQIAkAhNFQCARGiqAAAkQlMFACAR0r8/OSb/e2JIdQyd6OtHPwN0MI+5vHBZ6ZTebKlndJ73esZobhJ6s7lOMpaVTvpF+Fm+g5v9a7f0fsjyU79v+vl+wq+/BFW1SZVP9fcqy3XqtK70XOzzy0eyfnahv5+LpZ6jXTT+++bSv3mpX1NV6/riTCeP206fk3Wlj+ukNun3vZ912+8eZP2u0p+PGeUb681e1nedmR2+1RtqTSq4mvkZzPOzC1lfzPV3qbBXtdfjThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiE9O+P1Kmp0zEzMywzvaU+dGqwHfR8zoiIrtfzQfcmtduHTmOWjU4yThd633mh30NV6xmwbtZrhE//2nSqOa7vCx/yPTXlazbjZgtHRFGaGb+Nnmvr0uZzMxP2/Oqxfv5Sp0irRidzC5NSjojIzKzpptFHarHU58bZTp8b/aDPY/s59Ho763t9DkdE5GZ+eGT6s2sHvffVVqd/7x707N+8NO8508d7ca5ngUccSIZP9HepLk+fVf33uFMFACARmioAAInQVAEASISmCgBAIjRVAAASIf37U+NifSblO5r85mBmW7r5vhER7aATgrtOp/R2vZkVnOmvXV7pJF5h0r+ZmQns3vN3f+TKJs36fod/49RZ06P5Hh448H7PhU7/lrWZp2u+V5O5ntk7neuUb2nm74ZJ8h78uhX6b6pSJ1gLk4aeTvVrGgaT7u/0udrudNJ2tz5wf2U+o9480Jp5x+udvh6s1nr2b17oa9RsqZ8/mCR0hD+uda3nNlflm7dG7lQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBESP/+3jPJWfPsQ2lXF3JsTepuZ2YCd24Ab66/jlnuks2OTg1+9zfmeJwWcn2PuH93p0n5jiYpemgPeaGTs1Wpk5w2zWvmwfYmUdt2Js2ut/7dazL7cO86N3OrM/sFNa/VHL1Oj++2M7G/27k5L83nELmud2Ym8G6nrxMu9T+a60p5YOZ3Xen34FK+w8EDchh3qgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEmFJzY+VXWlgF8OYqhk+bv49VWR6CcChPfdmSU3X72V9GHUk3ub63bIL+/RD/1Y0MX0boX+/F9W4z3w89ZcG3uDwjuY7av/ELF/JTd1tpzM/BDG27gccvDw350ah65lZFuKW2rjvra3LakR24Lx3S5Lq6UI/v9E/jOF+ICE3w+5LNwTf/EhBU/nzvql1qzObit1GD+0/BneqAAAkQlMFACARmioAAInQVAEASISmCgBAIqR/f6xcstWlV+3gfJMKdglZM/Q6ImLo9ejwttUp377T9TBp4ezEIe3jiUnov/8r86IO/M376y3miv//b8fUzez6g3/jErKZSYvaiKdJMLth6tmovyP94L87Nhnf6QS8S+269K8zuASz/S0LMxw/IhqT8p0vL2R9Mnsl62Wl07+lGWo/qfXzF3OdLp42+vkREdnQyvrm4U7WX77U7+EY3KkCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJkP59x1zarx90OrA1idqu0+k2tx2337bV24mI2Gw2sr5dr/Vr2unXmpm0pBsn61LBNjh6IFFqc8FmvvD7Pfn3DdjUuqkfiBfbxzKTzs3NnGuTCs5MKtili8POlPZp897Em7MT07+ZOTlc/UB0WpYrM983ImI6X8r6bK3n487nOi28XMxlvd/q+myiE8mXl2eyfracyXpERJHpa87DvU75fvPlZ3Zbr8OdKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAjp33dsMEnY3W4n66vVg66v72V9u9HJvcHMMX1Y6+1HRNze6KTc/e2trO+3Oh0YZoZwZka3uvmwo9nOQT6Gekr5vXEonXuaE1Oqh7ZkEq9uPq5L/xZm5mxR6Lrbvp2jHWHf3+BSwSalmucmwWzHX5+WhC6bxmwoQk/ajViYa9TFhU7nXj+6kvWm0q91OdN7fvzkiazPzPMjIvper2q4N9e0Z19/abf1OtypAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAiZD+fceGoZf17VbP2b2/v9H1O1M38zbdrOBXt/4X71+8en7Sa+pbnQ4sTGKxKO3wX2lwM4EPJUpdytcEid/z8O/JXBj1TULEmdmaS9u6mb25mQnstuOStnaGsI3gHprZe1qSuDBzit1rtefMoB8oD7wHdxYszLXl0aNHst7t9TVtfaa3s1zoGcJPP/hA1udL/fyIiM1Kzye/v7+T9bs7vaLhGNypAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAiZD+fcfc7N/9Xidn15uVrLvZv6uVTrftzFzeVy91wjci4vbVS1nf7nSyLgudbC5NGtMlE336VxvdsOCIGGz6l5zvSU4+XGbW7Zvs4+S6SeCavecuFWwTu/5d+HnEul66OcV2HrHet3nLB4YFe6VpE9OpnrV7eX0t6+alRrvTaeHpZCLryzM9z7wyxy4iYrPR17vWrILo+s5u63W4UwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABIh/fvOufm1OtvqfsF+b+ZqbrcPsu7ScFuTLo6IaM0+hn4v61lm3oPZ/ti5Oakm4Wi2MxxI8o6kf5M4OUNqDq+buRxxYF6w+wx7vbGh19+4Uz9zH6g9ffavTRibWb6FSRH7c8O9t9NmEUdEuIfqupH12UzP4HXHezBJ26apdL2uZb03Sd6IiNG8ibLRCeOzqyu7rdfhThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiE9O+7ZtJ7Poynk4xdp9O8u72ey9t1JrFrs7kRpf22mFSfjXa6xLNJUbr6aeXDj5njffqk1PeES526lK/7zA8MEbbpX5ciNXO0+1Z/p4dWp06HUj/fzv49NAg5cwfktLo7lU4d5ZvZOcin31/19qQxCeZSp4VzN9fYXHAy83z3vYiIKE1S+fxSp3xHk8I+BneqAAAkQlMFACARmioAAInQVAEASISmCgBAIjRVAAASYUnNO+Yi8Xnultro2Hg/6mHSrVlqM4x62UCpZ1hHRMSk0THzttD13ixxsAPvzXICO8jcrqk5fcC53dZ778SlM+YB+5Ef+Hd9Xuh9F4X+krph9I59rWYA/2C+O64eEZH1+v0NxWlD/sdSn0uFec/+e64d+mkB95rcUqX9zvzoR+sG3rvlVpq/fpg/iIhqMpf16ycfyvry4tpv7DW4UwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABIh/fuOudRpXuh/77i6CyCOZkB+luk0YVX6f2dlE526LHu9ra7XL6rrzSDz3qX6TJLRpf3eIP1rh6W/76Fg8/4Hm/J1SU73PfeJ3aquZb2uJ7LeNK5uBrnn+jN3adeuM9/bA4Pc3Y9KuO9hXetzrDbHoqrMOWmGzrv92h8viIh2r1O72+1G1jcb/SMe261ZiRDuWqTfQ+nqbtB+RJSV/m5MpzoV/DaLAbhTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEiH9+67Z8bVu9q9JqZp/Hrm6CdzZeasREUWYpGam66NJGI9mSGdmXpQJUPr074HoXmZmKufueL/n8V8/49fUzXYyM6O2anSqNSJiOtPJzOlkJusu/VuZgdZ+bq5+Pb2ZCdzu9/oPIqLt3LxbrWvNJdmcBObrbOuZuSD0JsEfEbHf69SuTfma+s4cJ3c96E3aujSf56Tx52rtkuETXS+r0+ZI/4e4UwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABLJxvHQ1EcAAHAs7lQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkQlMFACARmioAAInQVAEASISmCgBAIjRVAAASoakCAJAITRUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAiNFUAABKhqQIAkAhNFQCARGiqAAAkUh77xCzLvs/XgSNVVSXrRVHI+nK5kPVHj65l/Ww5t/suS72PoR9lve8HWR9DP7/rWrNf/TWtKl2vK/9dHXtd3+31vvNC/7vzv/qv/4Xdx++T60cXsu6O8H7U38/pqD/zTbuz+97tzV6GTpZzczkbavP9bPVnXgx7vd/qTJbH0nypIuJyPpP1i8ulrC8v9T6WuX5+Na1lfapPvdgU+oG218ciIqIo9D7a9UbWR7PvYaI/n8Zcu8ZMf5eaMNfA2uw4Ih70VybyQX//3OH4v/1f/s92H/9+m699BgAAOApNFQCARGiqAAAkQlMFACARmioAAIkcnf7Fj8NoUpTX15ey/umnH8v6bDIx2/f7blsdoStrk9LsTEoz0/+WWyx08tglJZtGpwBzky6OiBh6ndTMc/2aJo1OPr4vLiaPZH16qb8/80xfUu5NknO7v7P7Xt3qx8ZMJzYf1vpzn5q08GbQqdM8prqu30LMzvSxiIh4dPGBrF9c6VRwPddp/UnWyPp+1AncrXl+1pm0a+nvrzITqu3n+oBcDuY9LPRrstePTG9nWulobpf7dnax19+NbGJS/6V+rcfgThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEiE9O9PzK9/9StZn810Wq3IdbJu7+aemjmcERHTmU45lpX+m8YkjJcLneq7vLzQzz/Tzx8HHUvcrFeyHhExM+/h+vpK1nfbtd3W++Af/OEnsj6/0qnWWaHT1bf3OoG7eva13Xc30Wnw9aD3cb/RSdjdVs/yne/1ZzuY7/O8MLOmz89lPSLi0aV+bF7r73SWmTRqrtOrVavP+67Rr3U0ifnHZmZzRETV68eqpb62TJc6rT+f6s9z2uhzcmcGdZcuyTs98B5qfZzmtT7ew+hnoL8Od6oAACRCUwUAIBGaKgAAidBUAQBIhKYKAEAipH9/Yv7pP/0TWd9ut7Lemfm7p9Yj/HzcR48ey/onn34k6+cmLXl+fibrZ+c6TfjsG50cffFCpwYjIi7MvuvazKy917NS3xe/+oN/KuuTSicw+0wnQi8Xeo7veuZnK7/Y3Mr6/E5/D68f6ZRvu3uQ9bzQ22lHk1qf6teaF2Z2bUQUpT6fitD7WJmv7szMVC4qnYCf5DpdXOtTLKZLPTs8IuKs0UnYczOre3mtz7FpqetDqVPYa3Mw+pVO99czn/49X+hryGBme2/uDgxBfw3uVAEASISmCgBAIjRVAAASoakCAJAITRUAgERI//7ENBM9wzIzqUvHPf3BJOsiIs7OdHTwn/7TfyLrF1f6+QszG/TR1bWsf/nF72T91cvnsr43s14jIp7vb2S973WKcrf323offPL0qayv2xtZf9joFPp2ambd7n1ic1Lqf/NPrvRn1bQ6sdllOp1eTfXlr8lnsp5ler8HE/OtPp/WnX5vbs5umBD6MNX1xVS/hw8+1DOur851Uj8iYnGpU76X8wtZXy5Nwl6/pPjm9pWsN61OBb8a9bFrzszBiIi80xe89UrP/t1tdfL8GNypAgCQCE0VAIBEaKoAACRCUwUAIBGaKgAAidBUAQBIhCU1PzFX13rZyXaj4+ddp5eEjKNefjCd+Vj6Bx9+IOt1o5cBlKX5eo16acKzZ9/K+ldffSPrDw96+Ubb+YH6w6AfK4rC1N/vU6Sa6SVc5UYvkZnpFQoRO/1ZbRr/7/p56H1Hqb/TTaO/u/OFXtpVlfp72+d6iUx7awb2z/xytn7QS1imoc8Bt6TmZnMv61elHsz/6Qd6icw/+KOfyfrkXL/OiIhZpZfUPLrQa2Qm5/o1ffPbZ7K+fdA/tvBwr99zZz7/u1d+GcwL871sQ5/3Waavp8fgThUAgERoqgAAJEJTBQAgEZoqAACJ0FQBAEjk/Y42/gT9+g9+Ketdq+Ntt2ZY9TDo9OH5xaXd98cffyzrV1f6b1yi9sUznQL887/8U1nfrnUacz7T6cPGpJEjIsrSpf3MH4yn/VDB75um0N+Tfa8vHQ9rnczchf5+9qFT6BER04lOnU7PHsn6bKITyU2jP/OuM5HQXCfEN5ne/mR80NuJiLZ1CfiNfv5Yy/p1pY/T2bX+sYDFowuzX33OLA50gqbSr2nb6e/G5iudwv3anPfrV/pY3Gx1+ndvfvyiGf2b6E1iuBh1Yryu9D6OwZ0qAACJ0FQBAEiEpgoAQCI0VQAAEqGpAgCQCOnfn5hHj/SMzjzXCcez86V5vv731NOner5vRMSHZvbvdKpnffa9TlHevdQpwEmjv46PLnXa88MPn8r6Yu7nF2+2JnXZ6nTgdq1n1r4v7tb6M9znOlVe6TG70az1Z3KW+/RvcaHTv5cLkwo2z69LnV7NW53w7My5kff6te62/j10/Y2st1t9Xtp0eqXP+ydP9HF9cmUS0mfnsl7rYHNERPQPOgF/d6dTvt/e6RneLuXbjTtZn5g099LN4y71KoGIiG3oa9Ry1CsFxtqvgngd7lQBAEiEpgoAQCI0VQAAEqGpAgCQCE0VAIBESP/+xHz8yUey3nc6+XZ+rhN0ZalTb2dnJr4ZPpnYDzoh2jQ6dTmb/n/bu7Ney/b1vuvP6Ge71lxN9bW7s8/Z5/jYxk4ch0RJpNgiQEgCUXKDFAQSUiQEQuIiggteAm8DcQUSCogLhERAOKRxnNiOHTs+++ymdnWrnf2co+fiONzk96xae/vvKm+v7+fyqVmjH+NZU/qNZ+r60aFed9vpv/1evtYpwyTx/1Y8PHSSo862Tqf683dFs5vLetQ5acqpTpdOc329TXJ97ZiZ5VOdkB3P9DV9UOhz1Wc6IZs582AbZ7bsoNX7UA/8WdPrtZPWL3WqvHJS/KdH+t649+B9WT+YzGT96EAfiybyE8zzq+eyvlzpZ85urvetmekU8Wl6X9YHhZNUzvR6yxvmdHeRvs6iWtdzZzb6bfBNFQCAQGiqAAAEQlMFACAQmioAAIHQVAEACIT077fMIHfmmA50GvPQSdSmqT71aaLTh2Zmu71O9Q2cdefOtg7HOqU5mYxkfbnQ620bnVg8cpKSZmaPHuiZnkMnnRpFd/vvzqbT10nmpKKHU30tHMeFrMcDP7F5dPhEryN2rt0Dfa6yVK+7z/S13jsJ3Dx1ErK9n2A+OtYJ1l1Xy3pR6+N38EAnnp+Mdbo491L8mT5GI32IzMzs+lrP5o2ypayPD/Q2jRL9PBg7Ke/Rsb7GRs7s36a8YQZzopPeUaRTvnXpzxF+k7v9xAAAICCaKgAAgdBUAQAIhKYKAEAgNFUAAAIh/fst8/rlV7KeZk6ybqJTg14y189imnVfcx7mdrOT9dJJ1nlzY6u9Tkp2vV5O2/jbud3q/5PGOv2bxt98BugfB6kOo9o01wnZSaFjpIeTE1kfDvQ5NzPrD/Xf/NOhnl9bOAnu4VSnyq3ROzdIdIo0GurlV51/17RbfQ/0zteZyJmLfZjphGx8rLfJm3U7TnU9qf0Z1zPnPFzP9XFdj/Xnk1bfe+vlpa6XC1lPU7382Vg/68zMskJfM0mur9diekMc+g34pgoAQCA0VQAAAqGpAgAQCE0VAIBAaKoAAARC+vdbpml1Erap9HzcutzI+sBJUEax/3dW4iRk16uVrG/3et6mOSM601Rv03iq55juyytZ36z0PpuZJZFOrWbOLORBoff5rpgVzlzWQ538PJzq2cqjkf788bGf2JzMdDJ44FwPqTPXtu/1dRg7c67TXl8LlXP9HzqJWjOzfuYkj51tShsnrT/Q+9Y691hW6ERyHeljmkR+gjkf6ftylumEbD3W52ez1ttaZfqZZrEzR/rAuVePH+jlmNmxkwCPWn1co8I/p2/CN1UAAAKhqQIAEAhNFQCAQGiqAAAEQlMFACAQ0r/fMquzM1kvhjqJNxjr1FviJOtqJ0VsZrZY6bTtzpnNm+V6HXmh55sWA518rJ005ufPXsh6mviX9YPGmRfc6bTfwNnWu2JypNOik0NdPxjrYz9yrsOnD5+4684OdfI4cubats6lu6n152vnWtgnOs2e1TotvCx03cwsMn39DJ0ZyXlUynpd6e8/Va9nU7e9TipntZ6nWyb+rNvl/FrWO2d++HSkl1X2znNio5PHjXMs+lqnkbPef3b13pznVG9rvPXP6ZvwTRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCC8UvMt86Pf+F1Z/+C7T2X98EC/ljDM9anfLnXk3szs/IV+heXTz76Q9av5Vtb/4i//kqyPxvqVmqUzsP96uZb187NzWTcze/7qlax/+P6Hsv7ogT+k+y649/ADWW+6nf4PiR6a7rwFY8mpftXBzCxr9OsiZaNfF6lqfT10sX51Jqr0Piwr/SqHdc4PRMz9H13IxvrVjLLU32d2if5BAu8ARon+dYrM+eGI3vl8s9Gvy5mZta0+Hl2v7+9o4DxzdnrdfaKXY7E+3htnewYLv53tsqWsd0N9HgbmX5dvwjdVAAACoakCABAITRUAgEBoqgAABEJTBQAgENK/3zKxM7z+wfGprN8/fSjrxUin20ZDPSjdzKzc60ThP/gHvybrq7UecH040wnH4UgPyo5MpwaPj/W2jsd6OWZmVaUThT/67HNd/1Qnm//Tv+2u4o+V8UgPO18u9TlZbPR1de+J8wMOTvDTzKytnB8/yHQqOE51Qrbc6vqi0oPiMyf8W+31Pkc3DNRvVnrdxUz/n3Srk+6lM+8+0Y8Du471eWudHxGwrU5Om5m1uV6W96MAca8/nw51Srre6PO53ejnR9luZL2P9XLMzE4u9DZFTvK475wDewt8UwUAIBCaKgAAgdBUAQAIhKYKAEAgNFUAAAIh/fst8wu/9Odl/enHH+n/UOjU5ctzPR93Mjlw133voU4S/+k/82dl/fhEp3y/9/3vyPpmq1N90+lI1g+ceuukiM3MioE+Hufnl7L+O//yS3dZd8Fqq2emls4s32mqHynDzEl2135yNvVSvp2O5y5WOsl5sZjL+upK71tvOiEbN86+TZy4sJlNxjoh2+71nOtokuttcuYOr5b6nvHOm630vOPWWa+Z2aAdy3rX6MTwwUTvW73Wx+n8ai7rFxfPZX0U6RRx2el0tplZNdbndNbpayZPvePxA3cd/wrfVAEACISmCgBAIDRVAAACoakCABAITRUAgEBI/37LfPTzPyfru61O9V280infH//ej2T98PTYXfeTp09k/ef/9J+S9arUsztfv3rhrkPZ7/Ry5tc64di2/gzQ0VjP9CxjfSs8/o5OKt8VxUDPVz4Y6tTuYKDTroOxTmonqZ/YjHXI067nej7us5dfyfo//Me/IeuL5WtZT5106YMHj2X9yQM9d9vM7GD0nqwPRjpln+X6e0557twDzj6cv9D3/WfnF3r5F/4Q5h/+7Mey/vSR3rd6oq+NxU6vY3Wh9+Hq9VzWf3Sp6/cuXsq6mdns3gNZP3LO6YeHOvF8G3xTBQAgEJoqAACB0FQBAAiEpgoAQCA0VQAAAiH9+y3z+uUrWT93Ur6/+o/+if78S524y8f+3Nxf/HN/TtZ/4Rf/hKzvK51YfPWVTuntd3q+6XLtzASe6KTyYKSTpmZmsTObtpzrJPFys3CXdRe0lU5St851MhnrVGtV6tR1k/mp07rTf/NHjU6XrvZ6IPFupe+Z60t9zrNEp39n93TKd3J0IutmZqNDfY0+ONCzZZNMz6aeOPWm1dt6/krPst680vN0L5Y6UW1m9jPt92V9dqjPdRzr85BW+t6bDfSx2JxOZT3LdWI87nXy3MxseXmt17HSaeivkkjW/+2/9h+46/j/t+ONnwAAALdCUwUAIBCaKgAAgdBUAQAIhKYKAEAgpH+/Zcq9TsheOjM9P/3RZ7L+zEngJk7y0czs4PierD99qmeAblc68VntHsl61+pU32SkE6gTZzxnrsOEZmY2mOhU3wcf6L8vf/3TT/2F3QHzC52cfVzoOdBV6Vw/zjzd67W/7nik05xJoVOnHzzRc1w3P/8Lsv7gpU7Ixr2+gB69p5O8jx7o69nM7PjwSNbbXh+Pui9lPYp04nk80ynse6cPZf3h449k/fRDfa+amT345KmsHz3Uz4No6zyjDvTxXo91evrQSeCOhhNZ72N/5nd1rffvcj+X9ZWTFr4NvqkCABAITRUAgEBoqgAABEJTBQAgEJoqAACBkP79limGOhF5dKJThj/3J35e1uOBno+b3RCdPTl5IOuvnuu5oWl8KOtRrPeh2ulZwdbrv/10VtisqvTsUTOzfaOTiY+f6ijxL/+bf8Zd1l3wxflXsp44CdnYSVEPTCc2u8afOTvt9blK9Bhce+QkXiepvt7W7+vrLR3pKyvLdNL29Fjfe2ZmnTO/eHWtU9XzuZ6FPBzrdSS5vtYfPdXp7MFU79tg5M8vnh3el/U00cfDzRE3zudH+jxHejSz5V7Kd+C8DmBm6aG+zratThjvnVnLt8E3VQAAAqGpAgAQCE0VAIBAaKoAAARCUwUAIBDSv98yr67msr5JdMJx+kjPQ/3FYz3H9HDkp95OZzohmKc61dc46U1z5pj2Oohnm5Weh1o3+m/CItXJZjOzSi/Knj+7kvUPPnI26o5YvNDzWq+GOtmdX+jr53DSyHo/1NeCmdmwdP5totOfg4FeR3WsZwXnB7o+cALwuZMi3pYb/R/M7OKFniE7v9azup+9Ppf14UTfY4/f13N572f6Xp199ENZ396QmC+3O1mft7q+r/V5WDV60PPmSieeq04vv4z1fT/c+YOk+05nkicj/Ryc9Pp43wbfVAEACISmCgBAIDRVAAACoakCABAITRUAgEBoqgAABMIrNd8y3VQPta9r/erHzImMH8Q69n6Q+a84DAr9SoFF+h2ErNCvLMTOQP2Dld6mZ1/q1wzWG/35xnTdzKzpdbS+yDJZH430IPi7onNef7p+rV+D6JPnekGNHgh/0Oth7WZm/Vi//5SU+pWaMtKPs4lzSe8bvfx957wScq4nvL+c69dmzMx+/Ou/KetfnX8q66+f6+tzfKpfVfqp5ULWk5/+gax/nH0o67tOL8fMbLfUr6qc1fp1q6rUr+fsV/qaKUb6u11i+rWthzP9vOmd1wrNzJYrPVB/d63rdeK/nvMmfFMFACAQmioAAIHQVAEACISmCgBAIDRVAAACIf37LbN88ZWs/+xP/4ysH41OZT1tdcowd1KwZmZJov9tudXLajonpdfrv+XiWKcxByN9mfaxToFWrU70mZk1tR5+fnJf//DA+U4P9b4rvvfd78l676Sok1YnZ2un3nbOjy6YWZvo9GfvXKNFp4eg97le9zDWseCu2sv6+V4nZLevdDrdzOzLr17K+o8+fSXrz1Znsj5+6Tyq93rfxgP9+ZnzYxNzfTrNzGy90vdMm+n7L+70/T3K9DaNZg9lvZ/q58co0+nixPnRATOz5vEjWV+v5rL+/DP95sJt8E0VAIBAaKoAAARCUwUAIBCaKgAAgdBUAQAIhPTvt8xRoROLk1z/fdQ7fzeVTS/ru70/8zJJ9OXStDoFuN3NZT1y5sk2tY4gPnnqpEB7vd7FQs9BNjNbb3Vy9OWFnmP6Dz77saz/9V/6i+46/jg5eXpP1uOlnuO6rLx5zPo6bCqd+DYzK/c6eb0YXuhtmuvrIRvoVGjhXs/O/N1UXzvzw7Gsm5mdPjiR9YuN3odlq9PQQ+dJXYz1Nm1bfbxfO7OCG+deMjOLMn1Ou71O53atPqdlop85Raz3Icr0edibXm8e6eWbmY2HzrzxoZ6l/nCqr/vb4JsqAACB0FQBAAiEpgoAQCA0VQAAAqGpAgAQCOnfb5nBSM+k/Oq5niU6Hk2cJemE7G6n53yama03Oo1Z63CgDZxZn7WT+EyzgayfXetZrFcrvT370h9kmhb678hhppODP3N6313WXTBIdNKyHuvrZzZ2kqKNvhYmTjLXzKzrdGIz2uhlXe50gvugnsr62tk3a3QSdt/rayTt/LT58fGxrH/Yf1/WD6deSlUn4GcPn+r6ob7v60afn9i5L8zMxrHev6R13iCodbrfCfla1TvPg945P85bAl3vPIjMzGJ9zdw/0snt6dHMX9Yb8E0VAIBAaKoAAARCUwUAIBCaKgAAgdBUAQAIhPTvt8xoNHP+pZXVzEngHh3pmaRR5P+ddb3Q815//NWZrL9a6tRumjqJTydGXNc6Hbgt9ZzUsr5hjmmrk4zLRK973d2QKLwD0lgnLbOJTqlOYp06HR7q9Oog1olvM7PODQbra70wnYwvndRuXOrrpG1XejkbfR3GsX+9HR4eyXpU6GTrR08eyvpgoo/rYKqTzZN8JOt9r+/v9IavV7lzvNORPq5dpueHtwud1t85aesu1fU818euafzU/+ZyLuuXzsz0fKSP623wTRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAiE9O+3TOz8HTQY6qhkVekE7majZ/zev6/Th2ZmmTObd7nRCdlipLc1dmaJNp3+/PXluV5+pVPHdkNid1vpRGGc6lvhWeUnCu+CR9/9RNbHsU5gTlJdz5yZ1XnuDIQ1s7rTadvISYn3sb5+KufzyUCf293cuz7nsr7P/dm/h06C9eRkJutRqmfRHg6de2mgU6p9ptfrPfCzxN+HLNPPlnarj+tgdiXrF70+1/3iWtbrSJ+f1nkbIGp1StnMrHf2r8j1vk0iP5X+JnxTBQAgEJoqAACB0FQBAAiEpgoAQCA0VQAAAiH9+y1zfq6TsB988IGsz2bHsl45qdb5tU7umZlNJzrBOTvUc0nLK72Oy/lC1rNCJ/GmR/dlPc/1/Nlkt5R1M7PV+UtZryo91zhL7vYt8uRAn/Ood+avtnoerJ5Ea1bG+vNmZnGayHrqzG/exzr9GafOvOdLPYt2eaZn1y4bPRP4wyf63jMzG8/0ccpbfVzrgd6HQ2dWcL/X12eT6YRsvdf3pDcT28ysdpLxfeacu7VOMBdD/cbB0HSCOan1PVnu9DGqnZS3mdnxqU7z5p2+xpalvgZug2+qAAAEQlMFACAQmioAAIHQVAEACISmCgBAIHc72vgtNHRSepNWp9hyZ25n4SRt29afdbsv9Rzhw7H+26xxEqLzpf58XenEYjFw5p46czvrtZ/cy5w/I9dO2q++4393bjb6nA8SPce1K3TK8rKu9Aoqnag1M7NSpzlrc1K+sX6cbU2nVPutMyu219dC0uu0eTo+1Msxs7R3rt1I369T0/XdypmDq28xGzT6OVFHul6VOgltZmZ7vQ9to+cLJ7Fe1vFUvyUwOdDXUrty7smhvi6u9/qtAjOzznmsffnimayvX+m3LH74w5911/Gv3O0nBgAAAdFUAQAIhKYKAEAgNFUAAAKhqQIAEAhNFQCAQHil5ltmONOvkWx3elh10ejh1lmi/57Kbrgkuth5PSDV9SenOu/f1TqK/9nLuay3jX4lYrPSr2PML17LuplZEul1j1L9ukS30Nt0V5RbPdS8Gupzkrf6xwy6Tr++sq/1KzhmZn2sX6loNvoc5qav9SR3hst3+tWMNtfj/4eRvs53W/8HHPKBfkWmzfS2bi71NpWVfk2lcn4soG30K0xd47xbkjqvF5lZU+l96JxX7CJnAH+U68/bVh/X5V6ft12pr8nOOZ9mZvFOr2Oz0edu1Tvbegt8UwUAIBCaKgAAgdBUAQAIhKYKAEAgNFUAAAIh/fstk050SnXd6qRct7mW9XujY1lPtv5AfSucFOBYJzijRCcTT2c6Ffyjr3SidLXSCb3LV1/pzy/0PpuZHR7pod5Rp9f9Z99/313WXbBwhs6njU5gtp0zZF1fnhaZM2jfzKJcr6NP9fVW5XqgerzXn+8H+jqc1k5SdKz3bbn1fxQgafX9mkf6eksLvU2tk1rfOj8e0a71fbxd61RrP/LPQ79yUv9D3T76VG9rfaafB9tS36/l3hmo78z+H4z088nMLO30uge5Pj/JcOYu6034pgoAQCA0VQAAAqGpAgAQCE0VAIBAaKoAAARC+vdbZjzQc0lNh9ts58zPvFrNZf2492exZjs9WzPe6yRjP3USi1udQGz2uj7N9fIrJ+232+oEpZlZkTmJz1wfwI8f3neXdRfkTup0X+vrKnZm1C5bfd2OR/7M2d5Jzk6dGbxm+txWTvQ4ifW+VUO9rQeZXmtzw3eT3Pk/RaHvs8F4JuuHTqJ2MNLJ43XszLStdX3+2olnm1nmrDvr9X6XzpznqNH17V5fM9tS3/ddreec10v/2WUDva3RXKeey9a/Lt+Eb6oAAARCUwUAIBCaKgAAgdBUAQAIhKYKAEAgUd/3OmIFAAC+Fr6pAgAQCE0VAIBAaKoAAARCUwUAIBCaKgAAgdBUAQAIhKYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEQlMFACAQmioAAIHQVAEACISmCgBAIDRVAAACoakCABAITRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCA0VQAAAqGpAgAQCE0VAIBAaKoAAARCUwUAIBCaKgAAgdBUAQAIhKYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEQlMFACAQmioAAIHQVAEACCS97QejKPrD3I47K031KRhPJrI+m83058djWU8Svfy+73W903Uzs67rvma9/Xqf73Xd3davWf9GyzJd/+rLZ+46/jh5/8FHsl42O1nvan28Guec13ntrrvr9bU77LZ6m+JGryNO9AqcVXeNcy1Euh7Het/MzPpW70Na6noVlXodQ70PyVrXu2wj63U/1MvXh87MzNJUn2vL9D60O32c2txZQaWfE5Hp/xCZ3ti88M/DXh9WszTTded67dsbDtTv45sqAACB0FQBAAiEpgoAQCA0VQAAAqGpAgAQyK3Tv3i7klj/vZNlOq1WDAr9eSfd5gVkvWSumVnb6pRe2+hEXNPqffi6qeCQ6d9Q67grotw5t851OHDClOPISU2OdMrdzCzu9OMp6w7053N9rjaNvt4s0W80NM71bE6SN+n9BPPeW3Ws112VzrJq5+2Lmb6em1R/frrTaeF2pBdvZubsgpvWb0f6f4yc4xcnOuXb9E7C3PSzrkz98xA76d/OO9eDb37f800VAIBAaKoAAARCUwUAIBCaKgAAgdBUAQAIhPTvOxY7Kd+80Am3gwOdfDw5OZH1wWDwtbbnpvRvVVWyvi/3sl46AzerWqf0/FTw10vm3rQPbvr3a6aC74pq4CRenXGwaaSvkcq5nk/iqbvu9kAvy1p9TSexvn4mkU68xq1OyLph3kRfz1F+7PwHs3Gz0v/H2Ye41GnU1pv9u3eu21gfu/Va70N7w2z33hkM3G71fZ8X+p5JOn0NRE46e9/oKHnmzGAuez/CnE31/6lKfTwa51l0G3xTBQAgEJoqAACB0FQBAAiEpgoAQCA0VQAAAiH9+44liU71jYZDWT891Snfx4+fyPp4PJb1yJk92jnzfc38lO9qtXbqS1nfbLayXjrp4rbVCUcvyXtz+lfvX++s466nf9PSuT4zJ4061un0w6GTch/5ic1Bps9J1Dtp1Eavo3JmzuaZvt6KQm9Tnzqza2+4RJJOp5uj7EjWMyc9HZleyap0krD7hazHA30PV7Wum5k1jZPCHui5zWPn/oudZ0ud6PN24Kx32+sU8XCvn0NmZp2zjizRz9kq8Y/Hm/BNFQCAQGiqAAAEQlMFACAQmioAAIHQVAEACIT07zsWe+nfsU4gnp6eyvrjx49kfTLRCT1zRn32vZ+cLZ05mUsn5Xt9peebXl1dOcvR6T1vhrAzMtRuGGPq/lvvHJC7nv69f/JA1ieHTvKz0H+nj4/0dTtx0pdmZo2TwOxKfY16KVVvdm3e6W1tnHnHk5He1i7RaVQzs4PUmb1dONdbrOfdjjJ9sW+X+t64eH0m6y/mOhV8cflS1s3MukoPQ07NmansHO/EdBK67/R93zb6eE9rJ/E88edIN7Xepmisr7Gizt1lvQnfVAEACISmCgBAIDRVAAACoakCABAITRUAgEBoqgAABMIrNe9YEuu/awYDHcU/PDyU9ZMTPWh/PNED9d3B8je8UtM0Olo/HOpXCnJn6Lr1et2t80pEW+u6Nzf/5pdg9L/2X7N+V/yVv/qXZf3BQz0QfjZ1XuHq9DVSxvqVEDOzttbXW93p1yD6Rl9vbas/nw314y9y7sndlb4W6sofvl4W+iIdZ859P9THz5kHb/VuJ+v3HupX7B7NL2T9iy+P9QrM7OWLz2X9cqdfjWuWzvGL9Q9pRKafdbHz4wKr3nkO3fAdMW31uUsLfQ20yTdvjXxTBQAgEJoqAACB0FQBAAiEpgoAQCA0VQAAAiH9+45FzoT3NNWnZjjUSbnxRA/gHzlDwBsnUds6qeCfbJP+GyxJvCn1eoh1tdvI+m6zkvW6dNKVTlK5uiGx6yWGO2dZvfcf7or9XJb7K5207Qp9zuOBHsw/K/yB+t3MSxLrofNJrZPEVaKHo/emU6T5zhnY/kgvf1/qfTYza0u9jjLSy8qcwe/FUO9zPNZvAzx0bsl89lTWJxP/RwHyiV5Y+0yfn239TH9eB5UtNb3PK6c7TXP9D1Xl3/f9UO9DvXfu+0o/H2+Db6oAAARCUwUAIBCaKgAAgdBUAQAIhKYKAEAgpH/fNSel580EzjJ9yopCJxyLXKcGvfm7XeWnf2NnW7NUJ0GHA71Nk7FOMB+MvaSyTlAmid637f6GebLt10v5tq1/PO6CV7/2q7K+OZjK+vRIzwQupjNZ/+iTn3bXPf3woaxnYyf9azrBWnX6+mlrfY/1E30txHu93vHIv0bKXqdI5xudeI3Welm1OevOdTK+6nQy97hey/rwvj/715xUdbzXy/oXZ/r4pZGe/dv1+pmmp5ab9Rtnn2PnWWdmqfPsinsdSe5uWNab8E0VAIBAaKoAAARCUwUAIBCaKgAAgdBUAQAIhPTvO+aE0ixyorZJ4qSCnQRu7szJbBr9eWcUsZn5CdnInLSfsw+DQqc0p1Nn1qvzt99goFOd6UanDM3M2taZ61rqlGbf+XNd74Lrqx/JervW11V5rlPB+fRE1u+9pz9vZnaw13NtJ1M957p15ubmkc6Rrif6+mn2uj7Sq7W212l2M7Oo0cnZ6Xom64toIetJo+dlezn32pnHnThvA+S9Pzd3fKDP3eHwpawPnBnhZaXfBoic8c+9kwreRDr9O4z18s3Mqlofv40+1VZvrt1lvQnfVAEACISmCgBAIDRVAAACoakCABAITRUAgEBI/75zOqUXOzFcbyZw6iTuUicV7NVjb8CvmbWNTgh6qWDvL7Yi0wnE6USnf9NUp4WHzpzitPDTmE2jt3XvzAvunFnBd8WDRD8iMue41NuVrO+cnOr1yyt33Scf6iRs1MxkPY70tva5TgVPO5087sZ6H6q1jopmsZ8QL3MnwXykZ87Wib4vt3P9+ch5GyDq9TaNOv35pnMiuGbWRHrdhennwcB7c+H4QNbzA73udaXPZ5Xpa29bOlFeM8sqvU2RM1c8Tb956p9vqgAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCCkf98xb9auV3fCv5Z8zVnBqVP30sVmZl4eru/8uaF63TrhOBzqFGCa6zTvQId/Lcl1WtjMrHISw7utnid61//unEY6aZnE+tGxG+hza60+7suzz911b1/c0/8n1ynx6dhJ8zrbFDV6RnTszJAdOrN/9yvnQjSzbqhnSneRvq7yxJlTnOkkdL3Rd+U41Qn7nV685dUN87Kd5HY/0PfZycmprHdDfd6KgT5vh6Veb1XoxO7+2StZNzObV07a2vn8rvzmqf+7/cQAACAgmioAAIHQVAEACISmCgBAIDRVAAACIf37rnnB2d6Zs9s7qTTn895fTbGT8vXqZv48Ym8XIm+bnHXkzkzgLNfpzdac+cWJXo6Z2X6n05ibtU4/RrGTZr0jMieRPTCdeK0bfXwXpU5frr743F1374yjfdTo6+c7H38s60fpU1lPCr0PcacTta0zg7od+snZQaKTxPtU5053kZNUNie226/18hO9b8VW35Otk0Y2M0v3+ng8vKe3KY3ek/VSXxoWJzoV3HnJ87G+MOL5DTOYt/p4V5u5rEfNN7/v+aYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEQvr3Heud7GzvpX87nYjrOp3289LC3mzhm2b/eqndzllYZLrupYhTJ/0bOXNM+0hfvv0NScbRWA9wHU90krFzzsNdEUd6/7exk5ytdMoycWYuF4VOr5qZLc8/l/XhSCdqt0M9c/bw+ETWI/da19dVtNOzaKPEf4z2ziqGTph37Bzvcu3Ue31co62O2taRTjDHsd43M7PhUB/vbuHM6o71HO2Bc96qoZ79GzkH72GiZ4H3n3iTfM2WzrnbbHS9ab75fc83VQAAAqGpAgAQCE0VAIBAaKoAAARCUwUAIBCaKgAAgfBKzR9RnfPqTNs4w74bHSfvWmfI9Nccdm9mliR6yHT/NV+18V7bSZzh9XGmo/i98/mm9ePwea6XlTvr8D5/V6xbfYzzSL/mVHmviiT6eh6PnR+IMLPlUl8/u6uNrC/KV7J+uNUD3qetfiWkyfX1kzvbGm/8Qe5x51xXtd63YaPr3Vg/qrtGv16yL+eyfmgHsh7X/usou0a/drJ1Tt0w06/tFJlzcQz0a27xUF97xVQvp7zhVn346rWsb1b69Z/9Xtdvg2+qAAAEQlMFACAQmioAAIHQVAEACISmCgBAIKR/3zFvcL6X/m2c9G/lDDL36p0XkHUG7Zv56d/OSfN6g/O9gfeRs/wkdZKPkZMWjv00pqdzftjgrg/U73t9LPeNHuSeOWnprNjKelr4j6Bxrf9PvdPp3+3ZQtbbh5eyvpodyvqw16ngKnZSqq3eTjOzNtaD7be5k/J1flRidKUTtV2v173v9D50uT6feerf+OVC3wNtr/ctGTjp35NjWY+d73ZtpJPNRavTyPdGD2XdzOzynk6An12vZH250OfhNvimCgBAIDRVAAACoakCABAITRUAgEBoqgAABEL694+o3kv/OjM6y52eVblNnRSbl8C9Yfav54bA8Nf8H842OdvqLadt/XmyZakTi/udThTu97p+V7ROujRpdTIzWu1kvY71ucpSP6ldOnNzY9P/p97oJOe20ed87KTNvesnrfQ9tnHSqGZmeafv16bW92XqvQ2Q6bR14iTgh04Kexjr5deNn3KPnX3IW90+4lzXJ5lOJO8zfW00zjUzyPTzoL7hO+LkUK97cqgTyflYz5G+Db6pAgAQCE0VAIBAaKoAAARCUwUAIBCaKgAAgZD+fdectF/fe7N/dQpwt9OpSy/T583fzQs9t9PMLEv0/3Fzg84/uON0nYHEnVNvOn0stk4S2sxsuVp/rfp6o+fM3hVlqROYsenj0qz0dVvH13r51cRd9950mjeJx7I+PdXriEt9neS1k6g1XV/3OgUbbf3rrRrolG/upPKrWK87Heo5xc4tYP1SH4uudxK7emyymZlluT6nXa+vjaTQyeN+pBPjEx1gttVeX2N1o/9D5Jw3M7NirI/3xHnbYd8z+xcAgHeOpgoAQCA0VQAAAqGpAgAQCE0VAIBASP9+y3gzgb2ZtmWl56R603HHE52sNDObjEay7v1l1juzed30r1P3ZrHuS53GXC50atTM7Pp6LusrJ/17U5L4Lmgbvf9dpR8dvXMxjMyZs2v6ujUzyxu9jmilo6o759w2Wz2/uHLmFFdjPSe23zrp0tyffp2V+trddfq+zJzUf+HMu40TnaiNx1NZLxf6WKQTP+0aL45kfWR65nEd6WUdODN+IyfCXBd6vU00l/Vk55+H2LmWUn2qbeKcn9vgmyoAAIHQVAEACISmCgBAIDRVAAACoakCABAI6d8/spwkmzOzt/Xm47Y6XVnVOt2Wpv4lMRw4SUNnm7x9+LqzgrvWm3esk6mL5dJbgy2XOuW72+vjVDuzlu+MgZM6TXVKta31cYzX+tqxyL0azJwx1LHp1He/0rNi19fnsp5PdPRzMtTbtKud+spPig6c27gd6fm4+61eVjTVqfzcCe2uSn3emkTf31mvU8FmZkXjPENivfIi0ccpipx9znQyfNrqdLHzMoBVjfdOg1kZ6X9bb/T93RQ3XJdvwDdVAAACoakCABAITRUAgEBoqgAABEJTBQAgENK/75g/BteJDTq/VJ9kTgzQ+XzrDOCNohvmZzr/Fjnr8JLK7r45WnfesU4Hbrf+vN69MyPZOx7ePtwZlU7IDlJ9XLpCz4duEp0uzZz5sWZmg04nXruRvn6SSq9jfflS1ot7zozfpb6XnDG+Zr1OI5uZXTmJ4Xir/08S688nA52cHRX6WEycdPaV6YR055xnM7My1bO095FOKsf1oaznib5mikwvZ73TifE+0/fwrvVT/xcXr/T/WTnXZeREz2/hjj8xAAAIh6YKAEAgNFUAAAKhqQIAEAhNFQCAQEj/vmO9kzptnAGX3tzLNNPpwOFIn+LCmdFa5Ho5ZjfN+NV6L0nsLcf5fOfMNfbm8npzjc384xdFev5o7CWb74jpWF8PyUAfr9aJyDYbnfLNGmcmsJkVU53A7J1T0g/0dbJazmV9tNDblA50PXL2bdf6aXZvXnBZX8h6X+vk8eMDJ1W91Z+vnXupdGYC214nfM3MtrU+D6XtZH3S6YRxWul1NIlOC0edPg/LUt/3z18+l3Uzs9cv9PG+XOht2t3wFsSb3O0nBgAAAdFUAQAIhKYKAEAgNFUAAAKhqQIAEAhNFQCAQHil5h3zXhcpncHv262OmbetXs7BgR6UPRrqmPzNQXK9jtZ5T6V3Ph8l3qs2ut42evlVpV+daZzPm5n1vfOjAM5rPnf8jRqLM/36wjjWj4564AxBd96D2TmvNJiZ7Z03oyYTve4219fbttevfsTO1Z7n+nWh3hkI3+79u+bZy2ey/urVlaynQ328R8cTWT+dTvVyTP+oxIE5g/yd3+MwM4uc45TtdH2T6nUPSn3eBoW+XxPn/j578aWs/7Pf+heybmb2wnmlZlfqbc3+AD+kcccfGQAAhENTBQAgEJoqAACB0FQBAAiEpgoAQCCkf98xLzm72+uU7/V8KevzxVrWx2M9iHs88OJ+OkFpZtY2XtpW17teJxmjWKcGvWSul/Ld7XRCuiz9gfqdO1Cfvy81fVyWlT5Xu9o5541O+Ub64z/RbWW5XerHVtzreprqxGvT6+tk0DiJ/EIn5vMbMvPbUiePf/xcD3/fbPV9/MEn35X1UazTv32q08Ktk+Zub7jv41afu9Y5Tp5xqpPhu0ov53w+l/WvvtDHbv7ilbvuaqevgShzUuzOtXQbPEkAAAiEpgoAQCA0VQAAAqGpAgAQCE0VAIBASP++Y12v46j7vU62Xl4tZP3lKz3bssh1yjc61qnBPNNzT83M2lYn6KraT9sqcaLXUbc6mbjZ6vmcq/VG1vdOctrMn7Xs/X0ZOfOI74rFSl+HvTMf15x09WbnzRD2z1XfHch66sytTgsn/Xugl+NNiK4q/S/tVO/zxPT2mJkNJjqFWyT6nrlcXst6X+ptGjip3aTPZX0R6c/nqT8v+yJ27lcn3V/FY1mPnLnQ+1KnvC/Oder4xYu5rF/e8Bxqcn1tFLF+O2IU6W29Db6pAgAQCE0VAIBAaKoAAARCUwUAIBCaKgAAgZD+fcd6J4zqzbtdrXTi9ezsStYHXvq308ufjP0kY+8klWtn9q85M37jRG+Tl7pcLHUKcLX00r86sWrmp3+jG+a33mXeXFbb6Rm1Ze/8nV7r5WxveAQdnerU7odP3pP1wemRrPdHj2Q9znQCfuFct6PSmTl8pJdjZvbw4UNd//CJrK+9BGvspFed70U6L28WO6ntrvFmgZvZVqdzS9PJ2QPnEogyvVVJqRPgq9qZc74+l/U0vmEfIn38+lxfl50zk/02+KYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEQvr3XXPClV2n02dl6aWCdULv8nIu67Ezt3Mz1jNDzcx6Z2OrRi/LYv03W5J66V+9nItLPe/Ym/1bVXpGsZl/XI30r9SNdKJ23enrLZnr5HVu+rothn5i8+DJTNc//q6sf/jTvyDr+0Jft4u5vj7XG506vZjv9PbMdErZzOz4oT5+H5efyHoe6ftvMh7KetM591iiH+1Jr49359zCZmZNrI/fznl2ZQN9DaTO88B7eaBz5h0nvT4WRa+vSTOzqNDrHmZOetrZ1tvgmyoAAIHQVAEACISmCgBAIDRVAAACoakCABAI6d8/opxgnbXO7Fp/VrBOLHpxv8XC/zurafU6qlYvq490otZL/7at3rfNWu/DZqtniTZeGtnMOmfYcuRs61336Od/XtYvL/Ss6W3+Y1lvr520cHrornsY65m9pw/el/XivQ9lfZTqGbVl86Wsvz7TafP5/ELWp/ePZd3MbDYYy/pH793Xn090+neU6+uz7vQ9kDnjr7tUP/KjG75elbFO4U5y/TwYpXqfKyd53zvx38rZ1sZJNpeZfw/n/UD/n1ofqCj95s8DvqkCABAITRUAgEBoqgAABEJTBQAgEJoqAACBkP59x7x5uk5I1XpndG3jJGd3e52sa50krzkzgc3MKicpVzV61q6X/o2d9F7kRBCbWu90Vev1egnfm/Tf4P/cBa8qfa7yqU54jrPvyHry4J6snzSJu+7TT57qdR/rebpRq6+30pnlu9noa/3lRqd/n529kvXJi0LWzcwmTz+W9YNEH4/RqV7Wl6/1unflStYj58k+TPXc3C7xz8N47OzfSCeVx2N9bUR7fX42S53u353r2d7NTj+7osyfIx1l+lmR7PQ+dH+AtwH4pgoAQCA0VQAAAqGpAgAQCE0VAIBAaKoAAARC+vdd81K+Tt0Z/WutkwouneRs0+h61zmpYDOrnZRv0zrpX2c5caJTl3GsL0f/WDgJvZsGmbopX9K/yrkzdzl3kpbH+amsPz7V9cPhgbvu06me8TtOJ7K+35eyXlR67nC90/vWnOu08Ovnz2X9VzfOzWdm5U5fix+/p2cenxYzXT+eyvpSB5Vtc61TwetG/4d4qmfjmpmlzu4NRk7KN9P38bzUz5Yfv9YzlZ+/0InnzVbvW9zr7TEz6xJnJ2J93w9z/5y+Cd9UAQAIhKYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEwis1f0x0TgK8dd7B6bx50b3/d1bkvPKSeK+weG+8eMOqneV4PyIQRfofosh/PaY3Z2EM1JfqnfP6U6nr9YG+RpbJSNZPJsf+ug/09bDb72W9OdevZqyvrmT94rV+veRsfS3rL8/0qzmL689k3cys7vTrH/u5/uGBn/6ufi1o0OnB76Nc15cj/cpTtdLHLnWG1JuZZYV+3SbJ9HD+ONMD+Bdf6B/keO78UMHZ4lzW+0wP/3fKP/k/ndPqcr3fm1gf19vgmyoAAIHQVAEACISmCgBAIDRVAAACoakCABAI6d8/srw0qk6v9k5EtnNSrbGTwE0S/5KIE50odMO8Tt3bs9b5VYCm0UlTL/HsHaPf3yq9TW74926ngqut3v/WuUyWnf5xhW2pk7Zp5F9vw/vO3/wbPQh/vdEp3/lap3ZfXs5l/fVrPVB/X+nr6vxyLetmZuvSGdq/1Nf0dKS39XT2SNa35Vwvv9Tbmo71MW1r//tVGTv3U6WTs1mmr4GX1z+W9cXzS734nU4d57lOEXc3vLnQOPd93ujIcNV88/ueb6oAAARCUwUAIBCaKgAAgdBUAQAIhKYKAEAgpH+/bb5mSrV3Y606DRfH/t9ZSaKTcnHsxX912dumvvfmj96U5v3D5R+/u2ET6ySnNfqc1BudzCydBLc99x9Bfavn5m6cGdTxQqdwP5u/lvWXK70P17WeaZsVei5vf8N3ky7RN0HlzK2+dlLBm8svZH3d6OMd5Tqp3zv38D7SyzEzOzjQc3C95OxBpY/TFxc65Xu50Z8va30sokzPL7Ze77OZWeK8iqDXbJbGNwwSfgO+qQIAEAhNFQCAQGiqAAAEQlMFACAQmioAAIFE/V2PNwIAEAjfVAEACISmCgBAIDRVAAACoakCABAITRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCA0VQAAAqGpAgAQCE0VAIBAaKoAAARCUwUAIBCaKgAAgdBUAQAIhKYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEQlMFACAQmioAAIHQVAEACISmCgBAIDRVAAACoakCABAITRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCA0VQAAAqGpAgAQCE0VAIBAaKoAAASS3vaDv/7r/1zWf/z557L+09//rqxfnZ/L+v/5f/zf7rpfX72W9c12q/9DXcvykw+/J+tPHx7K+qDQ9Yt6KevH+UBvj5kVh/dlvan0Piyv9T7/5//Ff+WuA29P3/fvehPeiv/4L/8NWe8S/ff4cKgfKfkwl/XohnVniV7WINHLst5ZWt/pbXKefkWqz23j1PN8ohdkZpPhVNbrotDrML2OttzJeuc868qqlPXtWtebzr+e9dEzaypdL7d7XXe2tW10PW2d73xOOb3hK2LqbGzpXBt1pq+l/+F//Z/9lfw+vqkCABAITRUAgEBoqgAABEJTBQAgEJoqAACB3Dr9+w9/5Vdk/Xc//W1Z/5e//Vuy/uqVTrVezK/cdWeRTqYNxkO9rGol68nymawvFmtZj+Lnsj5JdLrtiz6RdTOzuPlNWW9bnT4rcifhCLxF6di5pp17so91PXH+fo+izF132zSy3phOsFrrpHMLfS8NkrH+fKKX00U6gdu3ejvNzDYb/WyJd/oZUjnHr2n1WwJtpZOzVa2fK52X8r3h61XfOMfD2e+mdGLBrS6PvCR9oRO4u52TFr7hkVkPnGtjq9eReNHmW+CbKgAAgdBUAQAIhKYKAEAgNFUAAAKhqQIAEMit07+/97lO815c6Dm4r84WeoWJToyl+chd977Wybdy4UylbHSicP7VXNZfVi9lvRjpdPHB6EjWeyehZ2aWOCnfNtXrKGf8vYN3r9/ryGaV6HrihIWzXF//g8aJhJpZ6i0r0fd35ySSPWWrE7hN72yTl8yN/fRvEjvpUidhnJveafdp4CwndurDzhucq59DZmbXK51gbk3v99ZJBQ9bndrtM71NXecsx0kLFzcEdvNan9PImf1r/Td//vLkBgAgEJoqAACB0FQBAAiEpgoAQCA0VQAAArl1+veLTz+X9ajVi0jHOqHXtjrlu+10MszMrHVGfTb7c1lPEr1NUabXESc6oVd2esWrrZ5TfHCoZ4mamR0c3Zf1YqfX3U/8OcLA27LY6UR76oQmk5H+O7135rj24xsGtrY6senNBO4ivVF9o++lLtLblCV6m2Ln8+YlSM0si500b6yfUbnz+dbZpqbUSdiy1nOKd06wuav8Nxes07HattLryBL9nE2c5LGXAM+d45o6+5DfkCRvncRwYnodo1HhLutN+KYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEcuv0b9Q4ibjpQNYTb3aiExuMbvil9dx0EispdFJuv3VSYE46cJLq1O7e+YX52okj1+MDvV4zqzYbWV/s9X4XpT6uwNvURk5iM9f3XuSkKatKX+dJ7v9dH9U6bdt6c21T/YxKc+fZ5czszXLn7QHnTYeq9t9c6JwEazXS+9A7z8H9Tj9ztntdb50kbG263nnzjs2sclLYvfOMz50RzAPnDY9hp89zvNefL5zPT5yUsplZ4yTAs0wva2RO0vsW+KYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEQlMFACCQW79Ss+3WegFXOm59lel+feBE9JNDf1PKZinrkfPKS1XvZT23of78RMfek0xnw7dOpD9f+EOp20pHuscj/QMDZevHw4G3pe70/b1rnaH2nTMovtD3atT4932b6VdhOu+1EOd1vdi5j+NEP4uaXu+btXo53usrZmZbb5D7Rt/fZe+8xtfoetM6ryh2+gdN+sQ7bzf8sEGlX9uJSr3fg63et3uDiaznrTOA3znPkfMKU+G8zmVmVkTOjzPE+vyMohuOxxvwTRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAjk1unf2AlWtcOdrNdb3a8vSv35g9gfRh9HOqG12OhE18hJ1GYDvbupOUm80knWOcOn981K1s3MhtP7+v8sdbLOht88fQaEMhzo+3hszvXpDMiPnZRl5/zIhZlZ7yRheyd57NxJ1jtvHOSpTuRX3o977J23BJyEr5lZ4cxl934UoHJS/17KN3WCx13hJJV3evnt1v9RgKjSK5k4z8fTSP8AynuJTiQnTsp70Xnn2flxhto/D4lzDfROYysSBuoDAPDO0VQBAAiEpgoAQCA0VQAAAqGpAgAQyK3Tv5taJ7FmxZGsH8R6Du5576Step3YNTNrnBmQw0NnZuTISRo6s4K3a7388WAg6w8OHsr6s8tzWTczu7h4qf/BmT867fzjAbwts0N9fzuBfOucGbWtk8xcl/6M69ScleQ6mVmkTmLTCbZGiU7/pk4iuaj09kStP/s3debR7p2ZytbpjY2d52YSObOWS2dbK/0c39+Q/o2dNzZmnT5+7x3OZP17B1O9/EKnf5/3+tq47PT2tG7+22wQ6Wujdq6ZfMDsXwAA3jmaKgAAgdBUAQAIhKYKAEAgNFUAAAK5dfrXqr0sbzcbWR+Nx7L+yUM9A3eS+mmra2em7rQeynoS691al9eyvnUOw2g6k/UnHz+W9Xji/43y5Wdfynoa6wRdZ6R/8e7lzn25WTvzVyudUm2cVPCq9pOzRaefOXmuZ8umkV5HFOv7MnMSoUWs694s4sKZy2tmlvZ6WYmTbN41OtnqbKoNE30scmefWydF3DnPdzOz1pmFPOr1Og5zvW/jwUTWj0713PfU6U7ZlX5mXq3m+j+YmZX6OssjPY84ykn/AgDwztFUAQAIhKYKAEAgNFUAAAKhqQIAEMit079lo9NQlen0770jPefRS3QNxnrOrpnZg0inxhpnNuT2ci3rRa9X3nR6OQdHx3p7jnWCuWv8v1HOXy9kPa11ojC/IRUJvC1tq1OhfaXnrJbOLN+m0zNn48qf/ds7yxqVelmTTNcz57vDMNXJz3GqP5+2OtWae4OQzaxz7uN96cwXrvVx7fWLDjbM9T4cFToVXDrnYefMQTYzixO9D4lelPWtc21E+lpKkkNZf/DhI1lvHuhe0XzqP3/n53NZ90YwN/03f/7yTRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAjk1unfUeEMn3TivKvtVtYfHp7K+p/5s3/BXfd+o9Nkv/0b/0zWl7GeFdzNdCLuwPmV9w+d9NnDh7r+/PpK1s3MCu9IZ06sL/PniQJvy36vE5uRN+92r9PsI+fP98PYT84OYp3APM504vUw0/f3yBnjmsZ6OYNUP+smkV5Qb3qfzcz2O338lp1+Pi6dMHTR63XPnBm1s0Lv277Rxztrnee7mXWVTtv2ib4G9k6CebnUz8eDmZ5z/uDwPVl/+kC/DbLb+POLF2v9b+WlPg/91r8u34RvqgAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCC3Tv9aMdYLcEJj12sdY/vuVCe3Pvnhd9xVr1d6Wb/z1T/X27TQfyt0TvJtONQJuh9+52dlfVfvZH0xn8u6mVma6EPtZcyi2k/jAW9L7QQqx07q/8GBnvk9LfRs2bx3BsiaWTJfyvrpWD+LZoVe97jQd1ni3GKxMxN4mOoUbNX4+3DdXcv6dqf/z6Bw0tPO6wPecR1keue8sHXrJHnNzFaRXscw1s/ZJtLLqrb6rYzVRs9qPzL93J/OZrI+PtG9xcwseq7P3TrSSeV2qWfa3wbfVAEACISmCgBAIDRVAAACoakCABAITRUAgEBunf6NvZ95z/UihrX+fJbpz//ub3/urvv4np4NORoeyHqTXMj6eq9Tu0enM10/OpH15eWXsj644dfio0bvd5LoOF7U+XMsgbelcy7p2km8Hj56KOuPT2ayPrvhnknm57JedHrdo1gnPDMnvRqZs27nlYYu0cupWj/9W1f63+JI3/cTZxT4YKoTydMD/ebCtNHH4rzSadfohq9XqZPQ7nrnmea807DrdbK53OmE9P5SP8eTTqeLY+dYm5ntTe/3Va8TxuutP8/5TfimCgBAIDRVAAACoakCABAITRUAgEBoqgAABEJTBQAgkFu/UvPR++/LernWMebh+/p1l0cfP5D1i6szd93rUsfDB20h613lROIvF7K+G+oc++fPPtWf3+sB0P1Av/pjZtYket1Rr6PepTNMGnibYuf1iNqZv752BrYPjo9l/TD3/64fjfVrJO3FS1kv93qjlmv9Kl2c6Y09OtSD2adDvT3zjb63zcyWjX41rjP9jDp2Xgs6ns5kfTI7kvXeee3ETB+LqtH7ZmbW5XpZXaNfSYp65/POq03NTp+HjfMDJX2jn5mbrX41x8xsXukB+a86fTwu9SpuhW+qAAAEQlMFACAQmioAAIHQVAEACISmCgBAILdO/37w0Qf6HyonQfdAD6M/PLkn67uFHp5sZja/1knYPNGJta5eyfpypZNe9TOdPP69T39d1odTPTR8GPlDmFtnmP+u1OnA3hk+DbxN+UAnYZtqK+svnSH4p4tTWb//SL8NYGZ2dKz/T1Xq9P2n1/o+Xi30tg7GOmk7nur06rbR9+Rm59+rpfOLBLkznD+d6TcRZsf6PBw/0MeobfT3pXWp39Y4W+p0rJnZrnPepnC+klVONHzj/IBBO3CG/G/1No1afbwXi7neIDOrnRR75vwgQTHQ+3wbfFMFACAQmioAAIHQVAEACISmCgBAIDRVAAACuXX69+FDJ/2b6iTWxJnLO+l0Cmt84qcAF8uvZH29cVK+53NZn1dLWS83Oh341VevZP3pU53Qu17oJK+ZWdXrBPOy1ttk+z/A8EkgkGGh/+7eOtHP0kmKbjb6+m+ceb1mZm2m/63s9Tr2rU62Xjv1YufcYyv9PEh3OsG/qXTdzKxz5uBGsd6HtNFp1FE6lvXJVM8b31fOXF4dOrZd7QxtNrN56aSbIycV3OprI3PeaEj2+rlZzHUP2Tgj1vepP7/4+ES3uvyRTlVvOp0Mvw2+qQIAEAhNFQCAQGiqAAAEQlMFACAQmioAAIHcOv2beGk1JwW43+u5jd1Qp9iijZ8CfOXM9Hz95Zeyfl7rNNlP/eBDWf/hxz+U9StnTubLq9ey/uxM183MlnM927iq9Tqs9Y8H8LY0phObvRcWde6Z7Vwn9bcP/dTpKtJpzn2jU6F9qlP51UR/fuHM6t5UOhXcbnV9udX7ZmY2cnYvSfSjNxnq+75zzkPtJJI7Z85u7zzHm9g/DzoLbbYr9bZ6S8p63SvqTj+vy0Yfo7GTMB8c6N5iZvb+e4d6WY+eynqbHrjLehO+qQIAEAhNFQCAQGiqAAAEQlMFACAQmioAAIHcOv17MJvKerd1EmBjJwPmzP7dVn6C7tD0sMdXTnD2aKDnNv6lf+evyvr7jz6W9V11Letf/PhTWZ+fX+oNMrNqqJOJqZPq27T+HGHgbRnFzgxU5/ZOM/1IiVK9nHjoDHI1s8pZxy7X81rzoxNZP36o171L9HeKqtTPoqjWOdj4XKdRzczWc2eOsPN95tKJVU9a/ZzId3pb40RvU57o5Q8KZyiwmTlhWysbvawq0j2h2etE8rUzy3kz0sfuca6vmdMPjmXdzOzh++/LenagU8FVo7f1NvimCgBAIDRVAAACoakCABAITRUAgEBoqgAABHLr9O90oBNXcaqTW1VeyXrW6ZmKu83CXXc70kms9ULP0+2cJFte63rppP0s0qnBJ6dPZP0v/MUjvRwzO3/9QtZ3zozk1Env/f2//yvuOoDQ0jaX9cOpvjeGA/13+ul9/fbAyEnqm5l1rU6XRoc6sVmc6GU9OtD7YGP9+Ns7c3O3V/pezWf+nNiXL17J+vX1Wv+HnZMw3uh9KFJ9vIdOAjeu9azgo4l+O8HMLFvr/W72+hm/dVLb1cCZ2TvUM57bqT6ug0c65Z0ez/SKzazJ9LqjVu9D4oeh34hvqgAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCC3Tv+WzkzKqtNJuaTUn980Z7J+udQJMzOz82dXsr5wUmn3H74n6+MjnUCMTUe91s7y67qU9Xv37su6mdmDif5V+spJ+Waxn8YD3pbhqb4Op0769+hAvyUwm+p7z0ZOVNTM6kYnMy3RydZxoe+x4kg/5jaJ8+za6/t7cKKXfy8rZN3MrC/0vz23L2T91UKnfztnhnBR6+N3FOl9q3Z63/Rk4d/nzHOuJ/p/9YW+NmYzPbP56J5O+X50Xz9PHx7p9HfqrNfMrKycQfHOLOQ0vXVr/NfwTRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAjk1hGn7eJa1/c6PZVHetFVpGdefvbpZ+66Lxd6fqb3J8Fkck9/PHd+wt5ZTtnplGGf6SRZ1zsJMzObzHRycJbptGSU+olC4G353icPZH040LNoh2OdFp44810rZ/aqmVm50zO501j/n6pw5uNG+vOx80aDV08jnXbtJnrfzMzuJaey3rZ6WRdf6WfdcqOPxWWl31yYOjOV61jv25WTOjYzW5T6OTg80vv2vjOb9/SRno0+Hutn3UNnHvGhM4c+dfbNzKzs9rpe6/NQm9MrboFvqgAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCA0VQAAArn1KzXLuX4Vptnrwc2HT3QU/+JMR7f71n8dpa91VH7txMDHTqw/znR9sV7o9VY7Wb9a6nj2wUwfIzOzrtUx8MOpM1C/+OaRbiCUB4/0UPM81/d9q8tWOiPbW+eVBjMzy/QrEl2unwdxrL8jbFu9nL7Wn096/ZpKG+lh9PENt+rAeV3kgw+eyvrhwBlev9bPlnSpj18U61dq0k4/M6vEf6Vms9Kv8xzP9KuLH93T+/bk/WNZzwb6ADqHwmLnVcfOu/jMrNrrc13Xer+jxl/Wm/BNFQCAQGiqAAAEQlMFACAQmioAAIHQVAEACOTW6d/z83NZX3vpPWe4tZV6uHXiJPTMzMapToe1vd78ItPJrf2FTvMumrmsr3c6GZZ2Oh243PsJun6jk4PlXh+n44K/d/DuxbG+bpvaSUc6t3Hb6fu+7vzUv8X6PrPMidt2znB0Z2Z/4wzOT1Ln3tvp9aa5f6+OnO8t0eGBrE+cH/3YXOg3FFatfi5fXenzZjv9DMwjP+16b6rfmjjSZTsZ6PN2zxmEn0/1DxLUpk/cxkns7jf+Pqz2+o2NuNLraNIbrss34MkNAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEcuv0b+yk90axTq8ulmey3joprL2TMjQzO356JOvj5zpNtt5tZP3LF5/K+i7WqbFJp+dnrtq5rHdr/2+Us7U+fnGqE4unD953lwW8LXWj06JppGfaxk5iN0/0PZa2/j2zMZ3AbBudkE16Z45rq2fFWqdTp72T7rfISfLeMCbWSxhnTrq0yJ2ZvRNnfvFQ7/Mmei3rnfMcL0Z6vWZm7zuz1AdDfZwOa/2MH3kzmFO97k2rt3XZ6OVUlZ/YrUu9rU2vr42m9N/keBO+qQIAEAhNFQCAQGiqAAAEQlMFACAQmioAAIHcOv2bHOikbVQ6SaxOJ3D7yJmfGfnps+WVTnUNBjp5vJxfyvrlwViveziR9V2kk49ffKmTzcvrK1k3M+uciOB4fKI/Xz1zlwW8LYkzyzfLdWoyi/V9HHX68/uxM8fXzLqtMy976cxrjZxkq7MTWaYToYnpVLCX/jUnjWpmZr1O9/fOPOJs6CRtj/S2Ru09We9a/eyar3WqdTo+1BtkZtOJPqdbZ9ZyvNXP63Kl5xc3zqzgdaPP//Vap4s3G+egmlnjzJzvSie6HTuJ8VvgmyoAAIHQVAEACISmCgBAIDRVAAACoakCABDIrdO/27lOjXkLuNzq9NlwpBO7Ueb8jLyZ7dc6zfvw0WNZP5nqtFq90am0zEl6NYX+fJzqxOJqodNtZv5+P/lwqj9/rBPJwNsUZToJmzt3fl/re6aqdcqy7PRzwsysa/T/iSNnxmuvtymK9D4ksVN33lBInBRxVPvPLidgbANn3m0+0NuU5s7bA/GBrPfdqawvzq/1cqZ+KxhP9P51ja5fdnpbd1drWe+dmcBnnU7/vt4sZX290WlkM7P93kkGO8ntSean0t+Eb6oAAARCUwUAIBCaKgAAgdBUAQAIhKYKAEAgt07/Dkd6bm5b6sRVluhUXz7SibHpRs9zNDNLDvXc4VHhJIkTva2NMzMyTvRhqDcrWT8a6O1JP/5A1s3M0kOd5n148lDWm8RPFAJvy7rUqf+md2Z4t/peSmKn3jvxWDMbx/r+tqFO/yat3qYs0ctJhs7s30q/DZDmzvzzsf8YHUX63wa5Xnff63XHzvefeqSXn05msj480qng1dZ//hap8yzyZvZudcp3dTGX9ajSydzrXp/ns8WFrC/2TirczDYr3aeKSB/v3uk5t8E3VQAAAqGpAgAQCE0VAIBAaKoAAARCUwUAIJBbp3+TRCer0kKnp05zPdO2LPWsxb6Yueuu11eyvndSu3Gkk2zpQM+kXLb6833jpACdxNho6CfGjsb3Zb1N9Tatdzp5DLxNnTPL1yKdsI+d+biDQs+0rRsn4Wvm/skfOfXUeR54/6HI9eczb5NSnXZNM/+7SezMHTZntGzfOjOSnURyabreOuutJ/oZdX2hn7FmZiNnbnPkzDPfVPoaWNU6SZ4t9PK7xElCO8eidt5EMTMrS/2M73q97r0zg/k2+KYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEcuv0b6nHOVoX63Rg58Tbsl738a72Z09WW52EjU0ntLqVTp95QcOhk7jLM+fwbPW+tToQ+fvr1utomoGs71d6viXwNo2SQtbzRN97mVPvnJm26Q3h39ybFxzrdcSxTucWmf58kun7OHG2tXeeab2TUjUzKxt939eVft6tnfnFrfPWxCrSc3P3dSnrc3Pm7DZ+cjavl7I+cVK4i0ave+Wse+SkhcdOuvh0ot8s2Tpva5iZbTMnxe7Mqu4ifyb1m/BNFQCAQGiqAAAEQlMFACAQmioAAIHQVAEACISmCgBAILd+pWa308OQC2fwcFboKH5dXst6nunPm5kdnB7Jeur8l6zRcehuouPq1VxHvdPUGdg/1Sse934sfdjrZS02C1lPEv7ewbs3LvR7YpnzWoszc970SxNmiXNfmJnlhb5fC++HNLzHWazvpdYZFL/vnB/YyPTrb+1aPz/MzLaN8wrLSq9j7rza0rV6H3bOqzmLa/0azNWVfjeydI6Rmdlwrp/9UaJfeSmdV5vWhf78YOu8bljrV2S81ziTG96COTgYyrr32uTB8Ib3I9+AJzcAAIHQVAEACISmCgBAIDRVAAACoakCABDIrdO/l+srWT/qjmW9rPQQ/ItXznJOD9x1F7lO2xYDXd/X+m+FoTNveTDWScay0imzbaP3rUl1WtHMLL/Q+91HO/35oR4aDbxNk+FE/4NzqQ+deyDqdKo1bvxH0MRLEsfOYHsnYryp9Lqv1xtZ3znb2uY6ads5zwkzs+Vap21fXevU/8VKPw8a55lWd3rdO2ffqlJ/Pr/h2ZU5aevEGf4/SfXzdJfoY9H2Ov2bOO0pGerlHxV+/HfmbNOwGMn6xPmxhdvgmyoAAIHQVAEACISmCgBAIDRVAAACoakCABDIrdO/5aqU9WWik7CZM7t2MnZmie79/l61evZk2+nUWF7o5GwV68+bk96rW2emZ6mXU9yQZEwKvY4+cbZ14U1LBd6ecarntXqjqYtYJ2eTWCf1G/MTm63zePJSvvtWP6PmpU7UXmx0GnW91/d9G+nXB6ran/m93OjE8IvzS1m/vtap3brRB3zT631LS72to7F+3vSx/7x5NdfP+Hyoz93R9FDWJ6nzpkir92HizJceTGZ6vWO/h7SZ3r/EmXk8aJ1XRW6Bb6oAAARCUwUAIBCaKgAAgdBUAQAIhKYKAEAgUd97WToAAPB18E0VAIBAaKoAAARCUwUAIBCaKgAAgdBUAQAIhKYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEQlMFACAQmioAAIHQVAEACISmCgBAIDRVAAACoakCABAITRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCA0VQAAAqGpAgAQCE0VAIBAaKoAAARCUwUAIBCaKgAAgdBUAQAIhKYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEQlMFACAQmioAAIHQVAEACISmCgBAIOltP/jv/fVflPXT47GsR30p63kWyXpd7911r9aVrF/OG1mfHJzK+vnZK1n/6P17sv7k4VDWN5uVrNeV3k4zs7btZL0o9Dpevdbr+Lt/93fcdeDt6fv+XW/CW/HJz3wi6z/z0/+GrB9M9PU8vzqT9fimJ1Bcy/Jiq++NxXot6605995ArzxP9TMqTWTZur7V/2Bmbaf/rXX+S+deVvr7T+k8c7rWWZBTTpx9MzPLMn2cRpORXpZz/KJErzxJdb2sdE+4OL+U9fHoSNbNzNJ4IOtNo68N75z+o//td911/Ct8UwUAIBCaKgAAgdBUAQAIhKYKAEAgNFUAAAK5dfr35Hgq67NDnQCrdjqZm0Q6bTUsdIrYzGw4OpT10VT/TdDoVdu1kzKr9jpNGPe5rEem023r9U6v2Mz6SC9rtdMp6aslf+/g3Xv1+qWsN62+yX7h5/+UrH/vo5/Sy7947q57V+n7MjUdVc1jXU/yQi8n05/vO/2MakqdRm79yK41Tuo/crY1TjJZryp9vMutTqk2lV5vkuhHvpeENjMrDvQ2Jbk+HhY5z2XnOHWt/vx+r/d5UExkPY71dv6E3r+61s/ftvnm6X6e3AAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCC3Tv/ODg9kva71vM3emZ04HOvZoDcE6Kypde/3klulk5SbjnU67PRE79t0qBPJ+52et9l3fvosyfWyri6dOabzjbss4G0pd1tZP3ul52j/03/2a7K+3+rlfPd733PXvdpcyXof6fR9numUrzlvHHjLaTv9/KgandiNGicFa2bWO99bnISs93lvvHBb6X/w3lAYFvothMFI18382b9RpI9TH+t656SqO+e4JonepqTQ+5bEzvk3M+8Uda03i95d1BvxTRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAjk1unfutEpsxfPdQpwPNT9ejTUCa196cTbzGy+0mmy5VqncBtn+O8g02myLNWp3curuaxvN3q9Zn76t+/1oU5T/Yv0Rbx0lwW8LcNYpyOrUt8Dz599Jetxp5fTlM6gbjN79P5jWb93/z1ZX80vZb3c6yR9pEOn1pqOfqatNz/Wex6Y1Y3+P43zPHUCslZk+nkaT/XzNEn0zo2cty+SXJ+fn6zEmdnrvLHhJW2jWO9DPtDP5daZX+yEs613jp2ZWevMYK5rfR6qktm/AAC8czRVAAACoakCABAITRUAgEBoqgAABHLr9O/VtU7Q1a1Omc2Xetbn7Egv/+zKn3V7NdfputhJzm42eiZwk+sE2HKlt7Vwfkl+u9PJsP3OTzCPUp2um4xGsj5+fE/Wf/XXnrvrAEI7Gui/u5dbfS9tO30PvDrTbwn0vZ+ybCodIz15eCrrH7z/HVk/f/1C1q8X57Ie507S1pmnm6b+d5O+d+YFO5/35uPmzvzd6USvezDUidreSfL2N4R/neC2Nd5/clLSTesknmu9TVmqj13jxHwbLzptZlW1l3UvFezVb4NvqgAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCA0VQAAArn1KzXrrY5DHx4/lPWo0xHmLD+Q9ev5mbvui2u9rLLRr+EkTtJ7cKJfX7FIx89Xa73PdePE2AdjvXwzMyehnTrh+uFk4i8LeEt+8IG+Dn/vuX4NrV7raee7aifrry79+3650j8qce9cv252dqZfkfnku9+T9dP7erj85YX+UYAo9l6PcSbI202v2+gHQhzp50HiDKNPvdd/Emf52dd/pab2JtXXur7f6+d11znHwqk7byOZmd6HutbXmJmZRfpZ7pxSi5xXj26Db6oAAARCUwUAIBCaKgAAgdBUAQAIhKYKAEAgt07/Dsc6tTsc6wRdU+p+vd3rpFw+8NOu+UBHtKqNTiB6QbYs1SnfttPLzwd63ya5HrTvDYA2M6tKPeS/73Vastn7w/mBt+XJA/2jFVWvr8/2TKcmX831dV6V+h42M2uce2a9Xsn62aVO/371Sqd5P/zgI1k/PjrW21OvZX0ymsq6mVnV6UTqdqOXVTU6OetlUTtn8HtVOelfJ8jbxf7zpmr0M3u91edut9MrGQ6c4+Skf1snklzXenuqyt+HNHN2PNLP7CTxn+VvwjdVAAACoakCABAITRUAgEBoqgAABEJTBQAgkFunf+8dn8p6ZzrV13c6GdbFOtF3cqrTxWZmjTNj0vY6QZc7ia681mmycaxTacOJ3qbEmau5WS9k3cws9mZPOonh1UIfV+BtOjp2UvnObNTOqTuBebtaOve2mVWlvmeaWtdX8ytd3+j78npxLevHRyeyfu/4vv68d4zM7JPv6bnDl05S+frqlazXjU4RN6WTFnZmDveNPj9t78+6rVp9vPvWec7mOjGexIVejvP2RdPqbdps9LPRCUKbmT+DeTDU9aIg/QsAwDtHUwUAIBCaKgAAgdBUAQAIhKYKAEAgt07/blY6Kdf2lazv9nNZv3dfJ22vdv4M0ItrPeszy3TK7OhYz+784PF7sh6bjiZeXjrrdeZCdqZnC5uZHUz1Nj168kTWv/+DI1n/n/6X/8ddBxBacaiTsDPnHvheph8ps7G+v6/meo6rmdnVtU55Xi/1/9k4adF95yznWqeFt85M8bPzM1k/OtT3qpnZ67MLWf+5n/2Tsv7gwUzW59efyfqu0m9AbCr9lkUXOfN0W29iutmu0s/4JNPPu7zQz+W+19/hvJm9+70+b2Wpz3NzwwsT7ihfZ77wYOQfjzfhmyoAAIHQVAEACISmCgBAIDRVAAACoakCABDIrdO/TannZ8ZOqqou9azK/VYnxrreT872xVDWTx48kvV7p/dk/eGHH8v6wUjP+B20OsX25OlTXX//fVk3M3v6WKd8j451ujIb6PTZ3/lv/lt3HUBo3UTPux2k+tGRZTpJPx7o+/vBgZ5da2a2ONIp3/OFTqM+u9CJ18VeD4VdOrOFq1pvU9V4bzr4by5cL3TC+NmL57L+w+//nKx/8FTPEI63ejnpUEdhr5b6jYZ9qetmZlWln0VFouutk8JunONXV/rzlVOv9WLMCSmbmZ/+jWO9D1n+zb9v8k0VAIBAaKoAAARCUwUAIBCaKgAAgdBUAQAI5Nbp36dPTmX94kz/Un210TMp6/GhrH//w++76/5bf/PPy/pHH31H1u/deyDrRzM9f3d2oLcJuOvWpb6Xhs7c12ymk/qTfKmXM9DPCTOz8UgnZ0cHOrE5nunH2Zevndm1C2cm8Eqnjhsv1Vr7Q2fXjd6/3VYnhv/JP/l/Zf3VMz3795OPPpL10UGh1zvW53O90wlpM7M009sax97/0fUo0sfP+3ziRHbjRC8ncdLIZmZ9p9fR6gC4NU7y+Db4pgoAQCA0VQAAAqGpAgAQCE0VAIBAaKoAAARy6/TvINcfPTyYyHrbPZb1n/uTf0HW//Z/8l+66z440vNHAfzhuricyvpo5KR8BzpJPz28lvUk0wlfM7M81WnOmZcYzvTs37rTKVJvxm+515HQvTnpXycVbGbO/zA3dhp3G71Nm69k/fnnZ7L+cz/1iaxPHun55FGqZ5Cbma2d0cZNp8+pN0/XYp2STjv9+dj5ytf33j/4Cea2+XrriBNm/wIA8M7RVAEACISmCgBAIDRVAAACoakCABDIrdO/V5c6pZc68aknj/RMyr/1H/1nsv7HPeHbdzoHGHlJOeCPgLMzPbN3NBzLejnVaeGuPZD18UC/PWBmls5G+h+2+lk07PS2Tkc6LXw01feeNw92sdEzgfeVnzr1jAqdSH54qmcqH0/08+N0qhO1WfalrI+dBO57H31X1s3MLub6OF3N9fkpS30eGmcOcpzo4xpF+riOUmfudKaPqZlZ1zrzhZ2EeZ6T/gUA4J2jqQIAEAhNFQCAQGiqAAAEQlMFACAQmioAAIHc+pWaqtGR5LLREe2HTx7o+umT267yjepex8xLZ4r1zkm+L5z6a+dtl+1O1+NK183MTjJdf+pE5f1J3MDbM78+l/XdZiXr27UetH91qV93ePLEfx4cTvXrNkPntZ1Bdynrk0q/4vGwX8h6UeibdTjXk+U3e/+Vmr7XD5H3HukfHngw08s5mugfC0j0obD6nt6HZftc1ov1a70gMzsdf1//n0S/UvP8Ul8Du/1A1pv6pawnkX63aZDr+rgoZN3MrO+cc+Q849Nbd8Z/Hd9UAQAIhKYKAEAgNFUAAAKhqQIAEAhNFQCAQG6dcRoMddKrKXX6t2l12q9rdax1d0N7/w0dNLQLJ+a77XXSywvp1c5Q+32r920UO1FeHdAzM7Nlole+2OvIcO0cV+Bt2u/0EPSm1kPQ1yt9sw6HOvnppS/NzPrHx7o+1QPVi4l+Rp0k13qbRvpHAcYTnQqeTPW+7fey/JP/M9RJ2NNDnVSdjvTzIC/0uj939nmrT48lhX51YZz6D6+D5W/I+nGsz0/+/lNZ/+IrfbyvzvXn+04nz6Nct63EecaamcWRvtCiSPeQpr7hVY434JsqAACB0FQBAAiEpgoAQCA0VQAAAqGpAgAQyK3Tv+evv5T1yeRI1hd7PSfzN1/OZX2XHvjrXug03vm1nvUZZzodWNZ6ZqQT/rWs0vvQ9fpvkbbyY4DX5qR/O526c8J7wFs1Hul0aRzrR0fkpCzzXCfmnY+bmdlqpe+N3vSyptP7sl4MnaTtWA/OLZxn2nSmE7jdDUnRobPfk1Q/i+p+LutnI/183HZ633aVrjeVfiujGvj7UB/p52y20+eni76S9ScPdcp3MtDn4Xwx09vTXMl63+k+YWZWpPptitSZL9x23/wJzDdVAAACoakCABAITRUAgEBoqgAABEJTBQAgkFunf+NUp8mSgU4HVk6q77d+73dlfV/7m7Jz5uO2rU5oeQnEzXoj6+ulTo0NnRnCvZMM63t/Xm+W6tRd7ESPm+IP8NPzQCBHR3q+a5p9veszMj1jNc30fWFm1jv/x0sFb5152ePpoazniZ5FWxQ6ETrKlno5uX6umJm1jZ6dXDY6Sbxzvufscv2cyGpnznmrE8z1/pGsL7d++nfdO29B1HNZLxK9z/eOX8r6waFOBceDx7L+8rW+ZnY7P7Hbd/p4x96zvNPX3m3wTRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAjk1hG+Lj6R9by4J+v3T3Ry66svPpf1y7lOmJmZbTY6XeelfFdrJ+kV69RYudvJerfXKcMXz5/J+pPHD2XdzOzkWKfxSmdecJ3y9w7evbrRqdBioOdr905ivut0vb5hbq4587KzYiDrbaefB1eX+vlROIn8QaKXczDTKeLY/H2IYp0krkwnlc+cRHK51Z/vav32RbvRqe16NdHL6fw3F7ZrZ45w85Gsjwav9bo3F7J+fKrfviiKa1k/mn5H1hc3JHZ3a/2Mj/UlZondMJT6DXhyAwAQCE0VAIBAaKoAAARCUwUAIBCaKgAAgdw6/fvstU5P7Vqd3Fo3X8p69lrPhXx1oZNeZmZVqVO4WZbJernTidreCXRVpTNbuNLJvf1OJ5WbSifufrIOvU3eTNTJSKf6gLdpu9X3a+T9Oe6kf7dbncBtW32PmZkNnXvg8Ei/iVAMdJo3d54T+7Xetz7TadfhWKeOB2N/5my61W8iPOv0vi22+pEcxfo5Mcz0NmW9fitjYPo5NL/SyVwzs2qrz1HX63O6q/S6u1onm+vyUtZnx/pamgz1eqtEp7PNzLa1vja6Tl/IaUr6FwCAd46mCgBAIDRVAAACoakCABAITRUAgEBunf7NB3p27XCkk3hp6szndJK8u+srd91nZ2d63cOhrG+cdO7sUKfD5vOlrI/GU1n/+Dt65uX0QM/VNPPTj16yud/oZCLwNu2c9Grf60Ro0+ok7HKh3xJYLvW9Z2Z278EjWY8SneadOnNcYyfImTjfKWpnDO7GGfEbbf2k6K7Tz5CLrZ6dvN7pbRpP9DomB3o501S/rfFi72yrH8K2rtTP0zhxnl3Oaxb7ve4hdf2+rDe1Xu/Aee7v9j+WdTOzyJk9HTnzpWNnrvxt8E0VAIBAaKoAAARCUwUAIBCaKgAAgdBUAQAI5Nbp3x988lN6AYlOSV1d6XmOm41OwX78wXvuumcTPSfz6Fgnj720Dq9g8gAACvdJREFU8Gym078XE508ns5O9XpnM1nfOElJM7OXL57L+u/8i9+W9dNHj91lAW/Leq7v46bRyc/hWM93HU/1Pdx2eqatmVmS6MdT7AwermudPC63Tno10svvYz37d+GM+B3s/Znfm04va1856X7na05d6TcL5hu9/HqrE9K7Wqet28g/D+achz7WB6Tr9Rz33pnz3LX6mlkudW/ZbfWc4q7Xz30zszjW10CW66h3lurjdxt8UwUAIBCaKgAAgdBUAQAIhKYKAEAgNFUAAAKhqQIAEMitX6n5d//SvyXrX37+uaz/vWf6FZLxUEfrHz144K+80VHsJw/1ayf1bi/r7z16IuvlTr8esN/rGPanPz6X9eMTP1q/Xukoe9PpWPqD03vusoC35ehQv+7QmX7d4Qff0/fYeKpfT3t9pgftm5nVtR52Phrr10uur/SrcXHsvJrj1HeVft5UjX79oh/qofZmZn2qX1VJEr2OPNdT+9NY/0DJy5d6YH+906+d7Lf6VZ7WGYJvZpaMnDbRe78woI9TmujXKeNIn+e+08tpG/0s7Xr/WkoK/YxPEn1+emcfboNvqgAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCC3Tv/+1m/+hqwPBjod+Mu/9MuyvlzNZT2OE3fdXa97/3DoDO920oGT6YGsL+Z6m7ZO6jhygnIvv/pK/4OZ9aZTZv/13/k7sn4910m5//1//O/ddQCh/eCT78l649wb7z95JOtRohP5UaR/FMPMbLHU6dKq0on5PNfD5acT/ZyIEz00/XKuU//lVidCq9ofRn9yqu/jPNfD3w8znWCebz+S9d1KvwFRNvp415Xe1s45n2b+N68808c7dobz57luN169qXVid+skmLte77OZWdvoa6lr9cO8aW74gYE34JsqAACB0FQBAAiEpgoAQCA0VQAAAqGpAgAQyK3Tvy8+eyHrrR7baKf39Ozag6kzt/Py2l339Ws9x/ILJzH8+uVrWS9XOtX3G//4n8p6kuq/ObZbneibTPS+mZllmT7UH93X6b1x6h8P4G3Jpjoh+2B4X9b7Rt+TTa0TuFnsp04TJ0XatDr9e+LM3j490clPL+HZxU4qeK1ny3a9/ryZWWx6Zu8g08dpXeo3FKzTSdjpUKeIk17PWh4menvmV3o5ZmZt7aSwa30ehqOhrOepnvueOtdA7aR5e2fmcGROMzIzc94g2W69lK8/z/lN+KYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEcuv077//V/6arHeNnofZ9c4vqjv11XrlrvvDp09kfb3WvwD/8EQn35pWb+t/+Df/hqxHzi/SL5d6vX3vp89WK71/v/L3/i9Zj505psDblKQ6pbpodBJ2qoOZFplOyO53O3fd+62+ZwbOzNlBoZ8tqTPjt91fynqe6gTuWAeYb7zv92v9FoRV+k2E1y91OrdunH0e6Prjxy9lvS1nsj5O9WxhM7PLq1eyvtnp81Pu9XM2S3SCOR3p+bu7rb7GmlZfM9OJTh2bmfVOQnuz1QnmOHZO9i3wTRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAjk1unfgwOdiEti3Ze9lG/tpIVPTk/cdSeJToftS/+X3r/ONmWpPgy9M2O0qnTdm0lqZtY6Q5KrSscle+e4/nfuGoDwjgZHsl46s2hXtZ5ZPUh0mrJv/dm/selnRVvp/7Ne6Hq10/dSHOtZtH2v1zub6GTuaudEns2sXOkZsher78r6ZuPMwW30PqTuiNpDWf3o6XNZP/jIf/tiMNLzyc8vdNr2+lrPat/v9fN6vdFzh8tKp7PbTs9eT2J9fszM+l4fqDieyXqW6eN3G3xTBQAgEJoqAACB0FQBAAiEpgoAQCA0VQAAArl1+jdL9ezEstIpwNZJ9cVeWrjz52fWTnI2i/Vc0q5zEoWx3t2o06ng2PTyR4VeTtPpY2Rm1tZ6mw7HU70s81ORwNuSO7NlrXLupd65N0zPuk2H/n0/NZ3OXa/1ss5e6WRr69zfXur/8PhYfz7Rz65Jrp8TZmb7Sv+fzkn9d43e1tJJzm73ejlNpc9btX1f1t9771zWzcw++s6PZD0f6FRwnulZ7ZcX/1LWm1rP+O06XW+d2b/zuf/MnE71c3Y8nMl6Uej6bfBNFQCAQGiqAAAEQlMFACAQmioAAIHQVAEACOTW6d+60XNto0jP5U0SnYjzPh/1fgowMv1/+q+Z2vUSuJ1evGXePuiPWxL5hzMvdDK4deYRF06yGXibWtPp/tKZRbvfO/OyS33vFWP/7/qDEydNH+tk63Kh77/zc51sHQz07No00+tNMj0/1hlFbGZmufOmwAdP9WzZL77S27rbX+l173QStq2c502jZ/yWtT97/XqhU9j3T3U6dzLV52elP251rZPNI316rHSSzV3n/Aczy1Od/j2YPNDL6r/5902+qQIAEAhNFQCAQGiqAAAEQlMFACAQmioAAIHcOv3rzfJNnHmYaaIX3TozfqPey9SaJZHT+53/0jnr6J2kbRx7iWRn+c58zjT1E7ve3rl7fUMaGnhbrhZe8l5fn8uVTqPWla4PG52oNTOr9vqZMzvVadQsfiTrTa0TyftSz81dLXRMNc31tnbO2wZmZqvlRtaHk7WsHx3qZOvVtU7txqaTs32vt2nn7PP+Qp8fM7P1Vs9CvjjXieHEdIJ5u13KeuVcG2mvz38ajWW9iw9k3cys7/U1s9/pZ3n0B3j5gm+qAAAEQlMFACAQmioAAIHQVAEACISmCgBAIDRVAAACufUrNZ5yrwdue0OpPbHzuouZWerkm+NY/03gvSKT5Prz/mstzis4iRPD9pdkXfv1XpGJYv94AG/Lcq3v76ZpZL13BpEXA/0axGarXxUxM7u63Mr6q+f6Xnry5KGs/+zP/Kys//izH8v6+fmFrF9fXcp6dMOPX/TO6zarlTPYvnGeE84rTGmkX5HxfiSk7/R5Kyv9as5P/pMuN3v96lFs+nWhptb1nfOjAMNev8oznepXp6J4JutmZnWr+9Fiqdf9B/k9E76pAgAQCE0VAIBAaKoAAARCUwUAIBCaKgAAgdw6/ds0eii1N6S+rnUqLXaG43tJXjN/CL+XqPWSiUmqdzeOdFQuT3QErHficPFN6V/v37yUnjfNH3iLvKtws9HJ3Hv3T2W9yPQ92TT6OWFmdn11JevrlR7MvtvpBOvJif7848ePZd17ps1/dC3rsfNcMTNLUj0gP3JSuJGX/tWz5S12nhOds/w41c/Z0WCgV2BmsemEbN/qnhAl+vN5pncinrwn62mqB/bPjp7I+nhyX9bNzBZLfW1cX72W9abVx+82+KYKAEAgNFUAAAKhqQIAEAhNFQCAQGiqAAAEcuv0r5dW83jJXG8CbnNDf3eTs47ISRL3nU6fVd6+OfMi48SZIXzDwMi213ved84c4eTr7TPwh+HSmYM7Go90fagToQcTvfzcSXiamS0XOm3rZZKrSq/77Pxc1l+fncn68dGRrP/UD34g64ulTheb+c+E3V6nni+v9LIGhU4R751HV9nqZ1Se6/N2MNVzds3M6krP7K1KZy50qz8fxc7bF/FUrzjS5yHJ9cX09IOXejlmdrCYyfpo+JGsX129cpf1JnxTBQAgEJoqAACB0FQBAAiEpgoAQCA0VQAAAol6b9AlAAD4WvimCgBAIDRVAAACoakCABAITRUAgEBoqgAABEJTBQAgEJoqAACB0FQBAAiEpgoAQCD/H5KwsatLDhsXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x3000 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dls = get_ssl_dls('cifar10', bs=32, size=32, device=default_device())\n",
    "# aug = get_bt_aug_pipelines('bt_predhalf_aug_pipelines', 32)\n",
    "# show_bt_batch(dls, n_in=3, aug=aug, n=10, print_augs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
