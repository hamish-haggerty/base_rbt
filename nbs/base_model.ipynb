{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_model\n",
    "\n",
    "> In this module we have the base model, learner and other things we need to train encoder\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import importlib\n",
    "import sys\n",
    "import self_supervised\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import kornia.augmentation as korniatfm\n",
    "import torchvision.transforms as tvtfm\n",
    "from base_rbt.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the base functions and classes to train a basic BT-style model. Note that this (mostly) all comes directly from here: `https://github.com/KeremTurgutlu/self_supervised/blob/main/nbs/14%20-%20barlow_twins.ipynb`\n",
    "but we needed to extend some of the functionality for our purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the base classes and functions needed for image augmentation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#My edited version of RandTransform\n",
    "class RandomGaussianBlur(RandTransform):\n",
    "    \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "    order = 11\n",
    "    def __init__(self, \n",
    "                 p=1.0, #debugging (bug in libraries implementation)\n",
    "                 prob=0.5,#the real probability\n",
    "                 s=(8,32), #kernel\n",
    "                 sig=None, #sig_val is either manually input OR\n",
    "                 blur_r=(0.1,2),#is randomly chosen from uniform with these bounds\n",
    "                 same_on_batch=False, \n",
    "                 **kwargs): \n",
    "        \n",
    "        store_attr()\n",
    "        super().__init__(p=p, **kwargs)\n",
    "\n",
    "    def encodes(self, x:TensorImage):\n",
    "        \n",
    "        if isinstance(self.s, int):   s = (self.s,self.s)\n",
    "        elif isinstance(self.s, tuple) or isinstance(self.s, list): s=self.s\n",
    "     \n",
    "        #Default for ImageNet from BYOL / BT papers\n",
    "        if self.sig is None:\n",
    "            sig_val = np.random.uniform(self.blur_r[0],self.blur_r[1])\n",
    "        \n",
    "        else:\n",
    "            sig_val = self.sig\n",
    "            \n",
    "\n",
    "        tfm = korniatfm.RandomGaussianBlur(kernel_size=s,sigma=(sig_val,sig_val),same_on_batch=self.same_on_batch,p=self.prob)\n",
    "        return tfm(x)\n",
    "\n",
    "#Delete later: leaving for backward compatibility for now\n",
    "# class RandomGaussianBlur(RandTransform):\n",
    "#     \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "#     order = 11\n",
    "#     def __init__(self, p=0.5, s=(8,32), same_on_batch=False, **kwargs): \n",
    "#         store_attr()\n",
    "#         super().__init__(p=p, **kwargs)\n",
    "        \n",
    "#     def encodes(self, x:TensorImage):\n",
    "#         if isinstance(self.s, tuple): s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, list):  s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, int):   s = self.s\n",
    "#         s2 = int(s/4)*2+1\n",
    "#         tfm = korniatfm.RandomGaussianBlur((s2,s2),(s,s),same_on_batch=self.same_on_batch,p=1.) #p=1. is a bug\n",
    "#                                             #kernel #sigma\n",
    "        \n",
    "#         return tfm(x)\n",
    "\n",
    "\n",
    "class RandomCenterDropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.5, min_dropout_size=(20, 20), max_dropout_size=(60, 60), fill_value=0, same_on_batch=False):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.min_dropout_size = min_dropout_size\n",
    "        self.max_dropout_size = max_dropout_size\n",
    "        self.fill_value = fill_value\n",
    "        self.same_on_batch = same_on_batch\n",
    "        #self.id_transform = tvtfm.RandomResizedCrop((256, 256), scale=(1.,1.), ratio=(1.,1.))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Check if the augmentation should be applied to the whole batch or individually\n",
    "\n",
    "        #x=self.id_transform(x)\n",
    "\n",
    "        if self.same_on_batch:\n",
    "            if random.random() < self.p:\n",
    "                return self._apply_dropout(x)\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            # Apply dropout individually with given probability\n",
    "            for i in range(x.size(0)):\n",
    "                tem=random.random()\n",
    "                #print(f\"tem is: {tem}\")\n",
    "                if tem < self.p:\n",
    "                    x[i] = self._apply_dropout(x[i].unsqueeze(0)).squeeze(0)\n",
    "            return x\n",
    "\n",
    "    def _apply_dropout(self, img):\n",
    "        for i,count in enumerate(range(img.size(0))):  # Iterate through batch if necessary\n",
    "            _, h, w = img[i].shape\n",
    "            # Generate random dropout size within specified limits\n",
    "            dh = random.randint(self.min_dropout_size[0], self.max_dropout_size[0])\n",
    "            dw = random.randint(self.min_dropout_size[1], self.max_dropout_size[1])\n",
    "            \n",
    "            x1 = int(max((w - dw) / 2, 0))\n",
    "            y1 = int(max((h - dh) / 2, 0))\n",
    "            \n",
    "            mask = torch.ones_like(img[i])\n",
    "            mask[:, y1:y1+dh, x1:x1+dw] = self.fill_value\n",
    "            img[i] = img[i] * mask\n",
    "        \n",
    "        return img\n",
    "\n",
    "    \n",
    "def get_BT_batch_augs(size,\n",
    "                    flip=True,crop=True,noise=True,rotate=True,jitter=True,bw=True,blur=True,solar=True,cutout=False, #Whether to use  given aug or not\n",
    "                    resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.025, rotate_deg=30,jitter_s=.6,blur_s=(4,32),#hps of diff augs\n",
    "                    blur_r=(0.1,2),blur_sig=None,sol_t=0.05,sol_a=0.05,min_dropout_size=(25, 100),max_dropout_size=(50,150), #hps of diff augs\n",
    "                    flip_p=0.5, rotate_p=0.3,noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3,sol_p=0.1,cut_p=0.0, #prob of performing aug\n",
    "                    same_on_batch=False,stats=imagenet_stats,cuda=default_device().type == 'cuda',xtra_tfms=[]\n",
    "                    ):\n",
    "    \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    \n",
    "    tfms = []\n",
    "\n",
    "    korniatfm.RandomHorizontalFlip.order = RandomResizedCrop.order-1\n",
    "\n",
    "\n",
    "    if crop: tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "    #Unfortunately for some reason this doesn't work, so we can't apply \"same_on_batch=False\"\n",
    "    #tfms += [korniatfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio, same_on_batch=same_on_batch)]\n",
    "\n",
    "    if cutout: tfms+=[RandomCenterDropout(min_dropout_size=min_dropout_size,max_dropout_size=max_dropout_size, fill_value=0, p=cut_p,same_on_batch=same_on_batch)]\n",
    "    \n",
    "  \n",
    "    if flip: tfms += [korniatfm.RandomHorizontalFlip(p=flip_p,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if rotate: tfms += [Rotate(max_deg=rotate_deg, p=rotate_p, batch=same_on_batch)]\n",
    "\n",
    "                                             #brightness,contrast,saturation,hue\n",
    "    if jitter: tfms += [korniatfm.ColorJitter(0.4*jitter_s, 0.4*jitter_s, 0.2*jitter_s, 0.1*jitter_s, p=jitter_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if bw:     tfms += [korniatfm.RandomGrayscale(p=bw_p, same_on_batch=same_on_batch)]\n",
    "        \n",
    "    #sig will usually be None\n",
    "    if blur:   tfms += [RandomGaussianBlur(prob=blur_p, s=blur_s,sig=blur_sig,blur_r=blur_r, same_on_batch=same_on_batch)]\n",
    "\n",
    "    korniatfm.RandomSolarize.order = RandomGaussianBlur.order + 1 #we want to apply solarization after RandomGaussianBlur\n",
    "    \n",
    "    if solar: tfms += [korniatfm.RandomSolarize(p=sol_p,thresholds=sol_t, additions=sol_a,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if noise: tfms+=[korniatfm.RandomGaussianNoise(mean=0.0, std=noise_std, same_on_batch=same_on_batch, p=noise_p)]\n",
    "    \n",
    "    if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "\n",
    "    tfms += xtra_tfms\n",
    "\n",
    "    pipe = Pipeline(tfms, split_idx = 0)\n",
    "    return pipe\n",
    "\n",
    "@delegates(get_BT_batch_augs)\n",
    "def get_multi_aug_pipelines(size, **kwargs): return get_BT_batch_augs(size, **kwargs)\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(size=size,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_cifar10_aug_pipelines(size):\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    bt_cifar10_aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return bt_cifar10_aug_pipelines\n",
    "\n",
    "#Add other augmentations here e.g. BYOL augs\n",
    "IMAGENET_Augs = dict(flip_p1=0.5,flip_p2=0.5,jitter_p1=0.8,jitter_p2=0.8,bw_p1=0.2,\n",
    "                bw_p2=0.2,blur_p1=1.0,blur_p2=0.1,sol_p1=0.0,sol_p2=0.2,noise_p1=0.0,\n",
    "                noise_p2=0.0,cut_p=0,resize_scale=(0.7, 1.0),resize_ratio=(3/4, 4/3),rotate_deg=45.0,\n",
    "                rotate_p=0.5,blur_r=(0.1,2),blur_s=13,sol_t=0.1,sol_a=0.1,noise_std=0.1,min_dropout_size=None,max_dropout_size=None,\n",
    "                )\n",
    "\n",
    "DERMNET_Augs = IMAGENET_Augs.copy()\n",
    "DERMNET_Augs['min_dropout_size']=(50, 185)\n",
    "DERMNET_Augs['max_dropout_size']=(100,190)\n",
    "DERMNET_Augs['cut_p']=0.5\n",
    "\n",
    "def helper_get_bt_augs(size,Augs=IMAGENET_Augs):\n",
    "\n",
    "\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p1'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p1'],\n",
    "                        jitter_p=Augs['jitter_p1'], bw_p=Augs['bw_p1'], blur_p=Augs['blur_p1'],\n",
    "                        sol_p=Augs['sol_p1'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p2'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p2'],\n",
    "                        jitter_p=Augs['jitter_p2'], bw_p=Augs['bw_p2'], blur_p=Augs['blur_p2'],\n",
    "                        sol_p=Augs['sol_p2'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return aug_pipelines\n",
    "\n",
    "def get_bt_imagenet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=IMAGENET_Augs)\n",
    "\n",
    "def get_bt_dermnet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=DERMNET_Augs)\n",
    "\n",
    "\n",
    "\n",
    "bt_aug_func_dict = {'bt_cifar10_aug_pipelines':get_bt_cifar10_aug_pipelines,'bt_imagenet_aug_pipelines':get_bt_imagenet_aug_pipelines,\n",
    "                   'bt_dermnet_aug_pipelines':get_bt_dermnet_aug_pipelines\n",
    "                   }\n",
    "\n",
    "def get_bt_aug_pipelines(bt_augs,size):\n",
    "\n",
    "    return bt_aug_func_dict[bt_augs](size)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_ssl_dls(dataset,#cifar10, dermnet, etc\n",
    "            bs,\n",
    "            size,\n",
    "            device,\n",
    "            pct_dataset=1.0):\n",
    "    # Define the base package name in a variable for easy modification\n",
    "\n",
    "    try:\n",
    "        # Construct the module path\n",
    "        module_path = f\"{PACKAGE_NAME}.{dataset}_dataloading\"\n",
    "        \n",
    "        # Dynamically import the module\n",
    "        dataloading_module = importlib.import_module(module_path)\n",
    "    except ModuleNotFoundError:\n",
    "        # Handle the case where the module cannot be found\n",
    "        raise ImportError(f\"Could not find a data loading module for '{dataset}'. \"\n",
    "                          f\"Make sure '{module_path}' exists and is correctly named.\") from None\n",
    "    \n",
    "    # Assuming the function name follows a consistent naming convention\n",
    "    func_name = f\"get_bt_{dataset}_train_dls\"\n",
    "\n",
    "    try:\n",
    "        # Retrieve the data loading function from the module\n",
    "        data_loader_func = getattr(dataloading_module, func_name)\n",
    "    except AttributeError:\n",
    "        # Handle the case where the function does not exist in the module\n",
    "        raise AttributeError(f\"The function '{func_name}' was not found in '{module_path}'. \"\n",
    "                             \"Ensure it is defined and named correctly.\") from None\n",
    "    \n",
    "    # Proceed to call the function with arguments from the config\n",
    "    try:\n",
    "        dls_train = data_loader_func(bs=bs,size=size,device=device,pct_dataset=pct_dataset)\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the function call\n",
    "        raise RuntimeError(f\"An error occurred while calling '{func_name}' from '{module_path}': {e}\") from None\n",
    "    \n",
    "    return dls_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base functions / classes we need to train a BT / RBT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Base functions / classes we need to train a BT / RBT model.\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        \n",
    "    def forward(self,x): \n",
    "        \n",
    "        return self.projector(self.encoder(x))\n",
    "\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines,n_in,lmb,sparsity_level, \n",
    "                model_type='barlow_twins',print_augs=False\n",
    "                 ):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        store_attr('sparsity_level')\n",
    "        self.n_in=n_in\n",
    "        self.model_type = model_type\n",
    "        self.index=-1 #Gets updated after each batch\n",
    "        self.acc_dict = {}\n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self.index=-1  \n",
    "  \n",
    "    def before_batch(self):\n",
    "        \n",
    "        #TODO: Make this nicer (possibly can load in data as TensorImage(BW) or something?)\n",
    "        #This is a bit of a hack. Can make this more elegant later. But in new version of FastAI\n",
    "        #seems we need to compute TensorImage(BW) here, and depends on whether color or not, i.e. n_in.\n",
    "        if self.n_in == 1:\n",
    "\n",
    "            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            \n",
    "            #print(xi.shape)\n",
    "                                    \n",
    "        elif self.n_in == 3:\n",
    "            \n",
    "            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "\n",
    "        self.index=self.index+1\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1): \n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]]\n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#We want access to both representation and projection\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        \n",
    "    def forward(self,x): \n",
    "        tem = self.encoder(x)\n",
    "        return tem,self.projector(tem)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'forward returns tuple of (encoder(x),projector(encoder(x)))'\n",
    "\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    " \n",
    "    return BarlowTwinsModel(encoder, projector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we write down standard definition of `lf` for `RAT` method: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BarlowTwins needs an `lf` method to work properly. Here we provide the `lf` of standard barlow twins. Later we can\n",
    "patch in a new defintion of `lf` that involves random functions, inner maximization etc. The tools needed to do this are provised in `base_lf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt(pred,I,lmb):\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "    \n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs \n",
    "    cdiff = (C - I)**2\n",
    "    loss = (cdiff*I + cdiff*(1-I)*lmb).sum() \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_indiv_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb*(0.5*torch.abs(z1_enc) + 0.5*torch.abs(z2_enc)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BarlowTwinsModel(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (projector): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (1): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=8192, out_features=8192, bias=True)\n",
       "    (4): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=8192, out_features=8192, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from base_rbt.utils import *\n",
    "encoder = resnet_arch_to_encoder('resnet50',weight_type='random')\n",
    "model = create_barlow_twins_model(encoder, hidden_size=8192, projection_size=8192, bn=True, nlayers=3)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1_enc.pow(2) + 0.5 * z2_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_norm_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_fun(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm_enc.T @ z2norm_enc) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    loss = (cdiff*I).sum() #standard bt loss\n",
    "\n",
    "    print(f\"invariance loss is: {loss} and sparsity loss is: {sparsity}\")\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_proj_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                           ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm.pow(2) + 0.5 * z2norm.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb):\n",
    "    \"Assumes model created according to type p3\"\n",
    "\n",
    "    if self.model_type=='barlow_twins':\n",
    "         pred_enc = pred[0]\n",
    "         pred = pred[1]\n",
    "         return lf_bt(pred, self.I,self.lmb)\n",
    "\n",
    "    elif self.model_type=='indiv_sparse_barlow_twins':\n",
    "        return lf_bt_indiv_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='group_sparse_barlow_twins':\n",
    "        return lf_bt_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='group_norm_sparse_barlow_twins':\n",
    "        return lf_bt_group_norm_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='proj_group_sparse_barlow_twins':\n",
    "        return lf_bt_proj_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='fun':\n",
    "        return lf_bt_fun(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "\n",
    "    else: raise(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt(m):\n",
    "    return L(sequential(*m.encoder),m.projector).map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to use the above functions in an end to end fashion. First we get some data and plonk it into a dls, Then create an encoder, an augmentation pipeline, a learner, then fit\n",
    "the learner. This is the complete process of training BT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_bt_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "        \n",
    "    learn = Learner(dls,model=None, cbs=[BarlowTwins(aug,n_in=n_in,lmb=None,sparsity_level=None,\n",
    "                                                     print_augs=print_augs\n",
    "                                        )])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.barlow_twins.show(n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SaveBarlowLearnerCheckpoint(Callback):\n",
    "    \"Save such that can resume training \"\n",
    "    def __init__(self, experiment_dir,start_epoch=0, save_interval=250,with_opt=True):\n",
    "        self.experiment_dir = experiment_dir\n",
    "        self.start_epoch = start_epoch\n",
    "        self.save_interval = save_interval\n",
    "        self.with_opt = with_opt  # Decide whether to save optimizer state as well.\n",
    "\n",
    "    def after_epoch(self):\n",
    "        if (self.epoch+1) % self.save_interval == 0 and self.epoch>=self.start_epoch:\n",
    "            print(f\"Saving model and learner state at epoch {self.epoch}\")\n",
    "   \n",
    "            checkpoint_filename = f\"learner_checkpoint_epoch_{self.epoch}\"\n",
    "            checkpoint_path = os.path.join(self.experiment_dir, checkpoint_filename)\n",
    "            # Save the entire learner object, including the model's parameters and optimizer state.\n",
    "            self.learn.save(checkpoint_path, with_opt=self.with_opt)\n",
    "            print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "class SaveBarlowLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        encoder_filename = f\"trained_encoder_epoch_{self.epoch}.pth\"\n",
    "        encoder_path = os.path.join(self.experiment_dir, encoder_filename)\n",
    "        torch.save(self.learn.model.encoder.state_dict(), encoder_path)\n",
    "        print(f\"encoder state dict saved to {encoder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_barlow_model(arch,ps,hs,path):\n",
    "\n",
    "    encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_barlow_twins_model(encoder, hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BarlowTrainer:\n",
    "    \"Setup a learner for training a BT model. Can do transfer learning, normal training, or resume training.\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,#An encoder followed by a projector\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 lmb,\n",
    "                 sparsity_level,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 num_it=100, #Number of iterations to run lr_find for.\n",
    "                 load_learner_path=None, #Path to load learner from (optional)\n",
    "                 experiment_dir=None, #Where to save model checkpoints (optional)\n",
    "                 start_epoch=0, #Which epoch to start from\n",
    "                 save_interval=None, #How often to save model checkpoints (optional). \n",
    "                 export=False,\n",
    "                 ):\n",
    "\n",
    "        store_attr()\n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    \n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics.\n",
    "\n",
    "        Returns:\n",
    "        - learn: The Learner object.\n",
    "        \"\"\"\n",
    "      \n",
    "        self.model.to(self.device)\n",
    "\n",
    "        cbs = [BarlowTwins(self.bt_aug_pipelines,n_in=self.n_in,lmb=self.lmb,\n",
    "                           sparsity_level=self.sparsity_level,print_augs=False,\n",
    "                           model_type=self.model_type\n",
    "                           )\n",
    "              ]\n",
    "\n",
    "        learn=Learner(self.dls,self.model,splitter=my_splitter_bt,wd=self.wd, cbs=cbs\n",
    "                     )\n",
    "        \n",
    "        if self.load_learner_path: learn.load(self.load_learner_path,with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir:\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export:\n",
    "            cbs.append(SaveBarlowLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "                \n",
    "    \n",
    "    def bt_transfer_learning(self,freeze_epochs:int,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is already pretrained, we can do transfer learning.\n",
    "            Freeze encoder, train projector for a few epochs, then unfreeze and train all. \n",
    "        \"\"\"\n",
    "\n",
    "        self.learn.freeze()\n",
    "        test_grad_off(self.learn.encoder)\n",
    "        #self.learn.fit(freeze_epochs)\n",
    "        self.learn.fit_one_cycle(freeze_epochs, 2e-3, pct_start=0.99) #lifted from fastai `fine_tune`\n",
    "        self.learn.unfreeze()\n",
    "        test_grad_on(self.learn.model)\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it) #lets find a good maximum lr\n",
    "        lr=lrs.valley\n",
    "        discriminative_lrs = slice(lr/10,lr)\n",
    "        self.learn.fit_one_cycle(epochs, discriminative_lrs, pct_start=0.3, div=5.0, cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def bt_learning(self,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is not pretrained, we can do normal training.\n",
    "        \"\"\"\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "    \n",
    "    def continue_bt_learning(self,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Resume training with `fit_one_cycle` after loading a learner.\n",
    "        \"\"\"\n",
    "        \n",
    "        test_ne(self.load_learner_path,None)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs,start_epoch=start_epoch,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def train(self,learn_type, freeze_epochs:int,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Train model using BT\n",
    "        \"\"\"\n",
    "        if learn_type == 'transfer_learning':\n",
    "            \n",
    "            self.bt_transfer_learning(freeze_epochs=freeze_epochs,epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        elif learn_type=='continue_learning':\n",
    "            self.continue_bt_learning(epochs=epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "        \n",
    "        elif learn_type=='standard':\n",
    "            self.bt_learning(epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        else: raise Exception(\"Invalid weight_type\")\n",
    "\n",
    "        return self.learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a BT model. Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "    encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    \n",
    "    model = create_barlow_twins_model(encoder, hidden_size=config.hs, projection_size=config.ps)\n",
    "\n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    bt_trainer = BarlowTrainer(model=model,\n",
    "                    dls=dls,\n",
    "                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                    lmb=config.lmb,\n",
    "                    sparsity_level=config.sparsity_level,\n",
    "                    n_in=config.n_in,\n",
    "                    model_type=config.model_type,\n",
    "                    wd=config.wd,\n",
    "                    num_it=config.num_it,\n",
    "                    device=device,\n",
    "                    load_learner_path=load_learner_path,\n",
    "                    experiment_dir=experiment_dir,\n",
    "                    start_epoch=start_epoch,\n",
    "                    save_interval=config.save_interval,\n",
    "                    export=export\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = bt_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_path = '../configs/cifar10/bt_test_config.yaml'\n",
    "# config = load_config(config_path)\n",
    "\n",
    "# load_learner_path=None\n",
    "# experiment_dir=None\n",
    "# start_epoch=0\n",
    "\n",
    "\n",
    "# # Initialize the device for model training (CUDA or CPU)\n",
    "# device = default_device()\n",
    "\n",
    "# # Construct the model based on the configuration\n",
    "# # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "# encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "\n",
    "# model = create_barlow_twins_model(encoder, hidden_size=config.hs, projection_size=config.ps)\n",
    "\n",
    "# # Prepare data loaders according to the dataset specified in the configuration\n",
    "# dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "# # Set up data augmentation pipelines as specified in the configuration\n",
    "# bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "# # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "# #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "# bt_trainer = BarlowTrainer(model=model,\n",
    "#                dls=dls,\n",
    "#                bt_aug_pipelines=bt_aug_pipelines,\n",
    "#                lmb=config.lmb,\n",
    "#                sparsity_level=config.sparsity_level,\n",
    "#                n_in=config.n_in,\n",
    "#                model_type=config.model_type,\n",
    "#                wd=config.wd,\n",
    "#                num_it=config.num_it,\n",
    "#                device=device,\n",
    "#                load_learner_path=load_learner_path,\n",
    "#                experiment_dir=experiment_dir,\n",
    "#                start_epoch=start_epoch,\n",
    "#                save_interval=config.save_interval\n",
    "#                               )\n",
    "\n",
    "\n",
    "# bt_trainer.learn.lr_find??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_experiment_state(config,base_dir):\n",
    "    \"\"\"Get the load_learner_path, learn_type, start_epoch, interrupt_epoch for BT experiment.\n",
    "       Basically this tells us how to continue learning (e.g. we have run two sessions for \n",
    "       100 epochs, and want to continue for another 100 epochs). Return values are\n",
    "       None if we are starting from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    load_learner_path, _  = get_highest_num_path(base_dir, config)\n",
    "    #TODO:\n",
    "    #We can get start_epoch, interrupt epoch from `get_highest_epoch_path` + save_interval (may be None!)\n",
    "    start_epoch=0 if load_learner_path is None else int(load_learner_path.split('_')[-1])+1\n",
    "    \n",
    "    if start_epoch >= config.epochs:\n",
    "        print(f\"start_epoch={start_epoch}, but already completed {config.epochs} epochs. Exiting.\")\n",
    "        sys.exit()\n",
    "\n",
    "    interrupt_epoch = start_epoch + config.save_interval\n",
    "\n",
    "    #We can also get the learn_type from the load_learner_path + weight_type. \n",
    "    \n",
    "    if config.weight_type == 'random':\n",
    "        learn_type = 'standard'\n",
    "    \n",
    "    elif 'pretrained' in config.weight_type:\n",
    "        learn_type = 'transfer_learning'\n",
    "\n",
    "    learn_type = learn_type if load_learner_path is None else 'continue_learning'\n",
    "\n",
    "    return load_learner_path, learn_type, start_epoch, interrupt_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_experiment(config,\n",
    "                      base_dir,\n",
    "                      ):\n",
    "    \"\"\"Run several epochs of the experiment as defined in the config and where we are up to. e.g. epoch 0, or resuming\n",
    "    at epoch 99 etc. Basically a stateful version of `main_bt_train` that can be resumed. And saving.\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    experiment_dir, experiment_hash,git_commit_hash = setup_experiment(config,base_dir)\n",
    "\n",
    "    load_learner_path, learn_type, start_epoch, interrupt_epoch = get_bt_experiment_state(config,base_dir)\n",
    "\n",
    "    main_bt_train(config=config,\n",
    "            start_epoch=start_epoch,\n",
    "            interrupt_epoch=interrupt_epoch,\n",
    "            load_learner_path=load_learner_path,\n",
    "            learn_type=learn_type,\n",
    "            experiment_dir=experiment_dir,\n",
    "            )\n",
    "\n",
    "    # Save a metadata file in the experiment directory with the Git commit hash and other details\n",
    "    save_metadata_file(experiment_dir=experiment_dir, git_commit_hash=git_commit_hash)\n",
    "\n",
    "    # After experiment execution and all processing are complete\n",
    "    update_experiment_index(base_dir,{\n",
    "        \"experiment_hash\": experiment_hash,  # Unique identifier derived from the experiment's configuration\n",
    "        \"experiment_dir\": experiment_dir,  # Absolute path to the experiment's dedicated directory\n",
    "        \"git_commit_hash\": git_commit_hash,  # Git commit hash for the code version used in the experiment\n",
    "        # Potentially include additional details collected during or after the experiment, such as:\n",
    "        # Any other metadata or results summary that is relevant to the experiment\n",
    "                            })\n",
    "    \n",
    "    return experiment_dir,experiment_hash #Return the experiment_dir so we can easily access the results of the experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpfp7qoyge/SSL/cifar10/smallres/00ff5d7e and the experiment hash is: 00ff5d7e\n",
      "Configuration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpfp7qoyge/SSL/cifar10/smallres/00ff5d7e/config.yaml\n",
      "The git hash is: f10439d5e324d23952acec492ec116f94e92ea28\n",
      "Looking in /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpfp7qoyge/SSL/cifar10/smallres/00ff5d7e for highest num saved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb Cell 35\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m config_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../configs/cifar10/bt_test_config.yaml\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m experiment_dir,experiment_hash \u001b[39m=\u001b[39m main_bt_experiment(config,base_dir)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39mlistdir(experiment_dir))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39mlistdir(base_dir))\n",
      "\u001b[1;32m/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m experiment_dir, experiment_hash,git_commit_hash \u001b[39m=\u001b[39m setup_experiment(config,base_dir)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m load_learner_path, learn_type, start_epoch, interrupt_epoch \u001b[39m=\u001b[39m get_bt_experiment_state(config,base_dir)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m main_bt_train(config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         start_epoch\u001b[39m=\u001b[39;49mstart_epoch,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         interrupt_epoch\u001b[39m=\u001b[39;49minterrupt_epoch,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         load_learner_path\u001b[39m=\u001b[39;49mload_learner_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         learn_type\u001b[39m=\u001b[39;49mlearn_type,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         experiment_dir\u001b[39m=\u001b[39;49mexperiment_dir,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Save a metadata file in the experiment directory with the Git commit hash and other details\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m save_metadata_file(experiment_dir\u001b[39m=\u001b[39mexperiment_dir, git_commit_hash\u001b[39m=\u001b[39mgit_commit_hash)\n",
      "\u001b[1;32m/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb Cell 35\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m model \u001b[39m=\u001b[39m create_barlow_twins_model(encoder, hidden_size\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mhs, projection_size\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mps)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Prepare data loaders according to the dataset specified in the configuration\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m dls \u001b[39m=\u001b[39m get_ssl_dls(dataset\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdataset, bs\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mbs,size\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49msize, device\u001b[39m=\u001b[39;49mdevice,pct_dataset\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpct_dataset)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Set up data augmentation pipelines as specified in the configuration\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m bt_aug_pipelines \u001b[39m=\u001b[39m get_bt_aug_pipelines(bt_augs\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mbt_augs, size\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39msize)\n",
      "\u001b[1;32m/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb Cell 35\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Proceed to call the function with arguments from the config\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     dls_train \u001b[39m=\u001b[39m data_loader_func(bs\u001b[39m=\u001b[39;49mbs,size\u001b[39m=\u001b[39;49msize,device\u001b[39m=\u001b[39;49mdevice,pct_dataset\u001b[39m=\u001b[39;49mpct_dataset)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# Handle any errors that occur during the function call\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#Y122sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfunc_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m from \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodule_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m~/base_rbt/base_rbt/cifar10_dataloading.py:20\u001b[0m, in \u001b[0;36mget_bt_cifar10_train_dls\u001b[0;34m(bs, size, device, pct_dataset, num_workers)\u001b[0m\n\u001b[1;32m     18\u001b[0m path,fnames_train, labels_train \u001b[39m=\u001b[39m load_cifar10_train_data(pct_dataset)\n\u001b[1;32m     19\u001b[0m test_eq(\u001b[39mlen\u001b[39m(labels_train), \u001b[39mlen\u001b[39m(fnames_train))\n\u001b[0;32m---> 20\u001b[0m dls \u001b[39m=\u001b[39m ImageDataLoaders\u001b[39m.\u001b[39;49mfrom_lists(path, fnames_train, labels_train, bs\u001b[39m=\u001b[39;49mbs, item_tfms\u001b[39m=\u001b[39;49m[Resize(size\u001b[39m=\u001b[39;49msize)],\n\u001b[1;32m     21\u001b[0m                                   valid_pct\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m, num_workers\u001b[39m=\u001b[39;49mnum_workers, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m pct_dataset \u001b[39m==\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m     23\u001b[0m     test_eq(\u001b[39mlen\u001b[39m(dls\u001b[39m.\u001b[39mtrain), \u001b[39m50000\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/vision/data.py:198\u001b[0m, in \u001b[0;36mImageDataLoaders.from_lists\u001b[0;34m(cls, path, fnames, labels, valid_pct, seed, y_block, item_tfms, batch_tfms, img_cls, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     y_block \u001b[39m=\u001b[39m MultiCategoryBlock \u001b[39mif\u001b[39;00m is_listy(labels[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(labels[\u001b[39m0\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m (\n\u001b[1;32m    193\u001b[0m         RegressionBlock \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(labels[\u001b[39m0\u001b[39m], \u001b[39mfloat\u001b[39m) \u001b[39melse\u001b[39;00m CategoryBlock)\n\u001b[1;32m    194\u001b[0m dblock \u001b[39m=\u001b[39m DataBlock\u001b[39m.\u001b[39mfrom_columns(blocks\u001b[39m=\u001b[39m(ImageBlock(img_cls), y_block),\n\u001b[1;32m    195\u001b[0m                    splitter\u001b[39m=\u001b[39mRandomSplitter(valid_pct, seed\u001b[39m=\u001b[39mseed),\n\u001b[1;32m    196\u001b[0m                    item_tfms\u001b[39m=\u001b[39mitem_tfms,\n\u001b[1;32m    197\u001b[0m                    batch_tfms\u001b[39m=\u001b[39mbatch_tfms)\n\u001b[0;32m--> 198\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_dblock(dblock, (fnames, labels), path\u001b[39m=\u001b[39;49mpath, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/data/core.py:281\u001b[0m, in \u001b[0;36mDataLoaders.from_dblock\u001b[0;34m(cls, dblock, source, path, bs, val_bs, shuffle, device, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    271\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_dblock\u001b[39m(\u001b[39mcls\u001b[39m, \n\u001b[1;32m    272\u001b[0m     dblock, \u001b[39m# `DataBlock` object\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    280\u001b[0m ):\n\u001b[0;32m--> 281\u001b[0m     \u001b[39mreturn\u001b[39;00m dblock\u001b[39m.\u001b[39;49mdataloaders(source, path\u001b[39m=\u001b[39;49mpath, bs\u001b[39m=\u001b[39;49mbs, val_bs\u001b[39m=\u001b[39;49mval_bs, shuffle\u001b[39m=\u001b[39;49mshuffle, device\u001b[39m=\u001b[39;49mdevice, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/data/block.py:157\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[0;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m dsets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatasets(source, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[1;32m    156\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, \u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m: verbose}\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m dsets\u001b[39m.\u001b[39;49mdataloaders(path\u001b[39m=\u001b[39;49mpath, after_item\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitem_tfms, after_batch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_tfms, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/data/core.py:334\u001b[0m, in \u001b[0;36mFilteredBase.dataloaders\u001b[0;34m(self, bs, shuffle_train, shuffle, val_shuffle, n, path, dl_type, dl_kwargs, device, drop_last, val_bs, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m dl \u001b[39m=\u001b[39m dl_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubset(\u001b[39m0\u001b[39m), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[39m0\u001b[39m]))\n\u001b[1;32m    333\u001b[0m def_kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mbs\u001b[39m\u001b[39m'\u001b[39m:bs \u001b[39mif\u001b[39;00m val_bs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m val_bs,\u001b[39m'\u001b[39m\u001b[39mshuffle\u001b[39m\u001b[39m'\u001b[39m:val_shuffle,\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mNone\u001b[39;00m,\u001b[39m'\u001b[39m\u001b[39mdrop_last\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mFalse\u001b[39;00m}\n\u001b[0;32m--> 334\u001b[0m dls \u001b[39m=\u001b[39m [dl] \u001b[39m+\u001b[39m [dl\u001b[39m.\u001b[39mnew(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubset(i), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))\n\u001b[1;32m    335\u001b[0m               \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_subsets)]\n\u001b[1;32m    336\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dbunch_type(\u001b[39m*\u001b[39mdls, path\u001b[39m=\u001b[39mpath, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/data/core.py:334\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    332\u001b[0m dl \u001b[39m=\u001b[39m dl_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubset(\u001b[39m0\u001b[39m), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[39m0\u001b[39m]))\n\u001b[1;32m    333\u001b[0m def_kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mbs\u001b[39m\u001b[39m'\u001b[39m:bs \u001b[39mif\u001b[39;00m val_bs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m val_bs,\u001b[39m'\u001b[39m\u001b[39mshuffle\u001b[39m\u001b[39m'\u001b[39m:val_shuffle,\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mNone\u001b[39;00m,\u001b[39m'\u001b[39m\u001b[39mdrop_last\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mFalse\u001b[39;00m}\n\u001b[0;32m--> 334\u001b[0m dls \u001b[39m=\u001b[39m [dl] \u001b[39m+\u001b[39m [dl\u001b[39m.\u001b[39;49mnew(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubset(i), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmerge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))\n\u001b[1;32m    335\u001b[0m               \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_subsets)]\n\u001b[1;32m    336\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dbunch_type(\u001b[39m*\u001b[39mdls, path\u001b[39m=\u001b[39mpath, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/data/core.py:97\u001b[0m, in \u001b[0;36mTfmdDL.new\u001b[0;34m(self, dataset, cls, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_n_inp\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_types\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     96\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_one_pass()\n\u001b[1;32m     98\u001b[0m         res\u001b[39m.\u001b[39m_n_inp,res\u001b[39m.\u001b[39m_types \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_inp,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_types\n\u001b[1;32m     99\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e: \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/data/core.py:78\u001b[0m, in \u001b[0;36mTfmdDL._one_pass\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_one_pass\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 78\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_batch([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_item(\u001b[39mNone\u001b[39;49;00m)])\n\u001b[1;32m     79\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: b \u001b[39m=\u001b[39m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     80\u001b[0m     its \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter_batch(b)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/data/load.py:168\u001b[0m, in \u001b[0;36mDataLoader.do_batch\u001b[0;34m(self, b)\u001b[0m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_batch\u001b[39m(\u001b[39mself\u001b[39m, b): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_batch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbefore_batch(b)), b)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/data/load.py:164\u001b[0m, in \u001b[0;36mDataLoader.create_batch\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_batch\u001b[39m(\u001b[39mself\u001b[39m, b): \n\u001b[0;32m--> 164\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mreturn\u001b[39;00m (fa_collate,fa_convert)[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprebatched](b)\n\u001b[1;32m    165\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e: \n\u001b[1;32m    166\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprebatched: collate_error(e,b)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/data/load.py:51\u001b[0m, in \u001b[0;36mfa_collate\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mA replacement for PyTorch `default_collate` which maintains types and handles `Sequence`s\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m b \u001b[39m=\u001b[39m t[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 51\u001b[0m \u001b[39mreturn\u001b[39;00m (default_collate(t) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(b, _collate_types)\n\u001b[1;32m     52\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mtype\u001b[39m(t[\u001b[39m0\u001b[39m])([fa_collate(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mt)]) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(b, Sequence)\n\u001b[1;32m     53\u001b[0m         \u001b[39melse\u001b[39;00m default_collate(t))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/typing.py:994\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__instancecheck__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__instancecheck__\u001b[39m(\u001b[39mself\u001b[39m, obj):\n\u001b[0;32m--> 994\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__subclasscheck__\u001b[39;49m(\u001b[39mtype\u001b[39;49m(obj))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/typing.py:1158\u001b[0m, in \u001b[0;36m_SpecialGenericAlias.__subclasscheck__\u001b[0;34m(self, cls)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m__origin__, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__origin__)\n\u001b[1;32m   1157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mcls\u001b[39m, _GenericAlias):\n\u001b[0;32m-> 1158\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39missubclass\u001b[39;49m(\u001b[39mcls\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__origin__)\n\u001b[1;32m   1159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__subclasscheck__\u001b[39m(\u001b[39mcls\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/abc.py:123\u001b[0m, in \u001b[0;36mABCMeta.__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__subclasscheck__\u001b[39m(\u001b[39mcls\u001b[39m, subclass):\n\u001b[1;32m    122\u001b[0m     \u001b[39m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m _abc_subclasscheck(\u001b[39mcls\u001b[39;49m, subclass)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/abc.py:123\u001b[0m, in \u001b[0;36mABCMeta.__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__subclasscheck__\u001b[39m(\u001b[39mcls\u001b[39m, subclass):\n\u001b[1;32m    122\u001b[0m     \u001b[39m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m _abc_subclasscheck(\u001b[39mcls\u001b[39;49m, subclass)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/abc.py:123\u001b[0m, in \u001b[0;36mABCMeta.__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__subclasscheck__\u001b[39m(\u001b[39mcls\u001b[39m, subclass):\n\u001b[1;32m    122\u001b[0m     \u001b[39m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m _abc_subclasscheck(\u001b[39mcls\u001b[39;49m, subclass)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/_collections_abc.py:409\u001b[0m, in \u001b[0;36mCollection.__subclasshook__\u001b[0;34m(cls, C)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCollection\u001b[39;00m(Sized, Iterable, Container):\n\u001b[1;32m    407\u001b[0m     \u001b[39m__slots__\u001b[39m \u001b[39m=\u001b[39m ()\n\u001b[0;32m--> 409\u001b[0m     \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    410\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__subclasshook__\u001b[39m(\u001b[39mcls\u001b[39m, C):\n\u001b[1;32m    411\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m Collection:\n\u001b[1;32m    412\u001b[0m             \u001b[39mreturn\u001b[39;00m _check_methods(C,  \u001b[39m\"\u001b[39m\u001b[39m__len__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m__iter__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m__contains__\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "    config_path = '../configs/cifar10/bt_test_config.yaml'\n",
    "    config = load_config(config_path)\n",
    "\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "    print(os.listdir(experiment_dir))\n",
    "    print(os.listdir(base_dir))\n",
    "    print('experiment_dir and base_dir')\n",
    "\n",
    "    print('We can keep training - resuming from the checkpoint')\n",
    "\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    print(os.listdir(experiment_dir))\n",
    "    print(os.listdir(base_dir))\n",
    "    print('experiment_dir and base_dir')\n",
    "\n",
    "    #get path to fully fitted model\n",
    "    path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "    model = load_barlow_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "    print(model)\n",
    "\n",
    "    #New config but the first part of experiment_dir is same - just hash is different\n",
    "    #It shouldnt find a max file path\n",
    "    config.epochs=config.epochs+1\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
