{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_model\n",
    "\n",
    "> In this module we have the base model, learner and other things we need to train encoder with Barlow Twins and other methods.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import importlib\n",
    "import sys\n",
    "import self_supervised\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import kornia.augmentation as korniatfm\n",
    "import torchvision.transforms as tvtfm\n",
    "from base_rbt.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the base functions and classes to train a basic BT-style model. Note that this (mostly) all comes directly from here: `https://github.com/KeremTurgutlu/self_supervised/blob/main/nbs/14%20-%20barlow_twins.ipynb`\n",
    "but we needed to extend some of the functionality for our purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the base classes and functions needed for image augmentation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#My edited version of RandTransform\n",
    "class RandomGaussianBlur(RandTransform):\n",
    "    \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "    order = 11\n",
    "    def __init__(self, \n",
    "                 p=1.0, #debugging (bug in libraries implementation)\n",
    "                 prob=0.5,#the real probability\n",
    "                 s=(8,32), #kernel\n",
    "                 sig=None, #sig_val is either manually input OR\n",
    "                 blur_r=(0.1,2),#is randomly chosen from uniform with these bounds\n",
    "                 same_on_batch=False, \n",
    "                 **kwargs): \n",
    "        \n",
    "        store_attr()\n",
    "        super().__init__(p=p, **kwargs)\n",
    "\n",
    "    def encodes(self, x:TensorImage):\n",
    "        \n",
    "        if isinstance(self.s, int):   s = (self.s,self.s)\n",
    "        elif isinstance(self.s, tuple) or isinstance(self.s, list): s=self.s\n",
    "     \n",
    "        #Default for ImageNet from BYOL / BT papers\n",
    "        if self.sig is None:\n",
    "            sig_val = np.random.uniform(self.blur_r[0],self.blur_r[1])\n",
    "        \n",
    "        else:\n",
    "            sig_val = self.sig\n",
    "            \n",
    "\n",
    "        tfm = korniatfm.RandomGaussianBlur(kernel_size=s,sigma=(sig_val,sig_val),same_on_batch=self.same_on_batch,p=self.prob)\n",
    "        return tfm(x)\n",
    "\n",
    "#Delete later: leaving for backward compatibility for now\n",
    "# class RandomGaussianBlur(RandTransform):\n",
    "#     \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "#     order = 11\n",
    "#     def __init__(self, p=0.5, s=(8,32), same_on_batch=False, **kwargs): \n",
    "#         store_attr()\n",
    "#         super().__init__(p=p, **kwargs)\n",
    "        \n",
    "#     def encodes(self, x:TensorImage):\n",
    "#         if isinstance(self.s, tuple): s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, list):  s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, int):   s = self.s\n",
    "#         s2 = int(s/4)*2+1\n",
    "#         tfm = korniatfm.RandomGaussianBlur((s2,s2),(s,s),same_on_batch=self.same_on_batch,p=1.) #p=1. is a bug\n",
    "#                                             #kernel #sigma\n",
    "        \n",
    "#         return tfm(x)\n",
    "\n",
    "\n",
    "class RandomCenterDropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.5, min_dropout_size=(20, 20), max_dropout_size=(60, 60), fill_value=0, same_on_batch=False):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.min_dropout_size = min_dropout_size\n",
    "        self.max_dropout_size = max_dropout_size\n",
    "        self.fill_value = fill_value\n",
    "        self.same_on_batch = same_on_batch\n",
    "        #self.id_transform = tvtfm.RandomResizedCrop((256, 256), scale=(1.,1.), ratio=(1.,1.))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Check if the augmentation should be applied to the whole batch or individually\n",
    "\n",
    "        #x=self.id_transform(x)\n",
    "\n",
    "        if self.same_on_batch:\n",
    "            if random.random() < self.p:\n",
    "                return self._apply_dropout(x)\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            # Apply dropout individually with given probability\n",
    "            for i in range(x.size(0)):\n",
    "                tem=random.random()\n",
    "                #print(f\"tem is: {tem}\")\n",
    "                if tem < self.p:\n",
    "                    x[i] = self._apply_dropout(x[i].unsqueeze(0)).squeeze(0)\n",
    "            return x\n",
    "\n",
    "    def _apply_dropout(self, img):\n",
    "        for i,count in enumerate(range(img.size(0))):  # Iterate through batch if necessary\n",
    "            _, h, w = img[i].shape\n",
    "            # Generate random dropout size within specified limits\n",
    "            dh = random.randint(self.min_dropout_size[0], self.max_dropout_size[0])\n",
    "            dw = random.randint(self.min_dropout_size[1], self.max_dropout_size[1])\n",
    "            \n",
    "            x1 = int(max((w - dw) / 2, 0))\n",
    "            y1 = int(max((h - dh) / 2, 0))\n",
    "            \n",
    "            mask = torch.ones_like(img[i])\n",
    "            mask[:, y1:y1+dh, x1:x1+dw] = self.fill_value\n",
    "            img[i] = img[i] * mask\n",
    "        \n",
    "        return img\n",
    "\n",
    "    \n",
    "def get_BT_batch_augs(size,\n",
    "                    flip=True,crop=True,noise=True,rotate=True,jitter=True,bw=True,blur=True,solar=True,cutout=False, #Whether to use  given aug or not\n",
    "                    resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.025, rotate_deg=30,jitter_s=.6,blur_s=(4,32),#hps of diff augs\n",
    "                    blur_r=(0.1,2),blur_sig=None,sol_t=0.05,sol_a=0.05,min_dropout_size=(25, 100),max_dropout_size=(50,150), #hps of diff augs\n",
    "                    flip_p=0.5, rotate_p=0.3,noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3,sol_p=0.1,cut_p=0.0, #prob of performing aug\n",
    "                    same_on_batch=False,stats=imagenet_stats,cuda=default_device().type == 'cuda',xtra_tfms=[]\n",
    "                    ):\n",
    "    \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    \n",
    "    tfms = []\n",
    "\n",
    "    korniatfm.RandomHorizontalFlip.order = RandomResizedCrop.order-1\n",
    "\n",
    "\n",
    "    if crop: tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "    #Unfortunately for some reason this doesn't work, so we can't apply \"same_on_batch=False\"\n",
    "    #tfms += [korniatfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio, same_on_batch=same_on_batch)]\n",
    "\n",
    "    if cutout: tfms+=[RandomCenterDropout(min_dropout_size=min_dropout_size,max_dropout_size=max_dropout_size, fill_value=0, p=cut_p,same_on_batch=same_on_batch)]\n",
    "    \n",
    "  \n",
    "    if flip: tfms += [korniatfm.RandomHorizontalFlip(p=flip_p,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if rotate: tfms += [Rotate(max_deg=rotate_deg, p=rotate_p, batch=same_on_batch)]\n",
    "\n",
    "                                             #brightness,contrast,saturation,hue\n",
    "    if jitter: tfms += [korniatfm.ColorJitter(0.4*jitter_s, 0.4*jitter_s, 0.2*jitter_s, 0.1*jitter_s, p=jitter_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if bw:     tfms += [korniatfm.RandomGrayscale(p=bw_p, same_on_batch=same_on_batch)]\n",
    "        \n",
    "    #sig will usually be None\n",
    "    if blur:   tfms += [RandomGaussianBlur(prob=blur_p, s=blur_s,sig=blur_sig,blur_r=blur_r, same_on_batch=same_on_batch)]\n",
    "\n",
    "    korniatfm.RandomSolarize.order = RandomGaussianBlur.order + 1 #we want to apply solarization after RandomGaussianBlur\n",
    "    \n",
    "    if solar: tfms += [korniatfm.RandomSolarize(p=sol_p,thresholds=sol_t, additions=sol_a,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if noise: tfms+=[korniatfm.RandomGaussianNoise(mean=0.0, std=noise_std, same_on_batch=same_on_batch, p=noise_p)]\n",
    "    \n",
    "    if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "\n",
    "    tfms += xtra_tfms\n",
    "\n",
    "    pipe = Pipeline(tfms, split_idx = 0)\n",
    "    return pipe\n",
    "\n",
    "@delegates(get_BT_batch_augs)\n",
    "def get_multi_aug_pipelines(size, **kwargs): return get_BT_batch_augs(size, **kwargs)\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(size=size,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_cifar10_aug_pipelines(size):\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    bt_cifar10_aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return bt_cifar10_aug_pipelines\n",
    "\n",
    "#Add other augmentations here e.g. BYOL augs\n",
    "IMAGENET_Augs = dict(flip_p1=0.5,flip_p2=0.5,jitter_p1=0.8,jitter_p2=0.8,bw_p1=0.2,\n",
    "                bw_p2=0.2,blur_p1=1.0,blur_p2=0.1,sol_p1=0.0,sol_p2=0.2,noise_p1=0.0,\n",
    "                noise_p2=0.0,cut_p=0,resize_scale=(0.7, 1.0),resize_ratio=(3/4, 4/3),rotate_deg=45.0,\n",
    "                rotate_p=0.5,blur_r=(0.1,2),blur_s=13,sol_t=0.1,sol_a=0.1,noise_std=0.1,min_dropout_size=None,max_dropout_size=None,\n",
    "                )\n",
    "\n",
    "DERMNET_Augs = IMAGENET_Augs.copy()\n",
    "DERMNET_Augs['min_dropout_size']=(50, 185)\n",
    "DERMNET_Augs['max_dropout_size']=(100,190)\n",
    "DERMNET_Augs['cut_p']=0.33\n",
    "\n",
    "def helper_get_bt_augs(size,Augs=IMAGENET_Augs):\n",
    "\n",
    "\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p1'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p1'],\n",
    "                        jitter_p=Augs['jitter_p1'], bw_p=Augs['bw_p1'], blur_p=Augs['blur_p1'],\n",
    "                        sol_p=Augs['sol_p1'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p2'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p2'],\n",
    "                        jitter_p=Augs['jitter_p2'], bw_p=Augs['bw_p2'], blur_p=Augs['blur_p2'],\n",
    "                        sol_p=Augs['sol_p2'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return aug_pipelines\n",
    "\n",
    "def get_bt_imagenet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=IMAGENET_Augs)\n",
    "\n",
    "def get_bt_dermnet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=DERMNET_Augs)\n",
    "\n",
    "\n",
    "\n",
    "bt_aug_func_dict = {'bt_cifar10_aug_pipelines':get_bt_cifar10_aug_pipelines,'bt_imagenet_aug_pipelines':get_bt_imagenet_aug_pipelines,\n",
    "                   'bt_dermnet_aug_pipelines':get_bt_dermnet_aug_pipelines\n",
    "                   }\n",
    "\n",
    "def get_bt_aug_pipelines(bt_augs,size):\n",
    "\n",
    "    return bt_aug_func_dict[bt_augs](size)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_ssl_dls(dataset,#cifar10, dermnet, etc\n",
    "            bs,\n",
    "            size,\n",
    "            device,\n",
    "            pct_dataset=1.0):\n",
    "    # Define the base package name in a variable for easy modification\n",
    "\n",
    "    try:\n",
    "        # Construct the module path\n",
    "        module_path = f\"{PACKAGE_NAME}.{dataset}_dataloading\"\n",
    "        \n",
    "        # Dynamically import the module\n",
    "        dataloading_module = importlib.import_module(module_path)\n",
    "    except ModuleNotFoundError:\n",
    "        # Handle the case where the module cannot be found\n",
    "        raise ImportError(f\"Could not find a data loading module for '{dataset}'. \"\n",
    "                          f\"Make sure '{module_path}' exists and is correctly named.\") from None\n",
    "    \n",
    "    # Assuming the function name follows a consistent naming convention\n",
    "    func_name = f\"get_bt_{dataset}_train_dls\"\n",
    "\n",
    "    try:\n",
    "        # Retrieve the data loading function from the module\n",
    "        data_loader_func = getattr(dataloading_module, func_name)\n",
    "    except AttributeError:\n",
    "        # Handle the case where the function does not exist in the module\n",
    "        raise AttributeError(f\"The function '{func_name}' was not found in '{module_path}'. \"\n",
    "                             \"Ensure it is defined and named correctly.\") from None\n",
    "    \n",
    "    # Proceed to call the function with arguments from the config\n",
    "    try:\n",
    "        dls_train = data_loader_func(bs=bs,size=size,device=device,pct_dataset=pct_dataset)\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the function call\n",
    "        raise RuntimeError(f\"An error occurred while calling '{func_name}' from '{module_path}': {e}\") from None\n",
    "    \n",
    "    return dls_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base functions / classes we need to train a BT / RBT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Base functions / classes we need to train a BT / RBT model.\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "\n",
    "# class BarlowTwinsModel(Module):\n",
    "#     \"\"\"An encoder followed by a projector\n",
    "#     \"\"\"\n",
    "#     def __init__(self,encoder,projector):\n",
    "#         self.encoder = encoder\n",
    "#         self.projector = projector\n",
    "        \n",
    "#     def forward(self,x): \n",
    "        \n",
    "#         return self.projector(self.encoder(x))\n",
    "\n",
    "# def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "#     \"Create Barlow Twins model\"\n",
    "#     n_in  = in_channels(encoder)\n",
    "#     with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "#     projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "#     apply_init(projector)\n",
    "#     return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "\n",
    "#We want access to both representation and projection\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        \n",
    "    def forward(self,x): \n",
    "        tem = self.encoder(x)\n",
    "        return tem,self.projector(tem) #get access to both representation and projection if needed for loss\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'forward returns tuple of (encoder(x),projector(encoder(x)))'\n",
    "\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    " \n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "\n",
    "#Note: this requires an lf (loss function), which is patched in later.\n",
    "#The reason for this is we can specify via a string argument (e.g. via\n",
    "#a config file) what loss function we want to use. lf_bt is the default\n",
    "#(standard barlow twins loss function).\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines,n_in,lmb,sparsity_level, \n",
    "                model_type='barlow_twins',print_augs=False\n",
    "                 ):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        store_attr('sparsity_level')\n",
    "        self.n_in=n_in\n",
    "        self.model_type = model_type\n",
    "        self.index=-1 #Gets updated after each batch\n",
    "        self.acc_dict = {}\n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self.index=-1  \n",
    "  \n",
    "    def before_batch(self):\n",
    "        \n",
    "        #TODO: Make this nicer (possibly can load in data as TensorImage(BW) or something?)\n",
    "        #This is a bit of a hack. Can make this more elegant later. But in new version of FastAI\n",
    "        #seems we need to compute TensorImage(BW) here, and depends on whether color or not, i.e. n_in.\n",
    "        if self.n_in == 1:\n",
    "\n",
    "            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            \n",
    "            #print(xi.shape)\n",
    "                                    \n",
    "        elif self.n_in == 3:\n",
    "            \n",
    "            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    " \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1): \n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]]\n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the above for vicreg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Base functions / classes we need to train a \n",
    "#  model\n",
    "class VICRegModel(Module):\n",
    "    \"\"\"VICReg model with options for shared or separate projectors\"\"\"\n",
    "    def __init__(self, left_encoder, right_encoder, left_projector, right_projector):\n",
    "        #may have right_encoder = encoder_left and right_projector = left_projector.\n",
    "        #or e.g. encoders may have shared weights.\n",
    "        self.left_encoder = left_encoder\n",
    "        self.right_encoder = right_encoder\n",
    "        self.left_projector = left_projector\n",
    "        self.right_projector = right_projector\n",
    "        \n",
    "    def forward(self,x): #x is stacked xi,xj the two augmented views of batch\n",
    "      \n",
    "        x1, x2 = x[:x.size(0)//2], x[x.size(0)//2:]\n",
    "        \n",
    "        z1,z2 = self.left_projector(self.left_encoder(x1)), self.right_projector(self.right_encoder(x2))\n",
    "    \n",
    "        return z1, z2\n",
    "\n",
    "def create_vicreg_model(left_encoder, right_encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3, shared_projector=True):\n",
    "    \"\"\"\n",
    "    Create VICReg model with flexible projector configuration\n",
    "    \n",
    "    Args:\n",
    "    - left_encoder: first encoder model\n",
    "    - right_encoder: second encoder model (can be the same as left_encoder for shared encoder)\n",
    "    - hidden_size: hidden size for projector\n",
    "    - projection_size: output size for projector\n",
    "    - bn: whether to use batch normalization in projector\n",
    "    - nlayers: number of layers in projector\n",
    "    - shared_projector: if True, use the same projector for both branches\n",
    "    \"\"\"\n",
    "    n_in = in_channels(left_encoder)\n",
    "    with torch.no_grad(): representation = left_encoder(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    left_projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "    apply_init(left_projector)\n",
    "    \n",
    "    if not shared_projector:\n",
    "        right_projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "        apply_init(right_projector)\n",
    "    else:\n",
    "        right_projector = left_projector\n",
    "    \n",
    "    return VICRegModel(left_encoder, right_encoder, left_projector, right_projector)\n",
    "\n",
    "#helper function to compute vicreg loss.\n",
    "def off_diagonal(x):\n",
    "        n, m = x.shape\n",
    "        assert n == m\n",
    "        return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "class VICReg(BarlowTwins):\n",
    "    def __init__(self, aug_pipelines, n_in=3, sim_coeff=25, std_coeff=25, cov_coeff=1, \n",
    "                 model_type='vicreg', print_augs=False):\n",
    "        super().__init__(aug_pipelines, n_in, None, None, model_type, print_augs)\n",
    "        self.sim_coeff = sim_coeff\n",
    "        self.std_coeff = std_coeff\n",
    "        self.cov_coeff = cov_coeff\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.learn.loss_func = self.lf\n",
    "\n",
    "    def lf(self, pred, *yb):\n",
    "        x, y = pred  # Assuming the model returns two views (see VICRegModel)\n",
    "\n",
    "        # Invariance loss\n",
    "        repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "        # Variance loss\n",
    "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "        # Covariance loss\n",
    "        x = x - x.mean(dim=0)\n",
    "        y = y - y.mean(dim=0)\n",
    "        cov_x = (x.T @ x) / (x.size(0) - 1)\n",
    "        cov_y = (y.T @ y) / (y.size(0) - 1)\n",
    "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(x.size(1)) + \\\n",
    "                   off_diagonal(cov_y).pow_(2).sum().div(y.size(1))\n",
    "\n",
    "        # Total loss\n",
    "        loss = (\n",
    "            self.sim_coeff * repr_loss +\n",
    "            self.std_coeff * std_loss +\n",
    "            self.cov_coeff * cov_loss\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def before_batch(self):\n",
    "        #if self.model_type == 'br_vicreg':\n",
    "\n",
    "    #         # Create two copies of the input\n",
    "    #         x_left, x_right = self.x.clone(), self.x.clone()\n",
    "            \n",
    "    #         # Zero out the right half of x_left and the left half of x_right\n",
    "    #         mid = x_left.shape[-1] // 2\n",
    "    #         x_left[..., mid:] = 0\n",
    "    #         x_right[..., :mid] = 0\n",
    "            \n",
    "    #         print(f\"x shape: {self.x.shape}\")\n",
    "    #         print(f\"x_left shape: {x_left.shape}\")\n",
    "    #         print(f\"x_right shape: {x_right.shape}\")\n",
    "\n",
    "    #         # Apply augmentations\n",
    "    #         if self.n_in == 1:\n",
    "    #             xi = self.aug1(TensorImageBW(x_left))\n",
    "    #             xj = self.aug2(TensorImageBW(x_right))\n",
    "    #         elif self.n_in == 3:\n",
    "    #             xi = self.aug1(TensorImage(x_left))\n",
    "    #             xj = self.aug2(TensorImage(x_right))\n",
    "\n",
    "    #         print(f\"xi shape after aug: {xi.shape}\")\n",
    "    #         print(f\"xj shape after aug: {xj.shape}\")\n",
    "\n",
    "    #         # Concatenate the augmented halves\n",
    "    #         self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "    #         print(f\"Final self.learn.xb shape: {self.learn.xb[0].shape}\")\n",
    "\n",
    "        # The above splits x into x_left and x_right, with padding, then applies\n",
    "        # aug1 and aug2. Alternatively, we could compute aug1(x) and aug2(x). \n",
    "        # then zero pad the right half of aug1(x) and the left half of aug2(x).\n",
    "\n",
    "        #zero padding approach:\n",
    "        # if self.model_type == 'br_vicreg':\n",
    "        #     # Apply augmentations first\n",
    "        #     if self.n_in == 1:\n",
    "        #         xi = self.aug1(TensorImageBW(self.x))\n",
    "        #         xj = self.aug2(TensorImageBW(self.x))\n",
    "        #     elif self.n_in == 3:\n",
    "        #         xi = self.aug1(TensorImage(self.x))\n",
    "        #         xj = self.aug2(TensorImage(self.x))\n",
    "            \n",
    "        #     print(f\"x shape: {self.x.shape}\")\n",
    "        #     print(f\"xi shape after aug: {xi.shape}\")\n",
    "        #     print(f\"xj shape after aug: {xj.shape}\")\n",
    "\n",
    "        #     # Zero out the right half of xi and the left half of xj\n",
    "        #     mid = xi.shape[-1] // 2\n",
    "        #     xi[..., mid:] = 0\n",
    "        #     xj[..., :mid] = 0\n",
    "            \n",
    "        #     print(f\"xi shape after zeroing: {xi.shape}\")\n",
    "        #     print(f\"xj shape after zeroing: {xj.shape}\")\n",
    "\n",
    "        #     # Concatenate the augmented and zeroed halves\n",
    "        #     self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "        #     print(f\"Final self.learn.xb shape: {self.learn.xb[0].shape}\")\n",
    "        # else:\n",
    "        #     # Use the original BarlowTwins before_batch method for 'vicreg'\n",
    "        #     if self.n_in == 1:\n",
    "        #         xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "        #     elif self.n_in == 3:\n",
    "        #         xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "        #     self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "\n",
    "        #here we dont zero pad at all, just get 16x32 (for cifar, say)\n",
    "        if self.model_type == 'br_vicreg':\n",
    "            # Apply augmentations first\n",
    "            if self.n_in == 1:\n",
    "                xi = self.aug1(TensorImageBW(self.x))\n",
    "                xj = self.aug2(TensorImageBW(self.x))\n",
    "            elif self.n_in == 3:\n",
    "                xi = self.aug1(TensorImage(self.x))\n",
    "                xj = self.aug2(TensorImage(self.x))\n",
    "            \n",
    "            # Dynamically calculate the split point\n",
    "            _, _, height, width = xi.shape\n",
    "            split_point = width // 2\n",
    "\n",
    "            # Split each image into left and right halves\n",
    "            xi_left = xi[..., :split_point]  # Left half\n",
    "            xj_right = xj[..., split_point:]  # Right half\n",
    "            \n",
    "            # Concatenate the halves\n",
    "            self.learn.xb = (torch.cat([xi_left, xj_right], dim=0),)\n",
    "\n",
    "            print(f\"Input shape: {self.x.shape}\")\n",
    "            print(f\"Augmented left half shape: {xi_left.shape}\")\n",
    "            print(f\"Augmented right half shape: {xj_right.shape}\")\n",
    "            print(f\"Combined batch shape: {self.learn.xb[0].shape}\")\n",
    "\n",
    "        else:\n",
    "            # Original implementation for 'vicreg'\n",
    "            if self.n_in == 1:\n",
    "                xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            elif self.n_in == 3:\n",
    "                xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "            self.learn.xb = (torch.cat([xi, xj], dim=0),)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of barlow twins loss and sparse barlow twins loss functions, and proposes modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt(pred,I,lmb): #standard bt loss\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "    \n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs \n",
    "    cdiff = (C - I)**2\n",
    "    loss = (cdiff*I + cdiff*(1-I)*lmb).sum() \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_sparse_head(pred,I,lmb,projector,sparsity_level):\n",
    "  \n",
    "    bt_loss = lf_bt(pred,I,lmb)\n",
    "    L21 = torch.linalg.norm(projector[-1].weight, ord=2, dim=0).sum()\n",
    "\n",
    "    # print(f\"bt_loss is {bt_loss}, L21 is {L21}, scaled L21 is {sparsity_level*L21}\")\n",
    "    # print(bt_loss)\n",
    "    # print(L21)\n",
    "\n",
    "    \n",
    "    loss =  bt_loss + sparsity_level*L21 #barlow twins loss + L21 norm of last layer of projector\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_indiv_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb*(0.5*torch.abs(z1_enc) + 0.5*torch.abs(z2_enc)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1_enc.pow(2) + 0.5 * z2_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_norm_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_fun(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm_enc.T @ z2norm_enc) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    loss = (cdiff*I).sum() #standard bt loss\n",
    "\n",
    "    print(f\"invariance loss is: {loss} and sparsity loss is: {sparsity}\")\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_proj_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                           ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm.pow(2) + 0.5 * z2norm.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch in loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb):\n",
    "    \"Assumes model created according to type p3\"\n",
    "\n",
    "    if self.model_type=='barlow_twins':\n",
    "         pred_enc = pred[0]\n",
    "         pred = pred[1]\n",
    "         return lf_bt(pred, self.I,self.lmb)\n",
    "\n",
    "    elif self.model_type=='sparse_head_barlow_twins':\n",
    "        pred_enc = pred[0]\n",
    "        pred = pred[1]\n",
    "\n",
    "        return lf_bt_sparse_head(pred, self.I,lmb=self.lmb,projector=self.learn.model.projector,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "\n",
    "    elif self.model_type=='indiv_sparse_barlow_twins':\n",
    "        return lf_bt_indiv_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='group_sparse_barlow_twins':\n",
    "        return lf_bt_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='group_norm_sparse_barlow_twins':\n",
    "        return lf_bt_group_norm_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='proj_group_sparse_barlow_twins':\n",
    "        return lf_bt_proj_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='fun':\n",
    "        return lf_bt_fun(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "\n",
    "    else: raise(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt(m):\n",
    "    return L(sequential(*m.encoder),m.projector).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt_last_block_resnet50(m):\n",
    "    #Note: don't think we actually need this guy.\n",
    "    \"Freeze all but the last bottleneck layer\"\n",
    "    enc_except_final_block = sequential(*m.encoder[:-3], m.encoder[-3][:-1])\n",
    "    final_block_and_projector = sequential(m.encoder[-3][-1], m.projector)\n",
    "    return L(enc_except_final_block, final_block_and_projector).map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to use the above functions in an end to end fashion. First we get some data and plonk it into a dls, Then create an encoder, an augmentation pipeline, a learner, then fit\n",
    "the learner. This is the complete process of training BT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_bt_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "        \n",
    "    learn = Learner(dls,model=None, cbs=[BarlowTwins(aug,n_in=n_in,lmb=None,sparsity_level=None,\n",
    "                                                     print_augs=print_augs\n",
    "                                        )])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.barlow_twins.show(n=n)\n",
    "\n",
    "def show_vicreg_batch(dls,n_in,aug,n=2,print_augs=True,model_type='vicreg'):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "\n",
    "    learn = Learner(dls,model=None, cbs=[VICReg(aug,n_in=3,model_type=model_type)])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.vic_reg.show(n=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([64, 3, 32, 16])\n",
      "Augmented left half shape: torch.Size([32, 3, 32, 16])\n",
      "Augmented right half shape: torch.Size([32, 3, 32, 16])\n",
      "Combined batch shape: torch.Size([64, 3, 32, 16])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide \n",
    "\n",
    "dls = get_ssl_dls('cifar10',bs=32,size=128,device=default_device())\n",
    "aug = get_bt_cifar10_aug_pipelines(32)\n",
    "show_vicreg_batch(dls,n_in=3,aug=aug,n=2,print_augs=True,model_type='vicreg')\n",
    "show_vicreg_batch(dls,n_in=3,aug=aug,n=2,print_augs=True,model_type='br_vicreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SaveBarlowLearnerCheckpoint(Callback):\n",
    "    \"Save such that can resume training \"\n",
    "    def __init__(self, experiment_dir,start_epoch=0, save_interval=250,with_opt=True):\n",
    "        self.experiment_dir = experiment_dir\n",
    "        self.start_epoch = start_epoch\n",
    "        self.save_interval = save_interval\n",
    "        self.with_opt = with_opt  # Decide whether to save optimizer state as well.\n",
    "\n",
    "    def after_epoch(self):\n",
    "        if (self.epoch+1) % self.save_interval == 0 and self.epoch>=self.start_epoch:\n",
    "            print(f\"Saving model and learner state at epoch {self.epoch}\")\n",
    "   \n",
    "            checkpoint_filename = f\"learner_checkpoint_epoch_{self.epoch}\"\n",
    "            checkpoint_path = os.path.join(self.experiment_dir, checkpoint_filename)\n",
    "            # Save the entire learner object, including the model's parameters and optimizer state.\n",
    "            self.learn.save(checkpoint_path, with_opt=self.with_opt)\n",
    "            print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "class SaveBarlowLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        encoder_filename = f\"trained_encoder_epoch_{self.epoch}.pth\"\n",
    "        encoder_path = os.path.join(self.experiment_dir, encoder_filename)\n",
    "        torch.save(self.learn.model.encoder.state_dict(), encoder_path)\n",
    "        print(f\"encoder state dict saved to {encoder_path}\")\n",
    "\n",
    "\n",
    "class SaveVicRegLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        left_encoder_filename = f\"trained_left_encoder_epoch_{self.epoch}.pth\"\n",
    "        left_encoder_path = os.path.join(self.experiment_dir, left_encoder_filename)\n",
    "        torch.save(self.learn.model.left_encoder.state_dict(), left_encoder_path)\n",
    "        print(f\"Left encoder state dict saved to {left_encoder_path}\")\n",
    "\n",
    "        right_encoder_filename = f\"trained_right_encoder_epoch_{self.epoch}.pth\"\n",
    "        right_encoder_path = os.path.join(self.experiment_dir, right_encoder_filename)\n",
    "        torch.save(self.learn.model.right_encoder.state_dict(), right_encoder_path)\n",
    "        print(f\"Right encoder state dict saved to {right_encoder_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_barlow_model(arch,ps,hs,path):\n",
    "\n",
    "    encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_barlow_twins_model(encoder, hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_vicreg_model(arch,ps,hs,path):\n",
    "\n",
    "    left_encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    right_encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_vicreg_model(left_encoder,right_encoder,hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BarlowTrainer:\n",
    "    \"Setup a learner for training a BT model. Can do transfer learning, normal training, or resume training.\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,#An encoder followed by a projector\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 lmb,\n",
    "                 sparsity_level,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 splitter_str='none',\n",
    "                 num_it=100, #Number of iterations to run lr_find for.\n",
    "                 load_learner_path=None, #Path to load learner from (optional)\n",
    "                 experiment_dir=None, #Where to save model checkpoints (optional)\n",
    "                 start_epoch=0, #Which epoch to start from\n",
    "                 save_interval=None, #How often to save model checkpoints (optional). \n",
    "                 export=False,\n",
    "                 ):\n",
    "\n",
    "        store_attr()\n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    \n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics.\n",
    "\n",
    "        Returns:\n",
    "        - learn: The Learner object.\n",
    "        \"\"\"\n",
    "      \n",
    "        self.model.to(self.device)\n",
    "\n",
    "\n",
    "        cbs = [BarlowTwins(self.bt_aug_pipelines,n_in=self.n_in,lmb=self.lmb,\n",
    "                           sparsity_level=self.sparsity_level,print_augs=False,\n",
    "                           model_type=self.model_type\n",
    "                           )\n",
    "              ]\n",
    "\n",
    "        learn=Learner(self.dls,self.model,splitter=my_splitter_bt,wd=self.wd, cbs=cbs\n",
    "                     )\n",
    "        \n",
    "        if self.load_learner_path: learn.load(self.load_learner_path,with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir:\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export:\n",
    "            cbs.append(SaveBarlowLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "                \n",
    "    \n",
    "    def bt_transfer_learning(self,freeze_epochs:int,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is already pretrained, we can do transfer learning.\n",
    "            Freeze encoder, train projector for a few epochs, then unfreeze and train all. \n",
    "        \"\"\"\n",
    "        self.learn.freeze()\n",
    "        test_grad_off(self.learn.encoder)\n",
    "        self.learn.fit(freeze_epochs)\n",
    "\n",
    "         # Check if the splitter is 'my_splitter_bt_last_block_resnet50'\n",
    "        if self.splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "            # Unfreeze only the last bottleneck block\n",
    "            for param in self.learn.model.encoder[-3][-1].parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "            print(f'splitter_str={self.splitter_str}')\n",
    "        else:\n",
    "            # Unfreeze the entire encoder\n",
    "            self.learn.unfreeze()\n",
    "            test_grad_on(self.learn.model)\n",
    "        \n",
    "        \n",
    "        self.learn.summary()\n",
    "\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it) #lets find a good maximum lr\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley, cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def bt_learning(self,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is not pretrained, we can do normal training.\n",
    "        \"\"\"\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "    \n",
    "    def continue_bt_learning(self,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Resume training with `fit_one_cycle` after loading a learner.\n",
    "        \"\"\"\n",
    "        \n",
    "        test_ne(self.load_learner_path,None)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs,start_epoch=start_epoch,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def train(self,learn_type, freeze_epochs:int,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Train model using BT\n",
    "        \"\"\"\n",
    "        if learn_type == 'transfer_learning':\n",
    "            \n",
    "            self.bt_transfer_learning(freeze_epochs=freeze_epochs,epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        elif learn_type=='continue_learning':\n",
    "            self.continue_bt_learning(epochs=epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "        \n",
    "        elif learn_type=='standard':\n",
    "            self.bt_learning(epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        else: raise Exception(\"Invalid weight_type\")\n",
    "\n",
    "        return self.learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can inherit from the above for vicreg version. Just setting up the learner is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VICRegTrainer(BarlowTrainer):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 sparsity_level,\n",
    "                 sim_coeff,\n",
    "                 std_coeff,\n",
    "                 cov_coeff,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 splitter_str='none',\n",
    "                 num_it=100,\n",
    "                 load_learner_path=None,\n",
    "                 experiment_dir=None,\n",
    "                 start_epoch=0,\n",
    "                 save_interval=None,\n",
    "                 export=False):\n",
    "        \n",
    "        \n",
    "                # Store VICReg-specific attributes\n",
    "        store_attr('sim_coeff,std_coeff,cov_coeff') #why doesn't this work?\n",
    "        # Call the parent constructor with None for lmb\n",
    "        super().__init__(model, dls, bt_aug_pipelines,None,sparsity_level, n_in, model_type,\n",
    "                         wd, device, splitter_str, num_it, load_learner_path,\n",
    "                         experiment_dir, start_epoch, save_interval, export)\n",
    "        \n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics for VICReg.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        cbs = [VICReg(self.bt_aug_pipelines, n_in=self.n_in, \n",
    "                      sim_coeff=self.sim_coeff, std_coeff=self.std_coeff, cov_coeff=self.cov_coeff,\n",
    "                      model_type=self.model_type, print_augs=False)]\n",
    "\n",
    "        # Use the splitter based on splitter_str\n",
    "        # if self.splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "        #     splitter = my_splitter_bt_last_block_resnet50\n",
    "        # else:\n",
    "        #     splitter = my_splitter_bt\n",
    "        #learn = Learner(self.dls, self.model, splitter=splitter, wd=self.wd, cbs=cbs)\n",
    "        \n",
    "        #TODO: Implement custom splitter for VICReg\n",
    "        #splitter not supported yet for vicreg: we can do this but need a custom splitter.\n",
    "        #The issue is just that vicreg e.g. has encoder_left and encoder_right, v.s.\n",
    "        #BT which just has one encoder. Just leaving splitter off for now\n",
    "        learn = Learner(self.dls, self.model, wd=self.wd, cbs=cbs)\n",
    "        if self.load_learner_path: \n",
    "            learn.load(self.load_learner_path, with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir: #same as for barlow\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export: #different to barlow. Clearly we in principle want this \n",
    "                        #more abstract so it just works. But ok.\n",
    "            cbs.append(SaveVicRegLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "\n",
    "    # # Override the train method if necessary\n",
    "    # def train(self, learn_type, freeze_epochs:int, epochs:int, start_epoch:int, interrupt_epoch:int):\n",
    "    #     \"\"\"Train model using VICReg\"\"\"\n",
    "    #     # You can customize this method for VICReg-specific training logic if needed\n",
    "    #     return super().train(learn_type, freeze_epochs, epochs, start_epoch, interrupt_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that splitting/freezings works in `bt_transfer_learning`.\n",
    "\n",
    "It's a bit hacky but looks to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "encoder = resnet_arch_to_encoder(arch='resnet50', weight_type=random)\n",
    "model = create_barlow_twins_model(encoder, hidden_size=8192, projection_size=8192)\n",
    "dls = get_ssl_dls('cifar10',bs=64,size=32,device=default_device())\n",
    "\n",
    "cbs = [BarlowTwins(get_bt_aug_pipelines(bt_augs='bt_cifar10_aug_pipelines', size=32),\n",
    "       n_in=3,lmb=1/8192,sparsity_level=None,print_augs=False,\n",
    "        model_type='barlow_twins'\n",
    "                    )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy pasted from `bt_transfer_learning`\n",
    "\n",
    "Bit hacky, but ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BarlowTwinsModel (Input shape: 64 x 3 x 32 x 32)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     64 x 64 x 16 x 16   \n",
       "Conv2d                                    9408       False     \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "MaxPool2d                                                      \n",
       "Conv2d                                    4096       False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 8 x 8    \n",
       "Conv2d                                    32768      False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 4 x 4    \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    524288     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 2 x 2    \n",
       "Conv2d                                    524288     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2097152    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "AdaptiveAvgPool2d                                              \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048           \n",
       "Flatten                                                        \n",
       "____________________________________________________________________________\n",
       "                     64 x 8192           \n",
       "Linear                                    16785408   True      \n",
       "BatchNorm1d                               16384      True      \n",
       "ReLU                                                           \n",
       "Linear                                    67117056   True      \n",
       "BatchNorm1d                               16384      True      \n",
       "ReLU                                                           \n",
       "Linear                                    67117056   True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 174,560,320\n",
       "Total trainable params: 155,561,856\n",
       "Total non-trainable params: 18,998,464\n",
       "\n",
       "Optimizer used: <function Adam at 0x7fb1ddcf3130>\n",
       "Loss function: <bound method BarlowTwins.lf of BarlowTwins>\n",
       "\n",
       "Model frozen up to parameter group #1\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - CastToTensor\n",
       "  - BarlowTwins\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide \n",
    "learn=Learner(dls,model,splitter=my_splitter_bt,cbs=cbs\n",
    "             )\n",
    "\n",
    "\n",
    "splitter_str = 'my_splitter_bt_last_block_resnet50'\n",
    "#splitter_str='none'\n",
    "learn.freeze() #freeze everything up to projector\n",
    "test_grad_off(learn.encoder)\n",
    "\n",
    "    # Check if the splitter is 'my_splitter_bt_last_block_resnet50'\n",
    "if splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "    # Unfreeze only the last bottleneck block\n",
    "    for param in learn.model.encoder[-3][-1].parameters():\n",
    "        param.requires_grad = True\n",
    "else:\n",
    "    # Unfreeze the entire encoder\n",
    "    learn.unfreeze()\n",
    "\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a BT model. Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "    if hasattr(config,'splitter_str'):\n",
    "        splitter_str=config.splitter_str\n",
    "    else:\n",
    "        splitter_str='none'\n",
    "\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "    encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    \n",
    "    model = create_barlow_twins_model(encoder, hidden_size=config.hs, projection_size=config.ps)\n",
    "\n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    bt_trainer = BarlowTrainer(model=model,\n",
    "                    dls=dls,\n",
    "                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                    lmb=config.lmb,\n",
    "                    sparsity_level=config.sparsity_level,\n",
    "                    n_in=config.n_in,\n",
    "                    model_type=config.model_type,\n",
    "                    wd=config.wd,\n",
    "                    num_it=config.num_it,\n",
    "                    device=device,\n",
    "                    splitter_str=splitter_str,\n",
    "                    load_learner_path=load_learner_path,\n",
    "                    experiment_dir=experiment_dir,\n",
    "                    start_epoch=start_epoch,\n",
    "                    save_interval=config.save_interval,\n",
    "                    export=export\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = bt_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above but for vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_vicreg_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a vicreg model (standard or br) Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "    if hasattr(config,'splitter_str'):\n",
    "        splitter_str=config.splitter_str\n",
    "    else:\n",
    "        splitter_str='none'\n",
    "\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "\n",
    "    #vicreg model may require two encoders, so we need to handle this case\n",
    "    encoder_left = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    if config.model_type == 'vicreg':\n",
    "\n",
    "        if not config.shared_encoder:\n",
    "            encoder_right = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "        else:\n",
    "            encoder_right=encoder_left\n",
    "\n",
    "        model = create_vicreg_model(encoder_left, encoder_right, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "    elif config.model_type == 'br_vicreg':\n",
    "        #br_vicreg has a specific arch at present: i.e. \n",
    "        #we have two identical encoders *except* for the first few layers\n",
    "        #which `share_resnet_parameters` handles\n",
    "        encoder_right = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "                                  #specifically up to and including stage1. So far\n",
    "                                  #just for resnet18\n",
    "        test_eq(config.arch in ['resnet18','cifar_resnet18'],True)\n",
    "        share_resnet_parameters(encoder_left, encoder_right)\n",
    "\n",
    "        model = create_vicreg_model(encoder_left, encoder_right, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "\n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    #(this is same as for bt)\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    vicreg_trainer = VICRegTrainer(model=model,\n",
    "                                    dls=dls,\n",
    "                                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                                    sparsity_level=config.sparsity_level,\n",
    "                                    sim_coeff=config.sim_coeff,\n",
    "                                    std_coeff=config.std_coeff,\n",
    "                                    cov_coeff=config.cov_coeff,\n",
    "                                    n_in=config.n_in,\n",
    "                                    model_type=config.model_type,\n",
    "                                    wd=config.wd,\n",
    "                                    num_it=config.num_it,\n",
    "                                    device=device,\n",
    "                                    splitter_str=splitter_str,\n",
    "                                    load_learner_path=load_learner_path,\n",
    "                                    experiment_dir=experiment_dir,\n",
    "                                    start_epoch=start_epoch,\n",
    "                                    save_interval=config.save_interval,\n",
    "                                    export=export\n",
    "\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = vicreg_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_experiment_state(config,base_dir):\n",
    "    \"\"\"Get the load_learner_path, learn_type, start_epoch, interrupt_epoch for BT experiment.\n",
    "       Basically this tells us how to continue learning (e.g. we have run two sessions for \n",
    "       100 epochs, and want to continue for another 100 epochs). Return values are\n",
    "       None if we are starting from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    load_learner_path, _  = get_highest_num_path(base_dir, config)\n",
    "    #TODO:\n",
    "    #We can get start_epoch, interrupt epoch from `get_highest_epoch_path` + save_interval (may be None!)\n",
    "    start_epoch=0 if load_learner_path is None else int(load_learner_path.split('_')[-1])+1\n",
    "    \n",
    "    if start_epoch >= config.epochs:\n",
    "        print(f\"start_epoch={start_epoch}, but already completed {config.epochs} epochs. Exiting.\")\n",
    "        sys.exit()\n",
    "\n",
    "    interrupt_epoch = start_epoch + config.save_interval\n",
    "\n",
    "    #We can also get the learn_type from the load_learner_path + weight_type. \n",
    "    \n",
    "    if config.weight_type == 'random':\n",
    "        learn_type = 'standard'\n",
    "    \n",
    "    elif 'pretrained' in config.weight_type:\n",
    "        learn_type = 'transfer_learning'\n",
    "\n",
    "    learn_type = learn_type if load_learner_path is None else 'continue_learning'\n",
    "\n",
    "    return load_learner_path, learn_type, start_epoch, interrupt_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_experiment(config,\n",
    "                      base_dir,\n",
    "                      ):\n",
    "        \"\"\"Run several epochs of the experiment as defined in the config and where we are up to. e.g. epoch 0, or resuming\n",
    "        at epoch 99 etc. Basically a stateful version of `main_bt_train` that can be resumed. And saving.\n",
    "        \"\"\"\n",
    "    \n",
    "        \n",
    "        experiment_dir, experiment_hash,git_commit_hash = setup_experiment(config,base_dir)\n",
    "        load_learner_path, learn_type, start_epoch, interrupt_epoch = get_bt_experiment_state(config,base_dir)      \n",
    "        \n",
    "        if 'barlow' in config.model_type:\n",
    "        \n",
    "                main_bt_train(config=config,\n",
    "                        start_epoch=start_epoch,\n",
    "                        interrupt_epoch=interrupt_epoch,\n",
    "                        load_learner_path=load_learner_path,\n",
    "                        learn_type=learn_type,\n",
    "                        experiment_dir=experiment_dir,\n",
    "                        )\n",
    "        elif 'vicreg' in config.model_type:\n",
    "                \n",
    "                main_vicreg_train(config=config,\n",
    "                        start_epoch=start_epoch,\n",
    "                        interrupt_epoch=interrupt_epoch,\n",
    "                        load_learner_path=load_learner_path,\n",
    "                        learn_type=learn_type,\n",
    "                        experiment_dir=experiment_dir,\n",
    "                        )\n",
    "\n",
    "        # Save a metadata file in the experiment directory with the Git commit hash and other details\n",
    "        save_metadata_file(experiment_dir=experiment_dir, git_commit_hash=git_commit_hash)\n",
    "\n",
    "        # After experiment execution and all processing are complete\n",
    "        update_experiment_index(base_dir,{\n",
    "                \"experiment_hash\": experiment_hash,  # Unique identifier derived from the experiment's configuration\n",
    "                \"experiment_dir\": experiment_dir,  # Absolute path to the experiment's dedicated directory\n",
    "                \"git_commit_hash\": git_commit_hash,  # Git commit hash for the code version used in the experiment\n",
    "                # Potentially include additional details collected during or after the experiment, such as:\n",
    "                # Any other metadata or results summary that is relevant to the experiment\n",
    "                                })\n",
    "        \n",
    "        return experiment_dir,experiment_hash #Return the experiment_dir so we can easily access the results of the experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full end to end example with BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpkw0cp51v/SSL/cifar10/smallres/00ff5d7e and the experiment hash is: 00ff5d7e\n",
      "Configuration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpkw0cp51v/SSL/cifar10/smallres/00ff5d7e/config.yaml\n",
      "The git hash is: 021a355dc6c47c920af0ca9ad01f6544ff57ac40\n",
      "Looking in /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpkw0cp51v/SSL/cifar10/smallres/00ff5d7e for highest num saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4' class='' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      33.33% [4/12 00:04&lt;00:09]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>251.569962</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>243.164825</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>250.353958</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>257.614349</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(config_path)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# config.model_type = 'sparse_head_barlow_twins'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# config.sparsity_level=10\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# config.epochs=100\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# config.save_interval=100\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m experiment_dir,experiment_hash \u001b[38;5;241m=\u001b[39m \u001b[43mmain_bt_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(experiment_dir))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(base_dir))\n",
      "Cell \u001b[0;32mIn[34], line 17\u001b[0m, in \u001b[0;36mmain_bt_experiment\u001b[0;34m(config, base_dir)\u001b[0m\n\u001b[1;32m     13\u001b[0m load_learner_path, learn_type, start_epoch, interrupt_epoch \u001b[38;5;241m=\u001b[39m get_bt_experiment_state(config,base_dir)      \n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbarlow\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[0;32m---> 17\u001b[0m         \u001b[43mmain_bt_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43mload_learner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_learner_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlearn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexperiment_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvicreg\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[1;32m     26\u001b[0m         main_vicreg_train(config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m     27\u001b[0m                 start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch,\n\u001b[1;32m     28\u001b[0m                 interrupt_epoch\u001b[38;5;241m=\u001b[39minterrupt_epoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 experiment_dir\u001b[38;5;241m=\u001b[39mexperiment_dir,\n\u001b[1;32m     32\u001b[0m                 )\n",
      "Cell \u001b[0;32mIn[29], line 63\u001b[0m, in \u001b[0;36mmain_bt_train\u001b[0;34m(config, start_epoch, interrupt_epoch, load_learner_path, learn_type, experiment_dir)\u001b[0m\n\u001b[1;32m     44\u001b[0m bt_trainer \u001b[38;5;241m=\u001b[39m BarlowTrainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     45\u001b[0m                 dls\u001b[38;5;241m=\u001b[39mdls,\n\u001b[1;32m     46\u001b[0m                 bt_aug_pipelines\u001b[38;5;241m=\u001b[39mbt_aug_pipelines,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 export\u001b[38;5;241m=\u001b[39mexport\n\u001b[1;32m     60\u001b[0m                                 )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Train the model with the specified configurations and save `learn` checkpoints\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mbt_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfreeze_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreeze_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m learn\n",
      "Cell \u001b[0;32mIn[25], line 126\u001b[0m, in \u001b[0;36mBarlowTrainer.train\u001b[0;34m(self, learn_type, freeze_epochs, epochs, start_epoch, interrupt_epoch)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinue_bt_learning(epochs\u001b[38;5;241m=\u001b[39mepochs,start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch,interrupt_epoch\u001b[38;5;241m=\u001b[39minterrupt_epoch)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learn_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbt_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\n",
      "Cell \u001b[0;32mIn[25], line 105\u001b[0m, in \u001b[0;36mBarlowTrainer.bt_learning\u001b[0;34m(self, epochs, interrupt_epoch)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m\"\"\"If the encoder is not pretrained, we can do normal training.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m lrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\u001b[38;5;241m.\u001b[39mlr_find(num_it\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_it)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_one_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalley\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_training_cbs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/callback/schedule.py:119\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    116\u001b[0m lr_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([h[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mhypers])\n\u001b[1;32m    117\u001b[0m scheds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[38;5;241m/\u001b[39mdiv, lr_max, lr_max\u001b[38;5;241m/\u001b[39mdiv_final),\n\u001b[1;32m    118\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmom\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, \u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoms \u001b[38;5;28;01mif\u001b[39;00m moms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m moms))}\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParamScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:256\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:245\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:231\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:227\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    225\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:205\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_one_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_pred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m, in \u001b[0;36mBarlowTwinsModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x): \n\u001b[0;32m---> 39\u001b[0m     tem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tem,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojector(tem)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/_jit_internal.py:485\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/functional.py:769\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_max_pool2d\u001b[39m(\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;28minput\u001b[39m: Tensor, kernel_size: BroadcastingList2[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    762\u001b[0m     stride: Optional[BroadcastingList2[\u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    766\u001b[0m     return_indices: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    767\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m--> 769\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m            \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m         stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/overrides.py:1534\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1530\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/torch_core.py:378\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 378\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/_tensor.py:1279\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1279\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/_jit_internal.py:485\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     config_path = '../configs/cifar10/bt_test_config.yaml'\n",
    "#     config = load_config(config_path)\n",
    "\n",
    "#     # config.model_type = 'sparse_head_barlow_twins'\n",
    "#     # config.sparsity_level=10\n",
    "#     # config.epochs=100\n",
    "#     # config.save_interval=100\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     #get path to fully fitted model\n",
    "#     path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "#     model = load_barlow_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "#     print(model)\n",
    "\n",
    "#     #New config but the first part of experiment_dir is same - just hash is different\n",
    "#     #It shouldnt find a max file path\n",
    "#     config.epochs=config.epochs+1\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full end to end example for vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmp6m8s5nvw/SSL/cifar10/smallres/9a227c39 and the experiment hash is: 9a227c39\n",
      "Configuration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmp6m8s5nvw/SSL/cifar10/smallres/9a227c39/config.yaml\n",
      "The git hash is: 021a355dc6c47c920af0ca9ad01f6544ff57ac40\n",
      "Looking in /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmp6m8s5nvw/SSL/cifar10/smallres/9a227c39 for highest num saved\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "==:\nFalse\nTrue",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m config\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbr_vicreg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# config.model_type = 'sparse_head_barlow_twins'\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# config.sparsity_level=10\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# config.epochs=100\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# config.save_interval=100\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m experiment_dir,experiment_hash \u001b[38;5;241m=\u001b[39m \u001b[43mmain_bt_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(experiment_dir))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(base_dir))\n",
      "Cell \u001b[0;32mIn[34], line 26\u001b[0m, in \u001b[0;36mmain_bt_experiment\u001b[0;34m(config, base_dir)\u001b[0m\n\u001b[1;32m     17\u001b[0m         main_bt_train(config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m     18\u001b[0m                 start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch,\n\u001b[1;32m     19\u001b[0m                 interrupt_epoch\u001b[38;5;241m=\u001b[39minterrupt_epoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 experiment_dir\u001b[38;5;241m=\u001b[39mexperiment_dir,\n\u001b[1;32m     23\u001b[0m                 )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvicreg\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[0;32m---> 26\u001b[0m         \u001b[43mmain_vicreg_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                \u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[43mload_learner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_learner_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlearn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexperiment_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Save a metadata file in the experiment directory with the Git commit hash and other details\u001b[39;00m\n\u001b[1;32m     35\u001b[0m save_metadata_file(experiment_dir\u001b[38;5;241m=\u001b[39mexperiment_dir, git_commit_hash\u001b[38;5;241m=\u001b[39mgit_commit_hash)\n",
      "Cell \u001b[0;32mIn[50], line 45\u001b[0m, in \u001b[0;36mmain_vicreg_train\u001b[0;34m(config, start_epoch, interrupt_epoch, load_learner_path, learn_type, experiment_dir)\u001b[0m\n\u001b[1;32m     42\u001b[0m encoder_right \u001b[38;5;241m=\u001b[39m resnet_arch_to_encoder(arch\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39march, weight_type\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mweight_type)\n\u001b[1;32m     43\u001b[0m                           \u001b[38;5;66;03m#specifically up to and including stage1. So far\u001b[39;00m\n\u001b[1;32m     44\u001b[0m                           \u001b[38;5;66;03m#just for resnet18\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[43mtest_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43march\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresnet18\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcifar_resnet18\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m share_resnet_parameters(encoder_left, encoder_right)\n\u001b[1;32m     48\u001b[0m model \u001b[38;5;241m=\u001b[39m create_vicreg_model(encoder_left, encoder_right, hidden_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhs, projection_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mps, shared_projector\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mshared_projector)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastcore/test.py:37\u001b[0m, in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_eq\u001b[39m(a,b):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`test` that `a==b`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mequals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m==\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastcore/test.py:27\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: cname\u001b[38;5;241m=\u001b[39mcmp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m cmp(a,b),\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ==:\nFalse\nTrue"
     ]
    }
   ],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     config_path = '../configs/cifar10/vicreg_test_config.yaml'\n",
    "#     config = load_config(config_path)\n",
    "\n",
    "#     # config.model_type = 'sparse_head_barlow_twins'\n",
    "#     # config.sparsity_level=10\n",
    "#     # config.epochs=100\n",
    "#     # config.save_interval=100\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     #get path to fully fitted model\n",
    "#     path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "#     model = load_vicreg_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "#     print(model)\n",
    "\n",
    "#     #New config but the first part of experiment_dir is same - just hash is different\n",
    "#     #It shouldnt find a max file path\n",
    "#     config.epochs=config.epochs+1\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify runs with br_vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: cifar10\n",
      "arch: cifar_resnet18\n",
      "train_type: SSL\n",
      "weight_type: random\n",
      "size: 32\n",
      "n_in: 3\n",
      "bs: 128\n",
      "ps: 512\n",
      "hs: 512\n",
      "bt_augs: bt_cifar10_aug_pipelines\n",
      "model_type: br_vicreg\n",
      "sim_coeff: 25.0\n",
      "std_coeff: 25.0\n",
      "cov_coeff: 1.0\n",
      "sparsity_level: None\n",
      "shared_projector: True\n",
      "shared_encoder: True\n",
      "wd: 1.5e-06\n",
      "freeze_epochs: None\n",
      "num_it: 10\n",
      "pct_dataset: 0.003\n",
      "epochs: 6\n",
      "save_interval: 3\n",
      "encoder_dimension: 512\n",
      "The experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmp5u6a09uw/SSL/cifar10/cifar_resnet18/89066930 and the experiment hash is: 89066930\n",
      "Configuration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmp5u6a09uw/SSL/cifar10/cifar_resnet18/89066930/config.yaml\n",
      "The git hash is: 021a355dc6c47c920af0ca9ad01f6544ff57ac40\n",
      "Looking in /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmp5u6a09uw/SSL/cifar10/cifar_resnet18/89066930 for highest num saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/11 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([256, 3, 32, 16])\n",
      "Augmented left half shape: torch.Size([128, 3, 32, 16])\n",
      "Augmented right half shape: torch.Size([128, 3, 32, 16])\n",
      "Combined batch shape: torch.Size([256, 3, 32, 16])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m config\u001b[38;5;241m.\u001b[39march \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar_resnet18\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m pretty_print_ns(config)\n\u001b[0;32m---> 10\u001b[0m experiment_dir,experiment_hash \u001b[38;5;241m=\u001b[39m \u001b[43mmain_bt_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 26\u001b[0m, in \u001b[0;36mmain_bt_experiment\u001b[0;34m(config, base_dir)\u001b[0m\n\u001b[1;32m     17\u001b[0m         main_bt_train(config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m     18\u001b[0m                 start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch,\n\u001b[1;32m     19\u001b[0m                 interrupt_epoch\u001b[38;5;241m=\u001b[39minterrupt_epoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 experiment_dir\u001b[38;5;241m=\u001b[39mexperiment_dir,\n\u001b[1;32m     23\u001b[0m                 )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvicreg\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[0;32m---> 26\u001b[0m         \u001b[43mmain_vicreg_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                \u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[43mload_learner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_learner_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlearn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexperiment_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Save a metadata file in the experiment directory with the Git commit hash and other details\u001b[39;00m\n\u001b[1;32m     35\u001b[0m save_metadata_file(experiment_dir\u001b[38;5;241m=\u001b[39mexperiment_dir, git_commit_hash\u001b[38;5;241m=\u001b[39mgit_commit_hash)\n",
      "Cell \u001b[0;32mIn[50], line 88\u001b[0m, in \u001b[0;36mmain_vicreg_train\u001b[0;34m(config, start_epoch, interrupt_epoch, load_learner_path, learn_type, experiment_dir)\u001b[0m\n\u001b[1;32m     66\u001b[0m vicreg_trainer \u001b[38;5;241m=\u001b[39m VICRegTrainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     67\u001b[0m                                 dls\u001b[38;5;241m=\u001b[39mdls,\n\u001b[1;32m     68\u001b[0m                                 bt_aug_pipelines\u001b[38;5;241m=\u001b[39mbt_aug_pipelines,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m                                 )\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Train the model with the specified configurations and save `learn` checkpoints\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mvicreg_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfreeze_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreeze_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m learn\n",
      "Cell \u001b[0;32mIn[25], line 126\u001b[0m, in \u001b[0;36mBarlowTrainer.train\u001b[0;34m(self, learn_type, freeze_epochs, epochs, start_epoch, interrupt_epoch)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinue_bt_learning(epochs\u001b[38;5;241m=\u001b[39mepochs,start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch,interrupt_epoch\u001b[38;5;241m=\u001b[39minterrupt_epoch)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learn_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbt_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\n",
      "Cell \u001b[0;32mIn[25], line 103\u001b[0m, in \u001b[0;36mBarlowTrainer.bt_learning\u001b[0;34m(self, epochs, interrupt_epoch)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbt_learning\u001b[39m(\u001b[38;5;28mself\u001b[39m,epochs:\u001b[38;5;28mint\u001b[39m,interrupt_epoch:\u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124;03m\"\"\"If the encoder is not pretrained, we can do normal training.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     lrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_it\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_it\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\u001b[38;5;241m.\u001b[39mfit_one_cycle(epochs, lrs\u001b[38;5;241m.\u001b[39mvalley,cbs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_training_cbs(interrupt_epoch))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/callback/schedule.py:293\u001b[0m, in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[1;32m    291\u001b[0m n_epoch \u001b[38;5;241m=\u001b[39m num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    292\u001b[0m cb\u001b[38;5;241m=\u001b[39mLRFinder(start_lr\u001b[38;5;241m=\u001b[39mstart_lr, end_lr\u001b[38;5;241m=\u001b[39mend_lr, num_it\u001b[38;5;241m=\u001b[39mnum_it, stop_div\u001b[38;5;241m=\u001b[39mstop_div)\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_logging(): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suggest_funcs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     lrs, losses \u001b[38;5;241m=\u001b[39m tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorder\u001b[38;5;241m.\u001b[39mlrs[num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m]), tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorder\u001b[38;5;241m.\u001b[39mlosses[num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:256\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:245\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:231\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:227\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    225\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:213\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb): \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_events(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m, CancelBackwardException)\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelStepException\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:202\u001b[0m, in \u001b[0;36mLearner._step\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m--> 202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_step\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfastai optimizers currently do not support closure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p,pg,state,hyper \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_params(with_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcbs: state \u001b[38;5;241m=\u001b[39m _update(state, \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhyper\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[p] \u001b[38;5;241m=\u001b[39m state\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/optimizer.py:151\u001b[0m, in \u001b[0;36maverage_grad\u001b[0;34m(p, mom, dampening, grad_avg, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grad_avg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: grad_avg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m    150\u001b[0m damp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mmom \u001b[38;5;28;01mif\u001b[39;00m dampening \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1.\u001b[39m\n\u001b[0;32m--> 151\u001b[0m \u001b[43mgrad_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmom\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad_avg\u001b[39m\u001b[38;5;124m'\u001b[39m: grad_avg}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     config_path = '../configs/cifar10/vicreg_test_config.yaml'\n",
    "#     config = load_config(config_path)\n",
    "#     config.model_type = 'br_vicreg'\n",
    "#     config.arch = 'cifar_resnet18'\n",
    "\n",
    "#     pretty_print_ns(config)\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
