{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_model\n",
    "\n",
    "> In this module we have the base model, learner and other things we need to train encoder\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import self_supervised\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import kornia.augmentation as korniatfm\n",
    "import torchvision.transforms as tvtfm\n",
    "from base_rbt.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mdefault_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mdefault_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"Return or set default device; `use_cuda`: -1 - CUDA/mps if available; True - error if not available; False - CPU\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0muse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0m_has_mps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/torch_core.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "default_device??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the base functions and classes to train a basic BT-style model. Note that this (mostly) all comes directly from here: `https://github.com/KeremTurgutlu/self_supervised/blob/main/nbs/14%20-%20barlow_twins.ipynb`\n",
    "but we needed to extend some of the functionality for our purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the base classes and functions needed for image augmentation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#My edited version of RandTransform\n",
    "class RandomGaussianBlur(RandTransform):\n",
    "    \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "    order = 11\n",
    "    def __init__(self, \n",
    "                 p=1.0, #debugging (bug in libraries implementation)\n",
    "                 prob=0.5,#the real probability\n",
    "                 s=(8,32), #kernel\n",
    "                 sig=None, #sig_val is either manually input OR\n",
    "                 blur_r=(0.1,2),#is randomly chosen from uniform with these bounds\n",
    "                 same_on_batch=False, \n",
    "                 **kwargs): \n",
    "        \n",
    "        store_attr()\n",
    "        super().__init__(p=p, **kwargs)\n",
    "\n",
    "    def encodes(self, x:TensorImage):\n",
    "        \n",
    "        if isinstance(self.s, int):   s = (self.s,self.s)\n",
    "        elif isinstance(self.s, tuple) or isinstance(self.s, list): s=self.s\n",
    "     \n",
    "        #Default for ImageNet from BYOL / BT papers\n",
    "        if self.sig is None:\n",
    "            sig_val = np.random.uniform(self.blur_r[0],self.blur_r[1])\n",
    "        \n",
    "        else:\n",
    "            sig_val = self.sig\n",
    "            \n",
    "\n",
    "        tfm = korniatfm.RandomGaussianBlur(kernel_size=s,sigma=(sig_val,sig_val),same_on_batch=self.same_on_batch,p=self.prob)\n",
    "        return tfm(x)\n",
    "\n",
    "#Delete later: leaving for backward compatibility for now\n",
    "# class RandomGaussianBlur(RandTransform):\n",
    "#     \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "#     order = 11\n",
    "#     def __init__(self, p=0.5, s=(8,32), same_on_batch=False, **kwargs): \n",
    "#         store_attr()\n",
    "#         super().__init__(p=p, **kwargs)\n",
    "        \n",
    "#     def encodes(self, x:TensorImage):\n",
    "#         if isinstance(self.s, tuple): s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, list):  s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, int):   s = self.s\n",
    "#         s2 = int(s/4)*2+1\n",
    "#         tfm = korniatfm.RandomGaussianBlur((s2,s2),(s,s),same_on_batch=self.same_on_batch,p=1.) #p=1. is a bug\n",
    "#                                             #kernel #sigma\n",
    "        \n",
    "#         return tfm(x)\n",
    "    \n",
    "def get_BT_batch_augs(size,\n",
    "                    flip=True,crop=True,noise=True,rotate=True,jitter=True,bw=True,blur=True,solar=True, #Whether to use  given aug or not\n",
    "                    resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.025, rotate_deg=30,jitter_s=.6,blur_s=(4,32),blur_r=(0.1,2),blur_sig=None,sol_t=0.05,sol_a=0.05, #hps of diff augs\n",
    "                    flip_p=0.5, rotate_p=0.3,noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3,sol_p=0.1, #prob of performing aug\n",
    "                    same_on_batch=False,stats=imagenet_stats,cuda=default_device().type == 'cuda',xtra_tfms=[]):\n",
    "    \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    \n",
    "    tfms = []\n",
    "\n",
    "    korniatfm.RandomHorizontalFlip.order = RandomResizedCrop.order-1\n",
    "    \n",
    "    if crop: tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "    \n",
    "    #Unfortunately for some reason this doesn't work, so we can't apply \"same_on_batch=False\"\n",
    "    #tfms += [korniatfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if flip: tfms += [korniatfm.RandomHorizontalFlip(p=flip_p,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if rotate: tfms += [Rotate(max_deg=rotate_deg, p=rotate_p, batch=same_on_batch)]\n",
    "\n",
    "                                             #brightness,contrast,saturation,hue\n",
    "    if jitter: tfms += [korniatfm.ColorJitter(0.4*jitter_s, 0.4*jitter_s, 0.2*jitter_s, 0.1*jitter_s, p=jitter_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if bw:     tfms += [korniatfm.RandomGrayscale(p=bw_p, same_on_batch=same_on_batch)]\n",
    "        \n",
    "    #sig will usually be None\n",
    "    if blur:   tfms += [RandomGaussianBlur(prob=blur_p, s=blur_s,sig=blur_sig,blur_r=blur_r, same_on_batch=same_on_batch)]\n",
    "\n",
    "    korniatfm.RandomSolarize.order = RandomGaussianBlur.order + 1 #we want to apply solarization after RandomGaussianBlur\n",
    "    \n",
    "    if solar: tfms += [korniatfm.RandomSolarize(p=sol_p,thresholds=sol_t, additions=sol_a,same_on_batch=same_on_batch)]\n",
    "\n",
    "    \n",
    "    if noise: tfms+=[korniatfm.RandomGaussianNoise(mean=0.0, std=noise_std, same_on_batch=False, p=noise_p)]\n",
    "    \n",
    "    if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "\n",
    "    tfms += xtra_tfms\n",
    "\n",
    "    pipe = Pipeline(tfms, split_idx = 0)\n",
    "    return pipe\n",
    "\n",
    "@delegates(get_BT_batch_augs)\n",
    "def get_multi_aug_pipelines(size, **kwargs): return get_BT_batch_augs(size, **kwargs)\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(size=size,**kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base functions / classes we need to train a BT / RBT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Base functions / classes we need to train a BT / RBT model.\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        \n",
    "    def forward(self,x): \n",
    "        \n",
    "        return self.projector(self.encoder(x))\n",
    "\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines,n_in, model_type='barlow_twins',lmb=5e-3, print_augs=False):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        self.n_in=n_in\n",
    "        self.model_type = model_type\n",
    "        self.index=-1 #Gets updated after each batch\n",
    "        self.seed = np.random.randint(0,10000) #gets updated after each batch\n",
    "        self.acc_dict = {}\n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self.index=-1  \n",
    "  \n",
    "    def before_batch(self):\n",
    "        \n",
    "        #TODO: Make this nicer (possibly can load in data as TensorImage(BW) or something?)\n",
    "        #This is a bit of a hack. Can make this more elegant later. But in new version of FastAI\n",
    "        #seems we need to compute TensorImage(BW) here, and depends on whether color or not, i.e. n_in.\n",
    "        if self.n_in == 1:\n",
    "\n",
    "            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            \n",
    "            #print(xi.shape)\n",
    "                                    \n",
    "        elif self.n_in == 3:\n",
    "            \n",
    "            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "\n",
    "        self.index=self.index+1\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1): \n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]]\n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Here we give the model API for `new idea` or `RAT` -> i.e. two projector networks\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class P2BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector,projector2):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        self.projector2 = projector2\n",
    "        \n",
    "    def forward(self,x): \n",
    "        tem = self.encoder(x)\n",
    "        return self.projector(tem),self.projector2(tem)\n",
    "\n",
    "def create_p2barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    \n",
    "    projector2 = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector2)\n",
    "    \n",
    "    \n",
    "    return P2BarlowTwinsModel(encoder, projector,projector2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#We want access to both representation and projection\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class P3BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        \n",
    "    def forward(self,x): \n",
    "        tem = self.encoder(x)\n",
    "        return tem,self.projector(tem)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'forward returns tuple of (encoder(x),projector(encoder(x)))'\n",
    "\n",
    "def create_p3barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    \n",
    " \n",
    "    return P3BarlowTwinsModel(encoder, projector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class P4BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,encoder2,projector,projector2):\n",
    "        self.encoder = encoder\n",
    "        self.encoder2 = encoder2\n",
    "        self.projector = projector\n",
    "        self.projector2 = projector2\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        #If we have multiple GPUs can take advantage of it here...\n",
    "        tem,tem2 = self.encoder(x),self.encoder2(x)\n",
    "        return self.projector(tem),self.projector2(tem2)\n",
    "\n",
    "def create_p4barlow_twins_model(encoder,encoder2, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    \n",
    "    projector2 = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector2)\n",
    "    \n",
    "    \n",
    "    return P4BarlowTwinsModel(encoder,encoder2, projector,projector2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we write down standard definition of `lf` for `RAT` method: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BarlowTwins needs an `lf` method to work properly. Here we provide the `lf` of standard barlow twins. Later we can\n",
    "patch in a new defintion of `lf` that involves random functions, inner maximization etc. The tools needed to do this are provised in `base_lf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt(pred,I,lmb):\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "    \n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs \n",
    "    cdiff = (C - I)**2\n",
    "    loss = (cdiff*I + cdiff*(1-I)*lmb).sum() \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_rbt_sparse(pred,I,lmb,sparsity_level,\n",
    "               ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb*0.5*(torch.abs(z1_enc).sum() + torch.abs(z2_enc).sum())\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb,sparsity_level=0.25):\n",
    "    \"Assumes model created according to type p3\"\n",
    "\n",
    "    if self.model_type=='barlow_twins':\n",
    "         pred_enc = pred[0]\n",
    "         pred = pred[1]\n",
    "         return lf_bt(pred, self.I,self.lmb)\n",
    "\n",
    "    elif self.model_type=='sparse_barlow_twins':\n",
    "        return lf_rbt_sparse(pred, self.I,self.lmb,sparsity_level=sparsity_level)\n",
    "\n",
    "    else: raise(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt(m):\n",
    "    return L(sequential(*m.encoder),m.projector).map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to use the above functions in an end to end fashion. First we get some data and plonk it into a dls, Then create an encoder, an augmentation pipeline, a learner, then fit\n",
    "the learner. This is the complete process of training BT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_bt_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "        \n",
    "    learn = Learner(dls,model=None, cbs=[BarlowTwins(aug,n_in=n_in,print_augs=print_augs)])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.barlow_twins.show(n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TrainBT:\n",
    "    \"Train model using BT.\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,#An encoder followed by a projector\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 lmb,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 ):\n",
    "\n",
    "        store_attr()\n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    \n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics.\n",
    "\n",
    "        Returns:\n",
    "        - learn: The Learner object.\n",
    "        \"\"\"\n",
    "      \n",
    "        self.model.to(self.device)\n",
    "  \n",
    "        learn=Learner(self.dls,self.model,splitter=my_splitter_bt,wd=self.wd, cbs=[BarlowTwins(self.bt_aug_pipelines,n_in=self.n_in,lmb=self.lmb,print_augs=False,model_type=self.model_type)])\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def bt_transfer_learning(self,freeze_epochs:int=1,epochs:int=1):\n",
    "        \"\"\"If the encoder is alreaady pretrained, we can do transfer learning.\n",
    "            Freeze encoder, train projector for a few epochs, then unfreeze and train all. \n",
    "        \"\"\"\n",
    "\n",
    "        self.learn.freeze()\n",
    "        test_grad_off(self.learn.encoder)\n",
    "        self.learn.fit(freeze_epochs)\n",
    "        self.learn.unfreeze()\n",
    "        test_grad_on(self.learn.model)\n",
    "        lrs = self.learn.lr_find()\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley)\n",
    "\n",
    "        return self.learn.model\n",
    "\n",
    "    def bt_learning(self,epochs:int=1):\n",
    "        \"\"\"If the encoder is not pretrained, we can do normal training.\n",
    "        \"\"\"\n",
    "        \n",
    "        lrs = self.learn.lr_find()\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley)\n",
    "\n",
    "        return self.learn.model\n",
    "\n",
    "def train_bt(model,#An encoder followed by a projector\n",
    "            dls,\n",
    "            bt_aug_pipelines,\n",
    "            lmb,\n",
    "            n_in,\n",
    "            model_type,\n",
    "            wd,\n",
    "            epochs,\n",
    "            freeze_epochs,\n",
    "            weight_type,\n",
    "            device,\n",
    "            ):\n",
    "    \n",
    "    bt_trainer = TrainBT(model=model,dls=dls,bt_aug_pipelines=bt_aug_pipelines,\n",
    "                        lmb=lmb,n_in=n_in,model_type=model_type,wd=wd,device=device\n",
    "                        )\n",
    "\n",
    "    if weight_type!='random':\n",
    "        model=bt_trainer.bt_transfer_learning(freeze_epochs=freeze_epochs,epochs=epochs)\n",
    "    else:\n",
    "        model=bt_trainer.bt_learning(epochs=epochs)\n",
    "\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentations for CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def get_bt_cifar10_aug_pipelines(size):\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    bt_cifar10_aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return bt_cifar10_aug_pipelines\n",
    "\n",
    "#Add other augmentations here e.g. BYOL augs\n",
    "\n",
    "bt_aug_func_dict = {'bt_cifar10_aug_pipelines':get_bt_cifar10_aug_pipelines}\n",
    "\n",
    "\n",
    "def get_bt_aug_pipelines(bt_augs,size):\n",
    "\n",
    "    return bt_aug_func_dict[bt_augs](size)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End to end example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='23' class='' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      5.90% [23/390 01:20&lt;21:26 456.3763]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m bt_aug_pipelines \u001b[39m=\u001b[39m get_bt_aug_pipelines(bt_augs\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mbt_augs, size\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39msize)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# ###Setup saving?\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# #Make directory based on config file? (this is on google drive)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#     ###save checkpoints here? every 100 epochs?\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m model \u001b[39m=\u001b[39m train_bt(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                 dls\u001b[39m=\u001b[39;49mdls,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                 bt_aug_pipelines\u001b[39m=\u001b[39;49mbt_aug_pipelines,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                 lmb\u001b[39m=\u001b[39;49mlmb,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m                 n_in\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mn_in,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m                 model_type\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mmodel_type,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m                 wd\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mwd,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m                 epochs\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mepochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m                 freeze_epochs\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mfreeze_epochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m                 device\u001b[39m=\u001b[39;49mdevice\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m                 )\n",
      "\u001b[1;32m/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb Cell 25\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     model\u001b[39m=\u001b[39mbt_trainer\u001b[39m.\u001b[39mbt_transfer_learning(freeze_epochs\u001b[39m=\u001b[39mfreeze_epochs,epochs\u001b[39m=\u001b[39mepochs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     model\u001b[39m=\u001b[39mbt_trainer\u001b[39m.\u001b[39;49mbt_learning(epochs\u001b[39m=\u001b[39;49mepochs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "\u001b[1;32m/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb Cell 25\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbt_learning\u001b[39m(\u001b[39mself\u001b[39m,epochs:\u001b[39mint\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m\"\"\"If the encoder is not pretrained, we can do normal training.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     lrs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearn\u001b[39m.\u001b[39;49mlr_find()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearn\u001b[39m.\u001b[39mfit_one_cycle(epochs, lrs\u001b[39m.\u001b[39mvalley)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamishhaggerty/base_rbt/nbs/base_model.ipynb#X54sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearn\u001b[39m.\u001b[39mmodel\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/callback/schedule.py:293\u001b[0m, in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[1;32m    291\u001b[0m n_epoch \u001b[39m=\u001b[39m num_it\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mtrain) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    292\u001b[0m cb\u001b[39m=\u001b[39mLRFinder(start_lr\u001b[39m=\u001b[39mstart_lr, end_lr\u001b[39m=\u001b[39mend_lr, num_it\u001b[39m=\u001b[39mnum_it, stop_div\u001b[39m=\u001b[39mstop_div)\n\u001b[0;32m--> 293\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_logging(): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(n_epoch, cbs\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m suggest_funcs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     lrs, losses \u001b[39m=\u001b[39m tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecorder\u001b[39m.\u001b[39mlrs[num_it\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m]), tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecorder\u001b[39m.\u001b[39mlosses[num_it\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:256\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mset_hypers(lr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr \u001b[39mif\u001b[39;00m lr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m lr)\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epoch \u001b[39m=\u001b[39m n_epoch\n\u001b[0;32m--> 256\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_fit, \u001b[39m'\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelFitException, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_end_cleanup)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    194\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:245\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epoch):\n\u001b[1;32m    244\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch\u001b[39m=\u001b[39mepoch\n\u001b[0;32m--> 245\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch, \u001b[39m'\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelEpochException)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    194\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_epoch\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch_train()\n\u001b[1;32m    240\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:231\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_epoch_train\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mtrain\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_batches, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelTrainException)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    194\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall_batches\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mone_batch(\u001b[39m*\u001b[39;49mo)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:227\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    225\u001b[0m b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_device(b)\n\u001b[1;32m    226\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(b)\n\u001b[0;32m--> 227\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_one_batch, \u001b[39m'\u001b[39;49m\u001b[39mbatch\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelBatchException)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    194\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:212\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mself\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mafter_loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    211\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39myb): \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backward, \u001b[39m'\u001b[39;49m\u001b[39mbackward\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelBackwardException)\n\u001b[1;32m    213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_with_events(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step, \u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m, CancelStepException)\n\u001b[1;32m    214\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    194\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._backward\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m--> 201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backward\u001b[39m(\u001b[39mself\u001b[39m): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_grad\u001b[39m.\u001b[39;49mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/_tensor.py:479\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \n\u001b[1;32m    434\u001b[0m \u001b[39mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39;49mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39;49m,),\n\u001b[1;32m    482\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    483\u001b[0m         gradient\u001b[39m=\u001b[39;49mgradient,\n\u001b[1;32m    484\u001b[0m         retain_graph\u001b[39m=\u001b[39;49mretain_graph,\n\u001b[1;32m    485\u001b[0m         create_graph\u001b[39m=\u001b[39;49mcreate_graph,\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[1;32m    488\u001b[0m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/overrides.py:1534\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1530\u001b[0m                   \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1532\u001b[0m \u001b[39m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[39m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1534\u001b[0m result \u001b[39m=\u001b[39m torch_func_method(public_api, types, args, kwargs)\n\u001b[1;32m   1536\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1537\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/torch_core.py:378\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39m__str__\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m__repr__\u001b[39m\u001b[39m'\u001b[39m): \u001b[39mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    377\u001b[0m \u001b[39mif\u001b[39;00m _torch_handled(args, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_opt, func): types \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mTensor,)\n\u001b[0;32m--> 378\u001b[0m res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m__torch_function__(func, types, args, ifnone(kwargs, {}))\n\u001b[1;32m    379\u001b[0m dict_objs \u001b[39m=\u001b[39m _find_args(args) \u001b[39mif\u001b[39;00m args \u001b[39melse\u001b[39;00m _find_args(\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mvalues()))\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mtype\u001b[39m(res),TensorBase) \u001b[39mand\u001b[39;00m dict_objs: res\u001b[39m.\u001b[39mset_meta(dict_objs[\u001b[39m0\u001b[39m],as_copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/_tensor.py:1279\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m   1278\u001b[0m \u001b[39mwith\u001b[39;00m _C\u001b[39m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1279\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1280\u001b[0m     \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1281\u001b[0m         \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "\n",
    "# #Choose the config file: this is all we change to run different experiments\n",
    "config_path = '../configs/cifar10/config1.yaml'\n",
    "config = load_config(config_path)\n",
    "\n",
    "#cuda or cpu\n",
    "device = default_device()\n",
    "\n",
    "###hps from config\n",
    "\n",
    "#still need to figure out how to set lmb properly\n",
    "lmb = 1/config.ps\n",
    "#config.lmb = lmb\n",
    "\n",
    "#Based on the config, construct model\n",
    "encoder = resnet_arch_to_encoder(arch=config.arch,weight_type=config.weight_type)\n",
    "model = create_p3barlow_twins_model(encoder, hidden_size=config.hs, projection_size=config.ps)\n",
    "\n",
    "#Based on config, construct data\n",
    "dls = get_ssl_dls(dataset=config.dataset,bs=config.bs, device=device)\n",
    "\n",
    "#Based on config, construct augmentations\n",
    "bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "\n",
    "# ###Setup saving?\n",
    "\n",
    "# #Make directory based on config file? (this is on google drive)\n",
    "\n",
    "@patch\n",
    "def after_epoch(self:BarlowTwins):\n",
    "\n",
    "    if self.epoch % 100 == 0:\n",
    "        pass\n",
    "        \n",
    "        #self.learn.save(f'bt_{self.epoch}')\n",
    "        #save the state_dict of the model\n",
    "        #probably a unique folder for each experiment?\n",
    "        #\n",
    "\n",
    "\n",
    "# model = train_bt(model=model,\n",
    "#                 dls=dls,\n",
    "#                 bt_aug_pipelines=bt_aug_pipelines,\n",
    "#                 lmb=lmb,\n",
    "#                 n_in=config.n_in,\n",
    "#                 model_type=config.model_type,\n",
    "#                 wd=config.wd,\n",
    "#                 epochs=config.epochs,\n",
    "#                 freeze_epochs=config.freeze_epochs,\n",
    "#                 weight_type=config.weight_type,\n",
    "#                 device=device,\n",
    "\n",
    "#                 ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/Experiments/cifar10/resnet18/2024-02-10_19-05-29/model_epoch_100.pt'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Example structure: /content/drive/My Drive/Experiments/cifar10/resnet18/2023-01-01_12-00-00/\n",
    "# base_dir = '/content/drive/My Drive/Experiments'\n",
    "# experiment_dir = os.path.join(base_dir, config.dataset, config.arch, datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "\n",
    "# epoch=100\n",
    "# checkpoint_path = os.path.join(experiment_dir, f'model_epoch_{epoch}.pt')\n",
    "# checkpoint_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get some MNIST data, define a model and augmentation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#Get some MNIST data and plonk it into a dls\n",
    "# bs=32\n",
    "# path = untar_data(URLs.MNIST)\n",
    "# items = get_image_files(path/'training') #i.e. NOT testing!!!\n",
    "# items=items.shuffle()\n",
    "# items = items[0:bs*2]\n",
    "# split = RandomSplitter(valid_pct=0.0)\n",
    "# tds = Datasets(items, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items))\n",
    "# dls = tds.dataloaders(bs=bs,num_workers=0, after_item=[ToTensor(), IntToFloatTensor()], device=default_device().type)\n",
    "\n",
    "# #Define the model\n",
    "# size=28\n",
    "# ps=10\n",
    "# hs=10\n",
    "# n_in=1\n",
    "# fastai_encoder = create_fastai_encoder(xresnet18(),pretrained=False,n_in=n_in)\n",
    "# #model = create_barlow_twins_model(fastai_encoder, hidden_size=hs,projection_size=ps)# projection_size=1024)\n",
    "# model = create_p3barlow_twins_model(fastai_encoder, hidden_size=hs,projection_size=ps)# projection_size=1024)\n",
    "\n",
    "\n",
    "# #Aug pipeline\n",
    "# aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=28,blur_r=(0.5,2.5),\n",
    "#                     rotate=True,jitter=False,noise=False,bw=False,blur=True,solar=False, #Whether to use aug or not\n",
    "#                     resize_scale=(0.5, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.05, rotate_deg=25,blur_s=11,sol_t=0.025,sol_a=0.025, #hps of augs\n",
    "#                     flip_p=0.1, rotate_p=0.5,noise_p=0.5, jitter_p=0.3, bw_p=0.3, blur_p=0.5,sol_p=0.2, #prob of performing aug\n",
    "#                     same_on_batch=False,stats=mnist_stats)\n",
    "\n",
    "# aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=28,blur_r=(0.5,2.5),\n",
    "#                     rotate=True,jitter=False,noise=True,bw=False,blur=False,solar=True, #Whether to use aug or not\n",
    "#                     resize_scale=(0.5, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.05, rotate_deg=25,blur_s=11,sol_t=0.025,sol_a=0.025, #hps of augs\n",
    "#                     flip_p=0.1, rotate_p=0.5,noise_p=0.5, jitter_p=0.3, bw_p=0.3, blur_p=1.0,sol_p=0.2, #prob of performing aug\n",
    "#                     same_on_batch=False,stats=mnist_stats)\n",
    "\n",
    "#\"union\" if 1 and 2\n",
    "# aug_pipelines_12 = get_barlow_twins_aug_pipelines(size=28,blur_r=(0.5,2.5),\n",
    "#                     rotate=True,jitter=False,noise=True,bw=False,blur=True,solar=True, #Whether to use aug or not\n",
    "#                     resize_scale=(0.5, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.05, rotate_deg=25,blur_s=11,sol_t=0.025,sol_a=0.025, #hps of augs\n",
    "#                     flip_p=0.1, rotate_p=0.5,noise_p=0.5, jitter_p=0.3, bw_p=0.3, blur_p=0.5,sol_p=0.2, #prob of performing aug\n",
    "#                     same_on_batch=False,stats=mnist_stats)\n",
    "\n",
    "#aug_pipelines = [aug_pipelines_1,aug_pipelines_1]\n",
    "# tem = BarlowTwins(aug_pipelines,n_in=n_in,print_augs=True)\n",
    "# learn = Learner(dls,model, cbs=[tem])\n",
    "# #learn.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#show_bt_batch(dls=dls,n_in=1,aug=aug_pipelines,n=2,print_augs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "\n",
    "#train_bt = TrainBT(model=model,hp_dict={'dls':dls,'aug_pipelines':aug_pipelines,'wd':1.5*1e-6,n_in':n_in,'lmb':1/ps,'model_type':'barlow_twins'})\n",
    "#model=train_bt.bt_learning(epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, here is an example on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# n_in=3\n",
    "# size=32\n",
    "# bs=100\n",
    "# path = untar_data(URLs.CIFAR)\n",
    "# items = get_image_files(path / \"train\")\n",
    "# items=items.shuffle()\n",
    "# items = items[0:200]\n",
    "# split = RandomSplitter(valid_pct=0.0) #randomly split training set into training and validation\n",
    "# #tds = Datasets(items,splits=split(items)) #Do we want this?\n",
    "# tds = Datasets(items, [[PILImage.create,Resize(size)], [parent_label, Categorize()]], splits=split(items)) #Or do we want this?\n",
    "\n",
    "# dls = tds.dataloaders(bs=bs,num_workers=0, after_item=[ToTensor(), IntToFloatTensor()], device=default_device().type)\n",
    "\n",
    "# fastai_encoder = create_fastai_encoder(xresnet18(),pretrained=False,n_in=n_in)\n",
    "# model = create_barlow_twins_model(fastai_encoder, hidden_size=10,projection_size=10)# projection_size=1024)\n",
    "\n",
    "# aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "#                                                  bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "#                                                  resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "#                                                  bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n",
    "#                                                  stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "#                                                  )\n",
    "\n",
    "# aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "#                                                  bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "#                                                  resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n",
    "#                                                  bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n",
    "#                                                  stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "#                                                  )\n",
    "\n",
    "# aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "# aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "# aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "# learn = Learner(dls,model, cbs=[BarlowTwins(aug_pipelines,n_in=n_in,print_augs=True)])\n",
    "# #learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the augmentations used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#show_bt_batch(dls=dls,n_in=n_in,aug=aug_pipelines,n=20,print_augs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
