{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_model\n",
    "\n",
    "> In this module we have the base model, learner and other things we need to train encoder with Barlow Twins and other methods.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import importlib\n",
    "import sys\n",
    "import self_supervised\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import kornia.augmentation as korniatfm\n",
    "import torchvision.transforms as tvtfm\n",
    "from base_rbt.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the base functions and classes to train a basic BT-style model. Note that this (mostly) all comes directly from here: `https://github.com/KeremTurgutlu/self_supervised/blob/main/nbs/14%20-%20barlow_twins.ipynb`\n",
    "but we needed to extend some of the functionality for our purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the base classes and functions needed for image augmentation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#My edited version of RandTransform\n",
    "class RandomGaussianBlur(RandTransform):\n",
    "    \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "    order = 11\n",
    "    def __init__(self, \n",
    "                 p=1.0, #debugging (bug in libraries implementation)\n",
    "                 prob=0.5,#the real probability\n",
    "                 s=(8,32), #kernel\n",
    "                 sig=None, #sig_val is either manually input OR\n",
    "                 blur_r=(0.1,2),#is randomly chosen from uniform with these bounds\n",
    "                 same_on_batch=False, \n",
    "                 **kwargs): \n",
    "        \n",
    "        store_attr()\n",
    "        super().__init__(p=p, **kwargs)\n",
    "\n",
    "    def encodes(self, x:TensorImage):\n",
    "        \n",
    "        if isinstance(self.s, int):   s = (self.s,self.s)\n",
    "        elif isinstance(self.s, tuple) or isinstance(self.s, list): s=self.s\n",
    "     \n",
    "        #Default for ImageNet from BYOL / BT papers\n",
    "        if self.sig is None:\n",
    "            sig_val = np.random.uniform(self.blur_r[0],self.blur_r[1])\n",
    "        \n",
    "        else:\n",
    "            sig_val = self.sig\n",
    "            \n",
    "\n",
    "        tfm = korniatfm.RandomGaussianBlur(kernel_size=s,sigma=(sig_val,sig_val),same_on_batch=self.same_on_batch,p=self.prob)\n",
    "        return tfm(x)\n",
    "\n",
    "#Delete later: leaving for backward compatibility for now\n",
    "# class RandomGaussianBlur(RandTransform):\n",
    "#     \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "#     order = 11\n",
    "#     def __init__(self, p=0.5, s=(8,32), same_on_batch=False, **kwargs): \n",
    "#         store_attr()\n",
    "#         super().__init__(p=p, **kwargs)\n",
    "        \n",
    "#     def encodes(self, x:TensorImage):\n",
    "#         if isinstance(self.s, tuple): s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, list):  s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, int):   s = self.s\n",
    "#         s2 = int(s/4)*2+1\n",
    "#         tfm = korniatfm.RandomGaussianBlur((s2,s2),(s,s),same_on_batch=self.same_on_batch,p=1.) #p=1. is a bug\n",
    "#                                             #kernel #sigma\n",
    "        \n",
    "#         return tfm(x)\n",
    "\n",
    "\n",
    "class RandomCenterDropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.5, min_dropout_size=(20, 20), max_dropout_size=(60, 60), fill_value=0, same_on_batch=False):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.min_dropout_size = min_dropout_size\n",
    "        self.max_dropout_size = max_dropout_size\n",
    "        self.fill_value = fill_value\n",
    "        self.same_on_batch = same_on_batch\n",
    "        #self.id_transform = tvtfm.RandomResizedCrop((256, 256), scale=(1.,1.), ratio=(1.,1.))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Check if the augmentation should be applied to the whole batch or individually\n",
    "\n",
    "        #x=self.id_transform(x)\n",
    "\n",
    "        if self.same_on_batch:\n",
    "            if random.random() < self.p:\n",
    "                return self._apply_dropout(x)\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            # Apply dropout individually with given probability\n",
    "            for i in range(x.size(0)):\n",
    "                tem=random.random()\n",
    "                #print(f\"tem is: {tem}\")\n",
    "                if tem < self.p:\n",
    "                    x[i] = self._apply_dropout(x[i].unsqueeze(0)).squeeze(0)\n",
    "            return x\n",
    "\n",
    "    def _apply_dropout(self, img):\n",
    "        for i,count in enumerate(range(img.size(0))):  # Iterate through batch if necessary\n",
    "            _, h, w = img[i].shape\n",
    "            # Generate random dropout size within specified limits\n",
    "            dh = random.randint(self.min_dropout_size[0], self.max_dropout_size[0])\n",
    "            dw = random.randint(self.min_dropout_size[1], self.max_dropout_size[1])\n",
    "            \n",
    "            x1 = int(max((w - dw) / 2, 0))\n",
    "            y1 = int(max((h - dh) / 2, 0))\n",
    "            \n",
    "            mask = torch.ones_like(img[i])\n",
    "            mask[:, y1:y1+dh, x1:x1+dw] = self.fill_value\n",
    "            img[i] = img[i] * mask\n",
    "        \n",
    "        return img\n",
    "\n",
    "    \n",
    "# def get_BT_batch_augs(size,\n",
    "#                     flip=True,crop=True,noise=True,rotate=True,jitter=True,bw=True,blur=True,solar=True,cutout=False, #Whether to use  given aug or not\n",
    "#                     resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.025, rotate_deg=30,jitter_s=.6,blur_s=(4,32),#hps of diff augs\n",
    "#                     blur_r=(0.1,2),blur_sig=None,sol_t=0.05,sol_a=0.05,min_dropout_size=(25, 100),max_dropout_size=(50,150), #hps of diff augs\n",
    "#                     flip_p=0.5, rotate_p=0.3,noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3,sol_p=0.1,cut_p=0.0, #prob of performing aug\n",
    "#                     same_on_batch=False,stats=imagenet_stats,cuda=default_device().type == 'cuda',xtra_tfms=[]\n",
    "#                     ):\n",
    "#     \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    \n",
    "#     tfms = []\n",
    "\n",
    "#     korniatfm.RandomHorizontalFlip.order = RandomResizedCrop.order-1\n",
    "\n",
    "\n",
    "#     if crop: tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "#     #Unfortunately for some reason this doesn't work, so we can't apply \"same_on_batch=False\"\n",
    "#     #tfms += [korniatfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio, same_on_batch=same_on_batch)]\n",
    "\n",
    "#     if cutout: tfms+=[RandomCenterDropout(min_dropout_size=min_dropout_size,max_dropout_size=max_dropout_size, fill_value=0, p=cut_p,same_on_batch=same_on_batch)]\n",
    "    \n",
    "  \n",
    "#     if flip: tfms += [korniatfm.RandomHorizontalFlip(p=flip_p,same_on_batch=same_on_batch)]\n",
    "\n",
    "#     if rotate: tfms += [Rotate(max_deg=rotate_deg, p=rotate_p, batch=same_on_batch)]\n",
    "\n",
    "#                                              #brightness,contrast,saturation,hue\n",
    "#     if jitter: tfms += [korniatfm.ColorJitter(0.4*jitter_s, 0.4*jitter_s, 0.2*jitter_s, 0.1*jitter_s, p=jitter_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "#     if bw:     tfms += [korniatfm.RandomGrayscale(p=bw_p, same_on_batch=same_on_batch)]\n",
    "        \n",
    "#     #sig will usually be None\n",
    "#     if blur:   tfms += [RandomGaussianBlur(prob=blur_p, s=blur_s,sig=blur_sig,blur_r=blur_r, same_on_batch=same_on_batch)]\n",
    "\n",
    "#     korniatfm.RandomSolarize.order = RandomGaussianBlur.order + 1 #we want to apply solarization after RandomGaussianBlur\n",
    "    \n",
    "#     if solar: tfms += [korniatfm.RandomSolarize(p=sol_p,thresholds=sol_t, additions=sol_a,same_on_batch=same_on_batch)]\n",
    "\n",
    "#     if noise: tfms+=[korniatfm.RandomGaussianNoise(mean=0.0, std=noise_std, same_on_batch=same_on_batch, p=noise_p)]\n",
    "    \n",
    "#     if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "\n",
    "#     tfms += xtra_tfms\n",
    "\n",
    "#     pipe = Pipeline(tfms, split_idx = 0)\n",
    "#     return pipe\n",
    "\n",
    "def get_BT_batch_augs(size,\n",
    "                    flip=True, crop=True, noise=True, rotate=True, jitter=True, bw=True, blur=True, solar=True, cutout=False, quarter_mask=False,  # Whether to use given aug or not\n",
    "                    resize_scale=(0.08, 1.0), resize_ratio=(3/4, 4/3), noise_std=0.025, rotate_deg=30, jitter_s=.6, blur_s=(4,32),  # hps of diff augs\n",
    "                    blur_r=(0.1,2), blur_sig=None, sol_t=0.05, sol_a=0.05, min_dropout_size=(25, 100), max_dropout_size=(50,150),  # hps of diff augs\n",
    "                    flip_p=0.5, rotate_p=0.3, noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3, sol_p=0.1, cut_p=0.0, quarter_mask_p=0.5,  # prob of performing aug\n",
    "                    same_on_batch=False, stats=imagenet_stats, cuda=default_device().type == 'cuda', xtra_tfms=[]\n",
    "                    ):\n",
    "    \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    \n",
    "    tfms = []\n",
    "\n",
    "    korniatfm.RandomHorizontalFlip.order = RandomResizedCrop.order-1\n",
    "\n",
    "    if crop: tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "\n",
    "    if cutout: tfms += [RandomCenterDropout(min_dropout_size=min_dropout_size, max_dropout_size=max_dropout_size, fill_value=0, p=cut_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if quarter_mask:\n",
    "        tfms += [RandomQuarterMask(p=quarter_mask_p)]\n",
    "        \n",
    "    # if half_mask:\n",
    "    #     tfms += [RandomHalfMask(p=half_mask_p)]  # Add this line\n",
    "\n",
    "    if flip: tfms += [korniatfm.RandomHorizontalFlip(p=flip_p, same_on_batch=same_on_batch)]\n",
    "\n",
    "    if rotate: tfms += [Rotate(max_deg=rotate_deg, p=rotate_p, batch=same_on_batch)]\n",
    "\n",
    "    if jitter: tfms += [korniatfm.ColorJitter(0.4*jitter_s, 0.4*jitter_s, 0.2*jitter_s, 0.1*jitter_s, p=jitter_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if bw: tfms += [korniatfm.RandomGrayscale(p=bw_p, same_on_batch=same_on_batch)]\n",
    "        \n",
    "    if blur: tfms += [RandomGaussianBlur(prob=blur_p, s=blur_s, sig=blur_sig, blur_r=blur_r, same_on_batch=same_on_batch)]\n",
    "\n",
    "    korniatfm.RandomSolarize.order = RandomGaussianBlur.order + 1\n",
    "    \n",
    "    if solar: tfms += [korniatfm.RandomSolarize(p=sol_p, thresholds=sol_t, additions=sol_a, same_on_batch=same_on_batch)]\n",
    "\n",
    "    if noise: tfms += [korniatfm.RandomGaussianNoise(mean=0.0, std=noise_std, same_on_batch=same_on_batch, p=noise_p)]\n",
    "    \n",
    "    if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "\n",
    "    tfms += xtra_tfms\n",
    "\n",
    "    pipe = Pipeline(tfms, split_idx = 0)\n",
    "    return pipe\n",
    "\n",
    "# class RandomHalfMask(RandTransform):\n",
    "#     \"Randomly mask either the left or right half of the image or batch of images\"\n",
    "#     order = 11  # Adjust this order as needed\n",
    "    \n",
    "#     def __init__(self, p=0.5):\n",
    "#         super().__init__(p=p)\n",
    "    \n",
    "#     def encodes(self, x:TensorImage):\n",
    "#         if random.random() > self.p:\n",
    "#             return x\n",
    "        \n",
    "#         if x.dim() == 3:  # Single image\n",
    "#             c, h, w = x.shape\n",
    "#             mask = torch.ones_like(x)\n",
    "#             if random.random() < 0.5:\n",
    "#                 mask[:, :, w//2:] = 0  # Mask right half\n",
    "#             else:\n",
    "#                 mask[:, :, :w//2] = 0  # Mask left half\n",
    "#         elif x.dim() == 4:  # Batch of images\n",
    "#             b, c, h, w = x.shape\n",
    "#             mask = torch.ones_like(x)\n",
    "#             for i in range(b):\n",
    "#                 if random.random() < 0.5:\n",
    "#                     mask[i, :, :, w//2:] = 0  # Mask right half\n",
    "#                 else:\n",
    "#                     mask[i, :, :, :w//2] = 0  # Mask left half\n",
    "#         else:\n",
    "#             raise ValueError(f\"Expected 3D or 4D tensor, got {x.dim()}D tensor\")\n",
    "        \n",
    "#         return x * mask\n",
    "\n",
    "# class RandomHalfMask(RandTransform):\n",
    "#     \"Randomly mask either the left or right half of the image or batch of images with probability p\"\n",
    "#     order = 11  # Adjust this order as needed\n",
    "    \n",
    "#     def __init__(self, p=0.5):\n",
    "#         super().__init__(p=1.0)  # Always apply the transform\n",
    "#         self.mask_prob = p  # Probability of applying a mask\n",
    "    \n",
    "#     def encodes(self, x:TensorImage):\n",
    "#         if random.random() >= self.mask_prob:\n",
    "#             return x  # No masking applied\n",
    "        \n",
    "#         if x.dim() == 3:  # Single image\n",
    "#             c, h, w = x.shape\n",
    "#             mask = torch.ones_like(x)\n",
    "#             if random.random() < 0.5:\n",
    "#                 mask[:, :, w//2:] = 0  # Mask right half\n",
    "#             else:\n",
    "#                 mask[:, :, :w//2] = 0  # Mask left half\n",
    "#             return x * mask\n",
    "#         elif x.dim() == 4:  # Batch of images\n",
    "#             b, c, h, w = x.shape\n",
    "#             mask = torch.ones_like(x)\n",
    "#             for i in range(b):\n",
    "#                 if random.random() < 0.5:\n",
    "#                     mask[i, :, :, w//2:] = 0  # Mask right half\n",
    "#                 else:\n",
    "#                     mask[i, :, :, :w//2] = 0  # Mask left half\n",
    "#             return x * mask\n",
    "#         else:\n",
    "#             raise ValueError(f\"Expected 3D or 4D tensor, got {x.dim()}D tensor\")\n",
    "\n",
    "class RandomQuarterMask(RandTransform):\n",
    "    \"Randomly mask a quarter of the image with probability p\"\n",
    "    order = 11  # Adjust this order as needed\n",
    "    \n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__(p=1.0)  # Always apply the transform\n",
    "        self.mask_prob = p  # Probability of applying a mask\n",
    "    \n",
    "    def encodes(self, x:TensorImage):\n",
    "        if random.random() >= self.mask_prob:\n",
    "            return x  # No masking applied\n",
    "        \n",
    "        if x.dim() == 3:  # Single image\n",
    "            return self._mask_single_image(x)\n",
    "        elif x.dim() == 4:  # Batch of images\n",
    "            return torch.stack([self._mask_single_image(img) for img in x])\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 3D or 4D tensor, got {x.dim()}D tensor\")\n",
    "    \n",
    "    def _mask_single_image(self, img):\n",
    "        c, h, w = img.shape\n",
    "        mask = torch.ones_like(img)\n",
    "        quarter = random.choice(['top_left', 'top_right', 'bottom_left', 'bottom_right'])\n",
    "        \n",
    "        if quarter == 'top_left':\n",
    "            mask[:, :h//2, :w//2] = 0\n",
    "        elif quarter == 'top_right':\n",
    "            mask[:, :h//2, w//2:] = 0\n",
    "        elif quarter == 'bottom_left':\n",
    "            mask[:, h//2:, :w//2] = 0\n",
    "        else:  # bottom_right\n",
    "            mask[:, h//2:, w//2:] = 0\n",
    "        \n",
    "        return img * mask\n",
    "\n",
    "@delegates(get_BT_batch_augs)\n",
    "def get_multi_aug_pipelines(size, **kwargs): return get_BT_batch_augs(size, **kwargs)\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(size=size,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_cifar10_aug_pipelines(size):\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    bt_cifar10_aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return bt_cifar10_aug_pipelines\n",
    "\n",
    "#Add other augmentations here e.g. BYOL augs\n",
    "IMAGENET_Augs = dict(flip_p1=0.5,flip_p2=0.5,jitter_p1=0.8,jitter_p2=0.8,bw_p1=0.2,\n",
    "                bw_p2=0.2,blur_p1=1.0,blur_p2=0.1,sol_p1=0.0,sol_p2=0.2,noise_p1=0.0,\n",
    "                noise_p2=0.0,cut_p=0,resize_scale=(0.7, 1.0),resize_ratio=(3/4, 4/3),rotate_deg=45.0,\n",
    "                rotate_p=0.5,blur_r=(0.1,2),blur_s=13,sol_t=0.1,sol_a=0.1,noise_std=0.1,min_dropout_size=None,max_dropout_size=None,\n",
    "                )\n",
    "\n",
    "DERMNET_Augs = IMAGENET_Augs.copy()\n",
    "DERMNET_Augs['min_dropout_size']=(50, 185)\n",
    "DERMNET_Augs['max_dropout_size']=(100,190)\n",
    "DERMNET_Augs['cut_p']=0.33\n",
    "\n",
    "def helper_get_bt_augs(size,Augs=IMAGENET_Augs):\n",
    "\n",
    "\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p1'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p1'],\n",
    "                        jitter_p=Augs['jitter_p1'], bw_p=Augs['bw_p1'], blur_p=Augs['blur_p1'],\n",
    "                        sol_p=Augs['sol_p1'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p2'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p2'],\n",
    "                        jitter_p=Augs['jitter_p2'], bw_p=Augs['bw_p2'], blur_p=Augs['blur_p2'],\n",
    "                        sol_p=Augs['sol_p2'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return aug_pipelines\n",
    "\n",
    "def get_bt_imagenet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=IMAGENET_Augs)\n",
    "\n",
    "def get_bt_dermnet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=DERMNET_Augs)\n",
    "\n",
    "\n",
    "\n",
    "bt_aug_func_dict = {'bt_cifar10_aug_pipelines':get_bt_cifar10_aug_pipelines,'bt_imagenet_aug_pipelines':get_bt_imagenet_aug_pipelines,\n",
    "                   'bt_dermnet_aug_pipelines':get_bt_dermnet_aug_pipelines\n",
    "                   }\n",
    "\n",
    "def get_bt_aug_pipelines(bt_augs,size):\n",
    "\n",
    "    return bt_aug_func_dict[bt_augs](size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# def get_bt_predhalf_aug_pipelines(size):\n",
    "#     # Augmentations for the masked view\n",
    "#     aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "#                                                     bw=True, rotate=False, crop=False, noise=True, jitter=True, blur=True, solar=True, half_mask=True,\n",
    "#                                                     noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "#                                                     bw_p=0.2, flip_p=0.0, noise_p=0.5, jitter_p=0.5, blur_p=0.5, sol_p=0.0, half_mask_p=0.5,  # half_mask_p controls the probability of applying the mask\n",
    "#                                                     stats=cifar_stats, same_on_batch=False, xtra_tfms=[]\n",
    "#                                                     )\n",
    "\n",
    "#     # Augmentations for the full view (keep all augmentations)\n",
    "#     aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "#                                                     bw=True, rotate=True, crop=True, noise=True, jitter=True, blur=True, solar=True,\n",
    "#                                                     resize_scale=(0.4, 1.0), rotate_deg=45, noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1, sol_t=0.01, sol_a=0.01,\n",
    "#                                                     bw_p=0.2, flip_p=0.5, rotate_p=0.25, noise_p=0.5, jitter_p=0.5, blur_p=0.1, sol_p=0.2,\n",
    "#                                                     stats=cifar_stats, same_on_batch=False, xtra_tfms=[]\n",
    "#                                                     )\n",
    "\n",
    "#     bt_predhalf_aug_pipelines = [aug_pipelines_1, aug_pipelines_2]\n",
    "\n",
    "#     return bt_predhalf_aug_pipelines\n",
    "\n",
    "def get_bt_predhalf_aug_pipelines(size):\n",
    "    # Augmentations for the masked view\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=False, crop=False, noise=True, jitter=True, blur=True, solar=True, quarter_mask=True,\n",
    "                                                    noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                    bw_p=0.2, flip_p=0.0, noise_p=0.5, jitter_p=0.5, blur_p=0.5, sol_p=0.0, quarter_mask_p=0.5,\n",
    "                                                    stats=cifar_stats, same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    # Augmentations for the full view (keep all augmentations)\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True, crop=True, noise=True, jitter=True, blur=True, solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0), rotate_deg=45, noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1, sol_t=0.01, sol_a=0.01,\n",
    "                                                    bw_p=0.2, flip_p=0.5, rotate_p=0.25, noise_p=0.5, jitter_p=0.5, blur_p=0.1, sol_p=0.2,\n",
    "                                                    stats=cifar_stats, same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    bt_predhalf_aug_pipelines = [aug_pipelines_1, aug_pipelines_2]\n",
    "\n",
    "    return bt_predhalf_aug_pipelines\n",
    "\n",
    "# Update the bt_aug_func_dict\n",
    "bt_aug_func_dict['bt_predhalf_aug_pipelines'] = get_bt_predhalf_aug_pipelines\n",
    "\n",
    "# Add this to the bt_aug_func_dict\n",
    "bt_aug_func_dict['bt_predhalf_aug_pipelines'] = get_bt_predhalf_aug_pipelines\n",
    "\n",
    "#Test\n",
    "# dls = get_ssl_dls('cifar10', bs=32, size=32, device=default_device())\n",
    "# aug = get_bt_aug_pipelines('bt_predhalf_aug_pipelines', 32)\n",
    "# show_bt_batch(dls, n_in=3, aug=aug, n=2, print_augs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls = get_ssl_dls('cifar10', bs=32, size=32, device=default_device())\n",
    "# aug = get_bt_aug_pipelines('bt_predhalf_aug_pipelines', 32)\n",
    "# show_bt_batch(dls, n_in=3, aug=aug, n=2, print_augs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def downsample_image(image, scale_factor=0.125):\n",
    "#     \"\"\"Downsample an image and then upsample to original size.\"\"\"\n",
    "#     _, _, H, W = image.shape\n",
    "#     downsampled = F.interpolate(image, scale_factor=scale_factor, mode='bilinear', align_corners=False)\n",
    "#     return F.interpolate(downsampled, size=(H, W), mode='bilinear', align_corners=False)\n",
    "\n",
    "# def display_original_and_downsampled(original_batch, downsampled_batch, num_images=5):\n",
    "#     fig, axes = plt.subplots(2, num_images, figsize=(num_images*3, 6))\n",
    "    \n",
    "#     for i in range(num_images):\n",
    "#         # Display original image\n",
    "#         axes[0, i].imshow(original_batch[i].permute(1, 2, 0).cpu())\n",
    "#         axes[0, i].axis('off')\n",
    "#         axes[0, i].set_title('Original')\n",
    "        \n",
    "#         # Display downsampled image\n",
    "#         axes[1, i].imshow(downsampled_batch[i].permute(1, 2, 0).cpu())\n",
    "#         axes[1, i].axis('off')\n",
    "#         axes[1, i].set_title('Downsampled')\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# x,y = dls.one_batch()\n",
    "# # Downsample the batch\n",
    "# downsampled_x = downsample_image(x, scale_factor=0.2)  # Downsampling to 1/4 of original size\n",
    "\n",
    "# # Display the original and downsampled images\n",
    "# display_original_and_downsampled(x, downsampled_x, num_images=5)\n",
    "\n",
    "# print(f\"Original shape: {x.shape}\")\n",
    "# print(f\"Downsampled shape: {downsampled_x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_ssl_dls(dataset,#cifar10, dermnet, etc\n",
    "            bs,\n",
    "            size,\n",
    "            device,\n",
    "            pct_dataset=1.0):\n",
    "    # Define the base package name in a variable for easy modification\n",
    "\n",
    "    try:\n",
    "        # Construct the module path\n",
    "        module_path = f\"{PACKAGE_NAME}.{dataset}_dataloading\"\n",
    "        \n",
    "        # Dynamically import the module\n",
    "        dataloading_module = importlib.import_module(module_path)\n",
    "    except ModuleNotFoundError:\n",
    "        # Handle the case where the module cannot be found\n",
    "        raise ImportError(f\"Could not find a data loading module for '{dataset}'. \"\n",
    "                          f\"Make sure '{module_path}' exists and is correctly named.\") from None\n",
    "    \n",
    "    # Assuming the function name follows a consistent naming convention\n",
    "    func_name = f\"get_bt_{dataset}_train_dls\"\n",
    "\n",
    "    try:\n",
    "        # Retrieve the data loading function from the module\n",
    "        data_loader_func = getattr(dataloading_module, func_name)\n",
    "    except AttributeError:\n",
    "        # Handle the case where the function does not exist in the module\n",
    "        raise AttributeError(f\"The function '{func_name}' was not found in '{module_path}'. \"\n",
    "                             \"Ensure it is defined and named correctly.\") from None\n",
    "    \n",
    "    # Proceed to call the function with arguments from the config\n",
    "    try:\n",
    "        dls_train = data_loader_func(bs=bs,size=size,device=device,pct_dataset=pct_dataset)\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the function call\n",
    "        raise RuntimeError(f\"An error occurred while calling '{func_name}' from '{module_path}': {e}\") from None\n",
    "    \n",
    "    return dls_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base functions / classes we need to train a BT / RBT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Base functions / classes we need to train a BT / RBT model.\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "\n",
    "# class BarlowTwinsModel(Module):\n",
    "#     \"\"\"An encoder followed by a projector\n",
    "#     \"\"\"\n",
    "#     def __init__(self,encoder,projector):\n",
    "#         self.encoder = encoder\n",
    "#         self.projector = projector\n",
    "        \n",
    "#     def forward(self,x): \n",
    "        \n",
    "#         return self.projector(self.encoder(x))\n",
    "\n",
    "# def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "#     \"Create Barlow Twins model\"\n",
    "#     n_in  = in_channels(encoder)\n",
    "#     with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "#     projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "#     apply_init(projector)\n",
    "#     return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "\n",
    "#We want access to both representation and projection\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        \n",
    "    def forward(self,x): \n",
    "        tem = self.encoder(x)\n",
    "        return tem,self.projector(tem) #get access to both representation and projection if needed for loss\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'forward returns tuple of (encoder(x),projector(encoder(x)))'\n",
    "\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    " \n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "\n",
    "#Note: this requires an lf (loss function), which is patched in later.\n",
    "#The reason for this is we can specify via a string argument (e.g. via\n",
    "#a config file) what loss function we want to use. lf_bt is the default\n",
    "#(standard barlow twins loss function).\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines,n_in,lmb,sparsity_level, \n",
    "                model_type='barlow_twins',print_augs=False\n",
    "                 ):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        store_attr('sparsity_level')\n",
    "        self.n_in=n_in\n",
    "        self.model_type = model_type\n",
    "        self.index=-1 #Gets updated after each batch\n",
    "        self.acc_dict = {}\n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self.index=-1  \n",
    "  \n",
    "    def before_batch(self):\n",
    "        \n",
    "        #TODO: Make this nicer (possibly can load in data as TensorImage(BW) or something?)\n",
    "        #This is a bit of a hack. Can make this more elegant later. But in new version of FastAI\n",
    "        #seems we need to compute TensorImage(BW) here, and depends on whether color or not, i.e. n_in.\n",
    "        if self.n_in == 1:\n",
    "\n",
    "            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            \n",
    "            #print(xi.shape)\n",
    "                                    \n",
    "        elif self.n_in == 3:\n",
    "            \n",
    "            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    " \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1): \n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]]\n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the above for vicreg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Base functions / classes we need to train a \n",
    "#  model\n",
    "class VICRegModel(Module):\n",
    "    \"\"\"VICReg model with options for shared or separate projectors\"\"\"\n",
    "    def __init__(self, left_encoder, right_encoder, left_projector, right_projector):\n",
    "        #may have right_encoder = encoder_left and right_projector = left_projector.\n",
    "        #or e.g. encoders may have shared weights.\n",
    "        self.left_encoder = left_encoder\n",
    "        self.right_encoder = right_encoder\n",
    "        self.left_projector = left_projector\n",
    "        self.right_projector = right_projector\n",
    "        \n",
    "    def forward(self,x): #x is stacked xi,xj the two augmented views of batch\n",
    "      \n",
    "        x1, x2 = x[:x.size(0)//2], x[x.size(0)//2:]\n",
    "        \n",
    "        z1,z2 = self.left_projector(self.left_encoder(x1)), self.right_projector(self.right_encoder(x2))\n",
    "    \n",
    "        return z1, z2\n",
    "\n",
    "#override fastai method basically\n",
    "from fastai.vision.learner import in_channels as fastai_in_channels\n",
    "def in_channels(m):\n",
    "    try:\n",
    "        return m.in_channels\n",
    "    except AttributeError:\n",
    "        return fastai_in_channels(m)\n",
    "\n",
    "def create_vicreg_model(left_encoder, right_encoder,hidden_size=256, projection_size=128, bn=True, nlayers=3, shared_projector=True):\n",
    "    \"\"\"\n",
    "    Create VICReg model with flexible projector configuration\n",
    "    \n",
    "    Args:\n",
    "    - left_encoder: first encoder model\n",
    "    - right_encoder: second encoder model (can be the same as left_encoder for shared encoder)\n",
    "    - hidden_size: hidden size for projector\n",
    "    - projection_size: output size for projector\n",
    "    - bn: whether to use batch normalization in projector\n",
    "    - nlayers: number of layers in projector\n",
    "    - shared_projector: if True, use the same projector for both branches\n",
    "    \"\"\"\n",
    "    n_in = in_channels(left_encoder)\n",
    "    with torch.no_grad(): representation = left_encoder(torch.randn((2,n_in,32,32)))\n",
    "    \n",
    "    left_projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "    apply_init(left_projector)\n",
    "    \n",
    "    if not shared_projector:\n",
    "        right_projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "        apply_init(right_projector)\n",
    "    else:\n",
    "        right_projector = left_projector\n",
    "    \n",
    "    return VICRegModel(left_encoder, right_encoder, left_projector, right_projector)\n",
    "\n",
    "#helper function to compute vicreg loss.\n",
    "def off_diagonal(x):\n",
    "        n, m = x.shape\n",
    "        assert n == m\n",
    "        return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "class VICReg(BarlowTwins):\n",
    "    def __init__(self, aug_pipelines, n_in=3, sim_coeff=25, std_coeff=25, cov_coeff=1, \n",
    "                 model_type='vicreg', print_augs=False):\n",
    "        super().__init__(aug_pipelines, n_in, None, None, model_type, print_augs)\n",
    "        self.sim_coeff = sim_coeff\n",
    "        self.std_coeff = std_coeff\n",
    "        self.cov_coeff = cov_coeff\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.learn.loss_func = self.lf\n",
    "\n",
    "    def lf(self, pred, *yb):\n",
    "        x, y = pred  # Assuming the model returns two views (see VICRegModel)\n",
    "\n",
    "        # Invariance loss\n",
    "        repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "        # Variance loss\n",
    "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "        # Covariance loss\n",
    "        x = x - x.mean(dim=0)\n",
    "        y = y - y.mean(dim=0)\n",
    "        cov_x = (x.T @ x) / (x.size(0) - 1)\n",
    "        cov_y = (y.T @ y) / (y.size(0) - 1)\n",
    "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(x.size(1)) + \\\n",
    "                   off_diagonal(cov_y).pow_(2).sum().div(y.size(1))\n",
    "\n",
    "        # Total loss\n",
    "        loss = (\n",
    "            self.sim_coeff * repr_loss +\n",
    "            self.std_coeff * std_loss +\n",
    "            self.cov_coeff * cov_loss\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def before_batch(self):\n",
    "        #if self.model_type == 'br_vicreg':\n",
    "\n",
    "    #         # Create two copies of the input\n",
    "    #         x_left, x_right = self.x.clone(), self.x.clone()\n",
    "            \n",
    "    #         # Zero out the right half of x_left and the left half of x_right\n",
    "    #         mid = x_left.shape[-1] // 2\n",
    "    #         x_left[..., mid:] = 0\n",
    "    #         x_right[..., :mid] = 0\n",
    "            \n",
    "    #         print(f\"x shape: {self.x.shape}\")\n",
    "    #         print(f\"x_left shape: {x_left.shape}\")\n",
    "    #         print(f\"x_right shape: {x_right.shape}\")\n",
    "\n",
    "    #         # Apply augmentations\n",
    "    #         if self.n_in == 1:\n",
    "    #             xi = self.aug1(TensorImageBW(x_left))\n",
    "    #             xj = self.aug2(TensorImageBW(x_right))\n",
    "    #         elif self.n_in == 3:\n",
    "    #             xi = self.aug1(TensorImage(x_left))\n",
    "    #             xj = self.aug2(TensorImage(x_right))\n",
    "\n",
    "    #         print(f\"xi shape after aug: {xi.shape}\")\n",
    "    #         print(f\"xj shape after aug: {xj.shape}\")\n",
    "\n",
    "    #         # Concatenate the augmented halves\n",
    "    #         self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "    #         print(f\"Final self.learn.xb shape: {self.learn.xb[0].shape}\")\n",
    "\n",
    "        # The above splits x into x_left and x_right, with padding, then applies\n",
    "        # aug1 and aug2. Alternatively, we could compute aug1(x) and aug2(x). \n",
    "        # then zero pad the right half of aug1(x) and the left half of aug2(x).\n",
    "\n",
    "        #zero padding approach:\n",
    "        # if self.model_type == 'br_vicreg':\n",
    "        #     # Apply augmentations first\n",
    "        #     if self.n_in == 1:\n",
    "        #         xi = self.aug1(TensorImageBW(self.x))\n",
    "        #         xj = self.aug2(TensorImageBW(self.x))\n",
    "        #     elif self.n_in == 3:\n",
    "        #         xi = self.aug1(TensorImage(self.x))\n",
    "        #         xj = self.aug2(TensorImage(self.x))\n",
    "            \n",
    "        #     print(f\"x shape: {self.x.shape}\")\n",
    "        #     print(f\"xi shape after aug: {xi.shape}\")\n",
    "        #     print(f\"xj shape after aug: {xj.shape}\")\n",
    "\n",
    "        #     # Zero out the right half of xi and the left half of xj\n",
    "        #     mid = xi.shape[-1] // 2\n",
    "        #     xi[..., mid:] = 0\n",
    "        #     xj[..., :mid] = 0\n",
    "            \n",
    "        #     print(f\"xi shape after zeroing: {xi.shape}\")\n",
    "        #     print(f\"xj shape after zeroing: {xj.shape}\")\n",
    "\n",
    "        #     # Concatenate the augmented and zeroed halves\n",
    "        #     self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "        #     print(f\"Final self.learn.xb shape: {self.learn.xb[0].shape}\")\n",
    "        # else:\n",
    "        #     # Use the original BarlowTwins before_batch method for 'vicreg'\n",
    "        #     if self.n_in == 1:\n",
    "        #         xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "        #     elif self.n_in == 3:\n",
    "        #         xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "        #     self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "\n",
    "        #here we dont zero pad at all, just get 16x32 (for cifar, say)\n",
    "        if self.model_type == 'br_vicreg':\n",
    "            ### Original implementation for 'vicreg'\n",
    "            if self.n_in == 1:\n",
    "                xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            elif self.n_in == 3:\n",
    "                xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "                   # Randomly apply left/right masking with 50% probability\n",
    "            # p = 0.5\n",
    "            # if random.random() < p:\n",
    "            #     # Calculate the split point\n",
    "            #     _, _, _, width = xi.shape\n",
    "            #     split_point = width // 2\n",
    "                \n",
    "            #     # Zero out the right half of xi and the left half of xj\n",
    "            #     xi[:, :, :, split_point:] = 0\n",
    "            #     xj[:, :, :, :split_point] = 0\n",
    "                \n",
    "            self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "\n",
    "\n",
    "            # # Apply augmentations first\n",
    "            # if self.n_in == 1:\n",
    "            #     xi = self.aug1(TensorImageBW(self.x))\n",
    "            #     xj = self.aug2(TensorImageBW(self.x))\n",
    "            # elif self.n_in == 3:\n",
    "            #     xi = self.aug1(TensorImage(self.x))\n",
    "            #     xj = self.aug2(TensorImage(self.x))\n",
    "            \n",
    "            # # Dynamically calculate the split point\n",
    "            # _, _, height, width = xi.shape\n",
    "            # split_point = width // 2\n",
    "\n",
    "            # # Split each image into left and right halves\n",
    "            # xi_left = xi[..., :split_point]  # Left half\n",
    "            # xj_right = xj[..., split_point:]  # Right half\n",
    "            \n",
    "            # # Concatenate the halves\n",
    "            # self.learn.xb = (torch.cat([xi_left, xj_right], dim=0),)\n",
    "\n",
    "            # print(f\"Input shape: {self.x.shape}\")\n",
    "            # print(f\"Augmented left half shape: {xi_left.shape}\")\n",
    "            # print(f\"Augmented right half shape: {xj_right.shape}\")\n",
    "            # print(f\"Combined batch shape: {self.learn.xb[0].shape}\")\n",
    "\n",
    "        else:\n",
    "            # Original implementation for 'vicreg'\n",
    "            if self.n_in == 1:\n",
    "                xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            elif self.n_in == 3:\n",
    "                xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "            self.learn.xb = (torch.cat([xi, xj], dim=0),)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New idea / method: PredHalf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of barlow twins loss and sparse barlow twins loss functions, and proposes modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt(pred,I,lmb): #standard bt loss\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "    \n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs \n",
    "    cdiff = (C - I)**2\n",
    "    loss = (cdiff*I + cdiff*(1-I)*lmb).sum() \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_sparse_head(pred,I,lmb,projector,sparsity_level):\n",
    "  \n",
    "    bt_loss = lf_bt(pred,I,lmb)\n",
    "    L21 = torch.linalg.norm(projector[-1].weight, ord=2, dim=0).sum()\n",
    "\n",
    "    # print(f\"bt_loss is {bt_loss}, L21 is {L21}, scaled L21 is {sparsity_level*L21}\")\n",
    "    # print(bt_loss)\n",
    "    # print(L21)\n",
    "\n",
    "    \n",
    "    loss =  bt_loss + sparsity_level*L21 #barlow twins loss + L21 norm of last layer of projector\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_indiv_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb*(0.5*torch.abs(z1_enc) + 0.5*torch.abs(z2_enc)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1_enc.pow(2) + 0.5 * z2_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_norm_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_fun(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm_enc.T @ z2norm_enc) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    loss = (cdiff*I).sum() #standard bt loss\n",
    "\n",
    "    print(f\"invariance loss is: {loss} and sparsity loss is: {sparsity}\")\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_proj_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                           ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm.pow(2) + 0.5 * z2norm.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def lf_predhalf(pred_enc, pred, I, lmb):\n",
    "    bs = pred_enc.size(0) // 2\n",
    "    z1, z2 = pred_enc[:bs], pred_enc[bs:]  # encoder outputs\n",
    "    p1, p2 = pred[:bs], pred[bs:]  # predictor outputs\n",
    "\n",
    "    # Prediction loss\n",
    "    pred_loss = F.mse_loss(p1, z2)\n",
    "\n",
    "    # Variance loss\n",
    "    std_z1 = torch.sqrt(z1.var(dim=0) + 0.0001)\n",
    "    std_z2 = torch.sqrt(z2.var(dim=0) + 0.0001)\n",
    "    var_loss = torch.mean(F.relu(1 - std_z1)) / 2 + torch.mean(F.relu(1 - std_z2)) / 2\n",
    "\n",
    "    # Covariance loss\n",
    "      # Covariance loss\n",
    "    z1 = z1 - z1.mean(dim=0)\n",
    "    z2 = z2 - z2.mean(dim=0)\n",
    "    cov_z1 = (z1.T @ z1) / (z1.shape[0] - 1)\n",
    "    cov_z2 = (z2.T @ z2) / (z2.shape[0] - 1)\n",
    "    cov_loss = off_diagonal(cov_z1).pow_(2).sum().div(z1.shape[1]) + \\\n",
    "               off_diagonal(cov_z2).pow_(2).sum().div(z2.shape[1])\n",
    "\n",
    "    # Combine losses\n",
    "    loss = pred_loss + 25 * var_loss + 1 * cov_loss  # Adjust weights as needed\n",
    "\n",
    "    return loss\n",
    "\n",
    "def off_diagonal(x):\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch in loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb):\n",
    "    \"Assumes model created according to type p3\"\n",
    "\n",
    "    if self.model_type=='barlow_twins':\n",
    "         pred_enc = pred[0]\n",
    "         pred = pred[1]\n",
    "         return lf_bt(pred, self.I,self.lmb)\n",
    "\n",
    "    elif self.model_type=='sparse_head_barlow_twins':\n",
    "        pred_enc = pred[0]\n",
    "        pred = pred[1]\n",
    "\n",
    "        return lf_bt_sparse_head(pred, self.I,lmb=self.lmb,projector=self.learn.model.projector,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='indiv_sparse_barlow_twins':\n",
    "        return lf_bt_indiv_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='group_sparse_barlow_twins':\n",
    "        return lf_bt_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='group_norm_sparse_barlow_twins':\n",
    "        return lf_bt_group_norm_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='proj_group_sparse_barlow_twins':\n",
    "        return lf_bt_proj_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='fun':\n",
    "        return lf_bt_fun(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "\n",
    "    elif self.model_type == 'predhalf_barlow_twins':\n",
    "        pred_enc = pred[0]\n",
    "        pred = pred[1]\n",
    "        \n",
    "        return lf_predhalf(pred_enc, pred, self.I, self.lmb)\n",
    "\n",
    "\n",
    "    else: raise(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt(m):\n",
    "    return L(sequential(*m.encoder),m.projector).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt_last_block_resnet50(m):\n",
    "    #Note: don't think we actually need this guy.\n",
    "    \"Freeze all but the last bottleneck layer\"\n",
    "    enc_except_final_block = sequential(*m.encoder[:-3], m.encoder[-3][:-1])\n",
    "    final_block_and_projector = sequential(m.encoder[-3][-1], m.projector)\n",
    "    return L(enc_except_final_block, final_block_and_projector).map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to use the above functions in an end to end fashion. First we get some data and plonk it into a dls, Then create an encoder, an augmentation pipeline, a learner, then fit\n",
    "the learner. This is the complete process of training BT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_bt_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "        \n",
    "    learn = Learner(dls,model=None, cbs=[BarlowTwins(aug,n_in=n_in,lmb=None,sparsity_level=None,\n",
    "                                                     print_augs=print_augs\n",
    "                                        )])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.barlow_twins.show(n=n)\n",
    "\n",
    "def show_vicreg_batch(dls,n_in,aug,n=2,print_augs=True,model_type='vicreg'):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "\n",
    "    learn = Learner(dls,model=None, cbs=[VICReg(aug,n_in=3,model_type=model_type)])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.vic_reg.show(n=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide \n",
    "\n",
    "#dls = get_ssl_dls('cifar10',bs=32,size=128,device=default_device())\n",
    "#aug = get_bt_cifar10_aug_pipelines(32)\n",
    "#show_vicreg_batch(dls,n_in=3,aug=aug,n=2,print_augs=True,model_type='vicreg')\n",
    "#show_vicreg_batch(dls,n_in=3,aug=aug,n=8,print_augs=True,model_type='br_vicreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SaveBarlowLearnerCheckpoint(Callback):\n",
    "    \"Save such that can resume training \"\n",
    "    def __init__(self, experiment_dir,start_epoch=0, save_interval=250,with_opt=True):\n",
    "        self.experiment_dir = experiment_dir\n",
    "        self.start_epoch = start_epoch\n",
    "        self.save_interval = save_interval\n",
    "        self.with_opt = with_opt  # Decide whether to save optimizer state as well.\n",
    "\n",
    "    def after_epoch(self):\n",
    "        if (self.epoch+1) % self.save_interval == 0 and self.epoch>=self.start_epoch:\n",
    "            print(f\"Saving model and learner state at epoch {self.epoch}\")\n",
    "   \n",
    "            checkpoint_filename = f\"learner_checkpoint_epoch_{self.epoch}\"\n",
    "            checkpoint_path = os.path.join(self.experiment_dir, checkpoint_filename)\n",
    "            # Save the entire learner object, including the model's parameters and optimizer state.\n",
    "            self.learn.save(checkpoint_path, with_opt=self.with_opt)\n",
    "            print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "class SaveBarlowLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        encoder_filename = f\"trained_encoder_epoch_{self.epoch}.pth\"\n",
    "        encoder_path = os.path.join(self.experiment_dir, encoder_filename)\n",
    "        torch.save(self.learn.model.encoder.state_dict(), encoder_path)\n",
    "        print(f\"encoder state dict saved to {encoder_path}\")\n",
    "\n",
    "\n",
    "class SaveVicRegLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        left_encoder_filename = f\"trained_left_encoder_epoch_{self.epoch}.pth\"\n",
    "        left_encoder_path = os.path.join(self.experiment_dir, left_encoder_filename)\n",
    "        torch.save(self.learn.model.left_encoder.state_dict(), left_encoder_path)\n",
    "        print(f\"Left encoder state dict saved to {left_encoder_path}\")\n",
    "\n",
    "        right_encoder_filename = f\"trained_right_encoder_epoch_{self.epoch}.pth\"\n",
    "        right_encoder_path = os.path.join(self.experiment_dir, right_encoder_filename)\n",
    "        torch.save(self.learn.model.right_encoder.state_dict(), right_encoder_path)\n",
    "        print(f\"Right encoder state dict saved to {right_encoder_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_barlow_model(arch,ps,hs,path):\n",
    "\n",
    "    encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_barlow_twins_model(encoder, hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_vicreg_model(arch,ps,hs,path):\n",
    "\n",
    "    left_encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    right_encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_vicreg_model(left_encoder,right_encoder,hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BarlowTrainer:\n",
    "    \"Setup a learner for training a BT model. Can do transfer learning, normal training, or resume training.\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,#An encoder followed by a projector\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 lmb,\n",
    "                 sparsity_level,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 fit=False, #This means use learn.fit(.) in FastAI\n",
    "                 sgdr=False,\n",
    "                 splitter_str='none',\n",
    "                 num_it=100, #Number of iterations to run lr_find for.\n",
    "                 load_learner_path=None, #Path to load learner from (optional)\n",
    "                 experiment_dir=None, #Where to save model checkpoints (optional)\n",
    "                 start_epoch=0, #Which epoch to start from\n",
    "                 save_interval=None, #How often to save model checkpoints (optional). \n",
    "                 export=False,\n",
    "                 ):\n",
    "\n",
    "        store_attr()\n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    \n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics.\n",
    "\n",
    "        Returns:\n",
    "        - learn: The Learner object.\n",
    "        \"\"\"\n",
    "      \n",
    "        self.model.to(self.device)\n",
    "\n",
    "\n",
    "        cbs = [BarlowTwins(self.bt_aug_pipelines,n_in=self.n_in,lmb=self.lmb,\n",
    "                           sparsity_level=self.sparsity_level,print_augs=False,\n",
    "                           model_type=self.model_type\n",
    "                           )\n",
    "              ]\n",
    "\n",
    "        learn=Learner(self.dls,self.model,splitter=my_splitter_bt,wd=self.wd, cbs=cbs\n",
    "                     )\n",
    "        \n",
    "        if self.load_learner_path: learn.load(self.load_learner_path,with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir:\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export:\n",
    "            cbs.append(SaveBarlowLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "                \n",
    "    \n",
    "    def bt_transfer_learning(self,freeze_epochs:int,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is already pretrained, we can do transfer learning.\n",
    "            Freeze encoder, train projector for a few epochs, then unfreeze and train all. \n",
    "        \"\"\"\n",
    "        self.learn.freeze()\n",
    "        test_grad_off(self.learn.encoder)\n",
    "        self.learn.fit(freeze_epochs)\n",
    "\n",
    "         # Check if the splitter is 'my_splitter_bt_last_block_resnet50'\n",
    "        if self.splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "            # Unfreeze only the last bottleneck block\n",
    "            for param in self.learn.model.encoder[-3][-1].parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "            print(f'splitter_str={self.splitter_str}')\n",
    "        else:\n",
    "            # Unfreeze the entire encoder\n",
    "            self.learn.unfreeze()\n",
    "            test_grad_on(self.learn.model)\n",
    "        \n",
    "        \n",
    "        self.learn.summary()\n",
    "\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it) #lets find a good maximum lr\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley, cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def bt_learning(self,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is not pretrained, we can do normal training.\n",
    "        \"\"\"\n",
    "\n",
    "        #do stochastic gradient descent with warm restarts\n",
    "\n",
    "\n",
    "        if self.fit:\n",
    "            print('Just using constant learning rate etc with Adam for simplicity')\n",
    "            self.learn.fit(epochs,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "        \n",
    "\n",
    "        if self.sgdr: \n",
    "            print('using sgdr')\n",
    "            print(f'Epochs: {epochs}')\n",
    "            n_cycles = 5 #hardcode for simplicity\n",
    "            cycle_len = epochs//n_cycles\n",
    "\n",
    "            lrs = self.learn.lr_find(num_it=self.num_it)\n",
    "            self.learn.fit_sgdr(n_cycles=n_cycles, cycle_len=cycle_len, lr_max=lrs.valley, cbs=self._get_training_cbs(interrupt_epoch))\n",
    "        else:\n",
    "\n",
    "            lrs = self.learn.lr_find(num_it=self.num_it)\n",
    "            self.learn.fit_one_cycle(epochs, lrs.valley,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "        \n",
    "    def continue_bt_learning(self,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Resume training with `fit_one_cycle` after loading a learner.\n",
    "        \"\"\"\n",
    "        \n",
    "        test_ne(self.load_learner_path,None)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs,start_epoch=start_epoch,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def train(self,learn_type, freeze_epochs:int,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Train model using BT\n",
    "        \"\"\"\n",
    "        if learn_type == 'transfer_learning':\n",
    "            \n",
    "            self.bt_transfer_learning(freeze_epochs=freeze_epochs,epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        elif learn_type=='continue_learning':\n",
    "            self.continue_bt_learning(epochs=epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "        \n",
    "        elif learn_type=='standard':\n",
    "            self.bt_learning(epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        else: raise Exception(\"Invalid weight_type\")\n",
    "\n",
    "        return self.learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can inherit from the above for vicreg version. Just setting up the learner is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VICRegTrainer(BarlowTrainer):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 sparsity_level,\n",
    "                 sim_coeff,\n",
    "                 std_coeff,\n",
    "                 cov_coeff,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 fit=False,\n",
    "                 sgdr=False,\n",
    "                 splitter_str='none',\n",
    "                 num_it=100,\n",
    "                 load_learner_path=None,\n",
    "                 experiment_dir=None,\n",
    "                 start_epoch=0,\n",
    "                 save_interval=None,\n",
    "                 export=False):\n",
    "        \n",
    "        \n",
    "                # Store VICReg-specific attributes\n",
    "        store_attr('sim_coeff,std_coeff,cov_coeff') #why doesn't this work?\n",
    "        # Call the parent constructor with None for lmb\n",
    "        super().__init__(model, dls, bt_aug_pipelines,None,sparsity_level, n_in, model_type,\n",
    "                         wd, device,sgdr, splitter_str, num_it, load_learner_path,\n",
    "                         experiment_dir, start_epoch, save_interval, export)\n",
    "        \n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics for VICReg.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        cbs = [VICReg(self.bt_aug_pipelines, n_in=self.n_in, \n",
    "                      sim_coeff=self.sim_coeff, std_coeff=self.std_coeff, cov_coeff=self.cov_coeff,\n",
    "                      model_type=self.model_type, print_augs=False)]\n",
    "\n",
    "        # Use the splitter based on splitter_str\n",
    "        # if self.splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "        #     splitter = my_splitter_bt_last_block_resnet50\n",
    "        # else:\n",
    "        #     splitter = my_splitter_bt\n",
    "        #learn = Learner(self.dls, self.model, splitter=splitter, wd=self.wd, cbs=cbs)\n",
    "        \n",
    "        #TODO: Implement custom splitter for VICReg\n",
    "        #splitter not supported yet for vicreg: we can do this but need a custom splitter.\n",
    "        #The issue is just that vicreg e.g. has encoder_left and encoder_right, v.s.\n",
    "        #BT which just has one encoder. Just leaving splitter off for now\n",
    "        learn = Learner(self.dls, self.model, wd=self.wd, cbs=cbs)\n",
    "        if self.load_learner_path: \n",
    "            learn.load(self.load_learner_path, with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir: #same as for barlow\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export: #different to barlow. Clearly we in principle want this \n",
    "                        #more abstract so it just works. But ok.\n",
    "            cbs.append(SaveVicRegLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "\n",
    "    # # Override the train method if necessary\n",
    "    # def train(self, learn_type, freeze_epochs:int, epochs:int, start_epoch:int, interrupt_epoch:int):\n",
    "    #     \"\"\"Train model using VICReg\"\"\"\n",
    "    #     # You can customize this method for VICReg-specific training logic if needed\n",
    "    #     return super().train(learn_type, freeze_epochs, epochs, start_epoch, interrupt_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that splitting/freezings works in `bt_transfer_learning`.\n",
    "\n",
    "It's a bit hacky but looks to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "encoder = resnet_arch_to_encoder(arch='resnet50', weight_type=random)\n",
    "model = create_barlow_twins_model(encoder, hidden_size=8192, projection_size=8192)\n",
    "dls = get_ssl_dls('cifar10',bs=64,size=32,device=default_device())\n",
    "\n",
    "cbs = [BarlowTwins(get_bt_aug_pipelines(bt_augs='bt_cifar10_aug_pipelines', size=32),\n",
    "       n_in=3,lmb=1/8192,sparsity_level=None,print_augs=False,\n",
    "        model_type='barlow_twins'\n",
    "                    )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy pasted from `bt_transfer_learning`\n",
    "\n",
    "Bit hacky, but ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BarlowTwinsModel (Input shape: 64 x 3 x 32 x 32)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     64 x 64 x 16 x 16   \n",
       "Conv2d                                    9408       False     \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "MaxPool2d                                                      \n",
       "Conv2d                                    4096       False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 8 x 8    \n",
       "Conv2d                                    32768      False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 4 x 4    \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    524288     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 2 x 2    \n",
       "Conv2d                                    524288     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2097152    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "AdaptiveAvgPool2d                                              \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048           \n",
       "Flatten                                                        \n",
       "____________________________________________________________________________\n",
       "                     64 x 8192           \n",
       "Linear                                    16785408   True      \n",
       "BatchNorm1d                               16384      True      \n",
       "ReLU                                                           \n",
       "Linear                                    67117056   True      \n",
       "BatchNorm1d                               16384      True      \n",
       "ReLU                                                           \n",
       "Linear                                    67117056   True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 174,560,320\n",
       "Total trainable params: 155,561,856\n",
       "Total non-trainable params: 18,998,464\n",
       "\n",
       "Optimizer used: <function Adam>\n",
       "Loss function: <bound method BarlowTwins.lf of BarlowTwins>\n",
       "\n",
       "Model frozen up to parameter group #1\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - CastToTensor\n",
       "  - BarlowTwins\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide \n",
    "learn=Learner(dls,model,splitter=my_splitter_bt,cbs=cbs\n",
    "             )\n",
    "\n",
    "\n",
    "splitter_str = 'my_splitter_bt_last_block_resnet50'\n",
    "#splitter_str='none'\n",
    "learn.freeze() #freeze everything up to projector\n",
    "test_grad_off(learn.encoder)\n",
    "\n",
    "    # Check if the splitter is 'my_splitter_bt_last_block_resnet50'\n",
    "if splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "    # Unfreeze only the last bottleneck block\n",
    "    for param in learn.model.encoder[-3][-1].parameters():\n",
    "        param.requires_grad = True\n",
    "else:\n",
    "    # Unfreeze the entire encoder\n",
    "    learn.unfreeze()\n",
    "\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a BT model. Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "    if hasattr(config,'splitter_str'):\n",
    "        splitter_str=config.splitter_str\n",
    "    else:\n",
    "        splitter_str='none'\n",
    "\n",
    "    if hasattr(config,'nlayers'):\n",
    "        nlayers=config.nlayers\n",
    "    else:\n",
    "        nlayers=3\n",
    "\n",
    "    if hasattr(config,'sgdr'):\n",
    "        sgdr = config.sgdr\n",
    "    \n",
    "    else:\n",
    "        sgdr = False\n",
    "\n",
    "\n",
    "    if hasattr(config,'fit'):\n",
    "        fit = config.fit\n",
    "    else:\n",
    "        fit = False\n",
    "\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "    encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    \n",
    "    model = create_barlow_twins_model(encoder, hidden_size=config.hs, projection_size=config.ps,nlayers=nlayers)\n",
    "\n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    bt_trainer = BarlowTrainer(model=model,\n",
    "                    dls=dls,\n",
    "                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                    lmb=config.lmb,\n",
    "                    sparsity_level=config.sparsity_level,\n",
    "                    n_in=config.n_in,\n",
    "                    model_type=config.model_type,\n",
    "                    fit=fit,\n",
    "                    sgdr=sgdr,\n",
    "                    wd=config.wd,\n",
    "                    num_it=config.num_it,\n",
    "                    device=device,\n",
    "                    splitter_str=splitter_str,\n",
    "                    load_learner_path=load_learner_path,\n",
    "                    experiment_dir=experiment_dir,\n",
    "                    start_epoch=start_epoch,\n",
    "                    save_interval=config.save_interval,\n",
    "                    export=export\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = bt_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above but for vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_vicreg_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a vicreg model (standard or br) Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "    if hasattr(config,'splitter_str'):\n",
    "        splitter_str=config.splitter_str\n",
    "    else:\n",
    "        splitter_str='none'\n",
    "\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "\n",
    "    #vicreg model may require two encoders, so we need to handle this case\n",
    "    encoder_left = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    if config.model_type == 'vicreg':\n",
    "\n",
    "        if not config.shared_encoder:\n",
    "            encoder_right = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "        else:\n",
    "            encoder_right=encoder_left\n",
    "\n",
    "        model = create_vicreg_model(encoder_left, encoder_right, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "    # #At present, the arch is: encoder_left = encoder_right =  Transformer(CNN_Left(x),CNN_right(x)).\n",
    "    elif config.model_type == 'br_vicreg':\n",
    "        #Same as above for now since we are using left/right split augmentation\n",
    "\n",
    "        # res = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "        # encoder = BinocularEncoder(res)\n",
    "        # model = create_vicreg_model(encoder, encoder, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "        \n",
    "        encoder = BinocularResNet()\n",
    "        model = create_vicreg_model(encoder, encoder, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "\n",
    "\n",
    "    #     test_eq(config.arch,'cifar_resnet18_swin')\n",
    "    #     swin = BinocularAwareSwin()\n",
    "    #     cnn = resnet_arch_to_encoder('cifar_resnet18', n_in=96)\n",
    "    #     encoder = BinocularSwintoRes(swin=swin, cnn=cnn)\n",
    "\n",
    "    #     swin = BinocularAwareSwin()\n",
    "    #     cnn = resnet_arch_to_encoder('cifar_resnet18', n_in=96)\n",
    "    #     encoder = BinocularSwintoRes(swin=swin, cnn=cnn)\n",
    "    #     _x = torch.rand(1, 3, 32, 32)\n",
    "    #     _x = encoder(_x)\n",
    "    #     model = create_vicreg_model(encoder, encoder, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    #(this is same as for bt)\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    vicreg_trainer = VICRegTrainer(model=model,\n",
    "                                    dls=dls,\n",
    "                                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                                    sparsity_level=config.sparsity_level,\n",
    "                                    sim_coeff=config.sim_coeff,\n",
    "                                    std_coeff=config.std_coeff,\n",
    "                                    cov_coeff=config.cov_coeff,\n",
    "                                    n_in=config.n_in,\n",
    "                                    model_type=config.model_type,\n",
    "                                    wd=config.wd,\n",
    "                                    num_it=config.num_it,\n",
    "                                    device=device,\n",
    "                                    splitter_str=splitter_str,\n",
    "                                    load_learner_path=load_learner_path,\n",
    "                                    experiment_dir=experiment_dir,\n",
    "                                    start_epoch=start_epoch,\n",
    "                                    save_interval=config.save_interval,\n",
    "                                    export=export\n",
    "\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = vicreg_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_experiment_state(config,base_dir):\n",
    "    \"\"\"Get the load_learner_path, learn_type, start_epoch, interrupt_epoch for BT experiment.\n",
    "       Basically this tells us how to continue learning (e.g. we have run two sessions for \n",
    "       100 epochs, and want to continue for another 100 epochs). Return values are\n",
    "       None if we are starting from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    load_learner_path, _  = get_highest_num_path(base_dir, config)\n",
    "    #TODO:\n",
    "    #We can get start_epoch, interrupt epoch from `get_highest_epoch_path` + save_interval (may be None!)\n",
    "    start_epoch=0 if load_learner_path is None else int(load_learner_path.split('_')[-1])+1\n",
    "    \n",
    "    if start_epoch >= config.epochs:\n",
    "        print(f\"start_epoch={start_epoch}, but already completed {config.epochs} epochs. Exiting.\")\n",
    "        sys.exit()\n",
    "\n",
    "    interrupt_epoch = start_epoch + config.save_interval\n",
    "\n",
    "    #We can also get the learn_type from the load_learner_path + weight_type. \n",
    "    \n",
    "    if config.weight_type == 'random':\n",
    "        learn_type = 'standard'\n",
    "    \n",
    "    elif 'pretrained' in config.weight_type:\n",
    "        learn_type = 'transfer_learning'\n",
    "\n",
    "    learn_type = learn_type if load_learner_path is None else 'continue_learning'\n",
    "\n",
    "    return load_learner_path, learn_type, start_epoch, interrupt_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_experiment(config,\n",
    "                      base_dir,\n",
    "                      ):\n",
    "        \"\"\"Run several epochs of the experiment as defined in the config and where we are up to. e.g. epoch 0, or resuming\n",
    "        at epoch 99 etc. Basically a stateful version of `main_bt_train` that can be resumed. And saving.\n",
    "        \"\"\"\n",
    "    \n",
    "        \n",
    "        experiment_dir, experiment_hash,git_commit_hash = setup_experiment(config,base_dir)\n",
    "        load_learner_path, learn_type, start_epoch, interrupt_epoch = get_bt_experiment_state(config,base_dir)      \n",
    "        \n",
    "        if 'barlow' in config.model_type:\n",
    "        \n",
    "                main_bt_train(config=config,\n",
    "                        start_epoch=start_epoch,\n",
    "                        interrupt_epoch=interrupt_epoch,\n",
    "                        load_learner_path=load_learner_path,\n",
    "                        learn_type=learn_type,\n",
    "                        experiment_dir=experiment_dir,\n",
    "                        )\n",
    "        elif 'vicreg' in config.model_type:\n",
    "                \n",
    "                main_vicreg_train(config=config,\n",
    "                        start_epoch=start_epoch,\n",
    "                        interrupt_epoch=interrupt_epoch,\n",
    "                        load_learner_path=load_learner_path,\n",
    "                        learn_type=learn_type,\n",
    "                        experiment_dir=experiment_dir,\n",
    "                        )\n",
    "\n",
    "        # Save a metadata file in the experiment directory with the Git commit hash and other details\n",
    "        save_metadata_file(experiment_dir=experiment_dir, git_commit_hash=git_commit_hash)\n",
    "\n",
    "        # After experiment execution and all processing are complete\n",
    "        update_experiment_index(base_dir,{\n",
    "                \"experiment_hash\": experiment_hash,  # Unique identifier derived from the experiment's configuration\n",
    "                \"experiment_dir\": experiment_dir,  # Absolute path to the experiment's dedicated directory\n",
    "                \"git_commit_hash\": git_commit_hash,  # Git commit hash for the code version used in the experiment\n",
    "                # Potentially include additional details collected during or after the experiment, such as:\n",
    "                # Any other metadata or results summary that is relevant to the experiment\n",
    "                                })\n",
    "        \n",
    "        return experiment_dir,experiment_hash #Return the experiment_dir so we can easily access the results of the experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full end to end example with BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     config_path = '../configs/cifar10/bt_test_config.yaml'\n",
    "#     config = load_config(config_path)\n",
    "\n",
    "#     # config.model_type = 'sparse_head_barlow_twins'\n",
    "#     # config.sparsity_level=10\n",
    "#     # config.epochs=100\n",
    "#     # config.save_interval=100\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     #get path to fully fitted model\n",
    "#     path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "#     model = load_barlow_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "#     print(model)\n",
    "\n",
    "#     #New config but the first part of experiment_dir is same - just hash is different\n",
    "#     #It shouldnt find a max file path\n",
    "#     config.epochs=config.epochs+1\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full end to end example for vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     config_path = '../configs/cifar10/vicreg_test_config.yaml'\n",
    "#     config = load_config(config_path)\n",
    "\n",
    "#     # config.model_type = 'sparse_head_barlow_twins'\n",
    "#     # config.sparsity_level=10\n",
    "#     # config.epochs=100\n",
    "#     # config.save_interval=100\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     #get path to fully fitted model\n",
    "#     path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "#     model = load_vicreg_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "#     print(model)\n",
    "\n",
    "#     #New config but the first part of experiment_dir is same - just hash is different\n",
    "#     #It shouldnt find a max file path\n",
    "#     config.epochs=config.epochs+1\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify runs with br_vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     #config_path = '../configs/cifar10/vicreg_test_config.yaml'\n",
    "#     config_path = '../configs/cifar10/bt_predhalfconfig.yaml'\n",
    "#     config = load_config(config_path)\n",
    "#     config.pct_dataset = 0.01\n",
    "#     #config.model_type = 'br_vicreg'\n",
    "#     #config.arch = 'cnn_lr_cifar_resnet18'\n",
    "\n",
    "#     pretty_print_ns(config)\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls = get_ssl_dls('cifar10', bs=32, size=32, device=default_device())\n",
    "# aug = get_bt_aug_pipelines('bt_predhalf_aug_pipelines', 32)\n",
    "# show_bt_batch(dls, n_in=3, aug=aug, n=10, print_augs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
