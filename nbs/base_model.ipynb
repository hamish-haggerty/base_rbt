{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_model\n",
    "\n",
    "> In this module we have the base model, learner and other things we need to train encoder with Barlow Twins and other methods.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import importlib\n",
    "import sys\n",
    "import self_supervised\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import kornia.augmentation as korniatfm\n",
    "import torchvision.transforms as tvtfm\n",
    "from base_rbt.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the base functions and classes to train a basic BT-style model. Note that this (mostly) all comes directly from here: `https://github.com/KeremTurgutlu/self_supervised/blob/main/nbs/14%20-%20barlow_twins.ipynb`\n",
    "but we needed to extend some of the functionality for our purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the base classes and functions needed for image augmentation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#My edited version of RandTransform\n",
    "class RandomGaussianBlur(RandTransform):\n",
    "    \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "    order = 11\n",
    "    def __init__(self, \n",
    "                 p=1.0, #debugging (bug in libraries implementation)\n",
    "                 prob=0.5,#the real probability\n",
    "                 s=(8,32), #kernel\n",
    "                 sig=None, #sig_val is either manually input OR\n",
    "                 blur_r=(0.1,2),#is randomly chosen from uniform with these bounds\n",
    "                 same_on_batch=False, \n",
    "                 **kwargs): \n",
    "        \n",
    "        store_attr()\n",
    "        super().__init__(p=p, **kwargs)\n",
    "\n",
    "    def encodes(self, x:TensorImage):\n",
    "        \n",
    "        if isinstance(self.s, int):   s = (self.s,self.s)\n",
    "        elif isinstance(self.s, tuple) or isinstance(self.s, list): s=self.s\n",
    "     \n",
    "        #Default for ImageNet from BYOL / BT papers\n",
    "        if self.sig is None:\n",
    "            sig_val = np.random.uniform(self.blur_r[0],self.blur_r[1])\n",
    "        \n",
    "        else:\n",
    "            sig_val = self.sig\n",
    "            \n",
    "\n",
    "        tfm = korniatfm.RandomGaussianBlur(kernel_size=s,sigma=(sig_val,sig_val),same_on_batch=self.same_on_batch,p=self.prob)\n",
    "        return tfm(x)\n",
    "\n",
    "#Delete later: leaving for backward compatibility for now\n",
    "# class RandomGaussianBlur(RandTransform):\n",
    "#     \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "#     order = 11\n",
    "#     def __init__(self, p=0.5, s=(8,32), same_on_batch=False, **kwargs): \n",
    "#         store_attr()\n",
    "#         super().__init__(p=p, **kwargs)\n",
    "        \n",
    "#     def encodes(self, x:TensorImage):\n",
    "#         if isinstance(self.s, tuple): s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, list):  s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, int):   s = self.s\n",
    "#         s2 = int(s/4)*2+1\n",
    "#         tfm = korniatfm.RandomGaussianBlur((s2,s2),(s,s),same_on_batch=self.same_on_batch,p=1.) #p=1. is a bug\n",
    "#                                             #kernel #sigma\n",
    "        \n",
    "#         return tfm(x)\n",
    "\n",
    "\n",
    "class RandomCenterDropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.5, min_dropout_size=(20, 20), max_dropout_size=(60, 60), fill_value=0, same_on_batch=False):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.min_dropout_size = min_dropout_size\n",
    "        self.max_dropout_size = max_dropout_size\n",
    "        self.fill_value = fill_value\n",
    "        self.same_on_batch = same_on_batch\n",
    "        #self.id_transform = tvtfm.RandomResizedCrop((256, 256), scale=(1.,1.), ratio=(1.,1.))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Check if the augmentation should be applied to the whole batch or individually\n",
    "\n",
    "        #x=self.id_transform(x)\n",
    "\n",
    "        if self.same_on_batch:\n",
    "            if random.random() < self.p:\n",
    "                return self._apply_dropout(x)\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            # Apply dropout individually with given probability\n",
    "            for i in range(x.size(0)):\n",
    "                tem=random.random()\n",
    "                #print(f\"tem is: {tem}\")\n",
    "                if tem < self.p:\n",
    "                    x[i] = self._apply_dropout(x[i].unsqueeze(0)).squeeze(0)\n",
    "            return x\n",
    "\n",
    "    def _apply_dropout(self, img):\n",
    "        for i,count in enumerate(range(img.size(0))):  # Iterate through batch if necessary\n",
    "            _, h, w = img[i].shape\n",
    "            # Generate random dropout size within specified limits\n",
    "            dh = random.randint(self.min_dropout_size[0], self.max_dropout_size[0])\n",
    "            dw = random.randint(self.min_dropout_size[1], self.max_dropout_size[1])\n",
    "            \n",
    "            x1 = int(max((w - dw) / 2, 0))\n",
    "            y1 = int(max((h - dh) / 2, 0))\n",
    "            \n",
    "            mask = torch.ones_like(img[i])\n",
    "            mask[:, y1:y1+dh, x1:x1+dw] = self.fill_value\n",
    "            img[i] = img[i] * mask\n",
    "        \n",
    "        return img\n",
    "\n",
    "    \n",
    "def get_BT_batch_augs(size,\n",
    "                    flip=True,crop=True,noise=True,rotate=True,jitter=True,bw=True,blur=True,solar=True,cutout=False, #Whether to use  given aug or not\n",
    "                    resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.025, rotate_deg=30,jitter_s=.6,blur_s=(4,32),#hps of diff augs\n",
    "                    blur_r=(0.1,2),blur_sig=None,sol_t=0.05,sol_a=0.05,min_dropout_size=(25, 100),max_dropout_size=(50,150), #hps of diff augs\n",
    "                    flip_p=0.5, rotate_p=0.3,noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3,sol_p=0.1,cut_p=0.0, #prob of performing aug\n",
    "                    same_on_batch=False,stats=imagenet_stats,cuda=default_device().type == 'cuda',xtra_tfms=[]\n",
    "                    ):\n",
    "    \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    \n",
    "    tfms = []\n",
    "\n",
    "    korniatfm.RandomHorizontalFlip.order = RandomResizedCrop.order-1\n",
    "\n",
    "\n",
    "    if crop: tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "    #Unfortunately for some reason this doesn't work, so we can't apply \"same_on_batch=False\"\n",
    "    #tfms += [korniatfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio, same_on_batch=same_on_batch)]\n",
    "\n",
    "    if cutout: tfms+=[RandomCenterDropout(min_dropout_size=min_dropout_size,max_dropout_size=max_dropout_size, fill_value=0, p=cut_p,same_on_batch=same_on_batch)]\n",
    "    \n",
    "  \n",
    "    if flip: tfms += [korniatfm.RandomHorizontalFlip(p=flip_p,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if rotate: tfms += [Rotate(max_deg=rotate_deg, p=rotate_p, batch=same_on_batch)]\n",
    "\n",
    "                                             #brightness,contrast,saturation,hue\n",
    "    if jitter: tfms += [korniatfm.ColorJitter(0.4*jitter_s, 0.4*jitter_s, 0.2*jitter_s, 0.1*jitter_s, p=jitter_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if bw:     tfms += [korniatfm.RandomGrayscale(p=bw_p, same_on_batch=same_on_batch)]\n",
    "        \n",
    "    #sig will usually be None\n",
    "    if blur:   tfms += [RandomGaussianBlur(prob=blur_p, s=blur_s,sig=blur_sig,blur_r=blur_r, same_on_batch=same_on_batch)]\n",
    "\n",
    "    korniatfm.RandomSolarize.order = RandomGaussianBlur.order + 1 #we want to apply solarization after RandomGaussianBlur\n",
    "    \n",
    "    if solar: tfms += [korniatfm.RandomSolarize(p=sol_p,thresholds=sol_t, additions=sol_a,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if noise: tfms+=[korniatfm.RandomGaussianNoise(mean=0.0, std=noise_std, same_on_batch=same_on_batch, p=noise_p)]\n",
    "    \n",
    "    if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "\n",
    "    tfms += xtra_tfms\n",
    "\n",
    "    pipe = Pipeline(tfms, split_idx = 0)\n",
    "    return pipe\n",
    "\n",
    "@delegates(get_BT_batch_augs)\n",
    "def get_multi_aug_pipelines(size, **kwargs): return get_BT_batch_augs(size, **kwargs)\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(size=size,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_cifar10_aug_pipelines(size):\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    bt_cifar10_aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return bt_cifar10_aug_pipelines\n",
    "\n",
    "#Add other augmentations here e.g. BYOL augs\n",
    "IMAGENET_Augs = dict(flip_p1=0.5,flip_p2=0.5,jitter_p1=0.8,jitter_p2=0.8,bw_p1=0.2,\n",
    "                bw_p2=0.2,blur_p1=1.0,blur_p2=0.1,sol_p1=0.0,sol_p2=0.2,noise_p1=0.0,\n",
    "                noise_p2=0.0,cut_p=0,resize_scale=(0.7, 1.0),resize_ratio=(3/4, 4/3),rotate_deg=45.0,\n",
    "                rotate_p=0.5,blur_r=(0.1,2),blur_s=13,sol_t=0.1,sol_a=0.1,noise_std=0.1,min_dropout_size=None,max_dropout_size=None,\n",
    "                )\n",
    "\n",
    "DERMNET_Augs = IMAGENET_Augs.copy()\n",
    "DERMNET_Augs['min_dropout_size']=(50, 185)\n",
    "DERMNET_Augs['max_dropout_size']=(100,190)\n",
    "DERMNET_Augs['cut_p']=0.33\n",
    "\n",
    "def helper_get_bt_augs(size,Augs=IMAGENET_Augs):\n",
    "\n",
    "\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p1'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p1'],\n",
    "                        jitter_p=Augs['jitter_p1'], bw_p=Augs['bw_p1'], blur_p=Augs['blur_p1'],\n",
    "                        sol_p=Augs['sol_p1'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p2'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p2'],\n",
    "                        jitter_p=Augs['jitter_p2'], bw_p=Augs['bw_p2'], blur_p=Augs['blur_p2'],\n",
    "                        sol_p=Augs['sol_p2'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return aug_pipelines\n",
    "\n",
    "def get_bt_imagenet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=IMAGENET_Augs)\n",
    "\n",
    "def get_bt_dermnet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=DERMNET_Augs)\n",
    "\n",
    "\n",
    "\n",
    "bt_aug_func_dict = {'bt_cifar10_aug_pipelines':get_bt_cifar10_aug_pipelines,'bt_imagenet_aug_pipelines':get_bt_imagenet_aug_pipelines,\n",
    "                   'bt_dermnet_aug_pipelines':get_bt_dermnet_aug_pipelines\n",
    "                   }\n",
    "\n",
    "def get_bt_aug_pipelines(bt_augs,size):\n",
    "\n",
    "    return bt_aug_func_dict[bt_augs](size)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_ssl_dls(dataset,#cifar10, dermnet, etc\n",
    "            bs,\n",
    "            size,\n",
    "            device,\n",
    "            pct_dataset=1.0):\n",
    "    # Define the base package name in a variable for easy modification\n",
    "\n",
    "    try:\n",
    "        # Construct the module path\n",
    "        module_path = f\"{PACKAGE_NAME}.{dataset}_dataloading\"\n",
    "        \n",
    "        # Dynamically import the module\n",
    "        dataloading_module = importlib.import_module(module_path)\n",
    "    except ModuleNotFoundError:\n",
    "        # Handle the case where the module cannot be found\n",
    "        raise ImportError(f\"Could not find a data loading module for '{dataset}'. \"\n",
    "                          f\"Make sure '{module_path}' exists and is correctly named.\") from None\n",
    "    \n",
    "    # Assuming the function name follows a consistent naming convention\n",
    "    func_name = f\"get_bt_{dataset}_train_dls\"\n",
    "\n",
    "    try:\n",
    "        # Retrieve the data loading function from the module\n",
    "        data_loader_func = getattr(dataloading_module, func_name)\n",
    "    except AttributeError:\n",
    "        # Handle the case where the function does not exist in the module\n",
    "        raise AttributeError(f\"The function '{func_name}' was not found in '{module_path}'. \"\n",
    "                             \"Ensure it is defined and named correctly.\") from None\n",
    "    \n",
    "    # Proceed to call the function with arguments from the config\n",
    "    try:\n",
    "        dls_train = data_loader_func(bs=bs,size=size,device=device,pct_dataset=pct_dataset)\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the function call\n",
    "        raise RuntimeError(f\"An error occurred while calling '{func_name}' from '{module_path}': {e}\") from None\n",
    "    \n",
    "    return dls_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base functions / classes we need to train a BT / RBT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Base functions / classes we need to train a BT / RBT model.\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "\n",
    "# class BarlowTwinsModel(Module):\n",
    "#     \"\"\"An encoder followed by a projector\n",
    "#     \"\"\"\n",
    "#     def __init__(self,encoder,projector):\n",
    "#         self.encoder = encoder\n",
    "#         self.projector = projector\n",
    "        \n",
    "#     def forward(self,x): \n",
    "        \n",
    "#         return self.projector(self.encoder(x))\n",
    "\n",
    "# def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "#     \"Create Barlow Twins model\"\n",
    "#     n_in  = in_channels(encoder)\n",
    "#     with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "#     projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "#     apply_init(projector)\n",
    "#     return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "\n",
    "#We want access to both representation and projection\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        \n",
    "    def forward(self,x): \n",
    "        tem = self.encoder(x)\n",
    "        return tem,self.projector(tem) #get access to both representation and projection if needed for loss\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'forward returns tuple of (encoder(x),projector(encoder(x)))'\n",
    "\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    " \n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "\n",
    "#Note: this requires an lf (loss function), which is patched in later.\n",
    "#The reason for this is we can specify via a string argument (e.g. via\n",
    "#a config file) what loss function we want to use. lf_bt is the default\n",
    "#(standard barlow twins loss function).\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines,n_in,lmb,sparsity_level, \n",
    "                model_type='barlow_twins',print_augs=False\n",
    "                 ):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        store_attr('sparsity_level')\n",
    "        self.n_in=n_in\n",
    "        self.model_type = model_type\n",
    "        self.index=-1 #Gets updated after each batch\n",
    "        self.acc_dict = {}\n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self.index=-1  \n",
    "  \n",
    "    def before_batch(self):\n",
    "        \n",
    "        #TODO: Make this nicer (possibly can load in data as TensorImage(BW) or something?)\n",
    "        #This is a bit of a hack. Can make this more elegant later. But in new version of FastAI\n",
    "        #seems we need to compute TensorImage(BW) here, and depends on whether color or not, i.e. n_in.\n",
    "        if self.n_in == 1:\n",
    "\n",
    "            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            \n",
    "            #print(xi.shape)\n",
    "                                    \n",
    "        elif self.n_in == 3:\n",
    "            \n",
    "            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    " \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1): \n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]]\n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the above for vicreg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Base functions / classes we need to train a \n",
    "#  model\n",
    "class VICRegModel(Module):\n",
    "    \"\"\"VICReg model with options for shared or separate projectors\"\"\"\n",
    "    def __init__(self, left_encoder, right_encoder, left_projector, right_projector):\n",
    "        #may have right_encoder = encoder_left and right_projector = left_projector.\n",
    "        #or e.g. encoders may have shared weights.\n",
    "        self.left_encoder = left_encoder\n",
    "        self.right_encoder = right_encoder\n",
    "        self.left_projector = left_projector\n",
    "        self.right_projector = right_projector\n",
    "        \n",
    "    def forward(self,x): #x is stacked xi,xj the two augmented views of batch\n",
    "      \n",
    "        x1, x2 = x[:x.size(0)//2], x[x.size(0)//2:]\n",
    "        \n",
    "        z1,z2 = self.left_projector(self.left_encoder(x1)), self.right_projector(self.right_encoder(x2))\n",
    "    \n",
    "        return z1, z2\n",
    "\n",
    "def create_vicreg_model(left_encoder, right_encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3, shared_projector=True):\n",
    "    \"\"\"\n",
    "    Create VICReg model with flexible projector configuration\n",
    "    \n",
    "    Args:\n",
    "    - left_encoder: first encoder model\n",
    "    - right_encoder: second encoder model (can be the same as left_encoder for shared encoder)\n",
    "    - hidden_size: hidden size for projector\n",
    "    - projection_size: output size for projector\n",
    "    - bn: whether to use batch normalization in projector\n",
    "    - nlayers: number of layers in projector\n",
    "    - shared_projector: if True, use the same projector for both branches\n",
    "    \"\"\"\n",
    "    n_in = in_channels(left_encoder)\n",
    "    with torch.no_grad(): representation = left_encoder(torch.randn((2,n_in,32,32)))\n",
    "    \n",
    "    left_projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "    apply_init(left_projector)\n",
    "    \n",
    "    if not shared_projector:\n",
    "        right_projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "        apply_init(right_projector)\n",
    "    else:\n",
    "        right_projector = left_projector\n",
    "    \n",
    "    return VICRegModel(left_encoder, right_encoder, left_projector, right_projector)\n",
    "\n",
    "#helper function to compute vicreg loss.\n",
    "def off_diagonal(x):\n",
    "        n, m = x.shape\n",
    "        assert n == m\n",
    "        return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "class VICReg(BarlowTwins):\n",
    "    def __init__(self, aug_pipelines, n_in=3, sim_coeff=25, std_coeff=25, cov_coeff=1, \n",
    "                 model_type='vicreg', print_augs=False):\n",
    "        super().__init__(aug_pipelines, n_in, None, None, model_type, print_augs)\n",
    "        self.sim_coeff = sim_coeff\n",
    "        self.std_coeff = std_coeff\n",
    "        self.cov_coeff = cov_coeff\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.learn.loss_func = self.lf\n",
    "\n",
    "    def lf(self, pred, *yb):\n",
    "        x, y = pred  # Assuming the model returns two views (see VICRegModel)\n",
    "\n",
    "        # Invariance loss\n",
    "        repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "        # Variance loss\n",
    "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "        # Covariance loss\n",
    "        x = x - x.mean(dim=0)\n",
    "        y = y - y.mean(dim=0)\n",
    "        cov_x = (x.T @ x) / (x.size(0) - 1)\n",
    "        cov_y = (y.T @ y) / (y.size(0) - 1)\n",
    "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(x.size(1)) + \\\n",
    "                   off_diagonal(cov_y).pow_(2).sum().div(y.size(1))\n",
    "\n",
    "        # Total loss\n",
    "        loss = (\n",
    "            self.sim_coeff * repr_loss +\n",
    "            self.std_coeff * std_loss +\n",
    "            self.cov_coeff * cov_loss\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def before_batch(self):\n",
    "        #if self.model_type == 'br_vicreg':\n",
    "\n",
    "    #         # Create two copies of the input\n",
    "    #         x_left, x_right = self.x.clone(), self.x.clone()\n",
    "            \n",
    "    #         # Zero out the right half of x_left and the left half of x_right\n",
    "    #         mid = x_left.shape[-1] // 2\n",
    "    #         x_left[..., mid:] = 0\n",
    "    #         x_right[..., :mid] = 0\n",
    "            \n",
    "    #         print(f\"x shape: {self.x.shape}\")\n",
    "    #         print(f\"x_left shape: {x_left.shape}\")\n",
    "    #         print(f\"x_right shape: {x_right.shape}\")\n",
    "\n",
    "    #         # Apply augmentations\n",
    "    #         if self.n_in == 1:\n",
    "    #             xi = self.aug1(TensorImageBW(x_left))\n",
    "    #             xj = self.aug2(TensorImageBW(x_right))\n",
    "    #         elif self.n_in == 3:\n",
    "    #             xi = self.aug1(TensorImage(x_left))\n",
    "    #             xj = self.aug2(TensorImage(x_right))\n",
    "\n",
    "    #         print(f\"xi shape after aug: {xi.shape}\")\n",
    "    #         print(f\"xj shape after aug: {xj.shape}\")\n",
    "\n",
    "    #         # Concatenate the augmented halves\n",
    "    #         self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "    #         print(f\"Final self.learn.xb shape: {self.learn.xb[0].shape}\")\n",
    "\n",
    "        # The above splits x into x_left and x_right, with padding, then applies\n",
    "        # aug1 and aug2. Alternatively, we could compute aug1(x) and aug2(x). \n",
    "        # then zero pad the right half of aug1(x) and the left half of aug2(x).\n",
    "\n",
    "        #zero padding approach:\n",
    "        # if self.model_type == 'br_vicreg':\n",
    "        #     # Apply augmentations first\n",
    "        #     if self.n_in == 1:\n",
    "        #         xi = self.aug1(TensorImageBW(self.x))\n",
    "        #         xj = self.aug2(TensorImageBW(self.x))\n",
    "        #     elif self.n_in == 3:\n",
    "        #         xi = self.aug1(TensorImage(self.x))\n",
    "        #         xj = self.aug2(TensorImage(self.x))\n",
    "            \n",
    "        #     print(f\"x shape: {self.x.shape}\")\n",
    "        #     print(f\"xi shape after aug: {xi.shape}\")\n",
    "        #     print(f\"xj shape after aug: {xj.shape}\")\n",
    "\n",
    "        #     # Zero out the right half of xi and the left half of xj\n",
    "        #     mid = xi.shape[-1] // 2\n",
    "        #     xi[..., mid:] = 0\n",
    "        #     xj[..., :mid] = 0\n",
    "            \n",
    "        #     print(f\"xi shape after zeroing: {xi.shape}\")\n",
    "        #     print(f\"xj shape after zeroing: {xj.shape}\")\n",
    "\n",
    "        #     # Concatenate the augmented and zeroed halves\n",
    "        #     self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "        #     print(f\"Final self.learn.xb shape: {self.learn.xb[0].shape}\")\n",
    "        # else:\n",
    "        #     # Use the original BarlowTwins before_batch method for 'vicreg'\n",
    "        #     if self.n_in == 1:\n",
    "        #         xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "        #     elif self.n_in == 3:\n",
    "        #         xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "        #     self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "\n",
    "        #here we dont zero pad at all, just get 16x32 (for cifar, say)\n",
    "        if self.model_type == 'br_vicreg':\n",
    "            # Original implementation for 'vicreg'\n",
    "            if self.n_in == 1:\n",
    "                xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            elif self.n_in == 3:\n",
    "                xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "            self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "\n",
    "\n",
    "            # # Apply augmentations first\n",
    "            # if self.n_in == 1:\n",
    "            #     xi = self.aug1(TensorImageBW(self.x))\n",
    "            #     xj = self.aug2(TensorImageBW(self.x))\n",
    "            # elif self.n_in == 3:\n",
    "            #     xi = self.aug1(TensorImage(self.x))\n",
    "            #     xj = self.aug2(TensorImage(self.x))\n",
    "            \n",
    "            # # Dynamically calculate the split point\n",
    "            # _, _, height, width = xi.shape\n",
    "            # split_point = width // 2\n",
    "\n",
    "            # # Split each image into left and right halves\n",
    "            # xi_left = xi[..., :split_point]  # Left half\n",
    "            # xj_right = xj[..., split_point:]  # Right half\n",
    "            \n",
    "            # # Concatenate the halves\n",
    "            # self.learn.xb = (torch.cat([xi_left, xj_right], dim=0),)\n",
    "\n",
    "            # print(f\"Input shape: {self.x.shape}\")\n",
    "            # print(f\"Augmented left half shape: {xi_left.shape}\")\n",
    "            # print(f\"Augmented right half shape: {xj_right.shape}\")\n",
    "            # print(f\"Combined batch shape: {self.learn.xb[0].shape}\")\n",
    "\n",
    "        else:\n",
    "            # Original implementation for 'vicreg'\n",
    "            if self.n_in == 1:\n",
    "                xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            elif self.n_in == 3:\n",
    "                xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "            self.learn.xb = (torch.cat([xi, xj], dim=0),)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of barlow twins loss and sparse barlow twins loss functions, and proposes modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt(pred,I,lmb): #standard bt loss\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "    \n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs \n",
    "    cdiff = (C - I)**2\n",
    "    loss = (cdiff*I + cdiff*(1-I)*lmb).sum() \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_sparse_head(pred,I,lmb,projector,sparsity_level):\n",
    "  \n",
    "    bt_loss = lf_bt(pred,I,lmb)\n",
    "    L21 = torch.linalg.norm(projector[-1].weight, ord=2, dim=0).sum()\n",
    "\n",
    "    # print(f\"bt_loss is {bt_loss}, L21 is {L21}, scaled L21 is {sparsity_level*L21}\")\n",
    "    # print(bt_loss)\n",
    "    # print(L21)\n",
    "\n",
    "    \n",
    "    loss =  bt_loss + sparsity_level*L21 #barlow twins loss + L21 norm of last layer of projector\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_indiv_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb*(0.5*torch.abs(z1_enc) + 0.5*torch.abs(z2_enc)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1_enc.pow(2) + 0.5 * z2_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_norm_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_fun(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm_enc.T @ z2norm_enc) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    loss = (cdiff*I).sum() #standard bt loss\n",
    "\n",
    "    print(f\"invariance loss is: {loss} and sparsity loss is: {sparsity}\")\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_proj_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                           ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm.pow(2) + 0.5 * z2norm.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch in loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb):\n",
    "    \"Assumes model created according to type p3\"\n",
    "\n",
    "    if self.model_type=='barlow_twins':\n",
    "         pred_enc = pred[0]\n",
    "         pred = pred[1]\n",
    "         return lf_bt(pred, self.I,self.lmb)\n",
    "\n",
    "    elif self.model_type=='sparse_head_barlow_twins':\n",
    "        pred_enc = pred[0]\n",
    "        pred = pred[1]\n",
    "\n",
    "        return lf_bt_sparse_head(pred, self.I,lmb=self.lmb,projector=self.learn.model.projector,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='indiv_sparse_barlow_twins':\n",
    "        return lf_bt_indiv_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='group_sparse_barlow_twins':\n",
    "        return lf_bt_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='group_norm_sparse_barlow_twins':\n",
    "        return lf_bt_group_norm_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='proj_group_sparse_barlow_twins':\n",
    "        return lf_bt_proj_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='fun':\n",
    "        return lf_bt_fun(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "\n",
    "    else: raise(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt(m):\n",
    "    return L(sequential(*m.encoder),m.projector).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt_last_block_resnet50(m):\n",
    "    #Note: don't think we actually need this guy.\n",
    "    \"Freeze all but the last bottleneck layer\"\n",
    "    enc_except_final_block = sequential(*m.encoder[:-3], m.encoder[-3][:-1])\n",
    "    final_block_and_projector = sequential(m.encoder[-3][-1], m.projector)\n",
    "    return L(enc_except_final_block, final_block_and_projector).map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to use the above functions in an end to end fashion. First we get some data and plonk it into a dls, Then create an encoder, an augmentation pipeline, a learner, then fit\n",
    "the learner. This is the complete process of training BT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_bt_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "        \n",
    "    learn = Learner(dls,model=None, cbs=[BarlowTwins(aug,n_in=n_in,lmb=None,sparsity_level=None,\n",
    "                                                     print_augs=print_augs\n",
    "                                        )])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.barlow_twins.show(n=n)\n",
    "\n",
    "def show_vicreg_batch(dls,n_in,aug,n=2,print_augs=True,model_type='vicreg'):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "\n",
    "    learn = Learner(dls,model=None, cbs=[VICReg(aug,n_in=3,model_type=model_type)])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.vic_reg.show(n=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide \n",
    "\n",
    "dls = get_ssl_dls('cifar10',bs=32,size=128,device=default_device())\n",
    "aug = get_bt_cifar10_aug_pipelines(32)\n",
    "show_vicreg_batch(dls,n_in=3,aug=aug,n=2,print_augs=True,model_type='vicreg')\n",
    "show_vicreg_batch(dls,n_in=3,aug=aug,n=2,print_augs=True,model_type='br_vicreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SaveBarlowLearnerCheckpoint(Callback):\n",
    "    \"Save such that can resume training \"\n",
    "    def __init__(self, experiment_dir,start_epoch=0, save_interval=250,with_opt=True):\n",
    "        self.experiment_dir = experiment_dir\n",
    "        self.start_epoch = start_epoch\n",
    "        self.save_interval = save_interval\n",
    "        self.with_opt = with_opt  # Decide whether to save optimizer state as well.\n",
    "\n",
    "    def after_epoch(self):\n",
    "        if (self.epoch+1) % self.save_interval == 0 and self.epoch>=self.start_epoch:\n",
    "            print(f\"Saving model and learner state at epoch {self.epoch}\")\n",
    "   \n",
    "            checkpoint_filename = f\"learner_checkpoint_epoch_{self.epoch}\"\n",
    "            checkpoint_path = os.path.join(self.experiment_dir, checkpoint_filename)\n",
    "            # Save the entire learner object, including the model's parameters and optimizer state.\n",
    "            self.learn.save(checkpoint_path, with_opt=self.with_opt)\n",
    "            print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "class SaveBarlowLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        encoder_filename = f\"trained_encoder_epoch_{self.epoch}.pth\"\n",
    "        encoder_path = os.path.join(self.experiment_dir, encoder_filename)\n",
    "        torch.save(self.learn.model.encoder.state_dict(), encoder_path)\n",
    "        print(f\"encoder state dict saved to {encoder_path}\")\n",
    "\n",
    "\n",
    "class SaveVicRegLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        left_encoder_filename = f\"trained_left_encoder_epoch_{self.epoch}.pth\"\n",
    "        left_encoder_path = os.path.join(self.experiment_dir, left_encoder_filename)\n",
    "        torch.save(self.learn.model.left_encoder.state_dict(), left_encoder_path)\n",
    "        print(f\"Left encoder state dict saved to {left_encoder_path}\")\n",
    "\n",
    "        right_encoder_filename = f\"trained_right_encoder_epoch_{self.epoch}.pth\"\n",
    "        right_encoder_path = os.path.join(self.experiment_dir, right_encoder_filename)\n",
    "        torch.save(self.learn.model.right_encoder.state_dict(), right_encoder_path)\n",
    "        print(f\"Right encoder state dict saved to {right_encoder_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_barlow_model(arch,ps,hs,path):\n",
    "\n",
    "    encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_barlow_twins_model(encoder, hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_vicreg_model(arch,ps,hs,path):\n",
    "\n",
    "    left_encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    right_encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_vicreg_model(left_encoder,right_encoder,hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BarlowTrainer:\n",
    "    \"Setup a learner for training a BT model. Can do transfer learning, normal training, or resume training.\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,#An encoder followed by a projector\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 lmb,\n",
    "                 sparsity_level,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 splitter_str='none',\n",
    "                 num_it=100, #Number of iterations to run lr_find for.\n",
    "                 load_learner_path=None, #Path to load learner from (optional)\n",
    "                 experiment_dir=None, #Where to save model checkpoints (optional)\n",
    "                 start_epoch=0, #Which epoch to start from\n",
    "                 save_interval=None, #How often to save model checkpoints (optional). \n",
    "                 export=False,\n",
    "                 ):\n",
    "\n",
    "        store_attr()\n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    \n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics.\n",
    "\n",
    "        Returns:\n",
    "        - learn: The Learner object.\n",
    "        \"\"\"\n",
    "      \n",
    "        self.model.to(self.device)\n",
    "\n",
    "\n",
    "        cbs = [BarlowTwins(self.bt_aug_pipelines,n_in=self.n_in,lmb=self.lmb,\n",
    "                           sparsity_level=self.sparsity_level,print_augs=False,\n",
    "                           model_type=self.model_type\n",
    "                           )\n",
    "              ]\n",
    "\n",
    "        learn=Learner(self.dls,self.model,splitter=my_splitter_bt,wd=self.wd, cbs=cbs\n",
    "                     )\n",
    "        \n",
    "        if self.load_learner_path: learn.load(self.load_learner_path,with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir:\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export:\n",
    "            cbs.append(SaveBarlowLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "                \n",
    "    \n",
    "    def bt_transfer_learning(self,freeze_epochs:int,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is already pretrained, we can do transfer learning.\n",
    "            Freeze encoder, train projector for a few epochs, then unfreeze and train all. \n",
    "        \"\"\"\n",
    "        self.learn.freeze()\n",
    "        test_grad_off(self.learn.encoder)\n",
    "        self.learn.fit(freeze_epochs)\n",
    "\n",
    "         # Check if the splitter is 'my_splitter_bt_last_block_resnet50'\n",
    "        if self.splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "            # Unfreeze only the last bottleneck block\n",
    "            for param in self.learn.model.encoder[-3][-1].parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "            print(f'splitter_str={self.splitter_str}')\n",
    "        else:\n",
    "            # Unfreeze the entire encoder\n",
    "            self.learn.unfreeze()\n",
    "            test_grad_on(self.learn.model)\n",
    "        \n",
    "        \n",
    "        self.learn.summary()\n",
    "\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it) #lets find a good maximum lr\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley, cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def bt_learning(self,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is not pretrained, we can do normal training.\n",
    "        \"\"\"\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "    \n",
    "    def continue_bt_learning(self,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Resume training with `fit_one_cycle` after loading a learner.\n",
    "        \"\"\"\n",
    "        \n",
    "        test_ne(self.load_learner_path,None)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs,start_epoch=start_epoch,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def train(self,learn_type, freeze_epochs:int,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Train model using BT\n",
    "        \"\"\"\n",
    "        if learn_type == 'transfer_learning':\n",
    "            \n",
    "            self.bt_transfer_learning(freeze_epochs=freeze_epochs,epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        elif learn_type=='continue_learning':\n",
    "            self.continue_bt_learning(epochs=epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "        \n",
    "        elif learn_type=='standard':\n",
    "            self.bt_learning(epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        else: raise Exception(\"Invalid weight_type\")\n",
    "\n",
    "        return self.learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can inherit from the above for vicreg version. Just setting up the learner is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VICRegTrainer(BarlowTrainer):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 sparsity_level,\n",
    "                 sim_coeff,\n",
    "                 std_coeff,\n",
    "                 cov_coeff,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 splitter_str='none',\n",
    "                 num_it=100,\n",
    "                 load_learner_path=None,\n",
    "                 experiment_dir=None,\n",
    "                 start_epoch=0,\n",
    "                 save_interval=None,\n",
    "                 export=False):\n",
    "        \n",
    "        \n",
    "                # Store VICReg-specific attributes\n",
    "        store_attr('sim_coeff,std_coeff,cov_coeff') #why doesn't this work?\n",
    "        # Call the parent constructor with None for lmb\n",
    "        super().__init__(model, dls, bt_aug_pipelines,None,sparsity_level, n_in, model_type,\n",
    "                         wd, device, splitter_str, num_it, load_learner_path,\n",
    "                         experiment_dir, start_epoch, save_interval, export)\n",
    "        \n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics for VICReg.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        cbs = [VICReg(self.bt_aug_pipelines, n_in=self.n_in, \n",
    "                      sim_coeff=self.sim_coeff, std_coeff=self.std_coeff, cov_coeff=self.cov_coeff,\n",
    "                      model_type=self.model_type, print_augs=False)]\n",
    "\n",
    "        # Use the splitter based on splitter_str\n",
    "        # if self.splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "        #     splitter = my_splitter_bt_last_block_resnet50\n",
    "        # else:\n",
    "        #     splitter = my_splitter_bt\n",
    "        #learn = Learner(self.dls, self.model, splitter=splitter, wd=self.wd, cbs=cbs)\n",
    "        \n",
    "        #TODO: Implement custom splitter for VICReg\n",
    "        #splitter not supported yet for vicreg: we can do this but need a custom splitter.\n",
    "        #The issue is just that vicreg e.g. has encoder_left and encoder_right, v.s.\n",
    "        #BT which just has one encoder. Just leaving splitter off for now\n",
    "        learn = Learner(self.dls, self.model, wd=self.wd, cbs=cbs)\n",
    "        if self.load_learner_path: \n",
    "            learn.load(self.load_learner_path, with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir: #same as for barlow\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export: #different to barlow. Clearly we in principle want this \n",
    "                        #more abstract so it just works. But ok.\n",
    "            cbs.append(SaveVicRegLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "\n",
    "    # # Override the train method if necessary\n",
    "    # def train(self, learn_type, freeze_epochs:int, epochs:int, start_epoch:int, interrupt_epoch:int):\n",
    "    #     \"\"\"Train model using VICReg\"\"\"\n",
    "    #     # You can customize this method for VICReg-specific training logic if needed\n",
    "    #     return super().train(learn_type, freeze_epochs, epochs, start_epoch, interrupt_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that splitting/freezings works in `bt_transfer_learning`.\n",
    "\n",
    "It's a bit hacky but looks to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "encoder = resnet_arch_to_encoder(arch='resnet50', weight_type=random)\n",
    "model = create_barlow_twins_model(encoder, hidden_size=8192, projection_size=8192)\n",
    "dls = get_ssl_dls('cifar10',bs=64,size=32,device=default_device())\n",
    "\n",
    "cbs = [BarlowTwins(get_bt_aug_pipelines(bt_augs='bt_cifar10_aug_pipelines', size=32),\n",
    "       n_in=3,lmb=1/8192,sparsity_level=None,print_augs=False,\n",
    "        model_type='barlow_twins'\n",
    "                    )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy pasted from `bt_transfer_learning`\n",
    "\n",
    "Bit hacky, but ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BarlowTwinsModel (Input shape: 64 x 3 x 32 x 32)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     64 x 64 x 16 x 16   \n",
       "Conv2d                                    9408       False     \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "MaxPool2d                                                      \n",
       "Conv2d                                    4096       False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 8 x 8    \n",
       "Conv2d                                    32768      False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 4 x 4    \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    524288     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 2 x 2    \n",
       "Conv2d                                    524288     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2097152    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "AdaptiveAvgPool2d                                              \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048           \n",
       "Flatten                                                        \n",
       "____________________________________________________________________________\n",
       "                     64 x 8192           \n",
       "Linear                                    16785408   True      \n",
       "BatchNorm1d                               16384      True      \n",
       "ReLU                                                           \n",
       "Linear                                    67117056   True      \n",
       "BatchNorm1d                               16384      True      \n",
       "ReLU                                                           \n",
       "Linear                                    67117056   True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 174,560,320\n",
       "Total trainable params: 155,561,856\n",
       "Total non-trainable params: 18,998,464\n",
       "\n",
       "Optimizer used: <function Adam>\n",
       "Loss function: <bound method BarlowTwins.lf of BarlowTwins>\n",
       "\n",
       "Model frozen up to parameter group #1\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - CastToTensor\n",
       "  - BarlowTwins\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide \n",
    "learn=Learner(dls,model,splitter=my_splitter_bt,cbs=cbs\n",
    "             )\n",
    "\n",
    "\n",
    "splitter_str = 'my_splitter_bt_last_block_resnet50'\n",
    "#splitter_str='none'\n",
    "learn.freeze() #freeze everything up to projector\n",
    "test_grad_off(learn.encoder)\n",
    "\n",
    "    # Check if the splitter is 'my_splitter_bt_last_block_resnet50'\n",
    "if splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "    # Unfreeze only the last bottleneck block\n",
    "    for param in learn.model.encoder[-3][-1].parameters():\n",
    "        param.requires_grad = True\n",
    "else:\n",
    "    # Unfreeze the entire encoder\n",
    "    learn.unfreeze()\n",
    "\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a BT model. Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "    if hasattr(config,'splitter_str'):\n",
    "        splitter_str=config.splitter_str\n",
    "    else:\n",
    "        splitter_str='none'\n",
    "\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "    encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    \n",
    "    model = create_barlow_twins_model(encoder, hidden_size=config.hs, projection_size=config.ps)\n",
    "\n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    bt_trainer = BarlowTrainer(model=model,\n",
    "                    dls=dls,\n",
    "                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                    lmb=config.lmb,\n",
    "                    sparsity_level=config.sparsity_level,\n",
    "                    n_in=config.n_in,\n",
    "                    model_type=config.model_type,\n",
    "                    wd=config.wd,\n",
    "                    num_it=config.num_it,\n",
    "                    device=device,\n",
    "                    splitter_str=splitter_str,\n",
    "                    load_learner_path=load_learner_path,\n",
    "                    experiment_dir=experiment_dir,\n",
    "                    start_epoch=start_epoch,\n",
    "                    save_interval=config.save_interval,\n",
    "                    export=export\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = bt_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above but for vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_vicreg_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a vicreg model (standard or br) Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "    if hasattr(config,'splitter_str'):\n",
    "        splitter_str=config.splitter_str\n",
    "    else:\n",
    "        splitter_str='none'\n",
    "\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "\n",
    "    #vicreg model may require two encoders, so we need to handle this case\n",
    "    encoder_left = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    if config.model_type == 'vicreg':\n",
    "\n",
    "        if not config.shared_encoder:\n",
    "            encoder_right = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "        else:\n",
    "            encoder_right=encoder_left\n",
    "\n",
    "        model = create_vicreg_model(encoder_left, encoder_right, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "    #At present, the arch is: encoder_left = encoder_right =  Transformer(CNN_Left(x),CNN_right(x)).\n",
    "    elif config.model_type == 'br_vicreg':\n",
    "\n",
    "        #so far just implemented for cifar_resnet18. Basically we don't downsample / flatten output, since is passed to \n",
    "        #swin layer\n",
    "        left_res_encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type,remove_pool=True, flatten=False)\n",
    "        right_res_encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type,remove_pool=True, flatten=False)\n",
    "\n",
    "                                  #specifically up to and including stage1. So far\n",
    "                                  #just for resnet18\n",
    "        #share transformer that acts on distinct encoders. i.e.\n",
    "        #Transformer(left_res_encoder(x_left),right_res_encoder(x_right))\n",
    "\n",
    "        encoder = BinocularResNetToSwin(\n",
    "                 left_res_encoder,\n",
    "                 right_res_encoder,\n",
    "                            )\n",
    "        \n",
    "\n",
    "\n",
    "        model = create_vicreg_model(encoder, encoder, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "\n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    #(this is same as for bt)\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    vicreg_trainer = VICRegTrainer(model=model,\n",
    "                                    dls=dls,\n",
    "                                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                                    sparsity_level=config.sparsity_level,\n",
    "                                    sim_coeff=config.sim_coeff,\n",
    "                                    std_coeff=config.std_coeff,\n",
    "                                    cov_coeff=config.cov_coeff,\n",
    "                                    n_in=config.n_in,\n",
    "                                    model_type=config.model_type,\n",
    "                                    wd=config.wd,\n",
    "                                    num_it=config.num_it,\n",
    "                                    device=device,\n",
    "                                    splitter_str=splitter_str,\n",
    "                                    load_learner_path=load_learner_path,\n",
    "                                    experiment_dir=experiment_dir,\n",
    "                                    start_epoch=start_epoch,\n",
    "                                    save_interval=config.save_interval,\n",
    "                                    export=export\n",
    "\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = vicreg_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_experiment_state(config,base_dir):\n",
    "    \"\"\"Get the load_learner_path, learn_type, start_epoch, interrupt_epoch for BT experiment.\n",
    "       Basically this tells us how to continue learning (e.g. we have run two sessions for \n",
    "       100 epochs, and want to continue for another 100 epochs). Return values are\n",
    "       None if we are starting from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    load_learner_path, _  = get_highest_num_path(base_dir, config)\n",
    "    #TODO:\n",
    "    #We can get start_epoch, interrupt epoch from `get_highest_epoch_path` + save_interval (may be None!)\n",
    "    start_epoch=0 if load_learner_path is None else int(load_learner_path.split('_')[-1])+1\n",
    "    \n",
    "    if start_epoch >= config.epochs:\n",
    "        print(f\"start_epoch={start_epoch}, but already completed {config.epochs} epochs. Exiting.\")\n",
    "        sys.exit()\n",
    "\n",
    "    interrupt_epoch = start_epoch + config.save_interval\n",
    "\n",
    "    #We can also get the learn_type from the load_learner_path + weight_type. \n",
    "    \n",
    "    if config.weight_type == 'random':\n",
    "        learn_type = 'standard'\n",
    "    \n",
    "    elif 'pretrained' in config.weight_type:\n",
    "        learn_type = 'transfer_learning'\n",
    "\n",
    "    learn_type = learn_type if load_learner_path is None else 'continue_learning'\n",
    "\n",
    "    return load_learner_path, learn_type, start_epoch, interrupt_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_experiment(config,\n",
    "                      base_dir,\n",
    "                      ):\n",
    "        \"\"\"Run several epochs of the experiment as defined in the config and where we are up to. e.g. epoch 0, or resuming\n",
    "        at epoch 99 etc. Basically a stateful version of `main_bt_train` that can be resumed. And saving.\n",
    "        \"\"\"\n",
    "    \n",
    "        \n",
    "        experiment_dir, experiment_hash,git_commit_hash = setup_experiment(config,base_dir)\n",
    "        load_learner_path, learn_type, start_epoch, interrupt_epoch = get_bt_experiment_state(config,base_dir)      \n",
    "        \n",
    "        if 'barlow' in config.model_type:\n",
    "        \n",
    "                main_bt_train(config=config,\n",
    "                        start_epoch=start_epoch,\n",
    "                        interrupt_epoch=interrupt_epoch,\n",
    "                        load_learner_path=load_learner_path,\n",
    "                        learn_type=learn_type,\n",
    "                        experiment_dir=experiment_dir,\n",
    "                        )\n",
    "        elif 'vicreg' in config.model_type:\n",
    "                \n",
    "                main_vicreg_train(config=config,\n",
    "                        start_epoch=start_epoch,\n",
    "                        interrupt_epoch=interrupt_epoch,\n",
    "                        load_learner_path=load_learner_path,\n",
    "                        learn_type=learn_type,\n",
    "                        experiment_dir=experiment_dir,\n",
    "                        )\n",
    "\n",
    "        # Save a metadata file in the experiment directory with the Git commit hash and other details\n",
    "        save_metadata_file(experiment_dir=experiment_dir, git_commit_hash=git_commit_hash)\n",
    "\n",
    "        # After experiment execution and all processing are complete\n",
    "        update_experiment_index(base_dir,{\n",
    "                \"experiment_hash\": experiment_hash,  # Unique identifier derived from the experiment's configuration\n",
    "                \"experiment_dir\": experiment_dir,  # Absolute path to the experiment's dedicated directory\n",
    "                \"git_commit_hash\": git_commit_hash,  # Git commit hash for the code version used in the experiment\n",
    "                # Potentially include additional details collected during or after the experiment, such as:\n",
    "                # Any other metadata or results summary that is relevant to the experiment\n",
    "                                })\n",
    "        \n",
    "        return experiment_dir,experiment_hash #Return the experiment_dir so we can easily access the results of the experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full end to end example with BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     config_path = '../configs/cifar10/bt_test_config.yaml'\n",
    "#     config = load_config(config_path)\n",
    "\n",
    "#     # config.model_type = 'sparse_head_barlow_twins'\n",
    "#     # config.sparsity_level=10\n",
    "#     # config.epochs=100\n",
    "#     # config.save_interval=100\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     #get path to fully fitted model\n",
    "#     path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "#     model = load_barlow_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "#     print(model)\n",
    "\n",
    "#     #New config but the first part of experiment_dir is same - just hash is different\n",
    "#     #It shouldnt find a max file path\n",
    "#     config.epochs=config.epochs+1\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full end to end example for vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     config_path = '../configs/cifar10/vicreg_test_config.yaml'\n",
    "#     config = load_config(config_path)\n",
    "\n",
    "#     # config.model_type = 'sparse_head_barlow_twins'\n",
    "#     # config.sparsity_level=10\n",
    "#     # config.epochs=100\n",
    "#     # config.save_interval=100\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     #get path to fully fitted model\n",
    "#     path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "#     model = load_vicreg_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "#     print(model)\n",
    "\n",
    "#     #New config but the first part of experiment_dir is same - just hash is different\n",
    "#     #It shouldnt find a max file path\n",
    "#     config.epochs=config.epochs+1\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify runs with br_vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     config_path = '../configs/cifar10/vicreg_test_config.yaml'\n",
    "#     config = load_config(config_path)\n",
    "#     config.model_type = 'br_vicreg'\n",
    "#     config.arch = 'cifar_resnet18_swin'\n",
    "\n",
    "#     pretty_print_ns(config)\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
