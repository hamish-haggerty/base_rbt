{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_model\n",
    "\n",
    "> In this module we have the base model, learner and other things we need to train encoder\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import self_supervised\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import kornia.augmentation as korniatfm\n",
    "import torchvision.transforms as tvtfm\n",
    "from base_rbt.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the base functions and classes to train a basic BT-style model. Note that this (mostly) all comes directly from here: `https://github.com/KeremTurgutlu/self_supervised/blob/main/nbs/14%20-%20barlow_twins.ipynb`\n",
    "but we needed to extend some of the functionality for our purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the base classes and functions needed for image augmentation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#My edited version of RandTransform\n",
    "class RandomGaussianBlur(RandTransform):\n",
    "    \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "    order = 11\n",
    "    def __init__(self, \n",
    "                 p=1.0, #debugging (bug in libraries implementation)\n",
    "                 prob=0.5,#the real probability\n",
    "                 s=(8,32), #kernel\n",
    "                 sig=None, #sig_val is either manually input OR\n",
    "                 blur_r=(0.1,2),#is randomly chosen from uniform with these bounds\n",
    "                 same_on_batch=False, \n",
    "                 **kwargs): \n",
    "        \n",
    "        store_attr()\n",
    "        super().__init__(p=p, **kwargs)\n",
    "\n",
    "    def encodes(self, x:TensorImage):\n",
    "        \n",
    "        if isinstance(self.s, int):   s = (self.s,self.s)\n",
    "        elif isinstance(self.s, tuple) or isinstance(self.s, list): s=self.s\n",
    "     \n",
    "        #Default for ImageNet from BYOL / BT papers\n",
    "        if self.sig is None:\n",
    "            sig_val = np.random.uniform(self.blur_r[0],self.blur_r[1])\n",
    "        \n",
    "        else:\n",
    "            sig_val = self.sig\n",
    "            \n",
    "\n",
    "        tfm = korniatfm.RandomGaussianBlur(kernel_size=s,sigma=(sig_val,sig_val),same_on_batch=self.same_on_batch,p=self.prob)\n",
    "        return tfm(x)\n",
    "\n",
    "#Delete later: leaving for backward compatibility for now\n",
    "# class RandomGaussianBlur(RandTransform):\n",
    "#     \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "#     order = 11\n",
    "#     def __init__(self, p=0.5, s=(8,32), same_on_batch=False, **kwargs): \n",
    "#         store_attr()\n",
    "#         super().__init__(p=p, **kwargs)\n",
    "        \n",
    "#     def encodes(self, x:TensorImage):\n",
    "#         if isinstance(self.s, tuple): s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, list):  s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, int):   s = self.s\n",
    "#         s2 = int(s/4)*2+1\n",
    "#         tfm = korniatfm.RandomGaussianBlur((s2,s2),(s,s),same_on_batch=self.same_on_batch,p=1.) #p=1. is a bug\n",
    "#                                             #kernel #sigma\n",
    "        \n",
    "#         return tfm(x)\n",
    "\n",
    "\n",
    "class RandomCenterDropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.5, min_dropout_size=(20, 20), max_dropout_size=(60, 60), fill_value=0, same_on_batch=False):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.min_dropout_size = min_dropout_size\n",
    "        self.max_dropout_size = max_dropout_size\n",
    "        self.fill_value = fill_value\n",
    "        self.same_on_batch = same_on_batch\n",
    "        #self.id_transform = tvtfm.RandomResizedCrop((256, 256), scale=(1.,1.), ratio=(1.,1.))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Check if the augmentation should be applied to the whole batch or individually\n",
    "\n",
    "        #x=self.id_transform(x)\n",
    "\n",
    "        if self.same_on_batch:\n",
    "            if random.random() < self.p:\n",
    "                return self._apply_dropout(x)\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            # Apply dropout individually with given probability\n",
    "            for i in range(x.size(0)):\n",
    "                tem=random.random()\n",
    "                #print(f\"tem is: {tem}\")\n",
    "                if tem < self.p:\n",
    "                    x[i] = self._apply_dropout(x[i].unsqueeze(0)).squeeze(0)\n",
    "            return x\n",
    "\n",
    "    def _apply_dropout(self, img):\n",
    "        for i,count in enumerate(range(img.size(0))):  # Iterate through batch if necessary\n",
    "            _, h, w = img[i].shape\n",
    "            # Generate random dropout size within specified limits\n",
    "            dh = random.randint(self.min_dropout_size[0], self.max_dropout_size[0])\n",
    "            dw = random.randint(self.min_dropout_size[1], self.max_dropout_size[1])\n",
    "            \n",
    "            x1 = int(max((w - dw) / 2, 0))\n",
    "            y1 = int(max((h - dh) / 2, 0))\n",
    "            \n",
    "            mask = torch.ones_like(img[i])\n",
    "            mask[:, y1:y1+dh, x1:x1+dw] = self.fill_value\n",
    "            img[i] = img[i] * mask\n",
    "        \n",
    "        return img\n",
    "\n",
    "    \n",
    "def get_BT_batch_augs(size,\n",
    "                    flip=True,crop=True,noise=True,rotate=True,jitter=True,bw=True,blur=True,solar=True,cutout=False, #Whether to use  given aug or not\n",
    "                    resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.025, rotate_deg=30,jitter_s=.6,blur_s=(4,32),#hps of diff augs\n",
    "                    blur_r=(0.1,2),blur_sig=None,sol_t=0.05,sol_a=0.05,min_dropout_size=(25, 100),max_dropout_size=(50,150), #hps of diff augs\n",
    "                    flip_p=0.5, rotate_p=0.3,noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3,sol_p=0.1,cut_p=0.5, #prob of performing aug\n",
    "                    same_on_batch=False,stats=imagenet_stats,cuda=default_device().type == 'cuda',xtra_tfms=[]\n",
    "                    ):\n",
    "    \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    \n",
    "    tfms = []\n",
    "\n",
    "    korniatfm.RandomHorizontalFlip.order = RandomResizedCrop.order-1\n",
    "\n",
    "\n",
    "    if crop: tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "    #Unfortunately for some reason this doesn't work, so we can't apply \"same_on_batch=False\"\n",
    "    #tfms += [korniatfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio, same_on_batch=same_on_batch)]\n",
    "\n",
    "    if cutout: tfms+=[RandomCenterDropout(min_dropout_size=min_dropout_size,max_dropout_size=max_dropout_size, fill_value=0, p=cut_p,same_on_batch=same_on_batch)]\n",
    "    \n",
    "  \n",
    "    if flip: tfms += [korniatfm.RandomHorizontalFlip(p=flip_p,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if rotate: tfms += [Rotate(max_deg=rotate_deg, p=rotate_p, batch=same_on_batch)]\n",
    "\n",
    "                                             #brightness,contrast,saturation,hue\n",
    "    if jitter: tfms += [korniatfm.ColorJitter(0.4*jitter_s, 0.4*jitter_s, 0.2*jitter_s, 0.1*jitter_s, p=jitter_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if bw:     tfms += [korniatfm.RandomGrayscale(p=bw_p, same_on_batch=same_on_batch)]\n",
    "        \n",
    "    #sig will usually be None\n",
    "    if blur:   tfms += [RandomGaussianBlur(prob=blur_p, s=blur_s,sig=blur_sig,blur_r=blur_r, same_on_batch=same_on_batch)]\n",
    "\n",
    "    korniatfm.RandomSolarize.order = RandomGaussianBlur.order + 1 #we want to apply solarization after RandomGaussianBlur\n",
    "    \n",
    "    if solar: tfms += [korniatfm.RandomSolarize(p=sol_p,thresholds=sol_t, additions=sol_a,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if noise: tfms+=[korniatfm.RandomGaussianNoise(mean=0.0, std=noise_std, same_on_batch=same_on_batch, p=noise_p)]\n",
    "    \n",
    "    if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "\n",
    "    tfms += xtra_tfms\n",
    "\n",
    "    pipe = Pipeline(tfms, split_idx = 0)\n",
    "    return pipe\n",
    "\n",
    "@delegates(get_BT_batch_augs)\n",
    "def get_multi_aug_pipelines(size, **kwargs): return get_BT_batch_augs(size, **kwargs)\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(size=size,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_cifar10_aug_pipelines(size):\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    bt_cifar10_aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return bt_cifar10_aug_pipelines\n",
    "\n",
    "#Add other augmentations here e.g. BYOL augs\n",
    "IMAGENET_Augs = dict(flip_p1=0.5,flip_p2=0.5,jitter_p1=0.8,jitter_p2=0.8,bw_p1=0.2,\n",
    "                bw_p2=0.2,blur_p1=1.0,blur_p2=0.1,sol_p1=0.0,sol_p2=0.2,noise_p1=0.0,\n",
    "                noise_p2=0.0,cut_p=0,resize_scale=(0.7, 1.0),resize_ratio=(3/4, 4/3),rotate_deg=45.0,\n",
    "                rotate_p=0.5,blur_r=(0.1,2),blur_s=13,sol_t=0.1,sol_a=0.1,noise_std=0.1\n",
    "                )\n",
    "\n",
    "DERMNET_Augs = IMAGENET_Augs\n",
    "DERMNET_Augs['min_dropout_size']=(25, 100)\n",
    "DERMNET_Augs['max_dropout_size']=(50,150)\n",
    "DERMNET_Augs['cut_p']=0.5\n",
    "\n",
    "def helper_get_bt_augs(size,Augs=IMAGENET_Augs):\n",
    "\n",
    "\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p1'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p1'],\n",
    "                        jitter_p=Augs['jitter_p1'], bw_p=Augs['bw_p1'], blur_p=Augs['blur_p1'],\n",
    "                        sol_p=Augs['sol_p1'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p2'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p2'],\n",
    "                        jitter_p=Augs['jitter_p2'], bw_p=Augs['bw_p2'], blur_p=Augs['blur_p2'],\n",
    "                        sol_p=Augs['sol_p2'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return aug_pipelines\n",
    "\n",
    "def get_bt_imagenet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=IMAGENET_Augs)\n",
    "\n",
    "def get_bt_dermnet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=DERMNET_Augs)\n",
    "\n",
    "\n",
    "\n",
    "bt_aug_func_dict = {'bt_cifar10_aug_pipelines':get_bt_cifar10_aug_pipelines,'bt_imagenet_aug_pipelines':get_bt_imagenet_aug_pipelines,\n",
    "                   'bt_dermnet_aug_pipelines':get_bt_dermnet_aug_pipelines\n",
    "                   }\n",
    "\n",
    "def get_bt_aug_pipelines(bt_augs,size):\n",
    "\n",
    "    return bt_aug_func_dict[bt_augs](size)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base functions / classes we need to train a BT / RBT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Base functions / classes we need to train a BT / RBT model.\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        \n",
    "    def forward(self,x): \n",
    "        \n",
    "        return self.projector(self.encoder(x))\n",
    "\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines,n_in,lmb,sparsity_level, \n",
    "                model_type='barlow_twins',print_augs=False\n",
    "                 ):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        store_attr('sparsity_level')\n",
    "        self.n_in=n_in\n",
    "        self.model_type = model_type\n",
    "        self.index=-1 #Gets updated after each batch\n",
    "        self.acc_dict = {}\n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self.index=-1  \n",
    "  \n",
    "    def before_batch(self):\n",
    "        \n",
    "        #TODO: Make this nicer (possibly can load in data as TensorImage(BW) or something?)\n",
    "        #This is a bit of a hack. Can make this more elegant later. But in new version of FastAI\n",
    "        #seems we need to compute TensorImage(BW) here, and depends on whether color or not, i.e. n_in.\n",
    "        if self.n_in == 1:\n",
    "\n",
    "            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            \n",
    "            #print(xi.shape)\n",
    "                                    \n",
    "        elif self.n_in == 3:\n",
    "            \n",
    "            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "\n",
    "        self.index=self.index+1\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1): \n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]]\n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#We want access to both representation and projection\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        \n",
    "    def forward(self,x): \n",
    "        tem = self.encoder(x)\n",
    "        return tem,self.projector(tem)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'forward returns tuple of (encoder(x),projector(encoder(x)))'\n",
    "\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    "    \n",
    " \n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we write down standard definition of `lf` for `RAT` method: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BarlowTwins needs an `lf` method to work properly. Here we provide the `lf` of standard barlow twins. Later we can\n",
    "patch in a new defintion of `lf` that involves random functions, inner maximization etc. The tools needed to do this are provised in `base_lf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt(pred,I,lmb):\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "    \n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs \n",
    "    cdiff = (C - I)**2\n",
    "    loss = (cdiff*I + cdiff*(1-I)*lmb).sum() \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_indiv_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb*(0.5*torch.abs(z1_enc) + 0.5*torch.abs(z2_enc)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1_enc.pow(2) + 0.5 * z2_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_norm_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_fun(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm_enc.T @ z2norm_enc) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    loss = (cdiff*I).sum() #standard bt loss\n",
    "\n",
    "    print(f\"invariance loss is: {loss} and sparsity loss is: {sparsity}\")\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_proj_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                           ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm.pow(2) + 0.5 * z2norm.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb):\n",
    "    \"Assumes model created according to type p3\"\n",
    "\n",
    "    if self.model_type=='barlow_twins':\n",
    "         pred_enc = pred[0]\n",
    "         pred = pred[1]\n",
    "         return lf_bt(pred, self.I,self.lmb)\n",
    "\n",
    "    elif self.model_type=='indiv_sparse_barlow_twins':\n",
    "        return lf_bt_indiv_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='group_sparse_barlow_twins':\n",
    "        return lf_bt_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='group_norm_sparse_barlow_twins':\n",
    "        return lf_bt_group_norm_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='proj_group_sparse_barlow_twins':\n",
    "        return lf_bt_proj_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='fun':\n",
    "        return lf_bt_fun(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "\n",
    "    else: raise(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt(m):\n",
    "    return L(sequential(*m.encoder),m.projector).map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to use the above functions in an end to end fashion. First we get some data and plonk it into a dls, Then create an encoder, an augmentation pipeline, a learner, then fit\n",
    "the learner. This is the complete process of training BT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_bt_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "        \n",
    "    learn = Learner(dls,model=None, cbs=[BarlowTwins(aug,n_in=n_in,lmb=None,sparsity_level=None,\n",
    "                                                     print_augs=print_augs\n",
    "                                        )])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.barlow_twins.show(n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BarlowTrainer:\n",
    "    \"Setup a learner for training a BT model. Can do transfer learning, normal training, or resume training.\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,#An encoder followed by a projector\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 lmb,\n",
    "                 sparsity_level,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 num_it=100, #Number of iterations to run lr_find for.\n",
    "                 load_learner_path=None, #Path to load learner from (optional)\n",
    "                 experiment_dir=None, #Where to save model checkpoints (optional)\n",
    "                 start_epoch=0, #Which epoch to start from\n",
    "                 save_interval=None #How often to save model checkpoints (optional). \n",
    "\n",
    "                 ):\n",
    "\n",
    "        store_attr()\n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    \n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics.\n",
    "\n",
    "        Returns:\n",
    "        - learn: The Learner object.\n",
    "        \"\"\"\n",
    "      \n",
    "        self.model.to(self.device)\n",
    "\n",
    "        cbs = [BarlowTwins(self.bt_aug_pipelines,n_in=self.n_in,lmb=self.lmb,\n",
    "                           sparsity_level=self.sparsity_level,print_augs=False,\n",
    "                           model_type=self.model_type\n",
    "                           )\n",
    "              ]\n",
    "\n",
    "\n",
    "        learn=Learner(self.dls,self.model,splitter=my_splitter_bt,wd=self.wd, cbs=cbs\n",
    "                     )\n",
    "        \n",
    "        if self.load_learner_path: learn.load(self.load_learner_path,with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        if self.experiment_dir:\n",
    "            cbs.append(SaveLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "            \n",
    "        return cbs\n",
    "                \n",
    "\n",
    "    \n",
    "    def bt_transfer_learning(self,freeze_epochs:int,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is already pretrained, we can do transfer learning.\n",
    "            Freeze encoder, train projector for a few epochs, then unfreeze and train all. \n",
    "        \"\"\"\n",
    "\n",
    "        self.learn.freeze()\n",
    "        test_grad_off(self.learn.encoder)\n",
    "        self.learn.fit(freeze_epochs)\n",
    "        self.learn.unfreeze()\n",
    "        test_grad_on(self.learn.model)\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it)\n",
    "\n",
    "        \n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley,cbs=self._get_training_cbs(interrupt_epoch)\n",
    "                                )\n",
    "\n",
    "    def bt_learning(self,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is not pretrained, we can do normal training.\n",
    "        \"\"\"\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "    \n",
    "    def continue_bt_learning(self,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Resume training with `fit_one_cycle` after loading a learner.\n",
    "        \"\"\"\n",
    "        \n",
    "        test_ne(self.load_learner_path,None)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs,start_epoch=start_epoch,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def train(self,learn_type, freeze_epochs:int,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Train model using BT\n",
    "        \"\"\"\n",
    "        if learn_type == 'transfer_learning':\n",
    "            \n",
    "            self.bt_transfer_learning(freeze_epochs=freeze_epochs,epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        elif learn_type=='continue_learning':\n",
    "            self.continue_bt_learning(epochs=epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "        \n",
    "        elif learn_type=='standard':\n",
    "            self.bt_learning(epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        else: raise Exception(\"Invalid weight_type\")\n",
    "\n",
    "        return self.learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a BT model. Optionally save checkpoints of learner.\"\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "    encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    \n",
    "    model = create_barlow_twins_model(encoder, hidden_size=config.hs, projection_size=config.ps)\n",
    "\n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    bt_trainer = BarlowTrainer(model=model,\n",
    "                    dls=dls,\n",
    "                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                    lmb=config.lmb,\n",
    "                    sparsity_level=config.sparsity_level,\n",
    "                    n_in=config.n_in,\n",
    "                    model_type=config.model_type,\n",
    "                    wd=config.wd,\n",
    "                    num_it=config.num_it,\n",
    "                    device=device,\n",
    "                    load_learner_path=load_learner_path,\n",
    "                    experiment_dir=experiment_dir,\n",
    "                    start_epoch=start_epoch,\n",
    "                    save_interval=config.save_interval\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = bt_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_experiment(config,\n",
    "                      base_dir,\n",
    "                      ):\n",
    "    \"\"\"Run several epochs of the experiment as defined in the config and where we are up to. e.g. epoch 0, or resuming\n",
    "    at epoch 99 etc. Basically a stateful version of `main_bt_train` that can be resumed. And saving.\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    experiment_dir, experiment_hash,git_commit_hash = setup_experiment(config,base_dir)\n",
    "\n",
    "    load_learner_path, learn_type, start_epoch, interrupt_epoch = get_experiment_state(config,base_dir)\n",
    "\n",
    "    main_bt_train(config=config,\n",
    "            start_epoch=start_epoch,\n",
    "            interrupt_epoch=interrupt_epoch,\n",
    "            load_learner_path=load_learner_path,\n",
    "            learn_type=learn_type,\n",
    "            experiment_dir=experiment_dir,\n",
    "            )\n",
    "\n",
    "    # Save a metadata file in the experiment directory with the Git commit hash and other details\n",
    "    save_metadata_file(experiment_dir=experiment_dir, git_commit_hash=git_commit_hash)\n",
    "\n",
    "    # After experiment execution and all processing are complete\n",
    "    update_experiment_index(base_dir,{\n",
    "        \"experiment_hash\": experiment_hash,  # Unique identifier derived from the experiment's configuration\n",
    "        \"experiment_dir\": experiment_dir,  # Absolute path to the experiment's dedicated directory\n",
    "        \"git_commit_hash\": git_commit_hash,  # Git commit hash for the code version used in the experiment\n",
    "        # Potentially include additional details collected during or after the experiment, such as:\n",
    "        # Any other metadata or results summary that is relevant to the experiment\n",
    "                            })\n",
    "    \n",
    "    return experiment_dir,experiment_hash #Return the experiment_dir so we can easily access the results of the experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpu9w8ot2c/SSL/cifar10/smallres/62c27bad and the experiment hash is: 62c27bad\n",
      "Configuration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpu9w8ot2c/SSL/cifar10/smallres/62c27bad/config.yaml\n",
      "The git hash is: 30e42db1ebca0496e65130f2dd841a683a271b8f\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>227.522659</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>215.230545</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>228.231155</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>244.971024</td>\n",
       "      <td>None</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>247.001541</td>\n",
       "      <td>None</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>241.475922</td>\n",
       "      <td>None</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and learner state at epoch 5\n",
      "Checkpoint saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpu9w8ot2c/SSL/cifar10/smallres/62c27bad/learner_checkpoint_epoch_5\n",
      "Interrupting training before starting epoch 6\n",
      "Metadata saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpu9w8ot2c/SSL/cifar10/smallres/62c27bad/metadata.yaml\n",
      "Updated experiment index for hash: 62c27bad\n",
      "['learner_checkpoint_epoch_5.pth', 'metadata.yaml', 'config.yaml']\n",
      "['SSL', 'experiment_index.json']\n",
      "experiment_dir and base_dir\n",
      "We can keep training - resuming from the checkpoint\n",
      "The experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpu9w8ot2c/SSL/cifar10/smallres/62c27bad and the experiment hash is: 62c27bad\n",
      "Configuration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpu9w8ot2c/SSL/cifar10/smallres/62c27bad/config.yaml\n",
      "The git hash is: 30e42db1ebca0496e65130f2dd841a683a271b8f\n",
      "looking in /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpu9w8ot2c/SSL/cifar10/smallres for highest epoch saved\n",
      "Found max file path: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpu9w8ot2c/SSL/cifar10/smallres/62c27bad/learner_checkpoint_epoch_5.pth and max experiment dir: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpu9w8ot2c/SSL/cifar10/smallres/62c27bad\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>279.231262</td>\n",
       "      <td>None</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>238.140381</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>217.777405</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>205.353882</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>199.905914</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>197.964722</td>\n",
       "      <td>None</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and learner state at epoch 11\n",
      "Checkpoint saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpu9w8ot2c/SSL/cifar10/smallres/62c27bad/learner_checkpoint_epoch_11\n",
      "Metadata saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpu9w8ot2c/SSL/cifar10/smallres/62c27bad/metadata.yaml\n",
      "Updated experiment index for hash: 62c27bad\n",
      "['learner_checkpoint_epoch_5.pth', 'metadata.yaml', 'config.yaml', 'learner_checkpoint_epoch_11.pth']\n",
      "['SSL', 'experiment_index.json']\n",
      "experiment_dir and base_dir\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAG1CAYAAAAfhDVuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWUElEQVR4nO3dd3hUBb7G8e+k90ASEhISQgm9944UBSxUFVAsWBB3KSriquu6u7qu2NbesKEoCCioKFhAIfQW6T2hBUgISUgndc79I5BrpCUhyZmZvJ/nmefezJyZeQfPZt78TrMYhmEgIiIi4qCczA4gIiIiUpVUdkRERMShqeyIiIiIQ1PZEREREYemsiMiIiIOTWVHREREHJrKjoiIiDg0lR0RERFxaC5mB7AFVquVkydP4uvri8ViMTuOiIiIlIFhGGRmZhIWFoaT06XnNyo7wMmTJ4mIiDA7hoiIiFRAfHw84eHhl3xcZQfw9fUFiv+x/Pz8TE4jIiIiZZGRkUFERETJ9/ilqOxAyaYrPz8/lR0RERE7c6VdULSDsoiIiDg0lR0RERFxaNqMJSIiUkFWq5X8/HyzYzgsV1dXnJ2dr/p1VHZEREQqID8/n8OHD2O1Ws2O4tBq1apF3bp1r+rUMCo7IiIi5WQYBgkJCTg7OxMREXHZc7xIxRiGQU5ODklJSQCEhoZW+LVUdkRERMqpsLCQnJwcwsLC8PLyMjuOw/L09AQgKSmJ4ODgCm/SUhUVEREpp6KiIgDc3NxMTuL4zpfJgoKCCr+Gyo6IiEgF6RJDVa8y/o21GUtEHJe1CI6ug6xT4BMCkT3B6eqP7BAR+6KyIyKOac9i+OlxyDj5//f5hcGQF6HlMPNyiUi102YsEXE8exbDgrtKFx2AjITi+/csNieXyJ9Zi+Dwatj5dfH/tRaZneiyGjRowOuvv17ys8Vi4dtvvzUtT1lpsiMijsVaVDzRwbjIgwZggZ+egOY3apOWmEvTx2qjyY6IOJaj6y6c6JRiQMaJ4uVEzKLpY7VS2RERx5J1qkyL7T5wgOy8wioOI3IRV5w+Ujx9rORNWjNnzqRevXoXnPF52LBh3H333cTFxTF8+HBCQkLw8fGhS5cuLF++vFzvceLECcaMGUPt2rUJDAxk+PDhHDlyBIBVq1bh6upKYmJiqec8+uij9O3b96o+25Wo7IiIY/EJKdNi/4lOpd0zv3DLe+t4ddkBNh5KIb9Qp/2XamDS9PHWW28lOTmZFStWlNx35swZfv75Z8aNG0dWVhY33HADy5cvZ+vWrQwePJihQ4dy7NixMr1+Tk4O/fv3x8fHh1WrVrFmzRp8fHwYMmQI+fn59O3bl0aNGvH555+XPKewsJAvvviCe+65p1I/659pnx0RcShJtTtisQQSaE3B6SKn5zCwkO5ahwTP9hSeyWfL0TNsOXqGN389iKerM10bBtArKpCejYNoGeqH08VeRORqlHH6WOblyiggIIAhQ4Ywd+5cBg4cCMBXX31FQEAAAwcOxNnZmXbt2pUs/9xzz/HNN9+wePFiJk+efMXXnzdvHk5OTnz00Ucl58aZNWsWtWrVYuXKlQwaNIj77ruPWbNm8dhjjwGwZMkScnJyGD16dKV+1j9T2RERh3H8TA53fLSJZnl38r7b6xhYsJTaVGDBAtQa+T+iW15HfGoOa2OTWRuXwvq4ZJKz8ok+cJroA6cBqO3lSo/GxcWnV1QQDQK9dBI5uXplnD6WeblyGDduHA888ADvvvsu7u7uzJkzh7Fjx+Ls7Ex2djbPPPMMP/zwAydPnqSwsJCzZ8+WebITExNDbGwsvr6+pe7Pzc0lLi4OgPHjx/OPf/yDDRs20L17dz755BNGjx6Nt7d3pX/WP1LZERGHEHc6izs+2khCei5FAdeQfE1r6qz950WOdHmh5EiXiAAvxnatz9iu9TEMg/2nMlkbm8La2GQ2HkrhTE4BS3cmsnRn8T4GYf4e9IwKoldUIL0aBxHs52HGRxV7F9mzeF3MSODi++1Yih+P7Fnpbz106FCsVitLliyhS5curF69mldffRWAxx57jJ9//plXXnmFqKgoPD09ueWWW8jPzy/Ta1utVjp16sScOXMueKxOnToABAcHM3ToUGbNmkWjRo1YunQpK1eurLTPdykqOyJi9/aczODOjzeSkp1P4zrezLm/O3X8PaDLqDKfQdlisdC8rh/N6/pxX++GFBRZ2XE8raT8bD2Wxsn0XL6OOc7XMccBaBLsQ6+oIHo2DqR740D8PFyr82OLvXJyLj68fMFdgAX+NH0Eikt5FZwawdPTk1GjRjFnzhxiY2Np2rQpnTp1AmD16tWMHz+ekSNHApCVlVWyc3FZdOzYkfnz5xMcHIyfn98ll7v//vsZO3Ys4eHhNG7cmF69el3VZyoLlR0RsWsxR89wz6xNZOQW0irMj9n3diXQx734QSdnaNinQq/r6uxEp8gAOkUGMHVgE87mF7H5SCpr45JZF5vCrpPpHEzK4mBSFp+uO4KTBdqE16JX40B6RQXRKbI2Hq46j49cQsthMHr2Jc6z80KVnmdn3LhxDB06lN27d3PHHXeU3B8VFcWiRYsYOnQoFouFp59++oIjt670ui+//DLDhw/n2WefJTw8nGPHjrFo0SIee+wxwsPDARg8eDD+/v4899xzPPvss5X++S5GZUdE7Na62GTun72FnPwiOkfW5uPxXfD3rJrpiqebM32b1qFv0+JxfFpOPuvjUkrKz6HkbLbHp7E9Po13V8bh5uJE58ja9Ioq3t+nTT1/nLWzs/xRy2HFJ7es5uu3DRgwgICAAPbv38/tt99ecv9rr73GvffeS8+ePQkKCuLxxx8nIyOjzK/r5eXFqlWrePzxxxk1ahSZmZnUq1ePgQMHlpr0ODk5MX78eJ5//nnuuuuuSv1sl2IxDONiGwxrlIyMDPz9/UlPT7/s6E1EbMfyPaf469zfyS+00qdJEDPv7ISXm3l/vyWkn2VtbArrYpNZG5fMqYy8Uo/7erjQvVFgyeQnKthHOzvbsdzcXA4fPkzDhg3x8NC+W+U1YcIETp06xeLFVz554uX+rcv6/W3qZGfGjBksWrSIffv24enpSc+ePXnxxRdp1qxZyTKX+mXw0ksvlRy6lpeXx/Tp0/nyyy85e/YsAwcO5N133y0ZmYmIY1m8/STT5m+j0GowqGUIb93eAXcXczcZhfp7ckuncG7pFI5hGMSdzmZdXDJrDiaz4VAKGbmFLNtzimV7ig8nDvZ1p2fjwHM7PAdRr5anqflFqkN6ejqbN29mzpw5fPfdd9X2vqZOdoYMGcLYsWPp0qULhYWFPPXUU+zcuZM9e/aUHIb25zMt/vjjj9x3333ExsbSqFEjAP7yl7/w/fff8+mnnxIYGMijjz5KamoqMTExODtf+RegJjsi9uPLTcf4+zc7MQwY2aEeL9/SFhdn2z4/apHVYNeJ9JJNXpuPpJL3pxMYNgzypue5qU+PRoHU9nYzKa2UhSY7FdOvXz82bdrExIkTee2118r0nMqY7NjUZqzTp08THBxMdHT0JU8dPWLECDIzM/n111+B4pZYp04dPv/8c8aMGQPAyZMniYiIYOnSpQwePPiK76uyI2IfPlp9iOeW7AVgXLf6/Gd4a7s86V9uQRG/HzvDutgU1sQms+N4GtY//Ca2WKBlqF/JkV5dGwaYuolOLqSyU33sfjPWn6WnpwPFZ3m8mFOnTrFkyRI+++yzkvtiYmIoKChg0KBBJfeFhYXRunVr1q1bd9Gyk5eXR17e/29PL88OWCJS/QzD4I1fD/L68oMATLymEU8MaW63+7x4uDrTs3EQPRsHMX1wMzJyC9h4KJW1scmsi0vmwKksdp/MYPfJDD5YdQhXZwsdIs7v7BxIu4hauNr4NEvElthM2TEMg2nTptG7d29at2590WU+++wzfH19GTVqVMl9iYmJuLm5Ubt27VLLhoSEXLAJ7LwZM2bwzDPPVF54EakyhmHw3yV7+WjNYQAeG9yMv/ZrbLdF52L8PFy5rmUI17UsPmNuUmZu8ZFescmsjU3hRNpZNh1JZdORVF5bDt5u5y9rUVyYmtf1tcsJlyOwoY0jDqsy/o1tpuxMnjyZHTt2sGbNmksu88knnzBu3LgyjQwNw7jkL8Mnn3ySadOmlfyckZFBRERE+UOLSJUqsho89c1O5m2OB+DfQ1syvldDk1NVvWBfD4a3r8fw9vUwDINjqTklJzdcF5fMmZwCVuw/zYr9xZe1CPB2o0fj4rM6944Kon6gl8mfwPGd3x80Pz8fT0/tXF6VcnJyAHB1rfhpJWyi7EyZMoXFixezatWqSx5BtXr1avbv38/8+fNL3V+3bl3y8/M5c+ZMqelOUlISPXte/FTb7u7uuLu7V94HEJFKV1Bk5ZH52/hhRwJOFnjh5raM7lzz/iixWCxEBnoTGejN7d3qY7Ua7E3MYF1s8Tl+Nh1OJTU7nyU7EliyIwGA8Nqe9GocRM9zFzSt46vfd5XNxcUFLy8vTp8+jaurK05O2qxY2QzDICcnh6SkJGrVqlWmA44uxdQdlA3DYMqUKXzzzTesXLmSJk2aXHLZ8ePHs2vXLrZs2VLq/vM7KH/xxRclV01NSEggPDxcOyiL2KncgiImzfmdX/cl4eps4fUxHbixbajZsWxSfqGV7cfTzm3yKr6sRaG19K/1ZiG+9Dx3Pa9ujQLw1WUtKkV+fj6HDx8u11mGpfxq1apF3bp1L7q1xi6OxvrrX//K3Llz+e6770qdW8ff37/UWDAjI4PQ0FD+97//8eCDD17wOn/5y1/44Ycf+PTTTwkICGD69OmkpKTo0HMRO5SdV8iE2VtYF5eCu4sT79/Zif7Ngs2OZTey8wrZdCS1+OSGsSnsSSh9AIazk4W24f70Oncl946RtUw/R5E9s1qtZb5QppSfq6vrZb/H7aLsXGqfmlmzZjF+/PiSnz/44AMefvhhEhIS8Pf3v2D53NxcHnvsMebOnVvqpIJl3Q9HZUfENqTnFDD+001sPZaGj7sLH93dme6NAs2OZddSs/94WYtkjqTklHrcw9WJLg0C6Nm4+EivVmG6rIXYD7soO7ZCZUfEfKcz87jz443sS8yklpcrn93TlXYRtcyO5XCOn8kp2d9nbWwKyVmlL2vh7+lK90b/f6RX4zreDnXkmzgWlZ1yUNkRMdeJtLPc+dFGDiVnE+Tjzpz7u9Gsrq/ZsRyeYRgcTMoqOcR946EUMvMKSy1T18/jD5e1CCTUX0ceie1Q2SkHlR0R8xxJzmbcRxs5kXaWerU8+eL+bjQM8jY7Vo1UWGRl54l01sWlsOZgMjHHzpD/p8taNKrjfW5/n0B6NArC30s7O4t5VHbKQWVHxBz7EzO54+ONnM7Mo1GQN1/c340wXRDTZuQWFLHlyJmS/X12nki/4LIWrcP8S4706tIgAE837ews1UdlpxxUdkSq3/b4NO6etYm0nAJahPox+96uOh+MjUs/W8CGQynFR3rFpRCblFXqcTdnJzpG1jp3jp8g2oX72/xFWsW+qeyUg8qOSPXacCiF+z7dTHZ+ER3q1+LT8V21OcQOJabnsu7cjs7r4pJJSM8t9biPuwvdGgaU7O/TLMRXOztLpVLZKQeVHZHqs2JfEg9+EUNeoZWejQP58K7OeLvbxMnc5SoYhsHh5GzWxhVPftYfSiEtp6DUMkE+bvRoHETvc2d2jgjQZS3k6qjslIPKjkj1WLIjgYfnb6WgyGBg82DeGdcRD1ft4+GIiqwGe05mnDvEPZnNR1LJLSi9s3P9AC96nSs+PRsHEuijzZhSPio75aCyI1L1FmyJ54mFO7AaMLRdGK+Oboer9ueoMfIKi9h6LK1kf59t8WkU/emyFs3r+tLr3Cavrg0D8dHET65AZaccVHZEqtastYd55vs9AIztEsF/R7bRWXpruKy8QjYdTim5mvu+xMxSj7s4WWgfUYueUcVXcu/SoLb295ELqOyUg8qOSNUwDIN3VsTyyi8HALi/d0OeurGFvrTkAslZeayLO3+kVzLxqWdLPX5zx3BeubWt1h0pRWWnHFR2RCqfYRi88OM+Zq46BMDD1zbhoYFN9GUlZRKfmlN8Zue4FJbuTKDIavDq6HaM6hhudjSxIWX9/tYGcxGpdFarwT++3VVSdP5xYwsevrapio6UWUSAF2O71uet2zrw8MAmADz97S6OpmSbnEzskcqOiFSqwiIrj361nTkbj2GxwIxRbbi/TyOzY4kd+2v/KLo2CCA7v4ip87ZRUGS98pNE/kBlR0QqTV5hEX+d8zvfbD2Bi5OFN8Z24Lau9c2OJXbO2cnCa2Pb4+fhwvb4NF5ffsDsSGJnVHZEpFLk5Bdy/2db+GXPKdxcnJh5ZyeGtQszO5Y4iHq1PHnh5rYAvLsyjvVxKSYnEnuisiMiVy39bAF3fryJ1QeT8XJz5tPxXRjYIsTsWOJgbmgTypjOERgGPDJ/G2k5+WZHEjuhsiMiVyUlK4/bP9xAzNEz+Hm48MX93egZFWR2LHFQ/xzakkZB3iRm5PLEwp3ogGIpC5UdEamwxPRcRs9cz+6TGQT5uDHvgR50rF/b7FjiwLzdXXhjbAdcnS38tDuReZvjzY4kdkBlR0Qq5FhKDrfOXEfc6WxC/T2YP7EHLcN0niqpem3C/XlscDMAnvl+N7FJWSYnElunsiMi5XbwVCa3vL+O+NSzRAZ68dWDPWhcx8fsWFKD3N+7Eb2jgsgtsDL1y63kFRaZHUlsmMqOiJTLzuPpjJ65nqTMPJqF+PLVxB6E1/YyO5bUME5OFl4d3Y4Abzf2JGTw8k/7zY4kNkxlR0TKbPORVG7/cANncgpoF+7PvAe6E+znYXYsqaGC/Tx46dzh6B+tOUz0gdMmJxJbpbIjImWy6sBp7vx4I5l5hXRtGMAX93ejtreb2bGkhru2ZQh39YgE4NEF20nOyjM5kdgilR0RuaKfdiVy/2dbyC2w0q9ZHT67pyu+Hq5mxxIB4O83tKBpiA/JWXk89tV2HY4uF1DZEZHLWvT7cSbN/Z38Iis3tKnLB3d2xtPN2exYIiU8XJ1587YOuLk4sWL/aT5bd8TsSGJjVHZE5JI+X3+EaQu2U2Q1uKVTOG+OLf5CEbE1zev68dQNLQB4/sd97E3IMDmR2BL91hKRi3pvZRxPf7cbgPE9G/DSzW1xcdavDLFdd/WIZEDzYPILiw9Hzy3Q4ehSTL+5RKQUwzB4+ed9vPjTPgCmDIjiX0Nb4uRkMTmZyOVZLBZevqUtdXzdOZiUxX+X7DU7ktgIlR0RKWG1Gvx78W7eWREHwBPXN+fRQc2wWFR0xD4E+rjzv1vbAfD5hqMs23PK5ERiC1R2RASAwiIrj329g8/WH8VigedGtObBaxqbHUuk3Po2rcP9vRsC8Levt3MqI9fkRGI2lR0RIa+wiClfbmXh78dxPndm2ju6R5odS6TCHhvSjJahfpzJKWDagm1YrTocvSZT2RGp4c7mF/HA7Bh+3JWIm7MT747ryMgO4WbHErkq7i7Fh6N7uDqxNjaFD1cfMjuSmEhlR6QGy8wt4O5PNhF94DSers58PL4zg1vVNTuWSKWICvbhX0NbAfDyz/vZcTzN3EBiGpUdkRrqTHY+4z7ayKYjqfi6u/D5fV3p06SO2bFEKtXYLhEMaVWXQqvBQ/O2kZ1XaHYkMYHKjkgNlJSRy5gP1rPjeDoB3m58+UB3OjcIMDuWSKWzWCy8cHMb6vp5cDg5m2e/32N2JDGByo5IDROfmsOtM9dz4FQWIX7uLJjYndb1/M2OJVJlanm58dqY9lgsMH9LPEt2JJgdSaqZyo5IDRKblMWt76/naEoOEQGefP1gT6KCfc2OJVLlejQO5K/9ik+l8OSiHZxIO2tyIqlOKjsiNcTuk+mMmbmexIxcooJ9+GpiTyICvMyOJVJtHr62Ke0iapGRW8gj87ZRpMPRawyVHZEaIOboGcZ+sIGU7Hxa1/NjwcQe1PX3MDuWSLVydXbizbHt8XZzZtORVN5dEWt2JKkmKjsiDm5tbDJ3fryRzNxCOkfWZu6E7gR4u5kdS8QUkYHe/GdEawBe//UgMUfPmJxIqoPKjogDW7bnFPfM2kxOfhF9mgQx+76u+Hm4mh1LxFQjO9RjePswiqwGD83bSkZugdmRpIqp7Ig4qO+2neDBL2LIL7IyuFUIH93dGS83F7NjiZjOYrHwnxGtCa/tyfEzZ/nnt7vMjiRVTGVHxAHN3XiMh+cX74A5qkM93rm9I+4uzmbHErEZfh6uvDG2A85OFr7ddpJvth43O5JUIZUdEQfz4apD/P2bnRgG3Nk9kldubYeLs/6nLvJnnSJr89DAJgA8/e1ujqZkm5xIqop+A4o4CMMweHXZAf67dC8AD17TmGeHt8LJyWJyMhHbNal/FF0bBJCVV8hD87ZRUGQ1O5JUAZUdEQdgGAb/+WEvb/56EIDHBjfjieubY7Go6IhcjrOThdfGtsfXw4Vt8Wm8sfyg2ZGkCqjsiNi5IqvBEwt38snawwA8M6wVk/pHmZxKxH7Uq+XJjFFtAHhnZSwbDqWYnEgqm8qOiB3LL7Ty0LytzN8Sj5MFXrm1HXf3bGB2LBG7c1PbMEZ3Dscw4JH520jLyTc7klQilR0RO5VbUMSDX8Tww44EXJ0tvHN7R27pFG52LBG79a+hrWgY5E1Cei5PLNyJYehyEo5CZUfEDmXlFTJ+1iZ+25eEu4sTH97VmevbhJodS8Suebu78ObYDrg6W/hpdyLzN8ebHUkqicqOiJ1Jy8ln3Ecb2XAoFR93F2bf25V+zYLNjiXiENqE+zN9UDMAnvl+D7FJWSYnksqgsiNiR05n5jH2gw1sj0+jlpcrcyd0o1ujQLNjiTiUCX0a0SsqkLMFRTw0byt5hUVmR5KrpLIjYidOpJ1l9Mz17EvMpI6vO/Mf6EHb8FpmxxJxOE5OFl4d3Z7aXq7sPpnBKz/vNzuSXCWVHRE7cDg5m1vfW8fh5Gzq1fLkq4k9aFbX1+xYIg4rxM+Dl25pB8CHqw+z6sBpkxPJ1VDZEbFxexMyuPX99ZxMz6VRHW++/ksPGgR5mx1LxOFd1zKEO7tHAjBtwXaSs/JMTiQVpbIjYsO2HjvD2A82kJyVR4tQPxZM7EGov6fZsURqjKdubEGTYB+Ss/L429c7dDi6nVLZEbFR6+NSuOOjjaSfLaBj/VrMm9CdIB93s2OJ1Cgers68eVsH3Fyc+G1fErPXHzU7klSAyo6IDVqxL4nxszaRnV9Er6hAPr+vG/5ermbHEqmRWoT68ffrmwPw36V72ZeYYXIiKS+VHREb88OOk0yYvYW8QivXtgjh47u74O3uYnYskRrt7p4N6N+sDvmFVqZ+uZXcAh2Obk9UdkRsyILN8Uz9ciuFVoNh7cJ4746OeLg6mx1LpMazWCy8fGs7gnzcOXAqi+eX7jU7kpSDyo6Ijfh4zWH+tnAHVgNu6xrBa2Pa4+qs/4mK2IogH3f+N7r4cPTZ64+yfM8pkxNJWek3qYjJDMPgzV8P8p8f9gAwoU9Dnh/ZBmcni8nJROTPrmlah/t6NwTgbwt3kJSRa3IiKQuVHRETGYbBjB/38eqyAwBMu64pf7+hBRaLio6IrfrbkGa0CPUjNTufR7/ajtWqw9FtncqOiEmKrAZPfbuLD1YdAuDpm1oydWATFR0RG+fu4sxbt7XHw9WJ1QeT+XjNYbMjyRWo7IiYoKDIyrQF25i78RgWC7x4c5uS0biI2L6oYF/+eVMrAF76eR+7TqSbnEguR2VHpJrlFhTxly9+57ttJ3FxsvDm2A6M6VLf7FgiUk63dY1gcKsQCooMpn65lZz8QrMjySWo7IhUo+y8Qu77bDPL957CzcWJD+7qxNB2YWbHEpEKsFgsvDCqLXX9PDiUnM2z3+8xO5JcgsqOSDVJP1vAXZ9sYm1sCt5uznx6TxcGNA8xO5aIXIXa3m68OqYdFgvM2xzP0p0JZkeSi1DZEakGyVl53PbBBmKOnsHPw4Uv7u9Gz8ZBZscSkUrQs3EQf7mmMQBPLNzBybSzJieSP1PZEaliCelnGT1zPXsSMgjycWP+xB50qF/b7FgiUokeua4p7cL9ycgt5OH52yjS4eg2xdSyM2PGDLp06YKvry/BwcGMGDGC/fv3X7Dc3r17GTZsGP7+/vj6+tK9e3eOHTtW8ni/fv2wWCylbmPHjq3OjyJyUUdTsrnlvfUcOp1NmL8HCyb2oEWon9mxRKSSuTo78cbYDni7ObPpcCrvrYw1O5L8gallJzo6mkmTJrFhwwaWLVtGYWEhgwYNIjs7u2SZuLg4evfuTfPmzVm5ciXbt2/n6aefxsPDo9RrTZgwgYSEhJLbzJkzq/vjiJRy4FQmt76/nhNpZ2kQ6MVXf+lJozo+ZscSkSrSIMibZ4e3BuC15Qf5/dgZkxPJeRbDMGxm1nb69GmCg4OJjo6mb9++AIwdOxZXV1c+//zzSz6vX79+tG/fntdff71C75uRkYG/vz/p6en4+emvbrl6O4+nc9cnGzmTU0Dzur7Mvq8rwb4eV36iiNg1wzB4aN42Fm8/SUSAJ0un9sHXw9XsWA6rrN/fNrXPTnp68UmZAgICALBarSxZsoSmTZsyePBggoOD6datG99+++0Fz50zZw5BQUG0atWK6dOnk5mZecn3ycvLIyMjo9RNpLJsOpzKbR9u4ExOAe0iajHvge4qOiI1hMVi4bmRrQmv7Ul86ln++d1usyMJNlR2DMNg2rRp9O7dm9ati8eASUlJZGVl8cILLzBkyBB++eUXRo4cyahRo4iOji557rhx4/jyyy9ZuXIlTz/9NAsXLmTUqFGXfK8ZM2bg7+9fcouIiKjyzyc1w8r9Sdz1yUay8grp1jCAOfd3o5aXm9mxRKQa+Xm48sbY9jhZ4JutJ/hm63GzI9V4NrMZa9KkSSxZsoQ1a9YQHh4OwMmTJ6lXrx633XYbc+fOLVl22LBheHt78+WXX170tWJiYujcuTMxMTF07Njxgsfz8vLIy8sr+TkjI4OIiAhtxpKr8uPOBKbO20pBkUH/ZnV4745OeLg6mx1LREzyxvKDvLb8AD7uLiyd2of6gV5mR3I4drUZa8qUKSxevJgVK1aUFB2AoKAgXFxcaNmyZanlW7RoUeporD/r2LEjrq6uHDx48KKPu7u74+fnV+omcjW+jjnOpLm/U1BkcGObUGbe2VlFR6SGm9S/MV0a1CYrr/DcH0JWsyPVWKaWHcMwmDx5MosWLeK3336jYcPSF0J0c3OjS5cuFxyOfuDAASIjIy/5urt376agoIDQ0NAqyS3yR7PXH2H6V9uxGjC6czhv3tYBNxeb+DtCREzk4uzEa2Pa4+vhwrb4NN789eJ/gEvVczHzzSdNmsTcuXP57rvv8PX1JTExEQB/f388PT0BeOyxxxgzZgx9+/alf//+/PTTT3z//fesXLkSKD40fc6cOdxwww0EBQWxZ88eHn30UTp06ECvXr3M+mhSQ7yzIpaXfy4u4/f0asDTN7bEyclicioRsRXhtb2YMaoNk+du5e0VsfSKCqJ7o0CzY9U4pu6zY7Fc/Eth1qxZjB8/vuTnTz75hBkzZnD8+HGaNWvGM888w/DhwwGIj4/njjvuYNeuXWRlZREREcGNN97Iv/71r5Kjuq5Eh55LeRmGwUs/7+e9lXEATB0QxSPXNb3kOi0iNdtjX23nq5jjhPp78NNDffH30uHolaGs3982s4OymVR2pDysVoN/Ld7N5xuOAvDk9c2ZeO66OCIiF5OdV8hNb63hcHI2N7Spyzu3d9QfR5XArnZQFrEXhUVWpn+9nc83HMVigf+ObK2iIyJX5O3uwhtj2+PiZGHpzkQWbIk3O1KNorIjUkZ5hUVMnruVRb+fwNnJwutj2jOu26V3lBcR+aO24bWYPrgZAP9evIe401kmJ6o5VHZEyuBsfhETZsfw0+5E3JydeG9cR4a3r2d2LBGxMw/0aUTPxoGcLShi6pdbySssMjtSjaCyI3IFGbkF3PXJRlYdOI2nqzOfjO/CoFZ1zY4lInbIycnCq6PbU9vLld0nM/jfLwfMjlQjqOyIXEZqdj63f7iBzUfO4Ovhwhf3d6V3kyCzY4mIHavr78GLN7cF4INVh1h98LTJiRyfyo7IJRiGwQOzt7DrRAYB3m58OaE7nSLLdjoDEZHLGdSqLnd0rw/AtAXbScnKu8Iz5Gqo7IhcwsoDp9ly9Ayers4smNid1vX8zY4kIg7kqRta0iTYh9OZefzt6x3oTDBVR2VH5CIMwyg5tfudPSKJCvY1OZGIOBpPN+eSy8v8ui+p5NxdUvlUdkQuYm1sCluPpeHu4sSEPo3MjiMiDqpFqB9PXt8cgOeW7GV/YqbJiRyTyo7InxiGwRu/Fh8hcXu3+tTxdTc5kYg4svE9G9CvWR3yC61M/XIruQU6HL2yqeyI/MmGQ6lsPnIGNxcnHtTZkUWkilksFl65tR1BPu7sP5XJCz/uMzuSw1HZEfmT8/vqjO0SQYifh8lpRKQmCPJx55Vbiw9H/3TdEX7bd8rkRI5FZUfkDzYfSWX9oRRcnS2a6ohIterXLJj7ejcEYPpXO0jKyDU5keNQ2RH5g/NTnVs6RRBWy9PkNCJS0/xtSDNahPqRmp3Po19tx2rV4eiVQWVH5Jzfj51h9cFkXJws/LWfpjoiUv3cXZx5c2x7PFydWH0wmU/WHjY7kkNQ2RE5561zU51RHesREeBlchoRqamahPjy9E0tAXjxp33sOpFuciL7p7IjAuw4nsaK/adxdrIwqX+U2XFEpIa7vWt9BrUMoaDIYOq8reTkF5odya6p7IgAb/0WC8Dw9mFEBnqbnEZEajqLxcKLN7clxM+dQ6ez+c8Pe8yOZNdUdqTG230ynWV7TmGxoKmOiNiM2t5uvDa6PRYLfLkpnh93JpgdyW6p7EiN9/a5qc7QtmE0ruNjchoRkf/XMyqo5DQYTyzaycm0syYnsk8qO1Kj7U/M5MddiVgsMHmApjoiYnumXdeUduH+pJ8t4JH52yjS4ejlprIjNdpbvxUfgXVD61CahujK5iJie1ydnXhjbAe83JzZeDiV96PjzI5kd1R2pMaKTcpiyblt4JrqiIgtaxDkzbPDWwPw6rIDbD12xuRE9kVlR2qsd1bEYhgwqGUILUL9zI4jInJZN3esx9B2YRRZDR6at43M3AKzI9kNlR2pkQ4nZ/PdthMATB3YxOQ0IiJXZrFYeG5Ea+rV8uRYag7/+m632ZHshsqO1EjvrIjFasDA5sG0rudvdhwRkTLx93TljbHtcbLAoq0n+HbrCbMj2QWVHalx4lNz+ObcL4gpmuqIiJ3p3CCgZCL9j293cSwlx+REtk9lR2qcd1fGUmQ16Nu0Du0japkdR0Sk3Cb3j6JzZG2y8gp5aP5WCousZkeyaSo7UqMcP5PD1zHHAXhooI7AEhH75OLsxOtj2+Pr4cLWY2m8ee5CxnJxKjtSo7wfHUdBkUGvqEA6RQaYHUdEpMLCa3vx35FtAHh7RSwbD6WYnMh2qexIjZGYnsuCzcVTnakDtK+OiNi/Ye3CuKVTOFYDHpm/jfQcHY5+MSo7UmO8Hx1HfpGVbg0D6NYo0Ow4IiKV4t/DWtEg0IuT6bk8+c0ODEOXk/gzlR2pEZIycvly0zFA59UREcfi4+7CG2M74OJkYenORL7actzsSDZHZUdqhA9WHSKv0EqnyNr0bKypjog4lnYRtXh0UDMA/rV4N3Gns0xOZFtUdsThJWfl8cXGo0DxVMdisZicSESk8k3s24iejQM5W1DEQ/O2kl+ow9HPU9kRh/fR6sPkFlhpF1GLvk2CzI4jIlIlnJwsvDq6PbW8XNl1IoP//bLf7Eg2Q2VHHFpqdj6z1x8BYOqAKE11RMSh1fX34MWb2wIwc9Uh1hxMNjmRbVDZEYf2yZrD5OQX0SrMjwHNg82OIyJS5Qa3qsu4bvUBmLZgG6nZ+SYnMp/Kjjis9JwCPl13BNC+OiJSs/zjxpZEBfuQlJnH377W4egqO+KwPll7mKy8QprX9eW6FiFmxxERqTaebs68ObYDbs5OLN97ii82HjM7kqlUdsQhZeQWMGvtYaB4quPkpKmOiNQsLcP8eOL65gA898MeDpzKNDmReVR2xCHNXneEjNxCmgT7MKRVXbPjiIiY4p5eDejXrA55hVamfrmV3IIisyOZQmVHHE5WXiEfrSme6kweEKWpjojUWBaLhZdvaUeQjxv7EjN54cd9ZkcyhcqOOJzP1x8lLaeARkHe3NQ2zOw4IiKmquPrziu3tgPg03VH+G3fKZMTVT+VHXEoOfmFfLj6EFA81XHWVEdEhH7Ngrm3V0MAHvtqB0mZuSYnql4qO+JQ5m48Rmp2PpGBXgxrp6mOiMh5j1/fjBahfqRk5/Pogu1YrTXncHSVHXEYuQVFvB9dPNWZ1C8KF2et3iIi57m7OPPm2Pa4uzix+mAyn5w7YrUm0LeBOIwvNx0jOSuPerU8GdmxntlxRERsTpMQX56+qSUAL/60j10n0k1OVD1UdsQhFE914gCY1D8KV011REQualy3+lzXMoSCIoOH5m0lJ7/Q7EhVTt8I4hC+ijnOqYw8wvw9uLmTpjoiIpdisVh48ea2hPi5E3c6m//8sNfsSFVOZUfsXn6hlfdWxALwYL/GuLs4m5xIRMS2BXi78ero9lgsxbsA/LQrwexIVUplR+zewt+PczI9l2Bfd0Z3jjA7joiIXegVFcTEvo0BeHzhThLSz5qcqOqo7IhdKyiy8s75qc41jfFw1VRHRKSspl3XlLbh/qSfLeCR+dsoctDD0VV2xK59s/UEx8+cJcjHndu61jc7joiIXXFzceKNsR3wcnNmw6HUkgM9HI3KjtitwiIr756b6kzs2whPN011RETKq2GQN88MawXAq8sOsPXYGZMTVT6VHbFb3+84yZGUHAK83RjXXVMdEZGKuqVTODe1DaXIavDQvG1k5TnW4egVKjvx8fEcP3685OdNmzbx8MMP88EHH1RaMJHLKbIavPVb8VTn/j4N8XJzMTmRiIj9slgs/HdkG+rV8uRYag7//G6X2ZEqVYXKzu23386KFSsASExM5LrrrmPTpk38/e9/59lnn63UgCIXs2RnAodOZ1PLy5W7ejQwO46IiN3z93Tl9bHtcbLAot9P8N22E2ZHqjQVKju7du2ia9euACxYsIDWrVuzbt065s6dy6efflqZ+UQuYLUavP3bQQDu69UQH3dNdUREKkOXBgFMGdAEgH98s4v41ByTE1WOCpWdgoIC3N3dAVi+fDnDhg0DoHnz5iQkOPaJicR8P+9O5MCpLHw9XLi7VwOz44iIOJQpA6LoFFmbzLxCHpq3lcIiq9mRrlqFyk6rVq14//33Wb16NcuWLWPIkCEAnDx5ksDAwEoNKPJHVqvBG78WT3Xu6dUQPw9XkxOJiDgWF2cnXh/THl93F34/lsab5/aPtGcVKjsvvvgiM2fOpF+/ftx22220a9cOgMWLF5ds3hKpCsv3nmJfYiY+7i7cq6mOiEiViAjw4r+j2gDw9m8H2XQ41eREV6dCOzv069eP5ORkMjIyqF27dsn9DzzwAF5eXpUWTuSPDMPgzXP76tzdM5JaXm4mJxIRcVzD2oURvf80C38/zsPztvLjQ33x97LPaXqFJjtnz54lLy+vpOgcPXqU119/nf379xMcHFypAUXOW7n/NLtOZODl5sx9vRuZHUdExOE9M7wVkYFenEzP5e/f7sQw7PNyEhUqO8OHD2f27NkApKWl0a1bN/73v/8xYsQI3nvvvUoNKALFU53z++rc2T2SAG9NdUREqpqPuwtvjO2Ai5OFJTsS+Crm+JWfZIMqVHZ+//13+vTpA8DXX39NSEgIR48eZfbs2bz55puVGlAEYPXBZLbFp+Hh6sT9fTTVERGpLu0jajFtUFMA/r14N4dOZ5mcqPwqVHZycnLw9fUF4JdffmHUqFE4OTnRvXt3jh49WqkBRf441RnXLZI6vu4mJxIRqVkm9m1Mj0aB5OQX8dC8beQX2tfh6BUqO1FRUXz77bfEx8fz888/M2jQIACSkpLw8/Or1IAi6+NSiDl6BjcXJyb21VRHRKS6OTtZeHVMO2p5ubLzRDqvLjtgdqRyqVDZ+ec//8n06dNp0KABXbt2pUePHkDxlKdDhw6VGlDk/BFYt3etT7Cfh8lpRERqplB/T14Y1RaAmaviWBubbHKisqtQ2bnllls4duwYW7Zs4eeffy65f+DAgbz22muVFk5k46EUNhxKxc3ZiYnXaKojImKmIa3rcnu3+hgGTFuwjdTsfLMjlUmFyg5A3bp16dChAydPnuTEieKLhXXt2pXmzZtXWjiR81c2v7VzOKH+nianERGRp29sSeM63pzKyOPxhTvs4nD0CpUdq9XKs88+i7+/P5GRkdSvX59atWrxn//8B6u17DstzZgxgy5duuDr60twcDAjRoxg//79Fyy3d+9ehg0bhr+/P76+vnTv3p1jx46VPJ6Xl8eUKVMICgrC29ubYcOGcfy4fR4eJ/8v5ugZ1sQm4+Jk4S/9GpsdR0REAE83Z968rQNuzk4s23OKORuPXflJJqtQ2Xnqqad4++23eeGFF9i6dSu///47zz//PG+99RZPP/10mV8nOjqaSZMmsWHDBpYtW0ZhYSGDBg0iOzu7ZJm4uDh69+5N8+bNWblyJdu3b+fpp5/Gw+P/9914+OGH+eabb5g3bx5r1qwhKyuLm266iaKioop8PLERb53bV+eWTuGE19aZuUVEbEWrMH8ev754S85/ftjDwVOZJie6PItRgflTWFgY77//fsnVzs/77rvv+Otf/1qyWau8Tp8+TXBwMNHR0fTt2xeAsWPH4urqyueff37R56Snp1OnTh0+//xzxowZAxRfkDQiIoKlS5cyePDgK75vRkYG/v7+pKen62gyG7E9Po3h76zF2cnCikf7UT9QZUdExJZYrQb3fLqZ6AOnaV7Xl28n9cLD1blaM5T1+7tCk53U1NSL7pvTvHlzUlMrfrGw9PR0AAICAoDizWVLliyhadOmDB48mODgYLp168a3335b8pyYmBgKCgpKDn+H4jLWunVr1q1bd9H3ycvLIyMjo9RNbMv5qc6I9vVUdEREbJCTk4VXbm1HkI8b+xIzefGnfWZHuqQKlZ127drx9ttvX3D/22+/Tdu2bSsUxDAMpk2bRu/evWndujVQfN6erKwsXnjhBYYMGcIvv/zCyJEjGTVqFNHR0QAkJibi5uZW6oKkACEhISQmJl70vWbMmIG/v3/JLSIiokKZpWrsOpHO8r1JOFlgUn/tqyMiYqvq+Lrz8i3tAJi19ggr9iWZnOjiKnTV85deeokbb7yR5cuX06NHDywWC+vWrSM+Pp6lS5dWKMjkyZPZsWMHa9asKbnv/M7Ow4cP55FHHgGgffv2rFu3jvfff59rrrnmkq9nGAYWi+Wijz355JNMmzat5OeMjAwVHhtyfqozrF0Yjer4mJxGREQup3/zYO7p1YBZa4/w2Nfb+fGhvjZ3pvsKTXauueYaDhw4wMiRI0lLSyM1NZVRo0axe/duZs2aVe7XmzJlCosXL2bFihWEh4eX3B8UFISLiwstW7YstXyLFi1KjsaqW7cu+fn5nDlzptQySUlJhISEXPT93N3d8fPzK3UT27AvMYOfd5/CYoHJA6LMjiMiImXw+JDmNK/rS3JWPtO/2o7ValuHo1f4PDthYWH897//ZeHChSxatIjnnnuOM2fO8Nlnn5X5NQzDYPLkySxatIjffvuNhg0blnrczc2NLl26XHA4+oEDB4iMjASgU6dOuLq6smzZspLHExIS2LVrFz179qzoxxOTnD+vzg1tQokK9jU5jYiIlIWHqzNv3dYBdxcnog+cZta6I2ZHKqVCm7Eqy6RJk5g7dy7fffcdvr6+JfvY+Pv74+lZfAK5xx57jDFjxtC3b1/69+/PTz/9xPfff8/KlStLlr3vvvt49NFHCQwMJCAggOnTp9OmTRuuvfZasz6aVMDBU5ks3ZkAwBRNdURE7EqTEF/+cVNLnv52Fy/+uI/ujQJoFeZvdizgKiY7leG9994jPT2dfv36ERoaWnKbP39+yTIjR47k/fff56WXXqJNmzZ89NFHLFy4kN69e5cs89prrzFixAhGjx5Nr1698PLy4vvvv8fZuXoPgZOr8/aKWAwDhrSqS/O62rQoImJv7uhWn2tbhJBfZGXql1s5m28b57ur0Hl2LmX79u107NjR7k7mp/PsmO/Q6SyufTUaqwFLpva2mb8GRESkfFKz8xny+iqSMvO4vVt9nh/Zpsreq6zf3+XajDVq1KjLPp6WllaelxMp8c6KOKwGXNsiREVHRMSOBXi78dqY9tzx8UbmbjxG3yZ1GNK6rqmZylV2/P0v/yXk7+/PXXfddVWBpOY5mpLNt9uKz7o9daD21RERsXe9ooJ4oG8jZkYf4olFO2gX4W/qxZzLVXYqcli5yJW8uyKOIqtBv2Z1aBtey+w4IiJSCR69rhnrYlPYeSKdafO388X93XB2uvj576qaqTsoi8Sn5rDw9+Ir1E8Z0MTkNCIiUlncXJx4Y2x7vNycWX8ohfej40zLorIjpno/Oo5Cq0GfJkF0iqx95SeIiIjdaFTHh38Pa0VEgCc9GgealsPU8+xIzXYy7SwLtsQDmuqIiDiqWzuFM7RtGJ5u5p0ORpMdMc3M6DgKigy6Nwqga8MAs+OIiEgVsFgsphYdUNkRk5zKyOXLzcVTnakDNdUREZGqo7IjppgZfYj8QitdGtSmRyPztuOKiIjjU9mRanc6M4+5m44CxVMdi8WcQxFFRKRmUNmRavfR6kPkFlhpH1GL3lFBZscREREHp7Ij1SolK4/Z64unOg9pqiMiItVAZUeq1cdrDnO2oIg29fzp16yO2XFERKQGUNmRapOWk89n644A2ldHRESqj8qOVJtP1h4hO7+IFqF+XNsi2Ow4IiJSQ6jsSLVIP1vArLWHAZg6IEpTHRERqTYqO1ItPlt3hMzcQpqG+DC4VV2z44iISA2isiNVLjO3gI/XFE91pgxogpOTpjoiIlJ9VHakyn2+4SjpZwtoXMebG9qEmh1HRERqGJUdqVLZeYV8tLp4qjN5QBTOmuqIiEg1U9mRKjVn41FSs/NpEOjF0LZhZscREZEaSGVHqszZ/CI+WHUIgEn9o3Bx1uomIiLVT98+UmXmbjpGclY+EQGejOhQz+w4IiJSQ6nsSJXILShiZnQcAJP6ReGqqY6IiJhE30BSJRZsiScpM496tTwZ1THc7DgiIlKDqexIpcsrLOK9lcVTnQf7NcbNRauZiIiYR99CUum+jjlOQnoudf08GN1ZUx0RETGXyo5UqoIiK++uODfVuaYR7i7OJicSEZGaTmVHKtU3v5/gRNpZ6vi6M7ZrfbPjiIiIqOxI5SkssvL2ilgAJvZthIerpjoiImI+lR2pNN9tO8mx1BwCvd24vZumOiIiYhtUdqRSFFkN3jk31ZnQtxFebi4mJxIRESmmsiOV4ocdJzmUnE1tL1fu7B5pdhwREZESKjty1axWg7d+K57q3Ne7Id7umuqIiIjtUNmRq/bjrkRik7Lw83Dhrp4NzI4jIiJSisqOXJXiqc5BAO7t3RA/D1eTE4mIiJSmsiNX5Zc9p9iXmImvuwv39GxodhwREZELqOxIhRnG/091xvdqgL+XpjoiImJ7VHakwn7bl8Tukxl4uzlzby9NdURExDap7EiFGIbBm78WT3Xu7NGA2t5uJicSERG5OJUdqZDoA6fZfjwdT1dn7u+jqY6IiNgulR0ptz9Ode7oXp8gH3eTE4mIiFyayo6U27q4FH4/loa7ixMT+jYyO46IiMhlqexIub1xbqpzW9f6BPt6mJxGRETk8lR2pFw2HEph0+FU3JydePCaxmbHERERuSKVHSmX8/vqjOkSQV1/TXVERMT2qexImW05ksq6uBRcnS082E9THRERsQ8qO1Jmb567svktncKpV8vT5DQiIiJlo7IjZbL12BlWHTiNs5OFv/aLMjuOiIhImansSJm8dW6qM6pDPSICvExOIyIiUnYqO3JFO4+n89u+JJwsMKm/pjoiImJfVHbkis5f2XxE+3o0CPI2OY2IiEj5qOzIZe05mcEve05hscBfNdURERE7pLIjl/X2iuKpzk1tw4gK9jE5jYiISPmp7MglHTiVydKdiQBMGaCpjoiI2CeVHbmkt88dgXVDm7o0DfE1OY2IiEjFqOzIRcUmZfH9jpMATO7fxOQ0IiIiFaeyIxf17opYDAOuaxlCyzA/s+OIiIhUmMqOXOBIcjbfbjsBwNQBmuqIiIh9U9mRC7yzIharAQOaB9Mm3N/sOCIiIldFZUdKiU/N4ZutxVMdHYElIiKOQGVHSnl3ZRyFVoM+TYLoUL+22XFERESumsqOlDiRdpavY+IBeGig9tURERHHoLIjJd5fGUdBkUHPxoF0bhBgdhwREZFKobIjACSm5zJ/c/FUZ6qmOiIi4kBUdgSAmaviyC+y0rVhAN0bBZodR0REpNKo7AhJmbnM3XgM0Hl1RETE8ajsCB+uOkReoZWO9WvRK0pTHRERcSwqOzVcSlYeX2w4N9UZ2ASLxWJyIhERkcqlslPDfbTmMGcLimgX7s81TeuYHUdERKTSqezUYGey85m97ggAUwZoqiMiIo7J1LIzY8YMunTpgq+vL8HBwYwYMYL9+/eXWmb8+PFYLJZSt+7du5dapl+/fhcsM3bs2Or8KHbpk7WHyc4vomWoHwNbBJsdR0REpEqYWnaio6OZNGkSGzZsYNmyZRQWFjJo0CCys7NLLTdkyBASEhJKbkuXLr3gtSZMmFBqmZkzZ1bXx7BL6TkFfLr2CKB9dURExLG5mPnmP/30U6mfZ82aRXBwMDExMfTt27fkfnd3d+rWrXvZ1/Ly8rriMvL/Zq07TGZeIc3r+jKoZYjZcURERKqMTe2zk56eDkBAQOlLFaxcuZLg4GCaNm3KhAkTSEpKuuC5c+bMISgoiFatWjF9+nQyMzMv+T55eXlkZGSUutUkmbkFfLLmMFC8r46Tk6Y6IiLiuEyd7PyRYRhMmzaN3r1707p165L7r7/+em699VYiIyM5fPgwTz/9NAMGDCAmJgZ3d3cAxo0bR8OGDalbty67du3iySefZPv27Sxbtuyi7zVjxgyeeeaZavlctmj2+qNk5BYSFezD9a01DRMREcdmMQzDMDsEwKRJk1iyZAlr1qwhPDz8ksslJCQQGRnJvHnzGDVq1EWXiYmJoXPnzsTExNCxY8cLHs/LyyMvL6/k54yMDCIiIkhPT8fPz+/qP4wNy8orpPeLv5GWU8AbY9szvH09syOJiIhUSEZGBv7+/lf8/raJyc6UKVNYvHgxq1atumzRAQgNDSUyMpKDBw9ecpmOHTvi6urKwYMHL1p23N3dS6ZCNc0XG46SllNAoyBvbmobZnYcERGRKmdq2TEMgylTpvDNN9+wcuVKGjZseMXnpKSkEB8fT2ho6CWX2b17NwUFBZddpiY6m1/Eh6sOATCpfxTO2ldHRERqAFPLzqRJk5g7dy7fffcdvr6+JCYmAuDv74+npydZWVn8+9//5uabbyY0NJQjR47w97//naCgIEaOHAlAXFwcc+bM4YYbbiAoKIg9e/bw6KOP0qFDB3r16mXmx7M5czYeJSU7n/oBXgxvr6mOiIjUDKaWnffeew8oPingH82aNYvx48fj7OzMzp07mT17NmlpaYSGhtK/f3/mz5+Pr68vAG5ubvz666+88cYbZGVlERERwY033si//vUvnJ2dq/sj2azcgiJmlkx1GuPibFMH4omIiFQZ0zdjXY6npyc///zzZZeJiIggOjq6MmM5pHmbjnE6M496tTwZ2eHy+0WJiIg4Ev15XwPkFRbxfnTxVOev/Rvj5qL/7CIiUnPoW68G+GrLcRIzcgn19+CWTprqiIhIzaKy4+DyC628tzIOgAevaYy7i/ZjEhGRmkVlx8Et+v04J9LOEuzrzpguEWbHERERqXYqOw6soMjKOytjAZh4TWM8XDXVERGRmkdlx4F9u/UE8alnCfJx4/au9c2OIyIiYgqVHQdVWGTl3XP76jzQtxGebprqiIhIzaSy46B+2JHA4eRsanu5Mq5bpNlxRERETKOy44CKrAZv/VZ8odT7+zTC290mrvcqIiJiCpUdB7R0ZwJxp7Px93Tlrh6a6oiISM2msuNgrFaDt38rPgLrvt4N8fVwNTmRiIiIuVR2HMwvexLZfyoTXw8X7u7ZwOw4IiIiplPZcSCGYfDGr8VTnXt6NsDfU1MdERERlR0HsnxvEnsTMvB2c+be3g3NjiMiImITVHYchGEYvPlr8RFYd/dsQC0vN5MTiYiI2AaVHQex8sBpdp5Ix8vNmfv7NDI7joiIiM1Q2XEAhmHwxvLiqc4d3SMJ8NZUR0RE5DyVHQewJjaZbfFpuLs4MUFTHRERkVJUduzcH6c647pFUsfX3eREIiIitkVlx86tP5TClqNncHNxYuI1muqIiIj8mcqOnXvr3Hl1busSQYifh8lpREREbI/Kjh3bdDiV9YdScHW2MPGaxmbHERERsUkqO3bs/JXNb+0cQVgtT5PTiIiI2CaVHTv1+7EzrD6YjIuThb9oqiMiInJJKjt26q1zZ0u+uWM4EQFeJqcRERGxXSo7dmjH8TRW7D+Ns5OFv/bXVEdERORyVHbs0JvnjsAa3j6MyEBvk9OIiIjYNpUdO7PrRDrL957CyQKT+keZHUdERMTmqezYmbd/K57qDG0XRuM6PianERERsX0qO3Zkf2ImP+1OxGKByZrqiIiIlInKjh05f16dG1qH0iTE1+Q0IiIi9kFlx07EJmWyZGcCAJMHaKojIiJSVio7duLt32IxDBjcKoQWoX5mxxEREbEbKjt24HByNou3nwRgyoAmJqcRERGxLyo7duCdFbFYDbi2RTCt6/mbHUdERMSuqOzYuGMpOXyz9QSgqY6IiEhFqOzYuHdXxlJkNbimaR3aRdQyO46IiIjdUdmxYcfP5PB1zHEApg7UVEdERKQiVHZs2PvRcRRaDXpHBdEpsrbZcUREROySyo6NSkg/y4LNxVOdKTqvjoiISIWp7NiomdGHyC+y0q1hAN0aBZodR0RExG6p7NigpIxc5m46BsBD2ldHRETkqqjs2KCZqw6RX2ilc2RtejTWVEdERORqqOzYmOSsPOZsPAoUH4FlsVhMTiQiImLfVHZszIerD5FbYKVdRC36NAkyO46IiIjdU9mxIanZ+Xy+vniq89DAKE11REREKoHKjg35eM0hcvKLaF3Pj/7Ngs2OIyIi4hBUdmxEek4Bn607t6/OAO2rIyIiUllUdmzEJ2sPk5VXSItQP65rGWJ2HBEREYehsmMDMnIL+GTtYaD4bMma6oiIiFQelR0b8NnaI2TmFtIk2IchreqaHUdERMShqOyYLCuvkI/PT3UGNsHJSVMdERGRyqSyY7LP1x8lLaeARnW8ubFNqNlxREREHI7Kjoly8gv5cPUhACb3j8JZUx0REZFKp7JjojkbjpGanU9koBfD2oWZHUdERMQhqeyY5Gx+ETNXFU91JvWPwsVZ/ylERESqgr5hTfLlpmMkZ+URXtuTkR3qmR1HRETEYansmCC3oIiZq+KA4qmOq6Y6IiIiVUbfsib4aks8pzLyCPP34OaO4WbHERERcWgqO9Usr7CId1cWT3X+0q8xbi76TyAiIlKV9E1bzRbGnCAhPZcQP3du7RxhdhwRERGHp7JTjQqKrLy7MhaAB69pjIers8mJREREHJ/KTjX6ZusJjp85S5CPO7d1rW92HBERkRpBZaeaFBZZeWdF8VRnYt9GmuqIiIhUE5WdarJ4+0mOpuQQ4O3GuO6a6oiIiFQXlZ1qUGQ1ePu34qnOhD6N8HJzMTmRiIhIzaGyUw2W7EzgUHI2tbxcubNHpNlxREREahSVnSpmtRq89etBAO7r1RAfd011REREqpPKThX7aXciB5Oy8PVw4e5eDcyOIyIiUuOo7FQhq9XgzXNTnXt7NcTPw9XkRCIiIjWPyk4VWr73FPsSM/Fxd+HeXg3NjiMiIlIjmVp2ZsyYQZcuXfD19SU4OJgRI0awf//+UsuMHz8ei8VS6ta9e/dSy+Tl5TFlyhSCgoLw9vZm2LBhHD9+vDo/ykV9vOYwAON7NsDfS1MdERERM5hadqKjo5k0aRIbNmxg2bJlFBYWMmjQILKzs0stN2TIEBISEkpuS5cuLfX4ww8/zDfffMO8efNYs2YNWVlZ3HTTTRQVFVXnx7nAzDs78dDAJtzbW1MdERERs1gMwzDMDnHe6dOnCQ4OJjo6mr59+wLFk520tDS+/fbbiz4nPT2dOnXq8PnnnzNmzBgATp48SUREBEuXLmXw4MFXfN+MjAz8/f1JT0/Hz8+v0j6PiIiIVJ2yfn/b1D476enpAAQEBJS6f+XKlQQHB9O0aVMmTJhAUlJSyWMxMTEUFBQwaNCgkvvCwsJo3bo169atu+j75OXlkZGRUeomIiIijslmyo5hGEybNo3evXvTunXrkvuvv/565syZw2+//cb//vc/Nm/ezIABA8jLywMgMTERNzc3ateuXer1QkJCSExMvOh7zZgxA39//5JbRERE1X0wERERMZXNnOFu8uTJ7NixgzVr1pS6//ymKYDWrVvTuXNnIiMjWbJkCaNGjbrk6xmGgcViuehjTz75JNOmTSv5OSMjQ4VHRETEQdnEZGfKlCksXryYFStWEB4eftllQ0NDiYyM5ODB4vPX1K1bl/z8fM6cOVNquaSkJEJCQi76Gu7u7vj5+ZW6iYiIiGMytewYhsHkyZNZtGgRv/32Gw0bXvmopZSUFOLj4wkNDQWgU6dOuLq6smzZspJlEhIS2LVrFz179qyy7CIiImIfTN2MNWnSJObOnct3332Hr69vyT42/v7+eHp6kpWVxb///W9uvvlmQkNDOXLkCH//+98JCgpi5MiRJcved999PProowQGBhIQEMD06dNp06YN1157rZkfT0RERGyAqWXnvffeA6Bfv36l7p81axbjx4/H2dmZnTt3Mnv2bNLS0ggNDaV///7Mnz8fX1/fkuVfe+01XFxcGD16NGfPnmXgwIF8+umnODs7V+fHERERERtkU+fZMYvOsyMiImJ/7PI8OyIiIiKVTWVHREREHJrKjoiIiDg0lR0RERFxaCo7IiIi4tBs5nIRZjp/QJouCCoiImI/zn9vX+nAcpUdIDMzE0DXxxIREbFDmZmZ+Pv7X/JxnWcHsFqtnDx5kgEDBrBly5ZLLtelSxc2b95c5sfOX2A0Pj7eLs7fc7nPZ0vvUdHXKM/zyrrslZbTOmMb72Er68zVLqN1pvpeX+uM7bjc5zMMg8zMTMLCwnByuvSeOZrsAE5OToSHh+Pi4nLZ//DOzs6XfPxyj9nLxUYv9xls6T0q+hrleV5Zl73SclpnbOM9bGWdudpltM5U3+trnbEdV/o3uNxE5zztoPwHkyZNqvDjV3quPaiOz1AZ71HR1yjP88q6rNYZrTPlWfZql9E6U32vr3XGdlTGZ9BmrCqky1BIeWmdkfLSOiPlVRPXGU12qpC7uzv/+te/cHd3NzuK2AmtM1JeWmekvGriOqPJjoiIiDg0TXZERETEoansiIiIiENT2RERERGHprIjIiIiDk1lR0RERByayo6N2L9/P+3bty+5eXp68u2335odS2zc4cOH6d+/Py1btqRNmzZkZ2ebHUlsnIuLS8nvmfvvv9/sOGIHcnJyiIyMZPr06WZHqTAdem6DsrKyaNCgAUePHsXb29vsOGLDrrnmGp577jn69OlDamoqfn5+uLjoKjByaUFBQSQnJ5sdQ+zIU089xcGDB6lfvz6vvPKK2XEqRJMdG7R48WIGDhyooiOXtXv3blxdXenTpw8AAQEBKjoiUqkOHjzIvn37uOGGG8yOclVUdspo1apVDB06lLCwMCwWy0U3Mb377rs0bNgQDw8POnXqxOrVqyv0XgsWLGDMmDFXmVjMVtXrzMGDB/Hx8WHYsGF07NiR559/vhLTixmq4/dMRkYGnTp1onfv3kRHR1dScjFDdawv06dPZ8aMGZWU2Dz6M7CMsrOzadeuHffccw8333zzBY/Pnz+fhx9+mHfffZdevXoxc+ZMrr/+evbs2UP9+vUB6NSpE3l5eRc895dffiEsLAwo/kW0du1a5s2bV7UfSKpcVa8zBQUFrF69mm3bthEcHMyQIUPo0qUL1113XZV/Nqka1fF75siRI4SFhbFr1y5uvPFGdu7cWWOuj+Roqnp92bx5M02bNqVp06asW7euyj9PlTKk3ADjm2++KXVf165djQcffLDUfc2bNzeeeOKJcr327NmzjXHjxl1tRLExVbHOrFu3zhg8eHDJzy+99JLx0ksvXXVWsQ1V+XvmvCFDhhibN2+uaESxIVWxvjzxxBNGeHi4ERkZaQQGBhp+fn7GM888U1mRq5U2Y1WC/Px8YmJiGDRoUKn7Bw0aVO42rE1YNUNlrDNdunTh1KlTnDlzBqvVyqpVq2jRokVVxBUbUBnrzJkzZ0r+ij9+/Dh79uyhUaNGlZ5VzFcZ68uMGTOIj4/nyJEjvPLKK0yYMIF//vOfVRG3ymkzViVITk6mqKiIkJCQUveHhISQmJhY5tdJT09n06ZNLFy4sLIjio2pjHXGxcWF559/nr59+2IYBoMGDeKmm26qirhiAypjndm7dy8TJ07EyckJi8XCG2+8QUBAQFXEFZNV1veSo1DZqUQWi6XUz4ZhXHDf5fj7+3Pq1KnKjiU27GrXmeuvv57rr7++smOJDbuadaZnz57s3LmzKmKJjbra3zHnjR8/vpISmUObsSpBUFAQzs7OF7TlpKSkC1q1CGidkfLTOiPlofWlNJWdSuDm5kanTp1YtmxZqfuXLVtGz549TUoltkzrjJSX1hkpD60vpWkzVhllZWURGxtb8vPhw4fZtm0bAQEB1K9fn2nTpnHnnXfSuXNnevTowQcffMCxY8d48MEHTUwtZtI6I+WldUbKQ+tLOZh6LJgdWbFihQFccLv77rtLlnnnnXeMyMhIw83NzejYsaMRHR1tXmAxndYZKS+tM1IeWl/KTtfGEhEREYemfXZERETEoansiIiIiENT2RERERGHprIjIiIiDk1lR0RERByayo6IiIg4NJUdERERcWgqOyIiIuLQVHZExK41aNCA119/3ewYImLDVHZE5IrGjx/PiBEjzI5xUZs3b+aBBx6o8vdp0KABFosFi8WCp6cnzZs35+WXX6a8J6FXOROpfroQqIjYpIKCAlxdXa+4XJ06daohTbFnn32WCRMmkJuby/Lly/nLX/6Cn58fEydOrLYMIlJ+muyIyFXbs2cPN9xwAz4+PoSEhHDnnXeSnJxc8vhPP/1E7969qVWrFoGBgdx0003ExcWVPH7kyBEsFgsLFiygX79+eHh48MUXX5RMlF555RVCQ0MJDAxk0qRJFBQUlDz3z5MSi8XCRx99xMiRI/Hy8qJJkyYsXry4VN7FixfTpEkTPD096d+/P5999hkWi4W0tLTLfk5fX1/q1q1LgwYNuP/++2nbti2//PJLyeNxcXEMHz6ckJAQfHx86NKlC8uXLy95vF+/fhw9epRHHnmkZEp03rp16+jbty+enp5EREQwdepUsrOzy/zfQEQuTWVHRK5KQkIC11xzDe3bt2fLli389NNPnDp1itGjR5csk52dzbRp09i8eTO//vorTk5OjBw5EqvVWuq1Hn/8caZOncrevXsZPHgwACtWrCAuLo4VK1bw2Wef8emnn/Lpp59eNtMzzzzD6NGj2bFjBzfccAPjxo0jNTUVKC5Wt9xyCyNGjGDbtm1MnDiRp556qlyf2TAMVq5cyd69e0tNn7KysrjhhhtYvnw5W7duZfDgwQwdOpRjx44BsGjRIsLDw3n22WdJSEggISEBgJ07dzJ48GBGjRrFjh07mD9/PmvWrGHy5MnlyiUil2DuRddFxB7cfffdxvDhwy/62NNPP20MGjSo1H3x8fEGYOzfv/+iz0lKSjIAY+fOnYZhGMbhw4cNwHj99dcveN/IyEijsLCw5L5bb73VGDNmTMnPkZGRxmuvvVbyM2D84x//KPk5KyvLsFgsxo8//mgYhmE8/vjjRuvWrUu9z1NPPWUAxpkzZy7+D3Dufdzc3Axvb2/D1dXVAAwPDw9j7dq1l3yOYRhGy5YtjbfeeuuSeQ3DMO68807jgQceKHXf6tWrDScnJ+Ps2bOXfX0RuTJNdkTkqsTExLBixQp8fHxKbs2bNwco2VQVFxfH7bffTqNGjfDz86Nhw4YAJROP8zp37nzB67dq1QpnZ+eSn0NDQ0lKSrpsprZt25b8/97e3vj6+pY8Z//+/XTp0qXU8l27di3TZ33sscfYtm0b0dHR9O/fn6eeeoqePXuWPJ6dnc3f/vY3WrZsSa1atfDx8WHfvn0XfM4/i4mJ4dNPPy31bzh48GCsViuHDx8uUzYRuTTtoCwiV8VqtTJ06FBefPHFCx4LDQ0FYOjQoURERPDhhx8SFhaG1WqldevW5Ofnl1re29v7gtf4807KFovlgs1f5XmOYRil9pU5f19ZBAUFERUVRVRUFAsXLiQqKoru3btz7bXXAsVl6Oeff+aVV14hKioKT09Pbrnllgs+559ZrVYmTpzI1KlTL3isfv36ZcomIpemsiMiV6Vjx44sXLiQBg0a4OJy4a+UlJQU9u7dy8yZM+nTpw8Aa9asqe6YJZo3b87SpUtL3bdly5Zyv07t2rWZMmUK06dPZ+vWrVgsFlavXs348eMZOXIkULwPz5EjR0o9z83NjaKiolL3dezYkd27dxMVFVXuHCJyZdqMJSJlkp6ezrZt20rdjh07xqRJk0hNTeW2225j06ZNHDp0iF9++YV7772XoqIiateuTWBgIB988AGxsbH89ttvTJs2zbTPMXHiRPbt28fjjz/OgQMHWLBgQckOz3+e+FzJpEmT2L9/PwsXLgQgKiqKRYsWsW3bNrZv387tt99+wRSqQYMGrFq1ihMnTpQcsfb444+zfv16Jk2axLZt2zh48CCLFy9mypQpV/+BRURlR0TKZuXKlXTo0KHU7Z///CdhYWGsXbuWoqIiBg8eTOvWrXnooYfw9/fHyckJJycn5s2bR0xMDK1bt+aRRx7h5ZdfNu1zNGzYkK+//ppFixbRtm1b3nvvvZKjsdzd3cv1WnXq1OHOO+/k3//+N1arlddee43atWvTs2dPhg4dyuDBg+nYsWOp5zz77LMcOXKExo0bl5wjqG3btkRHR3Pw4EH69OlDhw4dePrpp0s2A4rI1bEYZd1YLSLioP773//y/vvvEx8fb3YUEakC2mdHRGqcd999ly5duhAYGMjatWt5+eWXdU4bEQemsiMiNc7Bgwd57rnnSE1NpX79+jz66KM8+eSTZscSkSqizVgiIiLi0LSDsoiIiDg0lR0RERFxaCo7IiIi4tBUdkRERMShqeyIiIiIQ1PZEREREYemsiMiIiIOTWVHREREHJrKjoiIiDi0/wMd0GiZdXAAdwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "    config_path = '../configs/cifar10/bt_test_config.yaml'\n",
    "    config = load_config(config_path)\n",
    "\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "    print(os.listdir(experiment_dir))\n",
    "    print(os.listdir(base_dir))\n",
    "    print('experiment_dir and base_dir')\n",
    "\n",
    "    print('We can keep training - resuming from the checkpoint')\n",
    "\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    print(os.listdir(experiment_dir))\n",
    "    print(os.listdir(base_dir))\n",
    "    print('experiment_dir and base_dir')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
