{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_model\n",
    "\n",
    "> In this module we have the base model, learner and other things we need to train encoder with Barlow Twins and other methods.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import importlib\n",
    "import sys\n",
    "import self_supervised\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "import kornia.augmentation as korniatfm\n",
    "import torchvision.transforms as tvtfm\n",
    "from base_rbt.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the base functions and classes to train a basic BT-style model. Note that this (mostly) all comes directly from here: `https://github.com/KeremTurgutlu/self_supervised/blob/main/nbs/14%20-%20barlow_twins.ipynb`\n",
    "but we needed to extend some of the functionality for our purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the base classes and functions needed for image augmentation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#My edited version of RandTransform\n",
    "class RandomGaussianBlur(RandTransform):\n",
    "    \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "    order = 11\n",
    "    def __init__(self, \n",
    "                 p=1.0, #debugging (bug in libraries implementation)\n",
    "                 prob=0.5,#the real probability\n",
    "                 s=(8,32), #kernel\n",
    "                 sig=None, #sig_val is either manually input OR\n",
    "                 blur_r=(0.1,2),#is randomly chosen from uniform with these bounds\n",
    "                 same_on_batch=False, \n",
    "                 **kwargs): \n",
    "        \n",
    "        store_attr()\n",
    "        super().__init__(p=p, **kwargs)\n",
    "\n",
    "    def encodes(self, x:TensorImage):\n",
    "        \n",
    "        if isinstance(self.s, int):   s = (self.s,self.s)\n",
    "        elif isinstance(self.s, tuple) or isinstance(self.s, list): s=self.s\n",
    "     \n",
    "        #Default for ImageNet from BYOL / BT papers\n",
    "        if self.sig is None:\n",
    "            sig_val = np.random.uniform(self.blur_r[0],self.blur_r[1])\n",
    "        \n",
    "        else:\n",
    "            sig_val = self.sig\n",
    "            \n",
    "\n",
    "        tfm = korniatfm.RandomGaussianBlur(kernel_size=s,sigma=(sig_val,sig_val),same_on_batch=self.same_on_batch,p=self.prob)\n",
    "        return tfm(x)\n",
    "\n",
    "#Delete later: leaving for backward compatibility for now\n",
    "# class RandomGaussianBlur(RandTransform):\n",
    "#     \"Randomly apply gaussian blur with probability `p` with a value of s\"\n",
    "#     order = 11\n",
    "#     def __init__(self, p=0.5, s=(8,32), same_on_batch=False, **kwargs): \n",
    "#         store_attr()\n",
    "#         super().__init__(p=p, **kwargs)\n",
    "        \n",
    "#     def encodes(self, x:TensorImage):\n",
    "#         if isinstance(self.s, tuple): s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, list):  s = np.random.randint(*self.s)\n",
    "#         if isinstance(self.s, int):   s = self.s\n",
    "#         s2 = int(s/4)*2+1\n",
    "#         tfm = korniatfm.RandomGaussianBlur((s2,s2),(s,s),same_on_batch=self.same_on_batch,p=1.) #p=1. is a bug\n",
    "#                                             #kernel #sigma\n",
    "        \n",
    "#         return tfm(x)\n",
    "\n",
    "\n",
    "class RandomCenterDropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.5, min_dropout_size=(20, 20), max_dropout_size=(60, 60), fill_value=0, same_on_batch=False):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.min_dropout_size = min_dropout_size\n",
    "        self.max_dropout_size = max_dropout_size\n",
    "        self.fill_value = fill_value\n",
    "        self.same_on_batch = same_on_batch\n",
    "        #self.id_transform = tvtfm.RandomResizedCrop((256, 256), scale=(1.,1.), ratio=(1.,1.))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Check if the augmentation should be applied to the whole batch or individually\n",
    "\n",
    "        #x=self.id_transform(x)\n",
    "\n",
    "        if self.same_on_batch:\n",
    "            if random.random() < self.p:\n",
    "                return self._apply_dropout(x)\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            # Apply dropout individually with given probability\n",
    "            for i in range(x.size(0)):\n",
    "                tem=random.random()\n",
    "                #print(f\"tem is: {tem}\")\n",
    "                if tem < self.p:\n",
    "                    x[i] = self._apply_dropout(x[i].unsqueeze(0)).squeeze(0)\n",
    "            return x\n",
    "\n",
    "    def _apply_dropout(self, img):\n",
    "        for i,count in enumerate(range(img.size(0))):  # Iterate through batch if necessary\n",
    "            _, h, w = img[i].shape\n",
    "            # Generate random dropout size within specified limits\n",
    "            dh = random.randint(self.min_dropout_size[0], self.max_dropout_size[0])\n",
    "            dw = random.randint(self.min_dropout_size[1], self.max_dropout_size[1])\n",
    "            \n",
    "            x1 = int(max((w - dw) / 2, 0))\n",
    "            y1 = int(max((h - dh) / 2, 0))\n",
    "            \n",
    "            mask = torch.ones_like(img[i])\n",
    "            mask[:, y1:y1+dh, x1:x1+dw] = self.fill_value\n",
    "            img[i] = img[i] * mask\n",
    "        \n",
    "        return img\n",
    "\n",
    "    \n",
    "def get_BT_batch_augs(size,\n",
    "                    flip=True,crop=True,noise=True,rotate=True,jitter=True,bw=True,blur=True,solar=True,cutout=False, #Whether to use  given aug or not\n",
    "                    resize_scale=(0.08, 1.0),resize_ratio=(3/4, 4/3),noise_std=0.025, rotate_deg=30,jitter_s=.6,blur_s=(4,32),#hps of diff augs\n",
    "                    blur_r=(0.1,2),blur_sig=None,sol_t=0.05,sol_a=0.05,min_dropout_size=(25, 100),max_dropout_size=(50,150), #hps of diff augs\n",
    "                    flip_p=0.5, rotate_p=0.3,noise_p=0.2, jitter_p=0.3, bw_p=0.3, blur_p=0.3,sol_p=0.1,cut_p=0.0, #prob of performing aug\n",
    "                    same_on_batch=False,stats=imagenet_stats,cuda=default_device().type == 'cuda',xtra_tfms=[]\n",
    "                    ):\n",
    "    \"Input batch augmentations implemented in tv+kornia+fastai\"\n",
    "    \n",
    "    tfms = []\n",
    "\n",
    "    korniatfm.RandomHorizontalFlip.order = RandomResizedCrop.order-1\n",
    "\n",
    "\n",
    "    if crop: tfms += [tvtfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio)]\n",
    "    #Unfortunately for some reason this doesn't work, so we can't apply \"same_on_batch=False\"\n",
    "    #tfms += [korniatfm.RandomResizedCrop((size, size), scale=resize_scale, ratio=resize_ratio, same_on_batch=same_on_batch)]\n",
    "\n",
    "    if cutout: tfms+=[RandomCenterDropout(min_dropout_size=min_dropout_size,max_dropout_size=max_dropout_size, fill_value=0, p=cut_p,same_on_batch=same_on_batch)]\n",
    "    \n",
    "  \n",
    "    if flip: tfms += [korniatfm.RandomHorizontalFlip(p=flip_p,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if rotate: tfms += [Rotate(max_deg=rotate_deg, p=rotate_p, batch=same_on_batch)]\n",
    "\n",
    "                                             #brightness,contrast,saturation,hue\n",
    "    if jitter: tfms += [korniatfm.ColorJitter(0.4*jitter_s, 0.4*jitter_s, 0.2*jitter_s, 0.1*jitter_s, p=jitter_p, same_on_batch=same_on_batch)]\n",
    "    \n",
    "    if bw:     tfms += [korniatfm.RandomGrayscale(p=bw_p, same_on_batch=same_on_batch)]\n",
    "        \n",
    "    #sig will usually be None\n",
    "    if blur:   tfms += [RandomGaussianBlur(prob=blur_p, s=blur_s,sig=blur_sig,blur_r=blur_r, same_on_batch=same_on_batch)]\n",
    "\n",
    "    korniatfm.RandomSolarize.order = RandomGaussianBlur.order + 1 #we want to apply solarization after RandomGaussianBlur\n",
    "    \n",
    "    if solar: tfms += [korniatfm.RandomSolarize(p=sol_p,thresholds=sol_t, additions=sol_a,same_on_batch=same_on_batch)]\n",
    "\n",
    "    if noise: tfms+=[korniatfm.RandomGaussianNoise(mean=0.0, std=noise_std, same_on_batch=same_on_batch, p=noise_p)]\n",
    "    \n",
    "    if stats is not None: tfms += [Normalize.from_stats(*stats, cuda=cuda)]\n",
    "\n",
    "    tfms += xtra_tfms\n",
    "\n",
    "    pipe = Pipeline(tfms, split_idx = 0)\n",
    "    return pipe\n",
    "\n",
    "@delegates(get_BT_batch_augs)\n",
    "def get_multi_aug_pipelines(size, **kwargs): return get_BT_batch_augs(size, **kwargs)\n",
    "\n",
    "@delegates(get_multi_aug_pipelines)\n",
    "def get_barlow_twins_aug_pipelines(size,**kwargs): return get_multi_aug_pipelines(size=size,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_cifar10_aug_pipelines(size):\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                    bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                    resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n",
    "                                                    bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n",
    "                                                    stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                    )\n",
    "\n",
    "    bt_cifar10_aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return bt_cifar10_aug_pipelines\n",
    "\n",
    "#Add other augmentations here e.g. BYOL augs\n",
    "IMAGENET_Augs = dict(flip_p1=0.5,flip_p2=0.5,jitter_p1=0.8,jitter_p2=0.8,bw_p1=0.2,\n",
    "                bw_p2=0.2,blur_p1=1.0,blur_p2=0.1,sol_p1=0.0,sol_p2=0.2,noise_p1=0.0,\n",
    "                noise_p2=0.0,cut_p=0,resize_scale=(0.7, 1.0),resize_ratio=(3/4, 4/3),rotate_deg=45.0,\n",
    "                rotate_p=0.5,blur_r=(0.1,2),blur_s=13,sol_t=0.1,sol_a=0.1,noise_std=0.1,min_dropout_size=None,max_dropout_size=None,\n",
    "                )\n",
    "\n",
    "DERMNET_Augs = IMAGENET_Augs.copy()\n",
    "DERMNET_Augs['min_dropout_size']=(50, 185)\n",
    "DERMNET_Augs['max_dropout_size']=(100,190)\n",
    "DERMNET_Augs['cut_p']=0.33\n",
    "\n",
    "def helper_get_bt_augs(size,Augs=IMAGENET_Augs):\n",
    "\n",
    "\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p1'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p1'],\n",
    "                        jitter_p=Augs['jitter_p1'], bw_p=Augs['bw_p1'], blur_p=Augs['blur_p1'],\n",
    "                        sol_p=Augs['sol_p1'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True,cutout=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        min_dropout_size=Augs['min_dropout_size'],max_dropout_size=Augs['max_dropout_size'],\n",
    "                        flip_p=Augs['flip_p2'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p2'],\n",
    "                        jitter_p=Augs['jitter_p2'], bw_p=Augs['bw_p2'], blur_p=Augs['blur_p2'],\n",
    "                        sol_p=Augs['sol_p2'],cut_p=Augs['cut_p'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None)\n",
    "\n",
    "    aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "    return aug_pipelines\n",
    "\n",
    "def get_bt_imagenet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=IMAGENET_Augs)\n",
    "\n",
    "def get_bt_dermnet_aug_pipelines(size):\n",
    "    return helper_get_bt_augs(size,Augs=DERMNET_Augs)\n",
    "\n",
    "\n",
    "\n",
    "bt_aug_func_dict = {'bt_cifar10_aug_pipelines':get_bt_cifar10_aug_pipelines,'bt_imagenet_aug_pipelines':get_bt_imagenet_aug_pipelines,\n",
    "                   'bt_dermnet_aug_pipelines':get_bt_dermnet_aug_pipelines\n",
    "                   }\n",
    "\n",
    "def get_bt_aug_pipelines(bt_augs,size):\n",
    "\n",
    "    return bt_aug_func_dict[bt_augs](size)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_ssl_dls(dataset,#cifar10, dermnet, etc\n",
    "            bs,\n",
    "            size,\n",
    "            device,\n",
    "            pct_dataset=1.0):\n",
    "    # Define the base package name in a variable for easy modification\n",
    "\n",
    "    try:\n",
    "        # Construct the module path\n",
    "        module_path = f\"{PACKAGE_NAME}.{dataset}_dataloading\"\n",
    "        \n",
    "        # Dynamically import the module\n",
    "        dataloading_module = importlib.import_module(module_path)\n",
    "    except ModuleNotFoundError:\n",
    "        # Handle the case where the module cannot be found\n",
    "        raise ImportError(f\"Could not find a data loading module for '{dataset}'. \"\n",
    "                          f\"Make sure '{module_path}' exists and is correctly named.\") from None\n",
    "    \n",
    "    # Assuming the function name follows a consistent naming convention\n",
    "    func_name = f\"get_bt_{dataset}_train_dls\"\n",
    "\n",
    "    try:\n",
    "        # Retrieve the data loading function from the module\n",
    "        data_loader_func = getattr(dataloading_module, func_name)\n",
    "    except AttributeError:\n",
    "        # Handle the case where the function does not exist in the module\n",
    "        raise AttributeError(f\"The function '{func_name}' was not found in '{module_path}'. \"\n",
    "                             \"Ensure it is defined and named correctly.\") from None\n",
    "    \n",
    "    # Proceed to call the function with arguments from the config\n",
    "    try:\n",
    "        dls_train = data_loader_func(bs=bs,size=size,device=device,pct_dataset=pct_dataset)\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the function call\n",
    "        raise RuntimeError(f\"An error occurred while calling '{func_name}' from '{module_path}': {e}\") from None\n",
    "    \n",
    "    return dls_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base functions / classes we need to train a BT / RBT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Base functions / classes we need to train a BT / RBT model.\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "\n",
    "# class BarlowTwinsModel(Module):\n",
    "#     \"\"\"An encoder followed by a projector\n",
    "#     \"\"\"\n",
    "#     def __init__(self,encoder,projector):\n",
    "#         self.encoder = encoder\n",
    "#         self.projector = projector\n",
    "        \n",
    "#     def forward(self,x): \n",
    "        \n",
    "#         return self.projector(self.encoder(x))\n",
    "\n",
    "# def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "#     \"Create Barlow Twins model\"\n",
    "#     n_in  = in_channels(encoder)\n",
    "#     with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "#     projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "#     apply_init(projector)\n",
    "#     return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "\n",
    "#We want access to both representation and projection\n",
    "\n",
    "#TODO: We can make these more abstract so can incrementally modify to build `bt/rbt` and also `new idea.` But for \n",
    "#sake of readability, might be easier to just modify the defintions elsewhere. Come back to this later...\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"\"\"An encoder followed by a projector\n",
    "    \"\"\"\n",
    "    def __init__(self,encoder,projector):\n",
    "        self.encoder = encoder\n",
    "        self.projector = projector\n",
    "        \n",
    "    def forward(self,x): \n",
    "        tem = self.encoder(x)\n",
    "        return tem,self.projector(tem) #get access to both representation and projection if needed for loss\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'forward returns tuple of (encoder(x),projector(encoder(x)))'\n",
    "\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    \n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector)\n",
    " \n",
    "    return BarlowTwinsModel(encoder, projector)\n",
    "\n",
    "\n",
    "#Note: this requires an lf (loss function), which is patched in later.\n",
    "#The reason for this is we can specify via a string argument (e.g. via\n",
    "#a config file) what loss function we want to use. lf_bt is the default\n",
    "#(standard barlow twins loss function).\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines,n_in,lmb,sparsity_level, \n",
    "                model_type='barlow_twins',print_augs=False\n",
    "                 ):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        store_attr('sparsity_level')\n",
    "        self.n_in=n_in\n",
    "        self.model_type = model_type\n",
    "        self.index=-1 #Gets updated after each batch\n",
    "        self.acc_dict = {}\n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self.index=-1  \n",
    "  \n",
    "    def before_batch(self):\n",
    "        \n",
    "        #TODO: Make this nicer (possibly can load in data as TensorImage(BW) or something?)\n",
    "        #This is a bit of a hack. Can make this more elegant later. But in new version of FastAI\n",
    "        #seems we need to compute TensorImage(BW) here, and depends on whether color or not, i.e. n_in.\n",
    "        if self.n_in == 1:\n",
    "\n",
    "            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            \n",
    "            #print(xi.shape)\n",
    "                                    \n",
    "        elif self.n_in == 3:\n",
    "            \n",
    "            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    " \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1): \n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]]\n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the above for vicreg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Base functions / classes we need to train a \n",
    "#  model\n",
    "class VICRegModel(Module):\n",
    "    \"\"\"VICReg model with options for shared or separate projectors\"\"\"\n",
    "    def __init__(self, left_encoder, right_encoder, left_projector, right_projector):\n",
    "        #may have right_encoder = encoder_left and right_projector = left_projector.\n",
    "        #or e.g. encoders may have shared weights.\n",
    "        self.left_encoder = left_encoder\n",
    "        self.right_encoder = right_encoder\n",
    "        self.left_projector = left_projector\n",
    "        self.right_projector = right_projector\n",
    "        \n",
    "    def forward(self,x): #x is stacked xi,xj the two augmented views of batch\n",
    "      \n",
    "        x1, x2 = x[:x.size(0)//2], x[x.size(0)//2:]\n",
    "        \n",
    "        z1,z2 = self.left_projector(self.left_encoder(x1)), self.right_projector(self.right_encoder(x2))\n",
    "    \n",
    "        return z1, z2\n",
    "\n",
    "#override fastai method basically\n",
    "from fastai.vision.learner import in_channels as fastai_in_channels\n",
    "def in_channels(m):\n",
    "    try:\n",
    "        return m.in_channels\n",
    "    except AttributeError:\n",
    "        return fastai_in_channels(m)\n",
    "\n",
    "def create_vicreg_model(left_encoder, right_encoder,hidden_size=256, projection_size=128, bn=True, nlayers=3, shared_projector=True):\n",
    "    \"\"\"\n",
    "    Create VICReg model with flexible projector configuration\n",
    "    \n",
    "    Args:\n",
    "    - left_encoder: first encoder model\n",
    "    - right_encoder: second encoder model (can be the same as left_encoder for shared encoder)\n",
    "    - hidden_size: hidden size for projector\n",
    "    - projection_size: output size for projector\n",
    "    - bn: whether to use batch normalization in projector\n",
    "    - nlayers: number of layers in projector\n",
    "    - shared_projector: if True, use the same projector for both branches\n",
    "    \"\"\"\n",
    "    n_in = in_channels(left_encoder)\n",
    "    with torch.no_grad(): representation = left_encoder(torch.randn((2,n_in,32,32)))\n",
    "    \n",
    "    left_projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "    apply_init(left_projector)\n",
    "    \n",
    "    if not shared_projector:\n",
    "        right_projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers)\n",
    "        apply_init(right_projector)\n",
    "    else:\n",
    "        right_projector = left_projector\n",
    "    \n",
    "    return VICRegModel(left_encoder, right_encoder, left_projector, right_projector)\n",
    "\n",
    "#helper function to compute vicreg loss.\n",
    "def off_diagonal(x):\n",
    "        n, m = x.shape\n",
    "        assert n == m\n",
    "        return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "class VICReg(BarlowTwins):\n",
    "    def __init__(self, aug_pipelines, n_in=3, sim_coeff=25, std_coeff=25, cov_coeff=1, \n",
    "                 model_type='vicreg', print_augs=False):\n",
    "        super().__init__(aug_pipelines, n_in, None, None, model_type, print_augs)\n",
    "        self.sim_coeff = sim_coeff\n",
    "        self.std_coeff = std_coeff\n",
    "        self.cov_coeff = cov_coeff\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.learn.loss_func = self.lf\n",
    "\n",
    "    def lf(self, pred, *yb):\n",
    "        x, y = pred  # Assuming the model returns two views (see VICRegModel)\n",
    "\n",
    "        # Invariance loss\n",
    "        repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "        # Variance loss\n",
    "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "        # Covariance loss\n",
    "        x = x - x.mean(dim=0)\n",
    "        y = y - y.mean(dim=0)\n",
    "        cov_x = (x.T @ x) / (x.size(0) - 1)\n",
    "        cov_y = (y.T @ y) / (y.size(0) - 1)\n",
    "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(x.size(1)) + \\\n",
    "                   off_diagonal(cov_y).pow_(2).sum().div(y.size(1))\n",
    "\n",
    "        # Total loss\n",
    "        loss = (\n",
    "            self.sim_coeff * repr_loss +\n",
    "            self.std_coeff * std_loss +\n",
    "            self.cov_coeff * cov_loss\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def before_batch(self):\n",
    "        #if self.model_type == 'br_vicreg':\n",
    "\n",
    "    #         # Create two copies of the input\n",
    "    #         x_left, x_right = self.x.clone(), self.x.clone()\n",
    "            \n",
    "    #         # Zero out the right half of x_left and the left half of x_right\n",
    "    #         mid = x_left.shape[-1] // 2\n",
    "    #         x_left[..., mid:] = 0\n",
    "    #         x_right[..., :mid] = 0\n",
    "            \n",
    "    #         print(f\"x shape: {self.x.shape}\")\n",
    "    #         print(f\"x_left shape: {x_left.shape}\")\n",
    "    #         print(f\"x_right shape: {x_right.shape}\")\n",
    "\n",
    "    #         # Apply augmentations\n",
    "    #         if self.n_in == 1:\n",
    "    #             xi = self.aug1(TensorImageBW(x_left))\n",
    "    #             xj = self.aug2(TensorImageBW(x_right))\n",
    "    #         elif self.n_in == 3:\n",
    "    #             xi = self.aug1(TensorImage(x_left))\n",
    "    #             xj = self.aug2(TensorImage(x_right))\n",
    "\n",
    "    #         print(f\"xi shape after aug: {xi.shape}\")\n",
    "    #         print(f\"xj shape after aug: {xj.shape}\")\n",
    "\n",
    "    #         # Concatenate the augmented halves\n",
    "    #         self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "    #         print(f\"Final self.learn.xb shape: {self.learn.xb[0].shape}\")\n",
    "\n",
    "        # The above splits x into x_left and x_right, with padding, then applies\n",
    "        # aug1 and aug2. Alternatively, we could compute aug1(x) and aug2(x). \n",
    "        # then zero pad the right half of aug1(x) and the left half of aug2(x).\n",
    "\n",
    "        #zero padding approach:\n",
    "        # if self.model_type == 'br_vicreg':\n",
    "        #     # Apply augmentations first\n",
    "        #     if self.n_in == 1:\n",
    "        #         xi = self.aug1(TensorImageBW(self.x))\n",
    "        #         xj = self.aug2(TensorImageBW(self.x))\n",
    "        #     elif self.n_in == 3:\n",
    "        #         xi = self.aug1(TensorImage(self.x))\n",
    "        #         xj = self.aug2(TensorImage(self.x))\n",
    "            \n",
    "        #     print(f\"x shape: {self.x.shape}\")\n",
    "        #     print(f\"xi shape after aug: {xi.shape}\")\n",
    "        #     print(f\"xj shape after aug: {xj.shape}\")\n",
    "\n",
    "        #     # Zero out the right half of xi and the left half of xj\n",
    "        #     mid = xi.shape[-1] // 2\n",
    "        #     xi[..., mid:] = 0\n",
    "        #     xj[..., :mid] = 0\n",
    "            \n",
    "        #     print(f\"xi shape after zeroing: {xi.shape}\")\n",
    "        #     print(f\"xj shape after zeroing: {xj.shape}\")\n",
    "\n",
    "        #     # Concatenate the augmented and zeroed halves\n",
    "        #     self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "        #     print(f\"Final self.learn.xb shape: {self.learn.xb[0].shape}\")\n",
    "        # else:\n",
    "        #     # Use the original BarlowTwins before_batch method for 'vicreg'\n",
    "        #     if self.n_in == 1:\n",
    "        #         xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "        #     elif self.n_in == 3:\n",
    "        #         xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "        #     self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "\n",
    "        #here we dont zero pad at all, just get 16x32 (for cifar, say)\n",
    "        if self.model_type == 'br_vicreg':\n",
    "            ### Original implementation for 'vicreg'\n",
    "            if self.n_in == 1:\n",
    "                xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            elif self.n_in == 3:\n",
    "                xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "\n",
    "                   # Randomly apply left/right masking with 50% probability\n",
    "            p = 0.5\n",
    "            if random.random() < p:\n",
    "                # Calculate the split point\n",
    "                _, _, _, width = xi.shape\n",
    "                split_point = width // 2\n",
    "                \n",
    "                # Zero out the right half of xi and the left half of xj\n",
    "                xi[:, :, :, split_point:] = 0\n",
    "                xj[:, :, :, :split_point] = 0\n",
    "                \n",
    "            self.learn.xb = (torch.cat([xi, xj], dim=0),)\n",
    "\n",
    "\n",
    "            # # Apply augmentations first\n",
    "            # if self.n_in == 1:\n",
    "            #     xi = self.aug1(TensorImageBW(self.x))\n",
    "            #     xj = self.aug2(TensorImageBW(self.x))\n",
    "            # elif self.n_in == 3:\n",
    "            #     xi = self.aug1(TensorImage(self.x))\n",
    "            #     xj = self.aug2(TensorImage(self.x))\n",
    "            \n",
    "            # # Dynamically calculate the split point\n",
    "            # _, _, height, width = xi.shape\n",
    "            # split_point = width // 2\n",
    "\n",
    "            # # Split each image into left and right halves\n",
    "            # xi_left = xi[..., :split_point]  # Left half\n",
    "            # xj_right = xj[..., split_point:]  # Right half\n",
    "            \n",
    "            # # Concatenate the halves\n",
    "            # self.learn.xb = (torch.cat([xi_left, xj_right], dim=0),)\n",
    "\n",
    "            # print(f\"Input shape: {self.x.shape}\")\n",
    "            # print(f\"Augmented left half shape: {xi_left.shape}\")\n",
    "            # print(f\"Augmented right half shape: {xj_right.shape}\")\n",
    "            # print(f\"Combined batch shape: {self.learn.xb[0].shape}\")\n",
    "\n",
    "        else:\n",
    "            # Original implementation for 'vicreg'\n",
    "            if self.n_in == 1:\n",
    "                xi, xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))\n",
    "            elif self.n_in == 3:\n",
    "                xi, xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))\n",
    "            self.learn.xb = (torch.cat([xi, xj], dim=0),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside random\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x2400 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_vicreg_batch(dls,n_in=3,aug=aug,n=8,print_augs=True,model_type='br_vicreg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of barlow twins loss and sparse barlow twins loss functions, and proposes modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt(pred,I,lmb): #standard bt loss\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "    \n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs \n",
    "    cdiff = (C - I)**2\n",
    "    loss = (cdiff*I + cdiff*(1-I)*lmb).sum() \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_sparse_head(pred,I,lmb,projector,sparsity_level):\n",
    "  \n",
    "    bt_loss = lf_bt(pred,I,lmb)\n",
    "    L21 = torch.linalg.norm(projector[-1].weight, ord=2, dim=0).sum()\n",
    "\n",
    "    # print(f\"bt_loss is {bt_loss}, L21 is {L21}, scaled L21 is {sparsity_level*L21}\")\n",
    "    # print(bt_loss)\n",
    "    # print(L21)\n",
    "\n",
    "    \n",
    "    loss =  bt_loss + sparsity_level*L21 #barlow twins loss + L21 norm of last layer of projector\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_indiv_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb*(0.5*torch.abs(z1_enc) + 0.5*torch.abs(z2_enc)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1_enc.pow(2) + 0.5 * z2_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_group_norm_sparse(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_fun(pred,I,lmb,sparsity_level,\n",
    "                      ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    \n",
    "\n",
    "    eps = 1e-7\n",
    "    z1_enc, z2_enc = pred_enc[:bs],pred_enc[bs:]\n",
    "    z1norm_enc = (z1_enc - z1_enc.mean(0)) / (z1_enc.std(0, unbiased=False)+eps)\n",
    "    z2norm_enc = (z2_enc - z2_enc.mean(0)) / (z2_enc.std(0, unbiased=False)+eps)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm_enc.pow(2) + 0.5 * z2norm_enc.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm_enc.T @ z2norm_enc) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    loss = (cdiff*I).sum() #standard bt loss\n",
    "\n",
    "    print(f\"invariance loss is: {loss} and sparsity loss is: {sparsity}\")\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lf_bt_proj_group_sparse(pred,I,lmb,sparsity_level,\n",
    "                           ):\n",
    "\n",
    "    pred_enc = pred[0]\n",
    "    pred = pred[1]\n",
    "\n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    sparsity = lmb * ((0.5 * z1norm.pow(2) + 0.5 * z2norm.pow(2)).pow(0.5)).sum()\n",
    "\n",
    "    C = (z1norm.T @ z2norm) / bs\n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    rr = cdiff*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #standard bt loss\n",
    "\n",
    "    loss = loss + sparsity_level*sparsity\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch in loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb):\n",
    "    \"Assumes model created according to type p3\"\n",
    "\n",
    "    if self.model_type=='barlow_twins':\n",
    "         pred_enc = pred[0]\n",
    "         pred = pred[1]\n",
    "         return lf_bt(pred, self.I,self.lmb)\n",
    "\n",
    "    elif self.model_type=='sparse_head_barlow_twins':\n",
    "        pred_enc = pred[0]\n",
    "        pred = pred[1]\n",
    "\n",
    "        return lf_bt_sparse_head(pred, self.I,lmb=self.lmb,projector=self.learn.model.projector,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='indiv_sparse_barlow_twins':\n",
    "        return lf_bt_indiv_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='group_sparse_barlow_twins':\n",
    "        return lf_bt_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='group_norm_sparse_barlow_twins':\n",
    "        return lf_bt_group_norm_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "    elif self.model_type=='proj_group_sparse_barlow_twins':\n",
    "        return lf_bt_proj_group_sparse(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "    \n",
    "    elif self.model_type=='fun':\n",
    "        return lf_bt_fun(pred, self.I,lmb=self.lmb,sparsity_level=self.sparsity_level)\n",
    "\n",
    "\n",
    "    else: raise(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt(m):\n",
    "    return L(sequential(*m.encoder),m.projector).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def my_splitter_bt_last_block_resnet50(m):\n",
    "    #Note: don't think we actually need this guy.\n",
    "    \"Freeze all but the last bottleneck layer\"\n",
    "    enc_except_final_block = sequential(*m.encoder[:-3], m.encoder[-3][:-1])\n",
    "    final_block_and_projector = sequential(m.encoder[-3][-1], m.projector)\n",
    "    return L(enc_except_final_block, final_block_and_projector).map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to use the above functions in an end to end fashion. First we get some data and plonk it into a dls, Then create an encoder, an augmentation pipeline, a learner, then fit\n",
    "the learner. This is the complete process of training BT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_bt_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "        \n",
    "    learn = Learner(dls,model=None, cbs=[BarlowTwins(aug,n_in=n_in,lmb=None,sparsity_level=None,\n",
    "                                                     print_augs=print_augs\n",
    "                                        )])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.barlow_twins.show(n=n)\n",
    "\n",
    "def show_vicreg_batch(dls,n_in,aug,n=2,print_augs=True,model_type='vicreg'):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "\n",
    "    learn = Learner(dls,model=None, cbs=[VICReg(aug,n_in=3,model_type=model_type)])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.vic_reg.show(n=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside random\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x2400 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide \n",
    "\n",
    "#dls = get_ssl_dls('cifar10',bs=32,size=128,device=default_device())\n",
    "#aug = get_bt_cifar10_aug_pipelines(32)\n",
    "#show_vicreg_batch(dls,n_in=3,aug=aug,n=2,print_augs=True,model_type='vicreg')\n",
    "show_vicreg_batch(dls,n_in=3,aug=aug,n=8,print_augs=True,model_type='br_vicreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SaveBarlowLearnerCheckpoint(Callback):\n",
    "    \"Save such that can resume training \"\n",
    "    def __init__(self, experiment_dir,start_epoch=0, save_interval=250,with_opt=True):\n",
    "        self.experiment_dir = experiment_dir\n",
    "        self.start_epoch = start_epoch\n",
    "        self.save_interval = save_interval\n",
    "        self.with_opt = with_opt  # Decide whether to save optimizer state as well.\n",
    "\n",
    "    def after_epoch(self):\n",
    "        if (self.epoch+1) % self.save_interval == 0 and self.epoch>=self.start_epoch:\n",
    "            print(f\"Saving model and learner state at epoch {self.epoch}\")\n",
    "   \n",
    "            checkpoint_filename = f\"learner_checkpoint_epoch_{self.epoch}\"\n",
    "            checkpoint_path = os.path.join(self.experiment_dir, checkpoint_filename)\n",
    "            # Save the entire learner object, including the model's parameters and optimizer state.\n",
    "            self.learn.save(checkpoint_path, with_opt=self.with_opt)\n",
    "            print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "class SaveBarlowLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        encoder_filename = f\"trained_encoder_epoch_{self.epoch}.pth\"\n",
    "        encoder_path = os.path.join(self.experiment_dir, encoder_filename)\n",
    "        torch.save(self.learn.model.encoder.state_dict(), encoder_path)\n",
    "        print(f\"encoder state dict saved to {encoder_path}\")\n",
    "\n",
    "\n",
    "class SaveVicRegLearnerModel(Callback):\n",
    "    def __init__(self, experiment_dir):\n",
    "        self.experiment_dir = experiment_dir\n",
    "\n",
    "    def after_fit(self):\n",
    "        model_filename = f\"trained_model_epoch_{self.epoch}.pth\"\n",
    "        model_path = os.path.join(self.experiment_dir, model_filename)\n",
    "        torch.save(self.learn.model.state_dict(), model_path)\n",
    "        print(f\"Model state dict saved to {model_path}\")\n",
    "\n",
    "        left_encoder_filename = f\"trained_left_encoder_epoch_{self.epoch}.pth\"\n",
    "        left_encoder_path = os.path.join(self.experiment_dir, left_encoder_filename)\n",
    "        torch.save(self.learn.model.left_encoder.state_dict(), left_encoder_path)\n",
    "        print(f\"Left encoder state dict saved to {left_encoder_path}\")\n",
    "\n",
    "        right_encoder_filename = f\"trained_right_encoder_epoch_{self.epoch}.pth\"\n",
    "        right_encoder_path = os.path.join(self.experiment_dir, right_encoder_filename)\n",
    "        torch.save(self.learn.model.right_encoder.state_dict(), right_encoder_path)\n",
    "        print(f\"Right encoder state dict saved to {right_encoder_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_barlow_model(arch,ps,hs,path):\n",
    "\n",
    "    encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_barlow_twins_model(encoder, hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_vicreg_model(arch,ps,hs,path):\n",
    "\n",
    "    left_encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    right_encoder = resnet_arch_to_encoder(arch=arch, weight_type='random')\n",
    "    model = create_vicreg_model(left_encoder,right_encoder,hidden_size=hs, projection_size=ps)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BarlowTrainer:\n",
    "    \"Setup a learner for training a BT model. Can do transfer learning, normal training, or resume training.\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,#An encoder followed by a projector\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 lmb,\n",
    "                 sparsity_level,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 splitter_str='none',\n",
    "                 num_it=100, #Number of iterations to run lr_find for.\n",
    "                 load_learner_path=None, #Path to load learner from (optional)\n",
    "                 experiment_dir=None, #Where to save model checkpoints (optional)\n",
    "                 start_epoch=0, #Which epoch to start from\n",
    "                 save_interval=None, #How often to save model checkpoints (optional). \n",
    "                 export=False,\n",
    "                 ):\n",
    "\n",
    "        store_attr()\n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    \n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics.\n",
    "\n",
    "        Returns:\n",
    "        - learn: The Learner object.\n",
    "        \"\"\"\n",
    "      \n",
    "        self.model.to(self.device)\n",
    "\n",
    "\n",
    "        cbs = [BarlowTwins(self.bt_aug_pipelines,n_in=self.n_in,lmb=self.lmb,\n",
    "                           sparsity_level=self.sparsity_level,print_augs=False,\n",
    "                           model_type=self.model_type\n",
    "                           )\n",
    "              ]\n",
    "\n",
    "        learn=Learner(self.dls,self.model,splitter=my_splitter_bt,wd=self.wd, cbs=cbs\n",
    "                     )\n",
    "        \n",
    "        if self.load_learner_path: learn.load(self.load_learner_path,with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir:\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export:\n",
    "            cbs.append(SaveBarlowLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "                \n",
    "    \n",
    "    def bt_transfer_learning(self,freeze_epochs:int,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is already pretrained, we can do transfer learning.\n",
    "            Freeze encoder, train projector for a few epochs, then unfreeze and train all. \n",
    "        \"\"\"\n",
    "        self.learn.freeze()\n",
    "        test_grad_off(self.learn.encoder)\n",
    "        self.learn.fit(freeze_epochs)\n",
    "\n",
    "         # Check if the splitter is 'my_splitter_bt_last_block_resnet50'\n",
    "        if self.splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "            # Unfreeze only the last bottleneck block\n",
    "            for param in self.learn.model.encoder[-3][-1].parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "            print(f'splitter_str={self.splitter_str}')\n",
    "        else:\n",
    "            # Unfreeze the entire encoder\n",
    "            self.learn.unfreeze()\n",
    "            test_grad_on(self.learn.model)\n",
    "        \n",
    "        \n",
    "        self.learn.summary()\n",
    "\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it) #lets find a good maximum lr\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley, cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def bt_learning(self,epochs:int,interrupt_epoch:int):\n",
    "        \"\"\"If the encoder is not pretrained, we can do normal training.\n",
    "        \"\"\"\n",
    "\n",
    "        lrs = self.learn.lr_find(num_it=self.num_it)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs, lrs.valley,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "    \n",
    "    def continue_bt_learning(self,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Resume training with `fit_one_cycle` after loading a learner.\n",
    "        \"\"\"\n",
    "        \n",
    "        test_ne(self.load_learner_path,None)\n",
    "\n",
    "        self.learn.fit_one_cycle(epochs,start_epoch=start_epoch,cbs=self._get_training_cbs(interrupt_epoch))\n",
    "\n",
    "    def train(self,learn_type, freeze_epochs:int,epochs:int,start_epoch:int,interrupt_epoch:int):\n",
    "        \"\"\"Train model using BT\n",
    "        \"\"\"\n",
    "        if learn_type == 'transfer_learning':\n",
    "            \n",
    "            self.bt_transfer_learning(freeze_epochs=freeze_epochs,epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        elif learn_type=='continue_learning':\n",
    "            self.continue_bt_learning(epochs=epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "        \n",
    "        elif learn_type=='standard':\n",
    "            self.bt_learning(epochs=epochs,interrupt_epoch=interrupt_epoch)\n",
    "\n",
    "        else: raise Exception(\"Invalid weight_type\")\n",
    "\n",
    "        return self.learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can inherit from the above for vicreg version. Just setting up the learner is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VICRegTrainer(BarlowTrainer):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 dls,\n",
    "                 bt_aug_pipelines,\n",
    "                 sparsity_level,\n",
    "                 sim_coeff,\n",
    "                 std_coeff,\n",
    "                 cov_coeff,\n",
    "                 n_in,\n",
    "                 model_type,\n",
    "                 wd,\n",
    "                 device,\n",
    "                 splitter_str='none',\n",
    "                 num_it=100,\n",
    "                 load_learner_path=None,\n",
    "                 experiment_dir=None,\n",
    "                 start_epoch=0,\n",
    "                 save_interval=None,\n",
    "                 export=False):\n",
    "        \n",
    "        \n",
    "                # Store VICReg-specific attributes\n",
    "        store_attr('sim_coeff,std_coeff,cov_coeff') #why doesn't this work?\n",
    "        # Call the parent constructor with None for lmb\n",
    "        super().__init__(model, dls, bt_aug_pipelines,None,sparsity_level, n_in, model_type,\n",
    "                         wd, device, splitter_str, num_it, load_learner_path,\n",
    "                         experiment_dir, start_epoch, save_interval, export)\n",
    "        \n",
    "        self.learn = self.setup_learn()\n",
    "\n",
    "    def setup_learn(self):\n",
    "        \"\"\"\n",
    "        Sets up the learner with the model, callbacks, and metrics for VICReg.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        cbs = [VICReg(self.bt_aug_pipelines, n_in=self.n_in, \n",
    "                      sim_coeff=self.sim_coeff, std_coeff=self.std_coeff, cov_coeff=self.cov_coeff,\n",
    "                      model_type=self.model_type, print_augs=False)]\n",
    "\n",
    "        # Use the splitter based on splitter_str\n",
    "        # if self.splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "        #     splitter = my_splitter_bt_last_block_resnet50\n",
    "        # else:\n",
    "        #     splitter = my_splitter_bt\n",
    "        #learn = Learner(self.dls, self.model, splitter=splitter, wd=self.wd, cbs=cbs)\n",
    "        \n",
    "        #TODO: Implement custom splitter for VICReg\n",
    "        #splitter not supported yet for vicreg: we can do this but need a custom splitter.\n",
    "        #The issue is just that vicreg e.g. has encoder_left and encoder_right, v.s.\n",
    "        #BT which just has one encoder. Just leaving splitter off for now\n",
    "        learn = Learner(self.dls, self.model, wd=self.wd, cbs=cbs)\n",
    "        if self.load_learner_path: \n",
    "            learn.load(self.load_learner_path, with_opt=True)\n",
    "\n",
    "        return learn\n",
    "    \n",
    "    def _get_training_cbs(self,interrupt_epoch):\n",
    "        \"Add train-time cbs to learner. Note e.g. we don't want these in operation when we're doing lr_find.\"\n",
    "\n",
    "        \n",
    "        cbs=[InterruptCallback(interrupt_epoch)]\n",
    "        \n",
    "        if self.experiment_dir: #same as for barlow\n",
    "            cbs.append(SaveBarlowLearnerCheckpoint(experiment_dir=self.experiment_dir,\n",
    "                                             start_epoch = self.start_epoch,\n",
    "                                             save_interval=self.save_interval,\n",
    "                                             )\n",
    "                      )\n",
    "        \n",
    "        if self.export: #different to barlow. Clearly we in principle want this \n",
    "                        #more abstract so it just works. But ok.\n",
    "            cbs.append(SaveVicRegLearnerModel(experiment_dir=self.experiment_dir))\n",
    "   \n",
    "        return cbs\n",
    "\n",
    "    # # Override the train method if necessary\n",
    "    # def train(self, learn_type, freeze_epochs:int, epochs:int, start_epoch:int, interrupt_epoch:int):\n",
    "    #     \"\"\"Train model using VICReg\"\"\"\n",
    "    #     # You can customize this method for VICReg-specific training logic if needed\n",
    "    #     return super().train(learn_type, freeze_epochs, epochs, start_epoch, interrupt_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that splitting/freezings works in `bt_transfer_learning`.\n",
    "\n",
    "It's a bit hacky but looks to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "encoder = resnet_arch_to_encoder(arch='resnet50', weight_type=random)\n",
    "model = create_barlow_twins_model(encoder, hidden_size=8192, projection_size=8192)\n",
    "dls = get_ssl_dls('cifar10',bs=64,size=32,device=default_device())\n",
    "\n",
    "cbs = [BarlowTwins(get_bt_aug_pipelines(bt_augs='bt_cifar10_aug_pipelines', size=32),\n",
    "       n_in=3,lmb=1/8192,sparsity_level=None,print_augs=False,\n",
    "        model_type='barlow_twins'\n",
    "                    )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy pasted from `bt_transfer_learning`\n",
    "\n",
    "Bit hacky, but ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BarlowTwinsModel (Input shape: 64 x 3 x 32 x 32)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     64 x 64 x 16 x 16   \n",
       "Conv2d                                    9408       False     \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "MaxPool2d                                                      \n",
       "Conv2d                                    4096       False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 8 x 8     \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 8 x 8    \n",
       "Conv2d                                    16384      False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 8 x 8    \n",
       "Conv2d                                    32768      False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 4 x 4    \n",
       "Conv2d                                    65536      False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 4 x 4    \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    524288     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 2 x 2   \n",
       "Conv2d                                    262144     False     \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 2 x 2    \n",
       "Conv2d                                    524288     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2097152    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    False     \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "AdaptiveAvgPool2d                                              \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048           \n",
       "Flatten                                                        \n",
       "____________________________________________________________________________\n",
       "                     64 x 8192           \n",
       "Linear                                    16785408   True      \n",
       "BatchNorm1d                               16384      True      \n",
       "ReLU                                                           \n",
       "Linear                                    67117056   True      \n",
       "BatchNorm1d                               16384      True      \n",
       "ReLU                                                           \n",
       "Linear                                    67117056   True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 174,560,320\n",
       "Total trainable params: 155,561,856\n",
       "Total non-trainable params: 18,998,464\n",
       "\n",
       "Optimizer used: <function Adam at 0x7fd2ae41f250>\n",
       "Loss function: <bound method BarlowTwins.lf of BarlowTwins>\n",
       "\n",
       "Model frozen up to parameter group #1\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - CastToTensor\n",
       "  - BarlowTwins\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide \n",
    "learn=Learner(dls,model,splitter=my_splitter_bt,cbs=cbs\n",
    "             )\n",
    "\n",
    "\n",
    "splitter_str = 'my_splitter_bt_last_block_resnet50'\n",
    "#splitter_str='none'\n",
    "learn.freeze() #freeze everything up to projector\n",
    "test_grad_off(learn.encoder)\n",
    "\n",
    "    # Check if the splitter is 'my_splitter_bt_last_block_resnet50'\n",
    "if splitter_str == 'my_splitter_bt_last_block_resnet50':\n",
    "    # Unfreeze only the last bottleneck block\n",
    "    for param in learn.model.encoder[-3][-1].parameters():\n",
    "        param.requires_grad = True\n",
    "else:\n",
    "    # Unfreeze the entire encoder\n",
    "    learn.unfreeze()\n",
    "\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a BT model. Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "    if hasattr(config,'splitter_str'):\n",
    "        splitter_str=config.splitter_str\n",
    "    else:\n",
    "        splitter_str='none'\n",
    "\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "    encoder = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    \n",
    "    model = create_barlow_twins_model(encoder, hidden_size=config.hs, projection_size=config.ps)\n",
    "\n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    bt_trainer = BarlowTrainer(model=model,\n",
    "                    dls=dls,\n",
    "                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                    lmb=config.lmb,\n",
    "                    sparsity_level=config.sparsity_level,\n",
    "                    n_in=config.n_in,\n",
    "                    model_type=config.model_type,\n",
    "                    wd=config.wd,\n",
    "                    num_it=config.num_it,\n",
    "                    device=device,\n",
    "                    splitter_str=splitter_str,\n",
    "                    load_learner_path=load_learner_path,\n",
    "                    experiment_dir=experiment_dir,\n",
    "                    start_epoch=start_epoch,\n",
    "                    save_interval=config.save_interval,\n",
    "                    export=export\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = bt_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above but for vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_vicreg_train(config,\n",
    "        start_epoch = 0,\n",
    "        interrupt_epoch = 100,\n",
    "        load_learner_path=None,\n",
    "        learn_type = 'standard', #can be 'standard', 'transfer_learning', or 'continue_learning'\n",
    "        experiment_dir=None,\n",
    "        ):\n",
    "    \"Basically map from config to training a vicreg model (standard or br) Optionally save checkpoints of learner, to reload and continue;\"\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the device for model training (CUDA or CPU)\n",
    "    device = default_device()\n",
    "\n",
    "    #This is for backwards compatibility with configs that don't have a splitter_str.\n",
    "    if hasattr(config,'splitter_str'):\n",
    "        splitter_str=config.splitter_str\n",
    "    else:\n",
    "        splitter_str='none'\n",
    "\n",
    "\n",
    "    # Construct the model based on the configuration\n",
    "    # This involves selecting the architecture and setting model-specific hyperparameters.\n",
    "\n",
    "    #vicreg model may require two encoders, so we need to handle this case\n",
    "    encoder_left = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "    if config.model_type == 'vicreg':\n",
    "\n",
    "        if not config.shared_encoder:\n",
    "            encoder_right = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "        else:\n",
    "            encoder_right=encoder_left\n",
    "\n",
    "        model = create_vicreg_model(encoder_left, encoder_right, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "    # #At present, the arch is: encoder_left = encoder_right =  Transformer(CNN_Left(x),CNN_right(x)).\n",
    "    elif config.model_type == 'br_vicreg':\n",
    "        #Same as above for now since we are using left/right split augmentation\n",
    "\n",
    "        print('We are using left/right image split augmentation')\n",
    "        print('the arch is standard siamese.')\n",
    "        if not config.shared_encoder:\n",
    "            encoder_right = resnet_arch_to_encoder(arch=config.arch, weight_type=config.weight_type)\n",
    "        else:\n",
    "            encoder_right=encoder_left\n",
    "\n",
    "        model = create_vicreg_model(encoder_left, encoder_right, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     test_eq(config.arch,'cifar_resnet18_swin')\n",
    "    #     swin = BinocularAwareSwin()\n",
    "    #     cnn = resnet_arch_to_encoder('cifar_resnet18', n_in=96)\n",
    "    #     encoder = BinocularSwintoRes(swin=swin, cnn=cnn)\n",
    "\n",
    "    #     swin = BinocularAwareSwin()\n",
    "    #     cnn = resnet_arch_to_encoder('cifar_resnet18', n_in=96)\n",
    "    #     encoder = BinocularSwintoRes(swin=swin, cnn=cnn)\n",
    "    #     _x = torch.rand(1, 3, 32, 32)\n",
    "    #     _x = encoder(_x)\n",
    "    #     model = create_vicreg_model(encoder, encoder, hidden_size=config.hs, projection_size=config.ps, shared_projector=config.shared_projector)\n",
    "    \n",
    "    # Prepare data loaders according to the dataset specified in the configuration\n",
    "    dls = get_ssl_dls(dataset=config.dataset, bs=config.bs,size=config.size, device=device,pct_dataset=config.pct_dataset)\n",
    "\n",
    "    # Set up data augmentation pipelines as specified in the configuration\n",
    "    #(this is same as for bt)\n",
    "    bt_aug_pipelines = get_bt_aug_pipelines(bt_augs=config.bt_augs, size=config.size)\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "\n",
    "    if experiment_dir and config.epochs == interrupt_epoch:\n",
    "        export=True\n",
    "    else:\n",
    "        export=False\n",
    "\n",
    "    #Setup the bt trainer. basically a `Learner` with a few extra bells and whistles\n",
    "    vicreg_trainer = VICRegTrainer(model=model,\n",
    "                                    dls=dls,\n",
    "                                    bt_aug_pipelines=bt_aug_pipelines,\n",
    "                                    sparsity_level=config.sparsity_level,\n",
    "                                    sim_coeff=config.sim_coeff,\n",
    "                                    std_coeff=config.std_coeff,\n",
    "                                    cov_coeff=config.cov_coeff,\n",
    "                                    n_in=config.n_in,\n",
    "                                    model_type=config.model_type,\n",
    "                                    wd=config.wd,\n",
    "                                    num_it=config.num_it,\n",
    "                                    device=device,\n",
    "                                    splitter_str=splitter_str,\n",
    "                                    load_learner_path=load_learner_path,\n",
    "                                    experiment_dir=experiment_dir,\n",
    "                                    start_epoch=start_epoch,\n",
    "                                    save_interval=config.save_interval,\n",
    "                                    export=export\n",
    "\n",
    "                                    )\n",
    "\n",
    "    # Train the model with the specified configurations and save `learn` checkpoints\n",
    "    learn = vicreg_trainer.train(learn_type=learn_type,freeze_epochs=config.freeze_epochs,epochs=config.epochs,start_epoch=start_epoch,interrupt_epoch=interrupt_epoch)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "BinocularSwintoRes working ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swin = BinocularAwareSwin()\n",
    "cnn = resnet_arch_to_encoder('cifar_resnet18', n_in=96)\n",
    "encoder = BinocularSwintoRes(swin=swin, cnn=cnn)\n",
    "\n",
    "swin = BinocularAwareSwin()\n",
    "cnn = resnet_arch_to_encoder('cifar_resnet18', n_in=96)\n",
    "encoder = BinocularSwintoRes(swin=swin, cnn=cnn)\n",
    "_x = torch.rand(1, 3, 32, 32)\n",
    "_x = encoder(_x)\n",
    "print(_x.shape)\n",
    "print('BinocularSwintoRes working ok')\n",
    "\n",
    "in_channels(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_bt_experiment_state(config,base_dir):\n",
    "    \"\"\"Get the load_learner_path, learn_type, start_epoch, interrupt_epoch for BT experiment.\n",
    "       Basically this tells us how to continue learning (e.g. we have run two sessions for \n",
    "       100 epochs, and want to continue for another 100 epochs). Return values are\n",
    "       None if we are starting from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    load_learner_path, _  = get_highest_num_path(base_dir, config)\n",
    "    #TODO:\n",
    "    #We can get start_epoch, interrupt epoch from `get_highest_epoch_path` + save_interval (may be None!)\n",
    "    start_epoch=0 if load_learner_path is None else int(load_learner_path.split('_')[-1])+1\n",
    "    \n",
    "    if start_epoch >= config.epochs:\n",
    "        print(f\"start_epoch={start_epoch}, but already completed {config.epochs} epochs. Exiting.\")\n",
    "        sys.exit()\n",
    "\n",
    "    interrupt_epoch = start_epoch + config.save_interval\n",
    "\n",
    "    #We can also get the learn_type from the load_learner_path + weight_type. \n",
    "    \n",
    "    if config.weight_type == 'random':\n",
    "        learn_type = 'standard'\n",
    "    \n",
    "    elif 'pretrained' in config.weight_type:\n",
    "        learn_type = 'transfer_learning'\n",
    "\n",
    "    learn_type = learn_type if load_learner_path is None else 'continue_learning'\n",
    "\n",
    "    return load_learner_path, learn_type, start_epoch, interrupt_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_bt_experiment(config,\n",
    "                      base_dir,\n",
    "                      ):\n",
    "        \"\"\"Run several epochs of the experiment as defined in the config and where we are up to. e.g. epoch 0, or resuming\n",
    "        at epoch 99 etc. Basically a stateful version of `main_bt_train` that can be resumed. And saving.\n",
    "        \"\"\"\n",
    "    \n",
    "        \n",
    "        experiment_dir, experiment_hash,git_commit_hash = setup_experiment(config,base_dir)\n",
    "        load_learner_path, learn_type, start_epoch, interrupt_epoch = get_bt_experiment_state(config,base_dir)      \n",
    "        \n",
    "        if 'barlow' in config.model_type:\n",
    "        \n",
    "                main_bt_train(config=config,\n",
    "                        start_epoch=start_epoch,\n",
    "                        interrupt_epoch=interrupt_epoch,\n",
    "                        load_learner_path=load_learner_path,\n",
    "                        learn_type=learn_type,\n",
    "                        experiment_dir=experiment_dir,\n",
    "                        )\n",
    "        elif 'vicreg' in config.model_type:\n",
    "                \n",
    "                main_vicreg_train(config=config,\n",
    "                        start_epoch=start_epoch,\n",
    "                        interrupt_epoch=interrupt_epoch,\n",
    "                        load_learner_path=load_learner_path,\n",
    "                        learn_type=learn_type,\n",
    "                        experiment_dir=experiment_dir,\n",
    "                        )\n",
    "\n",
    "        # Save a metadata file in the experiment directory with the Git commit hash and other details\n",
    "        save_metadata_file(experiment_dir=experiment_dir, git_commit_hash=git_commit_hash)\n",
    "\n",
    "        # After experiment execution and all processing are complete\n",
    "        update_experiment_index(base_dir,{\n",
    "                \"experiment_hash\": experiment_hash,  # Unique identifier derived from the experiment's configuration\n",
    "                \"experiment_dir\": experiment_dir,  # Absolute path to the experiment's dedicated directory\n",
    "                \"git_commit_hash\": git_commit_hash,  # Git commit hash for the code version used in the experiment\n",
    "                # Potentially include additional details collected during or after the experiment, such as:\n",
    "                # Any other metadata or results summary that is relevant to the experiment\n",
    "                                })\n",
    "        \n",
    "        return experiment_dir,experiment_hash #Return the experiment_dir so we can easily access the results of the experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full end to end example with BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     config_path = '../configs/cifar10/bt_test_config.yaml'\n",
    "#     config = load_config(config_path)\n",
    "\n",
    "#     # config.model_type = 'sparse_head_barlow_twins'\n",
    "#     # config.sparsity_level=10\n",
    "#     # config.epochs=100\n",
    "#     # config.save_interval=100\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     #get path to fully fitted model\n",
    "#     path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "#     model = load_barlow_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "#     print(model)\n",
    "\n",
    "#     #New config but the first part of experiment_dir is same - just hash is different\n",
    "#     #It shouldnt find a max file path\n",
    "#     config.epochs=config.epochs+1\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full end to end example for vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "#     config_path = '../configs/cifar10/vicreg_test_config.yaml'\n",
    "#     config = load_config(config_path)\n",
    "\n",
    "#     # config.model_type = 'sparse_head_barlow_twins'\n",
    "#     # config.sparsity_level=10\n",
    "#     # config.epochs=100\n",
    "#     # config.save_interval=100\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "    \n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "#     print(os.listdir(experiment_dir))\n",
    "#     print(os.listdir(base_dir))\n",
    "#     print('experiment_dir and base_dir')\n",
    "\n",
    "#     #get path to fully fitted model\n",
    "#     path = os.path.join(experiment_dir,f'trained_model_epoch_{config.epochs-1}.pth')\n",
    "#     model = load_vicreg_model(arch=config.arch,ps=config.ps,hs=config.hs,path=path)\n",
    "#     print(model)\n",
    "\n",
    "#     #New config but the first part of experiment_dir is same - just hash is different\n",
    "#     #It shouldnt find a max file path\n",
    "#     config.epochs=config.epochs+1\n",
    "#     experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify runs with br_vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: cifar10\n",
      "arch: cifar_resnet18_swin\n",
      "train_type: SSL\n",
      "weight_type: random\n",
      "size: 32\n",
      "n_in: 3\n",
      "bs: 128\n",
      "ps: 512\n",
      "hs: 512\n",
      "bt_augs: bt_cifar10_aug_pipelines\n",
      "model_type: br_vicreg\n",
      "sim_coeff: 25.0\n",
      "std_coeff: 25.0\n",
      "cov_coeff: 1.0\n",
      "sparsity_level: None\n",
      "shared_projector: True\n",
      "shared_encoder: True\n",
      "wd: 1.5e-06\n",
      "freeze_epochs: None\n",
      "num_it: 10\n",
      "pct_dataset: 0.003\n",
      "epochs: 6\n",
      "save_interval: 3\n",
      "encoder_dimension: 512\n",
      "The experiment_dir is: /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpixuogekg/SSL/cifar10/cifar_resnet18_swin/b9082aa9 and the experiment hash is: b9082aa9\n",
      "Configuration saved to /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpixuogekg/SSL/cifar10/cifar_resnet18_swin/b9082aa9/config.yaml\n",
      "The git hash is: dfb0c49b0b9b118b6a33713974b0d8fc23dbba8c\n",
      "Looking in /var/folders/95/qkdymsl93lz1tvnqky1vn_p00000gn/T/tmpixuogekg/SSL/cifar10/cifar_resnet18_swin/b9082aa9 for highest num saved\n",
      "hi\n",
      "torch.Size([1, 512])\n",
      "BinocularSwintoRes working ok\n",
      "n_in is: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/11 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m config\u001b[38;5;241m.\u001b[39march \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar_resnet18_swin\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m pretty_print_ns(config)\n\u001b[0;32m---> 10\u001b[0m experiment_dir,experiment_hash \u001b[38;5;241m=\u001b[39m \u001b[43mmain_bt_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 25\u001b[0m, in \u001b[0;36mmain_bt_experiment\u001b[0;34m(config, base_dir)\u001b[0m\n\u001b[1;32m     16\u001b[0m         main_bt_train(config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m     17\u001b[0m                 start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch,\n\u001b[1;32m     18\u001b[0m                 interrupt_epoch\u001b[38;5;241m=\u001b[39minterrupt_epoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 experiment_dir\u001b[38;5;241m=\u001b[39mexperiment_dir,\n\u001b[1;32m     22\u001b[0m                 )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvicreg\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[0;32m---> 25\u001b[0m         \u001b[43mmain_vicreg_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                \u001b[49m\u001b[43mload_learner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_learner_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlearn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexperiment_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Save a metadata file in the experiment directory with the Git commit hash and other details\u001b[39;00m\n\u001b[1;32m     34\u001b[0m save_metadata_file(experiment_dir\u001b[38;5;241m=\u001b[39mexperiment_dir, git_commit_hash\u001b[38;5;241m=\u001b[39mgit_commit_hash)\n",
      "Cell \u001b[0;32mIn[28], line 95\u001b[0m, in \u001b[0;36mmain_vicreg_train\u001b[0;34m(config, start_epoch, interrupt_epoch, load_learner_path, learn_type, experiment_dir)\u001b[0m\n\u001b[1;32m     73\u001b[0m vicreg_trainer \u001b[38;5;241m=\u001b[39m VICRegTrainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     74\u001b[0m                                 dls\u001b[38;5;241m=\u001b[39mdls,\n\u001b[1;32m     75\u001b[0m                                 bt_aug_pipelines\u001b[38;5;241m=\u001b[39mbt_aug_pipelines,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \n\u001b[1;32m     92\u001b[0m                                 )\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Train the model with the specified configurations and save `learn` checkpoints\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mvicreg_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfreeze_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreeze_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m learn\n",
      "Cell \u001b[0;32mIn[23], line 126\u001b[0m, in \u001b[0;36mBarlowTrainer.train\u001b[0;34m(self, learn_type, freeze_epochs, epochs, start_epoch, interrupt_epoch)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinue_bt_learning(epochs\u001b[38;5;241m=\u001b[39mepochs,start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch,interrupt_epoch\u001b[38;5;241m=\u001b[39minterrupt_epoch)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learn_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbt_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43minterrupt_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\n",
      "Cell \u001b[0;32mIn[23], line 103\u001b[0m, in \u001b[0;36mBarlowTrainer.bt_learning\u001b[0;34m(self, epochs, interrupt_epoch)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbt_learning\u001b[39m(\u001b[38;5;28mself\u001b[39m,epochs:\u001b[38;5;28mint\u001b[39m,interrupt_epoch:\u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124;03m\"\"\"If the encoder is not pretrained, we can do normal training.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     lrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_it\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_it\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\u001b[38;5;241m.\u001b[39mfit_one_cycle(epochs, lrs\u001b[38;5;241m.\u001b[39mvalley,cbs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_training_cbs(interrupt_epoch))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/callback/schedule.py:293\u001b[0m, in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[1;32m    291\u001b[0m n_epoch \u001b[38;5;241m=\u001b[39m num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    292\u001b[0m cb\u001b[38;5;241m=\u001b[39mLRFinder(start_lr\u001b[38;5;241m=\u001b[39mstart_lr, end_lr\u001b[38;5;241m=\u001b[39mend_lr, num_it\u001b[38;5;241m=\u001b[39mnum_it, stop_div\u001b[38;5;241m=\u001b[39mstop_div)\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_logging(): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suggest_funcs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     lrs, losses \u001b[38;5;241m=\u001b[39m tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorder\u001b[38;5;241m.\u001b[39mlrs[num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m]), tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorder\u001b[38;5;241m.\u001b[39mlosses[num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:256\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:245\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:231\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:227\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    225\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/learner.py:205\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_one_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_pred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[37], line 19\u001b[0m, in \u001b[0;36mVICRegModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x): \u001b[38;5;66;03m#x is stacked xi,xj the two augmented views of batch\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     x1, x2 \u001b[38;5;241m=\u001b[39m x[:x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m], x[x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m---> 19\u001b[0m     z1,z2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_projector(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_encoder(x1)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_projector(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z1, z2\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/base_rbt/base_rbt/utils.py:331\u001b[0m, in \u001b[0;36mBinocularSwintoRes.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    329\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswin(x)\n\u001b[1;32m    330\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Shape: (B, embed_dim, 32, 32)\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/fastai/torch_core.py:378\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 378\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/_tensor.py:1279\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1279\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "with tempfile.TemporaryDirectory() as base_dir:\n",
    "    \n",
    "    config_path = '../configs/cifar10/vicreg_test_config.yaml'\n",
    "    config = load_config(config_path)\n",
    "    config.model_type = 'br_vicreg'\n",
    "    config.arch = 'cifar_resnet18_swin'\n",
    "\n",
    "    pretty_print_ns(config)\n",
    "    experiment_dir,experiment_hash = main_bt_experiment(config,base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
