{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base_rbt\n",
    "\n",
    "> Base functions and classes we use for our hacking on BT / RBT and related ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "!pip install git+https://github.com/hamish-haggerty/base_rbt.git#egg='base_rbt'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing, import like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_rbt.base_model import *\n",
    "from base_rbt.base_lf import *\n",
    "from base_rbt.base_linear import *\n",
    "from base_rbt.helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need some other libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import self_supervised\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we give an end to end example. There are only a couple of steps. We first we need a dls i.e. a dataloader; then patch in our own definition of a loss funtion `lf`. Then it is a simple matter of defining an augmentation pipeline and fitting the model. We go through each of these now.\n",
    "First, get some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get some MNIST data and plonk it into a dls\n",
    "path = untar_data(URLs.MNIST)\n",
    "items = get_image_files(path/'training') #i.e. NOT testing!!!\n",
    "items = items.shuffle()\n",
    "items = items[0:10]\n",
    "split = RandomSplitter(valid_pct=0.0)\n",
    "tds = Datasets(items, [PILImageBW.create, [parent_label, Categorize()]], splits=split(items))\n",
    "dls = tds.dataloaders(bs=5,num_workers=0, after_item=[ToTensor(), IntToFloatTensor()], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to construct the `lf`. Here is a (silly!) modification to the BT loss function. We are just scaling the bt loss function by $0.01$. However, this illustrates the general API if we want to modify the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb): return 0.01*lf_bt(pred, self.I,self.lmb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we patch in our own definition of a loss function, using the tools from `base_lf`.  First define it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def lf_rbt(pred,seed,I,lmb):\n",
    "    \n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "    C = (z1norm.T @ z2norm) / bs \n",
    "    cdiff = (C - I)**2\n",
    "\n",
    "    #Get either max corr(f(x),g(y)) {if indep=True} or max 0.5*corr(x,g(y)) + 0.5*corr(f(x),y), {if indep=False}\n",
    "    #where the max is over f and g. Please see base_lf for details\n",
    "    CdiffSup = Cdiff_Sup(I=I,qs=ps,inner_steps=5,indep=False)\n",
    "    cdiff_2 = CdiffSup(z1norm,z2norm) #same shape as cdiff\n",
    "\n",
    "    #As above but f and g are now randomly sampled sinusoid. Please see base_lf for details\n",
    "    CdiffRand = Cdiff_Rand(seed=seed,std=0.1,K=2,indep=True)\n",
    "    cdiff_2_2 = CdiffRand(z1norm,z2norm) #same shape as cdiff\n",
    "\n",
    "    cdiff_2 = 0.5*cdiff_2_2 + 0.5*cdiff_2 #convex combination of rand and sup terms.\n",
    "\n",
    "    rr = cdiff_2*(1-I)*lmb #redundancy reduction term (scaled by lmb)\n",
    "\n",
    "    loss = (cdiff*I + rr).sum() #sum of redundancy reduction term and invariance term\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def lf_rat(pred,I,lmb):\n",
    "    \n",
    "    bs,nf = pred.size(0)//2,pred.size(1)\n",
    "    \n",
    "    pred1=pred[0]\n",
    "    pred2=pred[1]\n",
    "\n",
    "    z1, z2 = pred1[:bs],pred1[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    #Used to encode, primarily invariance\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    #Used to encode, primarily redundancy-reduction\n",
    "    z1_two,z2_two = pred2[:bs],pred2[bs:]\n",
    "    z1norm_two = (z1_two - z1_two.mean(0)) / z1_two.std(0, unbiased=False)\n",
    "    z2norm_two = (z2_two - z2_two.mean(0)) / z2_two.std(0, unbiased=False)\n",
    "\n",
    "    #The invariance term\n",
    "    Invar = (z1norm-z2norm).pow(2) #add to loss (there are d-terms)\n",
    "\n",
    "    #The redundancy reduction term\n",
    "    CdiffRand = Cdiff_Rand(seed=0,std=0.1,K=2,indep=True)\n",
    "    cdiff = CdiffRand(z1norm_two,z2norm_two)\n",
    "    CdiffSup = Cdiff_Sup(I=I,qs=ps,inner_steps=5,indep=False)\n",
    "    cdiff_2 = CdiffSup(z1norm_two,z2norm_two)\n",
    "    redun_reduc = 0.5*cdiff + 0.5*cdiff_2 #add to loss\n",
    "\n",
    "    #Make the reps different term\n",
    "    CdiffRand = Cdiff_Rand(seed=0,std=0.1,K=2,indep=True)\n",
    "    cdiff1  = CdiffRand(z1norm,z1norm_two)\n",
    "    CdiffSup = Cdiff_Sup(I=I,qs=ps,inner_steps=5,indep=False)\n",
    "    cdiff11 = CdiffSup(z1norm,z1norm_two)\n",
    "    cdiff1 = 0.5*cdiff1 + 0.5*cdiff11\n",
    "\n",
    "            #d terms                   #d^2 + d^2 terms\n",
    "    loss = Invar.sum() + self.lmb*(0.5*redun_reduc + 0.5*cdiff).sum() #Have to work out scaling constants (grid search?)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loss function has both a `random` component and a `sup` component.\n",
    "Next patch it in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @patch\n",
    "# def lf(self:BarlowTwins, pred,*yb): return lf_rbt(pred,seed=self.seed,I=self.I,lmb=self.lmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb): return lf_rat(pred,I=self.I,lmb=self.lmb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need an augmentation pipeline. Let's also take a look at what it looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianNoise -> RandomGaussianBlur -- {'p': 1.0, 'prob': 0.5, 's': 11, 's1': 3, 'same_on_batch': False} -> Normalize -- {'mean': tensor([[[[0.1310]]]]), 'std': tensor([[[[0.3080]]]]), 'axes': (0, 2, 3)}\n",
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> RandomGaussianNoise -> RandomGaussianBlur -- {'p': 1.0, 'prob': 0.5, 's': 11, 's1': 3, 'same_on_batch': False} -> Normalize -- {'mean': tensor([[[[0.1310]]]]), 'std': tensor([[[[0.3080]]]]), 'axes': (0, 2, 3)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x900 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_in=1\n",
    "fastai_encoder = create_fastai_encoder(xresnet18(),pretrained=False,n_in=1)\n",
    "\n",
    "#model = create_barlow_twins_model(fastai_encoder, hidden_size=10,projection_size=10)# projection_size=1024)\n",
    "model = create_p2barlow_twins_model(fastai_encoder, hidden_size=10,projection_size=10)# projection_size=1024)\n",
    "\n",
    "\n",
    "aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=28,\n",
    "                    rotate=False,jitter=False,bw=False,blur=True,solar=False, #Whether to use aug or not\n",
    "                    resize_scale=(0.5, 1.0),resize_ratio=(3/4, 4/3), rotate_deg=45,blur_s=11,s1=3,sol_t=0.05,sol_a=0.05, #hps of augs\n",
    "                    flip_p=0.5, rotate_p=0.3, jitter_p=0.3, bw_p=0.3, blur_p=0.5,sol_p=0.1, #prob of performing aug\n",
    "                    same_on_batch=False,stats=mnist_stats, cuda=(device=='cuda'))\n",
    "\n",
    "aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=28,\n",
    "                    rotate=False,jitter=False,bw=False,blur=True,solar=False, #Whether to use aug or not\n",
    "                    resize_scale=(0.5, 1.0),resize_ratio=(3/4, 4/3), rotate_deg=45,blur_s=11,s1=3,sol_t=0.05,sol_a=0.05, #hps of augs\n",
    "                    flip_p=0.5, rotate_p=0.3, jitter_p=0.3, bw_p=0.3, blur_p=0.5,sol_p=0.1, #prob of performing aug\n",
    "                    same_on_batch=False,stats=mnist_stats, cuda=(device=='cuda'))\n",
    "\n",
    "aug_pipelines = [aug_pipelines_1,aug_pipelines_1]\n",
    "tem = BarlowTwins(aug_pipelines,n_in=n_in,print_augs=True)\n",
    "learn = Learner(dls,model, cbs=[tem])\n",
    "b = dls.one_batch()\n",
    "learn._split(b)\n",
    "learn('before_batch')\n",
    "axes = learn.barlow_twins.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally,let's train RBT; We construct an encoder and a learner, then fit it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full usage of above\n",
    "ps=500 #projection size\n",
    "hs=ps #hidden size in mlp at the end; typically just = ps. \n",
    "fastai_encoder = create_fastai_encoder(xresnet18(),pretrained=False,n_in=1) #create the encoder\n",
    "model = create_barlow_twins_model(fastai_encoder, hidden_size=hs,projection_size=ps)#plonk the projector on the end of the encoder\n",
    "learn = Learner(dls,model, cbs=[BarlowTwins(aug_pipelines,n_in=1, print_augs=False)]) #build the learner\n",
    "#learn.fit(1) #train model, i.e. weights of encoder and projector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have trained the `fastai_encoder` can evaluate in various ways. e.g. linear evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ok now let's do an end to end CIFAR10 example. Let's comment a little more on the API as we go - this will be helpful when considering how to add functionality to (in particular) base_model**\n",
    "\n",
    "Here are the steps at a high level:\n",
    "- Define hps (e.g. batch size, projector dimension etc). Note that if the model changes then there may be different hps\n",
    "- Get the data (train, tune, test) -> dls,dls_val, dls_test\n",
    "- Patch in loss function definition\n",
    "- Setup/define augmentations, encoder, model, learner\n",
    "- Train BT/RBT (i.e. fit the learner\n",
    "- Train linear classifier and record performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1): We need the data, and to set all the hps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hps's\n",
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "cuda = (device=='cuda')\n",
    "seed=42\n",
    "n_in=3\n",
    "indim=1024 #find this by inspection, e.g. for resnet18 is 1024\n",
    "size=32\n",
    "ps=100\n",
    "seed=42 \n",
    "bs=64 #for training BT\n",
    "bs_val=128 #for training linear head\n",
    "bs_test=256 #for evaluating linear head\n",
    "ts=bs*2#00\n",
    "ts_val=bs_val*5\n",
    "ts_test=5*bs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data: dls, dls_val, dls_test\n",
    "#get the data: Need dls, dls_val, dls_test\n",
    "path = untar_data(URLs.CIFAR)\n",
    "fnames = get_image_files(path / \"train\")\n",
    "fnames.sort()\n",
    "#shuffle data (in reproducible way)\n",
    "seed_everything(seed=seed)\n",
    "fnames = fnames.shuffle()\n",
    "\n",
    "#fnames for train, eval and test\n",
    "fnames_train = fnames[0:ts]\n",
    "fnames_val = fnames[ts:ts+ts_val]\n",
    "fnames_test = fnames[ts+ts_val:ts+ts_val+ts_test]\n",
    "\n",
    "def label_func(fname):\n",
    "    return fname.name.split('_')[1].strip('png').strip('.')\n",
    "\n",
    "#labels for train,eval and test\n",
    "labels = [label_func(fname) for fname in fnames]\n",
    "labels_train = labels[0:ts]\n",
    "labels_val = labels[ts:ts+ts_val]\n",
    "labels_test = labels[ts+ts_val:ts+ts_val+ts_test]\n",
    "\n",
    "#Used for training encoder i.e. BT\n",
    "dls = ImageDataLoaders.from_lists(path, fnames_train, labels_train,bs=bs, item_tfms=[Resize(size=size)], #batch_tfms=[ToTensor(), IntToFloatTensor()],\n",
    "                                  valid_pct=0.0,num_workers=12,device=device,seed=seed)\n",
    "#Used for training linear classifier\n",
    "dls_val = ImageDataLoaders.from_lists(path, fnames_val, labels_val,bs=bs_val, item_tfms=[Resize(size=size)], #batch_tfms=[ToTensor(), IntToFloatTensor()],\n",
    "                                  valid_pct=0.0,num_workers=12,device=device,seed=seed)\n",
    "\n",
    "#Used for evaluating linear classifier\n",
    "dls_test = ImageDataLoaders.from_lists(path, fnames_test, labels_test,bs=bs_val, item_tfms=[Resize(size=size)], #batch_tfms=[ToTensor(), IntToFloatTensor()],\n",
    "                                  valid_pct=0.0,num_workers=12,device=device,seed=seed)\n",
    "\n",
    "\n",
    "set(labels) #Check that the labels make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2): Patch in definition of loss function, and also `after_epoch` (where we train linear classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using BT\n",
    "# @patch\n",
    "# def lf(self:BarlowTwins, pred,*yb): return lf_bt(pred, self.I,self.lmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lf_rat(pred,I,lmb):\n",
    "    \n",
    "    bs,nf = bs,nf = pred[0].size(0)//2,pred[0].size(1)\n",
    "    \n",
    "    pred1=pred[0]\n",
    "    pred2=pred[1]\n",
    "    \n",
    "    z1, z2 = pred1[:bs],pred1[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "\n",
    "    #Used to encode, primarily invariance\n",
    "    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "\n",
    "    #Used to encode, primarily redundancy-reduction\n",
    "    z1_two,z2_two = pred2[:bs],pred2[bs:]\n",
    "    z1norm_two = (z1_two - z1_two.mean(0)) / z1_two.std(0, unbiased=False)\n",
    "    z2norm_two = (z2_two - z2_two.mean(0)) / z2_two.std(0, unbiased=False)\n",
    "\n",
    "    #The invariance term\n",
    "    Invar = (z1norm-z2norm).pow(2) #add to loss (there are d-terms)\n",
    "\n",
    "    #The redundancy reduction term\n",
    "    CdiffRand = Cdiff_Rand(seed=0,std=0.1,K=2,indep=True)\n",
    "    cdiff = CdiffRand(z1norm_two,z2norm_two)\n",
    "    CdiffSup = Cdiff_Sup(I=I,qs=ps,inner_steps=5,indep=False)\n",
    "    cdiff_2 = CdiffSup(z1norm_two,z2norm_two)\n",
    "    redun_reduc = 0.5*cdiff + 0.5*cdiff_2 #add to loss\n",
    "\n",
    "    #Make the reps different term\n",
    "    CdiffRand = Cdiff_Rand(seed=0,std=0.1,K=2,indep=True)\n",
    "    cdiff1  = CdiffRand(z1norm,z1norm_two)\n",
    "    CdiffSup = Cdiff_Sup(I=I,qs=ps,inner_steps=5,indep=False)\n",
    "    cdiff11 = CdiffSup(z1norm,z1norm_two)\n",
    "    cdiff1 = 0.5*cdiff1 + 0.5*cdiff11\n",
    "\n",
    "            #d terms                   #d^2 + d^2 terms\n",
    "    loss = Invar.sum() + lmb*(0.5*redun_reduc + 0.5*cdiff).sum() #Have to work out scaling constants (grid search?)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb): return lf_rat(pred,I=self.I,lmb=self.lmb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch in `before_epoch` callback - perform linear evaluation every 200th epoch (say):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_pipelines_val=[get_linear_batch_augs(size=size,stats=cifar_stats,resize=True,resize_scale=(0.3, 1.0))]\n",
    "main_linear_eval = Main_Linear_Eval(size=size,n_in=n_in,numfit=1,indim=1024, #size,n_in=3 (color channels),number of epochs to fit linear, and output dimension of encoder\n",
    "                    dls_val=dls_val,dls_test=dls_test, #dls for training linear and evaluating linear\n",
    "                    stats=cifar_stats,\n",
    "                    aug_pipelines_val=aug_pipelines_val, #aug_pipeline for training \n",
    "                    encoder=None#encoder\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def after_epoch(self:BarlowTwins):\n",
    "\n",
    "    #Put in eval mode and turn gradients off\n",
    "    self.learn.eval()\n",
    "    grad_on(self.learn.model,on=False)\n",
    "    \n",
    "    #Test in eval mode\n",
    "    test_eq(self.learn.model.training,False)\n",
    "    #Test gradients off\n",
    "    test_grad_off(self.learn.model)\n",
    "\n",
    "    ##\n",
    "    main_linear_eval.encoder = self.learn.model.encoder #Update the encoder \n",
    "    main_linear_eval.model = LinearModel(encoder=main_linear_eval.encoder,indim=indim) #update the model (frozen encoder + head)\n",
    "    acc = main_linear_eval() #train linear head on frozen encoder and get accuracy on test set\n",
    "    self.acc_dict[self.epoch]=acc #update the acc_dict\n",
    "    ##\n",
    "    \n",
    "    #Put in train mode and turn gradients back on\n",
    "    self.learn.train()\n",
    "    grad_on(self.learn.model,on=True)\n",
    "\n",
    "    #Test training mode on\n",
    "    test_eq(self.learn.model.training,True)\n",
    "    #Test gradients on\n",
    "    test_grad_on(self.learn.model)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3): Define encoder and model; Define augmentation pipelines; Define learner.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai_encoder = create_fastai_encoder(xresnet18(),pretrained=False,n_in=n_in)\n",
    "\n",
    "#If we are using a different model, this call will just look like `create_rat_model(...)`\n",
    "model = create_p2barlow_twins_model(fastai_encoder, hidden_size=ps,projection_size=ps,nlayers=3)\n",
    "test(model.training,True,cmp=operator.eq,cname='model not in training mode')\n",
    "\n",
    "aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                 bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                 resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,\n",
    "                                                 bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.5,sol_p=0.0,\n",
    "                                                 stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                 )\n",
    "\n",
    "aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                                                 bw=True, rotate=True,noise=True, jitter=True, blur=True,solar=True,\n",
    "                                                 resize_scale=(0.4, 1.0),rotate_deg=45,noise_std=0.0125, jitter_s=1.0, blur_s=math.ceil(size/10)+1,sol_t=0.01,sol_a=0.01,\n",
    "                                                 bw_p=0.2, flip_p=0.5,rotate_p=0.25,noise_p=0.5, jitter_p=0.5, blur_p=0.1,sol_p=0.2,\n",
    "                                                 stats=cifar_stats,same_on_batch=False, xtra_tfms=[]\n",
    "                                                 )\n",
    "\n",
    "aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "#If we are using a different `callback` to `BarlowTwins` then we can simply replace `BarlowTwins` with \n",
    "#e.g. `BarlowTriplets`. We can define in base_model and just import with no issues. \n",
    "learn = Learner(dls,model, cbs=[BarlowTwins(aug_pipelines,n_in=n_in,lmb=1/ps,print_augs=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3): (Optional): View the augmentations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bt_batch(dls=dls,n_in=n_in,aug=aug_pipelines,n=20,print_augs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4): Fit the learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.fit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5): Setup for linear evaluation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_pipelines_val=[get_linear_batch_augs(size=size,stats=cifar_stats,resize_scale=(0.3, 1.0))]\n",
    "fastai_encoder.eval()\n",
    "grad_on(fastai_encoder,on=False)\n",
    "main_linear_eval = Main_Linear_Eval(size=size,n_in=n_in,numfit=1,indim=1024, #size,n_in=3 (color channels),number of epochs to fit linear, and output dimension of encoder\n",
    "                        dls_val=dls_val,dls_test=dls_test, #dls for training linear and evaluating linear\n",
    "                        stats=cifar_stats,\n",
    "                        aug_pipelines_val=aug_pipelines_val, #aug_pipeline for training \n",
    "                        encoder=fastai_encoder #encoder\n",
    "                                   )\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6): (optional): View validation augs (generally just cropping and normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_linear_batch(dls=dls_val,n_in=n_in,n=2,aug=aug_pipelines_val,print_augs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7): (optional): View validation augs (generally just cropping and normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=main_linear_eval()\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
