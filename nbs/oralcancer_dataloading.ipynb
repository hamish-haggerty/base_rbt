{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oral_dataloading\n",
    "\n",
    "> How to load isic datasets for supervised learning, and SSL\n",
    "\n",
    "Important: Note that have to download the data first from \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp oralcancer_dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "# from self_supervised.augmentations import *\n",
    "# from self_supervised.layers import *\n",
    "from base_rbt.utils import *\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# def list_files_in_directory(directory):\n",
    "#     # This function will list all files in the given directory and return them as a set\n",
    "#     return set(os.listdir(directory))\n",
    "\n",
    "# def check_for_overlap(train_dir, test_dir):\n",
    "#     # List all files in training and testing directories\n",
    "#     train_files = list_files_in_directory(train_dir)\n",
    "#     test_files = list_files_in_directory(test_dir)\n",
    "\n",
    "#     # Check for overlap\n",
    "#     overlap = train_files & test_files  # This will be the intersection of both sets\n",
    "#     if overlap:\n",
    "#         print(f\"Overlap detected: {overlap}\")\n",
    "#     else:\n",
    "#         print(\"No overlap between training and testing datasets.\")\n",
    "\n",
    "# # Define directories with corrected folder names and handling spaces\n",
    "# base_dir = '/content/Oral_Cancer_Data'\n",
    "# train_cancer_dir = os.path.join(base_dir, 'train', 'train', 'CANCER')\n",
    "# train_non_cancer_dir = os.path.join(base_dir, 'train', 'train', 'NON CANCER')  # Handling space in directory name\n",
    "# test_cancer_dir = os.path.join(base_dir, 'test', 'test', 'CANCER')\n",
    "# test_non_cancer_dir = os.path.join(base_dir, 'test', 'test', 'NON CANCER')  # Handling space in directory name\n",
    "\n",
    "# # Check for overlap in CANCER category\n",
    "# check_for_overlap(train_cancer_dir, test_cancer_dir)\n",
    "\n",
    "# # Check for overlap in NON CANCER category\n",
    "# check_for_overlap(train_non_cancer_dir, test_non_cancer_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main dataloader functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def label_func(x):\n",
    "    # Function to extract the label from the parent directory name\n",
    "    return x.parent.name\n",
    "\n",
    "def get_supervised_oralcancer_train_dls(bs, \n",
    "                                        dataset_dir, \n",
    "                                        size=256, \n",
    "                                        device='cpu', \n",
    "                                        pct_dataset=1.0, \n",
    "                                        num_workers=12):\n",
    "    train_dir = os.path.join(dataset_dir, \"train\", \"train\")  # Adjust for the additional directory layer\n",
    "    \n",
    "    # Get image files from the training directory\n",
    "    fnames = get_image_files(train_dir)\n",
    "\n",
    "    # Apply subset size\n",
    "    n = int(len(fnames) * pct_dataset)\n",
    "    fnames = fnames[:n]\n",
    "\n",
    "    # Data transformations\n",
    "    item_tfms = [Resize(size)]\n",
    "\n",
    "    # Create the DataLoader\n",
    "    dls = ImageDataLoaders.from_path_func(\n",
    "        path=train_dir,\n",
    "        fnames=fnames,\n",
    "        label_func=label_func,\n",
    "        bs=bs,\n",
    "        item_tfms=item_tfms,\n",
    "        valid_pct=0.0,  # No validation split, using all for training\n",
    "        device=device,\n",
    "        num_workers=num_workers * (device == 'cuda')\n",
    "    )\n",
    "\n",
    "    return dls\n",
    "\n",
    "def get_supervised_oralcancer_test_dls(bs, \n",
    "                                       dataset_dir, \n",
    "                                       size=256, \n",
    "                                       device='cpu', \n",
    "                                       pct_dataset=1.0, \n",
    "                                       num_workers=12):\n",
    "    test_dir = os.path.join(dataset_dir, \"test\", \"test\")  # Adjust for the additional directory layer\n",
    "    \n",
    "    # Get image files from the testing directory\n",
    "    fnames = get_image_files(test_dir)\n",
    "\n",
    "    # Apply subset size\n",
    "    n = int(len(fnames) * pct_dataset)\n",
    "    fnames = fnames[:n]\n",
    "\n",
    "    # Data transformations\n",
    "    item_tfms = [Resize(size)]\n",
    "\n",
    "    # Create the DataLoader\n",
    "    dls = ImageDataLoaders.from_path_func(\n",
    "        path=test_dir,\n",
    "        fnames=fnames,\n",
    "        label_func=label_func,\n",
    "        bs=bs,\n",
    "        item_tfms=item_tfms,\n",
    "        valid_pct=0,  # No validation split for the test set\n",
    "        device=device,\n",
    "        drop_last=False,\n",
    "        num_workers=num_workers * (device == 'cuda')\n",
    "    )\n",
    "\n",
    "    return dls\n",
    "\n",
    "\n",
    "def get_bt_oralcancer_train_dls(bs,size,device,pct_dataset=1.0,num_workers=12):\n",
    "    #NOTE: assume unzip like: !unzip -q -o \"/content/drive/My Drive/dermnet.zip\" -d \"/content/drive/My Drive/DermNetDataset\"\n",
    "\n",
    "    dataset_dir = \"/content/Oral_Cancer_Data\"  #hardcode for SSL.\n",
    "\n",
    "    return get_supervised_oralcancer_train_dls(bs, \n",
    "                                        dataset_dir, \n",
    "                                        size=size, \n",
    "                                        device=device, \n",
    "                                        pct_dataset=pct_dataset, \n",
    "                                        num_workers=num_workers)\n",
    "\n",
    "    \n",
    "\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
